#
# Copyright (C) 2018-2019 de4dot@gmail.com
#
# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the
# "Software"), to deal in the Software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of the Software, and to
# permit persons to whom the Software is furnished to do so, subject to
# the following conditions:
#
# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
# CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
#

INVALID, legacy, , legacy, 00, <invalid>, <invalid>, notinstr 16b 32b 64b
DeclareByte, legacy, , legacy, 00, <db>, <db>, notinstr 16b 32b 64b
DeclareWord, legacy, , legacy, 00, <dw>, <dw>, notinstr 16b 32b 64b
DeclareDword, legacy, , legacy, 00, <dd>, <dd>, notinstr 16b 32b 64b
DeclareQword, legacy, , legacy, 00, <dq>, <dq>, notinstr 16b 32b 64b
Add_rm8_r8, legacy, , legacy, 00, 00 /r, ADD r/m8| r8, 16b 32b 64b op=r8_or_mem;r8_reg lock xacquire xrelease
Add_rm16_r16, legacy, , legacy, 01, o16 01 /r, ADD r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg lock xacquire xrelease
Add_rm32_r32, legacy, , legacy, 01, o32 01 /r, ADD r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg lock xacquire xrelease
Add_rm64_r64, legacy, , legacy, 01, REX.W 01 /r, ADD r/m64| r64, 64b o64 op=r64_or_mem;r64_reg lock xacquire xrelease
Add_r8_rm8, legacy, , legacy, 02, 02 /r, ADD r8| r/m8, 16b 32b 64b op=r8_reg;r8_or_mem
Add_r16_rm16, legacy, , legacy, 03, o16 03 /r, ADD r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Add_r32_rm32, legacy, , legacy, 03, o32 03 /r, ADD r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Add_r64_rm64, legacy, , legacy, 03, REX.W 03 /r, ADD r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Add_AL_imm8, legacy, , legacy, 04, 04 ib, ADD AL| imm8, 16b 32b 64b op=al;imm8
Add_AX_imm16, legacy, , legacy, 05, o16 05 iw, ADD AX| imm16, 16b 32b 64b o16 op=ax;imm16
Add_EAX_imm32, legacy, , legacy, 05, o32 05 id, ADD EAX| imm32, 16b 32b 64b o32 op=eax;imm32
Add_RAX_imm32, legacy, , legacy, 05, REX.W 05 id, ADD RAX| imm32, 64b o64 op=rax;imm32sex64
Pushw_ES, legacy, , legacy, 06, o16 06, PUSH ES, 16b 32b o16 op=es
Pushd_ES, legacy, , legacy, 06, o32 06, PUSH ES, 16b 32b o32 op=es
Popw_ES, legacy, , legacy, 07, o16 07, POP ES, 16b 32b o16 op=es
Popd_ES, legacy, , legacy, 07, o32 07, POP ES, 16b 32b o32 op=es
Or_rm8_r8, legacy, , legacy, 08, 08 /r, OR r/m8| r8, 16b 32b 64b op=r8_or_mem;r8_reg lock xacquire xrelease
Or_rm16_r16, legacy, , legacy, 09, o16 09 /r, OR r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg lock xacquire xrelease
Or_rm32_r32, legacy, , legacy, 09, o32 09 /r, OR r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg lock xacquire xrelease
Or_rm64_r64, legacy, , legacy, 09, REX.W 09 /r, OR r/m64| r64, 64b o64 op=r64_or_mem;r64_reg lock xacquire xrelease
Or_r8_rm8, legacy, , legacy, 0A, 0A /r, OR r8| r/m8, 16b 32b 64b op=r8_reg;r8_or_mem
Or_r16_rm16, legacy, , legacy, 0B, o16 0B /r, OR r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Or_r32_rm32, legacy, , legacy, 0B, o32 0B /r, OR r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Or_r64_rm64, legacy, , legacy, 0B, REX.W 0B /r, OR r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Or_AL_imm8, legacy, , legacy, 0C, 0C ib, OR AL| imm8, 16b 32b 64b op=al;imm8
Or_AX_imm16, legacy, , legacy, 0D, o16 0D iw, OR AX| imm16, 16b 32b 64b o16 op=ax;imm16
Or_EAX_imm32, legacy, , legacy, 0D, o32 0D id, OR EAX| imm32, 16b 32b 64b o32 op=eax;imm32
Or_RAX_imm32, legacy, , legacy, 0D, REX.W 0D id, OR RAX| imm32, 64b o64 op=rax;imm32sex64
Pushw_CS, legacy, , legacy, 0E, o16 0E, PUSH CS, 16b 32b o16 op=cs
Pushd_CS, legacy, , legacy, 0E, o32 0E, PUSH CS, 16b 32b o32 op=cs
Popw_CS, legacy, , legacy, 0F, o16 0F, POP CS, 16b 32b o16 op=cs
Adc_rm8_r8, legacy, , legacy, 10, 10 /r, ADC r/m8| r8, 16b 32b 64b op=r8_or_mem;r8_reg lock xacquire xrelease
Adc_rm16_r16, legacy, , legacy, 11, o16 11 /r, ADC r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg lock xacquire xrelease
Adc_rm32_r32, legacy, , legacy, 11, o32 11 /r, ADC r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg lock xacquire xrelease
Adc_rm64_r64, legacy, , legacy, 11, REX.W 11 /r, ADC r/m64| r64, 64b o64 op=r64_or_mem;r64_reg lock xacquire xrelease
Adc_r8_rm8, legacy, , legacy, 12, 12 /r, ADC r8| r/m8, 16b 32b 64b op=r8_reg;r8_or_mem
Adc_r16_rm16, legacy, , legacy, 13, o16 13 /r, ADC r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Adc_r32_rm32, legacy, , legacy, 13, o32 13 /r, ADC r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Adc_r64_rm64, legacy, , legacy, 13, REX.W 13 /r, ADC r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Adc_AL_imm8, legacy, , legacy, 14, 14 ib, ADC AL| imm8, 16b 32b 64b op=al;imm8
Adc_AX_imm16, legacy, , legacy, 15, o16 15 iw, ADC AX| imm16, 16b 32b 64b o16 op=ax;imm16
Adc_EAX_imm32, legacy, , legacy, 15, o32 15 id, ADC EAX| imm32, 16b 32b 64b o32 op=eax;imm32
Adc_RAX_imm32, legacy, , legacy, 15, REX.W 15 id, ADC RAX| imm32, 64b o64 op=rax;imm32sex64
Pushw_SS, legacy, , legacy, 16, o16 16, PUSH SS, 16b 32b o16 op=ss
Pushd_SS, legacy, , legacy, 16, o32 16, PUSH SS, 16b 32b o32 op=ss
Popw_SS, legacy, , legacy, 17, o16 17, POP SS, 16b 32b o16 op=ss
Popd_SS, legacy, , legacy, 17, o32 17, POP SS, 16b 32b o32 op=ss
Sbb_rm8_r8, legacy, , legacy, 18, 18 /r, SBB r/m8| r8, 16b 32b 64b op=r8_or_mem;r8_reg lock xacquire xrelease
Sbb_rm16_r16, legacy, , legacy, 19, o16 19 /r, SBB r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg lock xacquire xrelease
Sbb_rm32_r32, legacy, , legacy, 19, o32 19 /r, SBB r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg lock xacquire xrelease
Sbb_rm64_r64, legacy, , legacy, 19, REX.W 19 /r, SBB r/m64| r64, 64b o64 op=r64_or_mem;r64_reg lock xacquire xrelease
Sbb_r8_rm8, legacy, , legacy, 1A, 1A /r, SBB r8| r/m8, 16b 32b 64b op=r8_reg;r8_or_mem
Sbb_r16_rm16, legacy, , legacy, 1B, o16 1B /r, SBB r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Sbb_r32_rm32, legacy, , legacy, 1B, o32 1B /r, SBB r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Sbb_r64_rm64, legacy, , legacy, 1B, REX.W 1B /r, SBB r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Sbb_AL_imm8, legacy, , legacy, 1C, 1C ib, SBB AL| imm8, 16b 32b 64b op=al;imm8
Sbb_AX_imm16, legacy, , legacy, 1D, o16 1D iw, SBB AX| imm16, 16b 32b 64b o16 op=ax;imm16
Sbb_EAX_imm32, legacy, , legacy, 1D, o32 1D id, SBB EAX| imm32, 16b 32b 64b o32 op=eax;imm32
Sbb_RAX_imm32, legacy, , legacy, 1D, REX.W 1D id, SBB RAX| imm32, 64b o64 op=rax;imm32sex64
Pushw_DS, legacy, , legacy, 1E, o16 1E, PUSH DS, 16b 32b o16 op=ds
Pushd_DS, legacy, , legacy, 1E, o32 1E, PUSH DS, 16b 32b o32 op=ds
Popw_DS, legacy, , legacy, 1F, o16 1F, POP DS, 16b 32b o16 op=ds
Popd_DS, legacy, , legacy, 1F, o32 1F, POP DS, 16b 32b o32 op=ds
And_rm8_r8, legacy, , legacy, 20, 20 /r, AND r/m8| r8, 16b 32b 64b op=r8_or_mem;r8_reg lock xacquire xrelease
And_rm16_r16, legacy, , legacy, 21, o16 21 /r, AND r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg lock xacquire xrelease
And_rm32_r32, legacy, , legacy, 21, o32 21 /r, AND r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg lock xacquire xrelease
And_rm64_r64, legacy, , legacy, 21, REX.W 21 /r, AND r/m64| r64, 64b o64 op=r64_or_mem;r64_reg lock xacquire xrelease
And_r8_rm8, legacy, , legacy, 22, 22 /r, AND r8| r/m8, 16b 32b 64b op=r8_reg;r8_or_mem
And_r16_rm16, legacy, , legacy, 23, o16 23 /r, AND r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
And_r32_rm32, legacy, , legacy, 23, o32 23 /r, AND r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
And_r64_rm64, legacy, , legacy, 23, REX.W 23 /r, AND r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
And_AL_imm8, legacy, , legacy, 24, 24 ib, AND AL| imm8, 16b 32b 64b op=al;imm8
And_AX_imm16, legacy, , legacy, 25, o16 25 iw, AND AX| imm16, 16b 32b 64b o16 op=ax;imm16
And_EAX_imm32, legacy, , legacy, 25, o32 25 id, AND EAX| imm32, 16b 32b 64b o32 op=eax;imm32
And_RAX_imm32, legacy, , legacy, 25, REX.W 25 id, AND RAX| imm32, 64b o64 op=rax;imm32sex64
Daa, legacy, , legacy, 27, 27, DAA, 16b 32b
Sub_rm8_r8, legacy, , legacy, 28, 28 /r, SUB r/m8| r8, 16b 32b 64b op=r8_or_mem;r8_reg lock xacquire xrelease
Sub_rm16_r16, legacy, , legacy, 29, o16 29 /r, SUB r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg lock xacquire xrelease
Sub_rm32_r32, legacy, , legacy, 29, o32 29 /r, SUB r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg lock xacquire xrelease
Sub_rm64_r64, legacy, , legacy, 29, REX.W 29 /r, SUB r/m64| r64, 64b o64 op=r64_or_mem;r64_reg lock xacquire xrelease
Sub_r8_rm8, legacy, , legacy, 2A, 2A /r, SUB r8| r/m8, 16b 32b 64b op=r8_reg;r8_or_mem
Sub_r16_rm16, legacy, , legacy, 2B, o16 2B /r, SUB r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Sub_r32_rm32, legacy, , legacy, 2B, o32 2B /r, SUB r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Sub_r64_rm64, legacy, , legacy, 2B, REX.W 2B /r, SUB r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Sub_AL_imm8, legacy, , legacy, 2C, 2C ib, SUB AL| imm8, 16b 32b 64b op=al;imm8
Sub_AX_imm16, legacy, , legacy, 2D, o16 2D iw, SUB AX| imm16, 16b 32b 64b o16 op=ax;imm16
Sub_EAX_imm32, legacy, , legacy, 2D, o32 2D id, SUB EAX| imm32, 16b 32b 64b o32 op=eax;imm32
Sub_RAX_imm32, legacy, , legacy, 2D, REX.W 2D id, SUB RAX| imm32, 64b o64 op=rax;imm32sex64
Das, legacy, , legacy, 2F, 2F, DAS, 16b 32b
Xor_rm8_r8, legacy, , legacy, 30, 30 /r, XOR r/m8| r8, 16b 32b 64b op=r8_or_mem;r8_reg lock xacquire xrelease
Xor_rm16_r16, legacy, , legacy, 31, o16 31 /r, XOR r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg lock xacquire xrelease
Xor_rm32_r32, legacy, , legacy, 31, o32 31 /r, XOR r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg lock xacquire xrelease
Xor_rm64_r64, legacy, , legacy, 31, REX.W 31 /r, XOR r/m64| r64, 64b o64 op=r64_or_mem;r64_reg lock xacquire xrelease
Xor_r8_rm8, legacy, , legacy, 32, 32 /r, XOR r8| r/m8, 16b 32b 64b op=r8_reg;r8_or_mem
Xor_r16_rm16, legacy, , legacy, 33, o16 33 /r, XOR r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Xor_r32_rm32, legacy, , legacy, 33, o32 33 /r, XOR r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Xor_r64_rm64, legacy, , legacy, 33, REX.W 33 /r, XOR r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Xor_AL_imm8, legacy, , legacy, 34, 34 ib, XOR AL| imm8, 16b 32b 64b op=al;imm8
Xor_AX_imm16, legacy, , legacy, 35, o16 35 iw, XOR AX| imm16, 16b 32b 64b o16 op=ax;imm16
Xor_EAX_imm32, legacy, , legacy, 35, o32 35 id, XOR EAX| imm32, 16b 32b 64b o32 op=eax;imm32
Xor_RAX_imm32, legacy, , legacy, 35, REX.W 35 id, XOR RAX| imm32, 64b o64 op=rax;imm32sex64
Aaa, legacy, , legacy, 37, 37, AAA, 16b 32b
Cmp_rm8_r8, legacy, , legacy, 38, 38 /r, CMP r/m8| r8, 16b 32b 64b op=r8_or_mem;r8_reg
Cmp_rm16_r16, legacy, , legacy, 39, o16 39 /r, CMP r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg
Cmp_rm32_r32, legacy, , legacy, 39, o32 39 /r, CMP r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg
Cmp_rm64_r64, legacy, , legacy, 39, REX.W 39 /r, CMP r/m64| r64, 64b o64 op=r64_or_mem;r64_reg
Cmp_r8_rm8, legacy, , legacy, 3A, 3A /r, CMP r8| r/m8, 16b 32b 64b op=r8_reg;r8_or_mem
Cmp_r16_rm16, legacy, , legacy, 3B, o16 3B /r, CMP r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Cmp_r32_rm32, legacy, , legacy, 3B, o32 3B /r, CMP r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Cmp_r64_rm64, legacy, , legacy, 3B, REX.W 3B /r, CMP r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Cmp_AL_imm8, legacy, , legacy, 3C, 3C ib, CMP AL| imm8, 16b 32b 64b op=al;imm8
Cmp_AX_imm16, legacy, , legacy, 3D, o16 3D iw, CMP AX| imm16, 16b 32b 64b o16 op=ax;imm16
Cmp_EAX_imm32, legacy, , legacy, 3D, o32 3D id, CMP EAX| imm32, 16b 32b 64b o32 op=eax;imm32
Cmp_RAX_imm32, legacy, , legacy, 3D, REX.W 3D id, CMP RAX| imm32, 64b o64 op=rax;imm32sex64
Aas, legacy, , legacy, 3F, 3F, AAS, 16b 32b
Inc_r16, legacy, , legacy, 40, o16 40+rw, INC r16, 16b 32b o16 op=r16_opcode
Inc_r32, legacy, , legacy, 40, o32 40+rd, INC r32, 16b 32b o32 op=r32_opcode
Dec_r16, legacy, , legacy, 48, o16 48+rw, DEC r16, 16b 32b o16 op=r16_opcode
Dec_r32, legacy, , legacy, 48, o32 48+rd, DEC r32, 16b 32b o32 op=r32_opcode
Push_r16, legacy, , legacy, 50, o16 50+rw, PUSH r16, 16b 32b 64b o16 op=r16_opcode
Push_r32, legacy, , legacy, 50, o32 50+rd, PUSH r32, 16b 32b o32 op=r32_opcode
Push_r64, legacy, , legacy, 50, 50+ro, PUSH r64, 64b op=r64_opcode
Pop_r16, legacy, , legacy, 58, o16 58+rw, POP r16, 16b 32b 64b o16 op=r16_opcode
Pop_r32, legacy, , legacy, 58, o32 58+rd, POP r32, 16b 32b o32 op=r32_opcode
Pop_r64, legacy, , legacy, 58, 58+ro, POP r64, 64b op=r64_opcode
Pushaw, legacy, , legacy, 60, o16 60, PUSHA, 16b 32b o16
Pushad, legacy, , legacy, 60, o32 60, PUSHAD, 16b 32b o32
Popaw, legacy, , legacy, 61, o16 61, POPA, 16b 32b o16
Popad, legacy, , legacy, 61, o32 61, POPAD, 16b 32b o32
Bound_r16_m1616, legacy, , legacy, 62, o16 62 /r, BOUND r16| m16&16, 16b 32b o16 op=r16_reg;mem
Bound_r32_m3232, legacy, , legacy, 62, o32 62 /r, BOUND r32| m32&32, 16b 32b o32 op=r32_reg;mem
Arpl_rm16_r16, legacy, , legacy, 63, o16 63 /r, ARPL r/m16| r16, 16b 32b o16 op=r16_or_mem;r16_reg
Arpl_r32m16_r32, legacy, , legacy, 63, o32 63 /r, ARPL r32/m16| r32, 16b 32b o32 op=r32_or_mem;r32_reg
Movsxd_r16_rm16, legacy, , legacy, 63, o16 63 /r, MOVSXD r16| r/m16, 64b o16 op=r16_reg;r16_or_mem
Movsxd_r32_rm32, legacy, , legacy, 63, o32 63 /r, MOVSXD r32| r/m32, 64b o32 op=r32_reg;r32_or_mem
Movsxd_r64_rm32, legacy, , legacy, 63, REX.W 63 /r, MOVSXD r64| r/m32, 64b o64 op=r64_reg;r32_or_mem
Push_imm16, legacy, , legacy, 68, o16 68 iw, PUSH imm16, 16b 32b 64b o16 op=imm16
Pushd_imm32, legacy, , legacy, 68, o32 68 id, PUSH imm32, 16b 32b o32 op=imm32
Pushq_imm32, legacy, , legacy, 68, 68 id, PUSH imm32, 64b op=imm32sex64
Imul_r16_rm16_imm16, legacy, , legacy, 69, o16 69 /r iw, IMUL r16| r/m16| imm16, 16b 32b 64b o16 op=r16_reg;r16_or_mem;imm16
Imul_r32_rm32_imm32, legacy, , legacy, 69, o32 69 /r id, IMUL r32| r/m32| imm32, 16b 32b 64b o32 op=r32_reg;r32_or_mem;imm32
Imul_r64_rm64_imm32, legacy, , legacy, 69, REX.W 69 /r id, IMUL r64| r/m64| imm32, 64b o64 op=r64_reg;r64_or_mem;imm32sex64
Pushw_imm8, legacy, , legacy, 6A, o16 6A ib, PUSH imm8, 16b 32b 64b o16 op=imm8sex16
Pushd_imm8, legacy, , legacy, 6A, o32 6A ib, PUSH imm8, 16b 32b o32 op=imm8sex32
Pushq_imm8, legacy, , legacy, 6A, 6A ib, PUSH imm8, 64b op=imm8sex64
Imul_r16_rm16_imm8, legacy, , legacy, 6B, o16 6B /r ib, IMUL r16| r/m16| imm8, 16b 32b 64b o16 op=r16_reg;r16_or_mem;imm8sex16
Imul_r32_rm32_imm8, legacy, , legacy, 6B, o32 6B /r ib, IMUL r32| r/m32| imm8, 16b 32b 64b o32 op=r32_reg;r32_or_mem;imm8sex32
Imul_r64_rm64_imm8, legacy, , legacy, 6B, REX.W 6B /r ib, IMUL r64| r/m64| imm8, 64b o64 op=r64_reg;r64_or_mem;imm8sex64
Insb_m8_DX, legacy, , legacy, 6C, 6C, INSB, 16b 32b 64b op=es_rDI;dx rep
Insw_m16_DX, legacy, , legacy, 6D, o16 6D, INSW, 16b 32b 64b o16 op=es_rDI;dx rep
Insd_m32_DX, legacy, , legacy, 6D, o32 6D, INSD, 16b 32b 64b o32 op=es_rDI;dx rep
Outsb_DX_m8, legacy, , legacy, 6E, 6E, OUTSB, 16b 32b 64b op=dx;seg_rSI rep
Outsw_DX_m16, legacy, , legacy, 6F, o16 6F, OUTSW, 16b 32b 64b o16 op=dx;seg_rSI rep
Outsd_DX_m32, legacy, , legacy, 6F, o32 6F, OUTSD, 16b 32b 64b o32 op=dx;seg_rSI rep
Jo_rel8_16, legacy, , legacy, 70, o16 70 cb, JO rel8, 16b 32b 64b o16 op=br16_1 bnd ht
Jo_rel8_32, legacy, , legacy, 70, o32 70 cb, JO rel8, 16b 32b o32 op=br32_1 bnd ht
Jo_rel8_64, legacy, , legacy, 70, 70 cb, JO rel8, 64b op=br64_1 bnd ht
Jno_rel8_16, legacy, , legacy, 71, o16 71 cb, JNO rel8, 16b 32b 64b o16 op=br16_1 bnd ht
Jno_rel8_32, legacy, , legacy, 71, o32 71 cb, JNO rel8, 16b 32b o32 op=br32_1 bnd ht
Jno_rel8_64, legacy, , legacy, 71, 71 cb, JNO rel8, 64b op=br64_1 bnd ht
Jb_rel8_16, legacy, , legacy, 72, o16 72 cb, JB rel8, 16b 32b 64b o16 op=br16_1 bnd ht
Jb_rel8_32, legacy, , legacy, 72, o32 72 cb, JB rel8, 16b 32b o32 op=br32_1 bnd ht
Jb_rel8_64, legacy, , legacy, 72, 72 cb, JB rel8, 64b op=br64_1 bnd ht
Jae_rel8_16, legacy, , legacy, 73, o16 73 cb, JAE rel8, 16b 32b 64b o16 op=br16_1 bnd ht
Jae_rel8_32, legacy, , legacy, 73, o32 73 cb, JAE rel8, 16b 32b o32 op=br32_1 bnd ht
Jae_rel8_64, legacy, , legacy, 73, 73 cb, JAE rel8, 64b op=br64_1 bnd ht
Je_rel8_16, legacy, , legacy, 74, o16 74 cb, JE rel8, 16b 32b 64b o16 op=br16_1 bnd ht
Je_rel8_32, legacy, , legacy, 74, o32 74 cb, JE rel8, 16b 32b o32 op=br32_1 bnd ht
Je_rel8_64, legacy, , legacy, 74, 74 cb, JE rel8, 64b op=br64_1 bnd ht
Jne_rel8_16, legacy, , legacy, 75, o16 75 cb, JNE rel8, 16b 32b 64b o16 op=br16_1 bnd ht
Jne_rel8_32, legacy, , legacy, 75, o32 75 cb, JNE rel8, 16b 32b o32 op=br32_1 bnd ht
Jne_rel8_64, legacy, , legacy, 75, 75 cb, JNE rel8, 64b op=br64_1 bnd ht
Jbe_rel8_16, legacy, , legacy, 76, o16 76 cb, JBE rel8, 16b 32b 64b o16 op=br16_1 bnd ht
Jbe_rel8_32, legacy, , legacy, 76, o32 76 cb, JBE rel8, 16b 32b o32 op=br32_1 bnd ht
Jbe_rel8_64, legacy, , legacy, 76, 76 cb, JBE rel8, 64b op=br64_1 bnd ht
Ja_rel8_16, legacy, , legacy, 77, o16 77 cb, JA rel8, 16b 32b 64b o16 op=br16_1 bnd ht
Ja_rel8_32, legacy, , legacy, 77, o32 77 cb, JA rel8, 16b 32b o32 op=br32_1 bnd ht
Ja_rel8_64, legacy, , legacy, 77, 77 cb, JA rel8, 64b op=br64_1 bnd ht
Js_rel8_16, legacy, , legacy, 78, o16 78 cb, JS rel8, 16b 32b 64b o16 op=br16_1 bnd ht
Js_rel8_32, legacy, , legacy, 78, o32 78 cb, JS rel8, 16b 32b o32 op=br32_1 bnd ht
Js_rel8_64, legacy, , legacy, 78, 78 cb, JS rel8, 64b op=br64_1 bnd ht
Jns_rel8_16, legacy, , legacy, 79, o16 79 cb, JNS rel8, 16b 32b 64b o16 op=br16_1 bnd ht
Jns_rel8_32, legacy, , legacy, 79, o32 79 cb, JNS rel8, 16b 32b o32 op=br32_1 bnd ht
Jns_rel8_64, legacy, , legacy, 79, 79 cb, JNS rel8, 64b op=br64_1 bnd ht
Jp_rel8_16, legacy, , legacy, 7A, o16 7A cb, JP rel8, 16b 32b 64b o16 op=br16_1 bnd ht
Jp_rel8_32, legacy, , legacy, 7A, o32 7A cb, JP rel8, 16b 32b o32 op=br32_1 bnd ht
Jp_rel8_64, legacy, , legacy, 7A, 7A cb, JP rel8, 64b op=br64_1 bnd ht
Jnp_rel8_16, legacy, , legacy, 7B, o16 7B cb, JNP rel8, 16b 32b 64b o16 op=br16_1 bnd ht
Jnp_rel8_32, legacy, , legacy, 7B, o32 7B cb, JNP rel8, 16b 32b o32 op=br32_1 bnd ht
Jnp_rel8_64, legacy, , legacy, 7B, 7B cb, JNP rel8, 64b op=br64_1 bnd ht
Jl_rel8_16, legacy, , legacy, 7C, o16 7C cb, JL rel8, 16b 32b 64b o16 op=br16_1 bnd ht
Jl_rel8_32, legacy, , legacy, 7C, o32 7C cb, JL rel8, 16b 32b o32 op=br32_1 bnd ht
Jl_rel8_64, legacy, , legacy, 7C, 7C cb, JL rel8, 64b op=br64_1 bnd ht
Jge_rel8_16, legacy, , legacy, 7D, o16 7D cb, JGE rel8, 16b 32b 64b o16 op=br16_1 bnd ht
Jge_rel8_32, legacy, , legacy, 7D, o32 7D cb, JGE rel8, 16b 32b o32 op=br32_1 bnd ht
Jge_rel8_64, legacy, , legacy, 7D, 7D cb, JGE rel8, 64b op=br64_1 bnd ht
Jle_rel8_16, legacy, , legacy, 7E, o16 7E cb, JLE rel8, 16b 32b 64b o16 op=br16_1 bnd ht
Jle_rel8_32, legacy, , legacy, 7E, o32 7E cb, JLE rel8, 16b 32b o32 op=br32_1 bnd ht
Jle_rel8_64, legacy, , legacy, 7E, 7E cb, JLE rel8, 64b op=br64_1 bnd ht
Jg_rel8_16, legacy, , legacy, 7F, o16 7F cb, JG rel8, 16b 32b 64b o16 op=br16_1 bnd ht
Jg_rel8_32, legacy, , legacy, 7F, o32 7F cb, JG rel8, 16b 32b o32 op=br32_1 bnd ht
Jg_rel8_64, legacy, , legacy, 7F, 7F cb, JG rel8, 64b op=br64_1 bnd ht
Add_rm8_imm8, legacy, , legacy, 80, 80 /0 ib, ADD r/m8| imm8, g=0 16b 32b 64b op=r8_or_mem;imm8 lock xacquire xrelease
Or_rm8_imm8, legacy, , legacy, 80, 80 /1 ib, OR r/m8| imm8, g=1 16b 32b 64b op=r8_or_mem;imm8 lock xacquire xrelease
Adc_rm8_imm8, legacy, , legacy, 80, 80 /2 ib, ADC r/m8| imm8, g=2 16b 32b 64b op=r8_or_mem;imm8 lock xacquire xrelease
Sbb_rm8_imm8, legacy, , legacy, 80, 80 /3 ib, SBB r/m8| imm8, g=3 16b 32b 64b op=r8_or_mem;imm8 lock xacquire xrelease
And_rm8_imm8, legacy, , legacy, 80, 80 /4 ib, AND r/m8| imm8, g=4 16b 32b 64b op=r8_or_mem;imm8 lock xacquire xrelease
Sub_rm8_imm8, legacy, , legacy, 80, 80 /5 ib, SUB r/m8| imm8, g=5 16b 32b 64b op=r8_or_mem;imm8 lock xacquire xrelease
Xor_rm8_imm8, legacy, , legacy, 80, 80 /6 ib, XOR r/m8| imm8, g=6 16b 32b 64b op=r8_or_mem;imm8 lock xacquire xrelease
Cmp_rm8_imm8, legacy, , legacy, 80, 80 /7 ib, CMP r/m8| imm8, g=7 16b 32b 64b op=r8_or_mem;imm8
Add_rm16_imm16, legacy, , legacy, 81, o16 81 /0 iw, ADD r/m16| imm16, g=0 16b 32b 64b o16 op=r16_or_mem;imm16 lock xacquire xrelease
Add_rm32_imm32, legacy, , legacy, 81, o32 81 /0 id, ADD r/m32| imm32, g=0 16b 32b 64b o32 op=r32_or_mem;imm32 lock xacquire xrelease
Add_rm64_imm32, legacy, , legacy, 81, REX.W 81 /0 id, ADD r/m64| imm32, g=0 64b o64 op=r64_or_mem;imm32sex64 lock xacquire xrelease
Or_rm16_imm16, legacy, , legacy, 81, o16 81 /1 iw, OR r/m16| imm16, g=1 16b 32b 64b o16 op=r16_or_mem;imm16 lock xacquire xrelease
Or_rm32_imm32, legacy, , legacy, 81, o32 81 /1 id, OR r/m32| imm32, g=1 16b 32b 64b o32 op=r32_or_mem;imm32 lock xacquire xrelease
Or_rm64_imm32, legacy, , legacy, 81, REX.W 81 /1 id, OR r/m64| imm32, g=1 64b o64 op=r64_or_mem;imm32sex64 lock xacquire xrelease
Adc_rm16_imm16, legacy, , legacy, 81, o16 81 /2 iw, ADC r/m16| imm16, g=2 16b 32b 64b o16 op=r16_or_mem;imm16 lock xacquire xrelease
Adc_rm32_imm32, legacy, , legacy, 81, o32 81 /2 id, ADC r/m32| imm32, g=2 16b 32b 64b o32 op=r32_or_mem;imm32 lock xacquire xrelease
Adc_rm64_imm32, legacy, , legacy, 81, REX.W 81 /2 id, ADC r/m64| imm32, g=2 64b o64 op=r64_or_mem;imm32sex64 lock xacquire xrelease
Sbb_rm16_imm16, legacy, , legacy, 81, o16 81 /3 iw, SBB r/m16| imm16, g=3 16b 32b 64b o16 op=r16_or_mem;imm16 lock xacquire xrelease
Sbb_rm32_imm32, legacy, , legacy, 81, o32 81 /3 id, SBB r/m32| imm32, g=3 16b 32b 64b o32 op=r32_or_mem;imm32 lock xacquire xrelease
Sbb_rm64_imm32, legacy, , legacy, 81, REX.W 81 /3 id, SBB r/m64| imm32, g=3 64b o64 op=r64_or_mem;imm32sex64 lock xacquire xrelease
And_rm16_imm16, legacy, , legacy, 81, o16 81 /4 iw, AND r/m16| imm16, g=4 16b 32b 64b o16 op=r16_or_mem;imm16 lock xacquire xrelease
And_rm32_imm32, legacy, , legacy, 81, o32 81 /4 id, AND r/m32| imm32, g=4 16b 32b 64b o32 op=r32_or_mem;imm32 lock xacquire xrelease
And_rm64_imm32, legacy, , legacy, 81, REX.W 81 /4 id, AND r/m64| imm32, g=4 64b o64 op=r64_or_mem;imm32sex64 lock xacquire xrelease
Sub_rm16_imm16, legacy, , legacy, 81, o16 81 /5 iw, SUB r/m16| imm16, g=5 16b 32b 64b o16 op=r16_or_mem;imm16 lock xacquire xrelease
Sub_rm32_imm32, legacy, , legacy, 81, o32 81 /5 id, SUB r/m32| imm32, g=5 16b 32b 64b o32 op=r32_or_mem;imm32 lock xacquire xrelease
Sub_rm64_imm32, legacy, , legacy, 81, REX.W 81 /5 id, SUB r/m64| imm32, g=5 64b o64 op=r64_or_mem;imm32sex64 lock xacquire xrelease
Xor_rm16_imm16, legacy, , legacy, 81, o16 81 /6 iw, XOR r/m16| imm16, g=6 16b 32b 64b o16 op=r16_or_mem;imm16 lock xacquire xrelease
Xor_rm32_imm32, legacy, , legacy, 81, o32 81 /6 id, XOR r/m32| imm32, g=6 16b 32b 64b o32 op=r32_or_mem;imm32 lock xacquire xrelease
Xor_rm64_imm32, legacy, , legacy, 81, REX.W 81 /6 id, XOR r/m64| imm32, g=6 64b o64 op=r64_or_mem;imm32sex64 lock xacquire xrelease
Cmp_rm16_imm16, legacy, , legacy, 81, o16 81 /7 iw, CMP r/m16| imm16, g=7 16b 32b 64b o16 op=r16_or_mem;imm16
Cmp_rm32_imm32, legacy, , legacy, 81, o32 81 /7 id, CMP r/m32| imm32, g=7 16b 32b 64b o32 op=r32_or_mem;imm32
Cmp_rm64_imm32, legacy, , legacy, 81, REX.W 81 /7 id, CMP r/m64| imm32, g=7 64b o64 op=r64_or_mem;imm32sex64
Add_rm8_imm8_82, legacy, , legacy, 82, 82 /0 ib, ADD r/m8| imm8, g=0 16b 32b op=r8_or_mem;imm8 lock xacquire xrelease
Or_rm8_imm8_82, legacy, , legacy, 82, 82 /1 ib, OR r/m8| imm8, g=1 16b 32b op=r8_or_mem;imm8 lock xacquire xrelease
Adc_rm8_imm8_82, legacy, , legacy, 82, 82 /2 ib, ADC r/m8| imm8, g=2 16b 32b op=r8_or_mem;imm8 lock xacquire xrelease
Sbb_rm8_imm8_82, legacy, , legacy, 82, 82 /3 ib, SBB r/m8| imm8, g=3 16b 32b op=r8_or_mem;imm8 lock xacquire xrelease
And_rm8_imm8_82, legacy, , legacy, 82, 82 /4 ib, AND r/m8| imm8, g=4 16b 32b op=r8_or_mem;imm8 lock xacquire xrelease
Sub_rm8_imm8_82, legacy, , legacy, 82, 82 /5 ib, SUB r/m8| imm8, g=5 16b 32b op=r8_or_mem;imm8 lock xacquire xrelease
Xor_rm8_imm8_82, legacy, , legacy, 82, 82 /6 ib, XOR r/m8| imm8, g=6 16b 32b op=r8_or_mem;imm8 lock xacquire xrelease
Cmp_rm8_imm8_82, legacy, , legacy, 82, 82 /7 ib, CMP r/m8| imm8, g=7 16b 32b op=r8_or_mem;imm8
Add_rm16_imm8, legacy, , legacy, 83, o16 83 /0 ib, ADD r/m16| imm8, g=0 16b 32b 64b o16 op=r16_or_mem;imm8sex16 lock xacquire xrelease
Add_rm32_imm8, legacy, , legacy, 83, o32 83 /0 ib, ADD r/m32| imm8, g=0 16b 32b 64b o32 op=r32_or_mem;imm8sex32 lock xacquire xrelease
Add_rm64_imm8, legacy, , legacy, 83, REX.W 83 /0 ib, ADD r/m64| imm8, g=0 64b o64 op=r64_or_mem;imm8sex64 lock xacquire xrelease
Or_rm16_imm8, legacy, , legacy, 83, o16 83 /1 ib, OR r/m16| imm8, g=1 16b 32b 64b o16 op=r16_or_mem;imm8sex16 lock xacquire xrelease
Or_rm32_imm8, legacy, , legacy, 83, o32 83 /1 ib, OR r/m32| imm8, g=1 16b 32b 64b o32 op=r32_or_mem;imm8sex32 lock xacquire xrelease
Or_rm64_imm8, legacy, , legacy, 83, REX.W 83 /1 ib, OR r/m64| imm8, g=1 64b o64 op=r64_or_mem;imm8sex64 lock xacquire xrelease
Adc_rm16_imm8, legacy, , legacy, 83, o16 83 /2 ib, ADC r/m16| imm8, g=2 16b 32b 64b o16 op=r16_or_mem;imm8sex16 lock xacquire xrelease
Adc_rm32_imm8, legacy, , legacy, 83, o32 83 /2 ib, ADC r/m32| imm8, g=2 16b 32b 64b o32 op=r32_or_mem;imm8sex32 lock xacquire xrelease
Adc_rm64_imm8, legacy, , legacy, 83, REX.W 83 /2 ib, ADC r/m64| imm8, g=2 64b o64 op=r64_or_mem;imm8sex64 lock xacquire xrelease
Sbb_rm16_imm8, legacy, , legacy, 83, o16 83 /3 ib, SBB r/m16| imm8, g=3 16b 32b 64b o16 op=r16_or_mem;imm8sex16 lock xacquire xrelease
Sbb_rm32_imm8, legacy, , legacy, 83, o32 83 /3 ib, SBB r/m32| imm8, g=3 16b 32b 64b o32 op=r32_or_mem;imm8sex32 lock xacquire xrelease
Sbb_rm64_imm8, legacy, , legacy, 83, REX.W 83 /3 ib, SBB r/m64| imm8, g=3 64b o64 op=r64_or_mem;imm8sex64 lock xacquire xrelease
And_rm16_imm8, legacy, , legacy, 83, o16 83 /4 ib, AND r/m16| imm8, g=4 16b 32b 64b o16 op=r16_or_mem;imm8sex16 lock xacquire xrelease
And_rm32_imm8, legacy, , legacy, 83, o32 83 /4 ib, AND r/m32| imm8, g=4 16b 32b 64b o32 op=r32_or_mem;imm8sex32 lock xacquire xrelease
And_rm64_imm8, legacy, , legacy, 83, REX.W 83 /4 ib, AND r/m64| imm8, g=4 64b o64 op=r64_or_mem;imm8sex64 lock xacquire xrelease
Sub_rm16_imm8, legacy, , legacy, 83, o16 83 /5 ib, SUB r/m16| imm8, g=5 16b 32b 64b o16 op=r16_or_mem;imm8sex16 lock xacquire xrelease
Sub_rm32_imm8, legacy, , legacy, 83, o32 83 /5 ib, SUB r/m32| imm8, g=5 16b 32b 64b o32 op=r32_or_mem;imm8sex32 lock xacquire xrelease
Sub_rm64_imm8, legacy, , legacy, 83, REX.W 83 /5 ib, SUB r/m64| imm8, g=5 64b o64 op=r64_or_mem;imm8sex64 lock xacquire xrelease
Xor_rm16_imm8, legacy, , legacy, 83, o16 83 /6 ib, XOR r/m16| imm8, g=6 16b 32b 64b o16 op=r16_or_mem;imm8sex16 lock xacquire xrelease
Xor_rm32_imm8, legacy, , legacy, 83, o32 83 /6 ib, XOR r/m32| imm8, g=6 16b 32b 64b o32 op=r32_or_mem;imm8sex32 lock xacquire xrelease
Xor_rm64_imm8, legacy, , legacy, 83, REX.W 83 /6 ib, XOR r/m64| imm8, g=6 64b o64 op=r64_or_mem;imm8sex64 lock xacquire xrelease
Cmp_rm16_imm8, legacy, , legacy, 83, o16 83 /7 ib, CMP r/m16| imm8, g=7 16b 32b 64b o16 op=r16_or_mem;imm8sex16
Cmp_rm32_imm8, legacy, , legacy, 83, o32 83 /7 ib, CMP r/m32| imm8, g=7 16b 32b 64b o32 op=r32_or_mem;imm8sex32
Cmp_rm64_imm8, legacy, , legacy, 83, REX.W 83 /7 ib, CMP r/m64| imm8, g=7 64b o64 op=r64_or_mem;imm8sex64
Test_rm8_r8, legacy, , legacy, 84, 84 /r, TEST r/m8| r8, 16b 32b 64b op=r8_or_mem;r8_reg
Test_rm16_r16, legacy, , legacy, 85, o16 85 /r, TEST r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg
Test_rm32_r32, legacy, , legacy, 85, o32 85 /r, TEST r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg
Test_rm64_r64, legacy, , legacy, 85, REX.W 85 /r, TEST r/m64| r64, 64b o64 op=r64_or_mem;r64_reg
Xchg_rm8_r8, legacy, , legacy, 86, 86 /r, XCHG r/m8| r8, 16b 32b 64b op=r8_or_mem;r8_reg lock xacquire xrelease
Xchg_rm16_r16, legacy, , legacy, 87, o16 87 /r, XCHG r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg lock xacquire xrelease
Xchg_rm32_r32, legacy, , legacy, 87, o32 87 /r, XCHG r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg lock xacquire xrelease
Xchg_rm64_r64, legacy, , legacy, 87, REX.W 87 /r, XCHG r/m64| r64, 64b o64 op=r64_or_mem;r64_reg lock xacquire xrelease
Mov_rm8_r8, legacy, , legacy, 88, 88 /r, MOV r/m8| r8, 16b 32b 64b op=r8_or_mem;r8_reg xrelease
Mov_rm16_r16, legacy, , legacy, 89, o16 89 /r, MOV r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg xrelease
Mov_rm32_r32, legacy, , legacy, 89, o32 89 /r, MOV r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg xrelease
Mov_rm64_r64, legacy, , legacy, 89, REX.W 89 /r, MOV r/m64| r64, 64b o64 op=r64_or_mem;r64_reg xrelease
Mov_r8_rm8, legacy, , legacy, 8A, 8A /r, MOV r8| r/m8, 16b 32b 64b op=r8_reg;r8_or_mem
Mov_r16_rm16, legacy, , legacy, 8B, o16 8B /r, MOV r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Mov_r32_rm32, legacy, , legacy, 8B, o32 8B /r, MOV r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Mov_r64_rm64, legacy, , legacy, 8B, REX.W 8B /r, MOV r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Mov_rm16_Sreg, legacy, , legacy, 8C, o16 8C /r, MOV r/m16| Sreg, 16b 32b 64b o16 op=r16_or_mem;seg_reg
Mov_r32m16_Sreg, legacy, , legacy, 8C, o32 8C /r, MOV r32/m16| Sreg, 16b 32b 64b o32 op=r32_or_mem;seg_reg
Mov_r64m16_Sreg, legacy, , legacy, 8C, REX.W 8C /r, MOV r64/m16| Sreg, 64b o64 op=r64_or_mem;seg_reg
Lea_r16_m, legacy, , legacy, 8D, o16 8D /r, LEA r16| m, 16b 32b 64b o16 op=r16_reg;mem
Lea_r32_m, legacy, , legacy, 8D, o32 8D /r, LEA r32| m, 16b 32b 64b o32 op=r32_reg;mem
Lea_r64_m, legacy, , legacy, 8D, REX.W 8D /r, LEA r64| m, 64b o64 op=r64_reg;mem
Mov_Sreg_rm16, legacy, , legacy, 8E, o16 8E /r, MOV Sreg| r/m16, 16b 32b 64b o16 op=seg_reg;r16_or_mem
Mov_Sreg_r32m16, legacy, , legacy, 8E, o32 8E /r, MOV Sreg| r32/m16, 16b 32b 64b o32 op=seg_reg;r32_or_mem
Mov_Sreg_r64m16, legacy, , legacy, 8E, REX.W 8E /r, MOV Sreg| r64/m16, 64b o64 op=seg_reg;r64_or_mem
Pop_rm16, legacy, , legacy, 8F, o16 8F /0, POP r/m16, g=0 16b 32b 64b o16 op=r16_or_mem
Pop_rm32, legacy, , legacy, 8F, o32 8F /0, POP r/m32, g=0 16b 32b o32 op=r32_or_mem
Pop_rm64, legacy, , legacy, 8F, 8F /0, POP r/m64, g=0 64b op=r64_or_mem
Nopw, legacy, , legacy, 90, o16 90, NOP, 16b 32b 64b o16
Nopd, legacy, , legacy, 90, o32 90, NOP, 16b 32b 64b o32
Nopq, legacy, , legacy, 90, REX.W 90, NOP, 64b o64
Xchg_r16_AX, legacy, , legacy, 90, o16 90+rw, XCHG r16| AX, 16b 32b 64b o16 op=r16_opcode;ax
Xchg_r32_EAX, legacy, , legacy, 90, o32 90+rd, XCHG r32| EAX, 16b 32b 64b o32 op=r32_opcode;eax
Xchg_r64_RAX, legacy, , legacy, 90, REX.W 90+ro, XCHG r64| RAX, 64b o64 op=r64_opcode;rax
Pause, legacy, F3, legacy, 90, F3 90, PAUSE, 16b 32b 64b
Cbw, legacy, , legacy, 98, o16 98, CBW, 16b 32b 64b o16
Cwde, legacy, , legacy, 98, o32 98, CWDE, 16b 32b 64b o32
Cdqe, legacy, , legacy, 98, REX.W 98, CDQE, 64b o64
Cwd, legacy, , legacy, 99, o16 99, CWD, 16b 32b 64b o16
Cdq, legacy, , legacy, 99, o32 99, CDQ, 16b 32b 64b o32
Cqo, legacy, , legacy, 99, REX.W 99, CQO, 64b o64
Call_ptr1616, legacy, , legacy, 9A, o16 9A cd, CALL ptr16:16, 16b 32b o16 op=farbr2_2
Call_ptr1632, legacy, , legacy, 9A, o32 9A cp, CALL ptr16:32, 16b 32b o32 op=farbr4_2
Wait, legacy, , legacy, 9B, 9B, WAIT, 16b 32b 64b
Pushfw, legacy, , legacy, 9C, o16 9C, PUSHF, 16b 32b 64b o16
Pushfd, legacy, , legacy, 9C, o32 9C, PUSHFD, 16b 32b o32
Pushfq, legacy, , legacy, 9C, 9C, PUSHFQ, 64b
Popfw, legacy, , legacy, 9D, o16 9D, POPF, 16b 32b 64b o16
Popfd, legacy, , legacy, 9D, o32 9D, POPFD, 16b 32b o32
Popfq, legacy, , legacy, 9D, 9D, POPFQ, 64b
Sahf, legacy, , legacy, 9E, 9E, SAHF, 16b 32b 64b
Lahf, legacy, , legacy, 9F, 9F, LAHF, 16b 32b 64b
Mov_AL_moffs8, legacy, , legacy, A0, A0 mo, MOV AL| moffs8, 16b 32b 64b op=al;mem_offs
Mov_AX_moffs16, legacy, , legacy, A1, o16 A1 mo, MOV AX| moffs16, 16b 32b 64b o16 op=ax;mem_offs
Mov_EAX_moffs32, legacy, , legacy, A1, o32 A1 mo, MOV EAX| moffs32, 16b 32b 64b o32 op=eax;mem_offs
Mov_RAX_moffs64, legacy, , legacy, A1, REX.W A1 mo, MOV RAX| moffs64, 64b o64 op=rax;mem_offs
Mov_moffs8_AL, legacy, , legacy, A2, A2 mo, MOV moffs8| AL, 16b 32b 64b op=mem_offs;al
Mov_moffs16_AX, legacy, , legacy, A3, o16 A3 mo, MOV moffs16| AX, 16b 32b 64b o16 op=mem_offs;ax
Mov_moffs32_EAX, legacy, , legacy, A3, o32 A3 mo, MOV moffs32| EAX, 16b 32b 64b o32 op=mem_offs;eax
Mov_moffs64_RAX, legacy, , legacy, A3, REX.W A3 mo, MOV moffs64| RAX, 64b o64 op=mem_offs;rax
Movsb_m8_m8, legacy, , legacy, A4, A4, MOVSB, 16b 32b 64b op=es_rDI;seg_rSI rep
Movsw_m16_m16, legacy, , legacy, A5, o16 A5, MOVSW, 16b 32b 64b o16 op=es_rDI;seg_rSI rep
Movsd_m32_m32, legacy, , legacy, A5, o32 A5, MOVSD, 16b 32b 64b o32 op=es_rDI;seg_rSI rep
Movsq_m64_m64, legacy, , legacy, A5, REX.W A5, MOVSQ, 64b o64 op=es_rDI;seg_rSI rep
Cmpsb_m8_m8, legacy, , legacy, A6, A6, CMPSB, 16b 32b 64b op=seg_rSI;es_rDI repe repne
Cmpsw_m16_m16, legacy, , legacy, A7, o16 A7, CMPSW, 16b 32b 64b o16 op=seg_rSI;es_rDI repe repne
Cmpsd_m32_m32, legacy, , legacy, A7, o32 A7, CMPSD, 16b 32b 64b o32 op=seg_rSI;es_rDI repe repne
Cmpsq_m64_m64, legacy, , legacy, A7, REX.W A7, CMPSQ, 64b o64 op=seg_rSI;es_rDI repe repne
Test_AL_imm8, legacy, , legacy, A8, A8 ib, TEST AL| imm8, 16b 32b 64b op=al;imm8
Test_AX_imm16, legacy, , legacy, A9, o16 A9 iw, TEST AX| imm16, 16b 32b 64b o16 op=ax;imm16
Test_EAX_imm32, legacy, , legacy, A9, o32 A9 id, TEST EAX| imm32, 16b 32b 64b o32 op=eax;imm32
Test_RAX_imm32, legacy, , legacy, A9, REX.W A9 id, TEST RAX| imm32, 64b o64 op=rax;imm32sex64
Stosb_m8_AL, legacy, , legacy, AA, AA, STOSB, 16b 32b 64b op=es_rDI;al rep
Stosw_m16_AX, legacy, , legacy, AB, o16 AB, STOSW, 16b 32b 64b o16 op=es_rDI;ax rep
Stosd_m32_EAX, legacy, , legacy, AB, o32 AB, STOSD, 16b 32b 64b o32 op=es_rDI;eax rep
Stosq_m64_RAX, legacy, , legacy, AB, REX.W AB, STOSQ, 64b o64 op=es_rDI;rax rep
Lodsb_AL_m8, legacy, , legacy, AC, AC, LODSB, 16b 32b 64b op=al;seg_rSI rep
Lodsw_AX_m16, legacy, , legacy, AD, o16 AD, LODSW, 16b 32b 64b o16 op=ax;seg_rSI rep
Lodsd_EAX_m32, legacy, , legacy, AD, o32 AD, LODSD, 16b 32b 64b o32 op=eax;seg_rSI rep
Lodsq_RAX_m64, legacy, , legacy, AD, REX.W AD, LODSQ, 64b o64 op=rax;seg_rSI rep
Scasb_AL_m8, legacy, , legacy, AE, AE, SCASB, 16b 32b 64b op=al;es_rDI repe repne
Scasw_AX_m16, legacy, , legacy, AF, o16 AF, SCASW, 16b 32b 64b o16 op=ax;es_rDI repe repne
Scasd_EAX_m32, legacy, , legacy, AF, o32 AF, SCASD, 16b 32b 64b o32 op=eax;es_rDI repe repne
Scasq_RAX_m64, legacy, , legacy, AF, REX.W AF, SCASQ, 64b o64 op=rax;es_rDI repe repne
Mov_r8_imm8, legacy, , legacy, B0, B0+rb ib, MOV r8| imm8, 16b 32b 64b op=r8_opcode;imm8
Mov_r16_imm16, legacy, , legacy, B8, o16 B8+rw iw, MOV r16| imm16, 16b 32b 64b o16 op=r16_opcode;imm16
Mov_r32_imm32, legacy, , legacy, B8, o32 B8+rd id, MOV r32| imm32, 16b 32b 64b o32 op=r32_opcode;imm32
Mov_r64_imm64, legacy, , legacy, B8, REX.W B8+ro io, MOV r64| imm64, 64b o64 op=r64_opcode;imm64
Rol_rm8_imm8, legacy, , legacy, C0, C0 /0 ib, ROL r/m8| imm8, g=0 16b 32b 64b op=r8_or_mem;imm8
Ror_rm8_imm8, legacy, , legacy, C0, C0 /1 ib, ROR r/m8| imm8, g=1 16b 32b 64b op=r8_or_mem;imm8
Rcl_rm8_imm8, legacy, , legacy, C0, C0 /2 ib, RCL r/m8| imm8, g=2 16b 32b 64b op=r8_or_mem;imm8
Rcr_rm8_imm8, legacy, , legacy, C0, C0 /3 ib, RCR r/m8| imm8, g=3 16b 32b 64b op=r8_or_mem;imm8
Shl_rm8_imm8, legacy, , legacy, C0, C0 /4 ib, SHL r/m8| imm8, g=4 16b 32b 64b op=r8_or_mem;imm8
Shr_rm8_imm8, legacy, , legacy, C0, C0 /5 ib, SHR r/m8| imm8, g=5 16b 32b 64b op=r8_or_mem;imm8
Sal_rm8_imm8, legacy, , legacy, C0, C0 /6 ib, SAL r/m8| imm8, g=6 16b 32b 64b op=r8_or_mem;imm8
Sar_rm8_imm8, legacy, , legacy, C0, C0 /7 ib, SAR r/m8| imm8, g=7 16b 32b 64b op=r8_or_mem;imm8
Rol_rm16_imm8, legacy, , legacy, C1, o16 C1 /0 ib, ROL r/m16| imm8, g=0 16b 32b 64b o16 op=r16_or_mem;imm8
Rol_rm32_imm8, legacy, , legacy, C1, o32 C1 /0 ib, ROL r/m32| imm8, g=0 16b 32b 64b o32 op=r32_or_mem;imm8
Rol_rm64_imm8, legacy, , legacy, C1, REX.W C1 /0 ib, ROL r/m64| imm8, g=0 64b o64 op=r64_or_mem;imm8
Ror_rm16_imm8, legacy, , legacy, C1, o16 C1 /1 ib, ROR r/m16| imm8, g=1 16b 32b 64b o16 op=r16_or_mem;imm8
Ror_rm32_imm8, legacy, , legacy, C1, o32 C1 /1 ib, ROR r/m32| imm8, g=1 16b 32b 64b o32 op=r32_or_mem;imm8
Ror_rm64_imm8, legacy, , legacy, C1, REX.W C1 /1 ib, ROR r/m64| imm8, g=1 64b o64 op=r64_or_mem;imm8
Rcl_rm16_imm8, legacy, , legacy, C1, o16 C1 /2 ib, RCL r/m16| imm8, g=2 16b 32b 64b o16 op=r16_or_mem;imm8
Rcl_rm32_imm8, legacy, , legacy, C1, o32 C1 /2 ib, RCL r/m32| imm8, g=2 16b 32b 64b o32 op=r32_or_mem;imm8
Rcl_rm64_imm8, legacy, , legacy, C1, REX.W C1 /2 ib, RCL r/m64| imm8, g=2 64b o64 op=r64_or_mem;imm8
Rcr_rm16_imm8, legacy, , legacy, C1, o16 C1 /3 ib, RCR r/m16| imm8, g=3 16b 32b 64b o16 op=r16_or_mem;imm8
Rcr_rm32_imm8, legacy, , legacy, C1, o32 C1 /3 ib, RCR r/m32| imm8, g=3 16b 32b 64b o32 op=r32_or_mem;imm8
Rcr_rm64_imm8, legacy, , legacy, C1, REX.W C1 /3 ib, RCR r/m64| imm8, g=3 64b o64 op=r64_or_mem;imm8
Shl_rm16_imm8, legacy, , legacy, C1, o16 C1 /4 ib, SHL r/m16| imm8, g=4 16b 32b 64b o16 op=r16_or_mem;imm8
Shl_rm32_imm8, legacy, , legacy, C1, o32 C1 /4 ib, SHL r/m32| imm8, g=4 16b 32b 64b o32 op=r32_or_mem;imm8
Shl_rm64_imm8, legacy, , legacy, C1, REX.W C1 /4 ib, SHL r/m64| imm8, g=4 64b o64 op=r64_or_mem;imm8
Shr_rm16_imm8, legacy, , legacy, C1, o16 C1 /5 ib, SHR r/m16| imm8, g=5 16b 32b 64b o16 op=r16_or_mem;imm8
Shr_rm32_imm8, legacy, , legacy, C1, o32 C1 /5 ib, SHR r/m32| imm8, g=5 16b 32b 64b o32 op=r32_or_mem;imm8
Shr_rm64_imm8, legacy, , legacy, C1, REX.W C1 /5 ib, SHR r/m64| imm8, g=5 64b o64 op=r64_or_mem;imm8
Sal_rm16_imm8, legacy, , legacy, C1, o16 C1 /6 ib, SAL r/m16| imm8, g=6 16b 32b 64b o16 op=r16_or_mem;imm8
Sal_rm32_imm8, legacy, , legacy, C1, o32 C1 /6 ib, SAL r/m32| imm8, g=6 16b 32b 64b o32 op=r32_or_mem;imm8
Sal_rm64_imm8, legacy, , legacy, C1, REX.W C1 /6 ib, SAL r/m64| imm8, g=6 64b o64 op=r64_or_mem;imm8
Sar_rm16_imm8, legacy, , legacy, C1, o16 C1 /7 ib, SAR r/m16| imm8, g=7 16b 32b 64b o16 op=r16_or_mem;imm8
Sar_rm32_imm8, legacy, , legacy, C1, o32 C1 /7 ib, SAR r/m32| imm8, g=7 16b 32b 64b o32 op=r32_or_mem;imm8
Sar_rm64_imm8, legacy, , legacy, C1, REX.W C1 /7 ib, SAR r/m64| imm8, g=7 64b o64 op=r64_or_mem;imm8
Retnw_imm16, legacy, , legacy, C2, o16 C2 iw, RET imm16, 16b 32b 64b o16 op=imm16 bnd
Retnd_imm16, legacy, , legacy, C2, o32 C2 iw, RET imm16, 16b 32b o32 op=imm16 bnd
Retnq_imm16, legacy, , legacy, C2, C2 iw, RET imm16, 64b op=imm16 bnd
Retnw, legacy, , legacy, C3, o16 C3, RET, 16b 32b 64b o16 bnd
Retnd, legacy, , legacy, C3, o32 C3, RET, 16b 32b o32 bnd
Retnq, legacy, , legacy, C3, C3, RET, 64b bnd
Les_r16_m1616, legacy, , legacy, C4, o16 C4 /r, LES r16| m16:16, 16b 32b o16 op=r16_reg;mem
Les_r32_m1632, legacy, , legacy, C4, o32 C4 /r, LES r32| m16:32, 16b 32b o32 op=r32_reg;mem
Lds_r16_m1616, legacy, , legacy, C5, o16 C5 /r, LDS r16| m16:16, 16b 32b o16 op=r16_reg;mem
Lds_r32_m1632, legacy, , legacy, C5, o32 C5 /r, LDS r32| m16:32, 16b 32b o32 op=r32_reg;mem
Mov_rm8_imm8, legacy, , legacy, C6, C6 /0 ib, MOV r/m8| imm8, g=0 16b 32b 64b op=r8_or_mem;imm8 xrelease
Xabort_imm8, legacy, , legacy, C6F8, C6 F8 ib, XABORT imm8, 16b 32b 64b op=imm8
Mov_rm16_imm16, legacy, , legacy, C7, o16 C7 /0 iw, MOV r/m16| imm16, g=0 16b 32b 64b o16 op=r16_or_mem;imm16 xrelease
Mov_rm32_imm32, legacy, , legacy, C7, o32 C7 /0 id, MOV r/m32| imm32, g=0 16b 32b 64b o32 op=r32_or_mem;imm32 xrelease
Mov_rm64_imm32, legacy, , legacy, C7, REX.W C7 /0 id, MOV r/m64| imm32, g=0 64b o64 op=r64_or_mem;imm32sex64 xrelease
Xbegin_rel16, legacy, , legacy, C7F8, o16 C7 F8 cw, XBEGIN rel16, 16b 32b 64b o16 op=xbegin_2
Xbegin_rel32, legacy, , legacy, C7F8, o32 C7 F8 cd, XBEGIN rel32, 16b 32b 64b o32 op=xbegin_4
Enterw_imm16_imm8, legacy, , legacy, C8, o16 C8 iw ib, ENTER imm16| imm8, 16b 32b 64b o16 op=imm16;imm8
Enterd_imm16_imm8, legacy, , legacy, C8, o32 C8 iw ib, ENTER imm16| imm8, 16b 32b o32 op=imm16;imm8
Enterq_imm16_imm8, legacy, , legacy, C8, C8 iw ib, ENTER imm16| imm8, 64b op=imm16;imm8
Leavew, legacy, , legacy, C9, o16 C9, LEAVE, 16b 32b 64b o16
Leaved, legacy, , legacy, C9, o32 C9, LEAVE, 16b 32b o32
Leaveq, legacy, , legacy, C9, C9, LEAVE, 64b
Retfw_imm16, legacy, , legacy, CA, o16 CA iw, RET imm16, 16b 32b 64b o16 op=imm16
Retfd_imm16, legacy, , legacy, CA, o32 CA iw, RET imm16, 16b 32b 64b o32 op=imm16
Retfq_imm16, legacy, , legacy, CA, REX.W CA iw, RET imm16, 64b o64 op=imm16
Retfw, legacy, , legacy, CB, o16 CB, RET, 16b 32b 64b o16
Retfd, legacy, , legacy, CB, o32 CB, RET, 16b 32b 64b o32
Retfq, legacy, , legacy, CB, REX.W CB, RET, 64b o64
Int3, legacy, , legacy, CC, CC, INT3, 16b 32b 64b
Int_imm8, legacy, , legacy, CD, CD ib, INT imm8, 16b 32b 64b op=imm8
Into, legacy, , legacy, CE, CE, INTO, 16b 32b
Iretw, legacy, , legacy, CF, o16 CF, IRET, 16b 32b 64b o16
Iretd, legacy, , legacy, CF, o32 CF, IRETD, 16b 32b 64b o32
Iretq, legacy, , legacy, CF, REX.W CF, IRETQ, 64b o64
Rol_rm8_1, legacy, , legacy, D0, D0 /0, ROL r/m8| 1, g=0 16b 32b 64b op=r8_or_mem;imm8_const_1
Ror_rm8_1, legacy, , legacy, D0, D0 /1, ROR r/m8| 1, g=1 16b 32b 64b op=r8_or_mem;imm8_const_1
Rcl_rm8_1, legacy, , legacy, D0, D0 /2, RCL r/m8| 1, g=2 16b 32b 64b op=r8_or_mem;imm8_const_1
Rcr_rm8_1, legacy, , legacy, D0, D0 /3, RCR r/m8| 1, g=3 16b 32b 64b op=r8_or_mem;imm8_const_1
Shl_rm8_1, legacy, , legacy, D0, D0 /4, SHL r/m8| 1, g=4 16b 32b 64b op=r8_or_mem;imm8_const_1
Shr_rm8_1, legacy, , legacy, D0, D0 /5, SHR r/m8| 1, g=5 16b 32b 64b op=r8_or_mem;imm8_const_1
Sal_rm8_1, legacy, , legacy, D0, D0 /6, SAL r/m8| 1, g=6 16b 32b 64b op=r8_or_mem;imm8_const_1
Sar_rm8_1, legacy, , legacy, D0, D0 /7, SAR r/m8| 1, g=7 16b 32b 64b op=r8_or_mem;imm8_const_1
Rol_rm16_1, legacy, , legacy, D1, o16 D1 /0, ROL r/m16| 1, g=0 16b 32b 64b o16 op=r16_or_mem;imm8_const_1
Rol_rm32_1, legacy, , legacy, D1, o32 D1 /0, ROL r/m32| 1, g=0 16b 32b 64b o32 op=r32_or_mem;imm8_const_1
Rol_rm64_1, legacy, , legacy, D1, REX.W D1 /0, ROL r/m64| 1, g=0 64b o64 op=r64_or_mem;imm8_const_1
Ror_rm16_1, legacy, , legacy, D1, o16 D1 /1, ROR r/m16| 1, g=1 16b 32b 64b o16 op=r16_or_mem;imm8_const_1
Ror_rm32_1, legacy, , legacy, D1, o32 D1 /1, ROR r/m32| 1, g=1 16b 32b 64b o32 op=r32_or_mem;imm8_const_1
Ror_rm64_1, legacy, , legacy, D1, REX.W D1 /1, ROR r/m64| 1, g=1 64b o64 op=r64_or_mem;imm8_const_1
Rcl_rm16_1, legacy, , legacy, D1, o16 D1 /2, RCL r/m16| 1, g=2 16b 32b 64b o16 op=r16_or_mem;imm8_const_1
Rcl_rm32_1, legacy, , legacy, D1, o32 D1 /2, RCL r/m32| 1, g=2 16b 32b 64b o32 op=r32_or_mem;imm8_const_1
Rcl_rm64_1, legacy, , legacy, D1, REX.W D1 /2, RCL r/m64| 1, g=2 64b o64 op=r64_or_mem;imm8_const_1
Rcr_rm16_1, legacy, , legacy, D1, o16 D1 /3, RCR r/m16| 1, g=3 16b 32b 64b o16 op=r16_or_mem;imm8_const_1
Rcr_rm32_1, legacy, , legacy, D1, o32 D1 /3, RCR r/m32| 1, g=3 16b 32b 64b o32 op=r32_or_mem;imm8_const_1
Rcr_rm64_1, legacy, , legacy, D1, REX.W D1 /3, RCR r/m64| 1, g=3 64b o64 op=r64_or_mem;imm8_const_1
Shl_rm16_1, legacy, , legacy, D1, o16 D1 /4, SHL r/m16| 1, g=4 16b 32b 64b o16 op=r16_or_mem;imm8_const_1
Shl_rm32_1, legacy, , legacy, D1, o32 D1 /4, SHL r/m32| 1, g=4 16b 32b 64b o32 op=r32_or_mem;imm8_const_1
Shl_rm64_1, legacy, , legacy, D1, REX.W D1 /4, SHL r/m64| 1, g=4 64b o64 op=r64_or_mem;imm8_const_1
Shr_rm16_1, legacy, , legacy, D1, o16 D1 /5, SHR r/m16| 1, g=5 16b 32b 64b o16 op=r16_or_mem;imm8_const_1
Shr_rm32_1, legacy, , legacy, D1, o32 D1 /5, SHR r/m32| 1, g=5 16b 32b 64b o32 op=r32_or_mem;imm8_const_1
Shr_rm64_1, legacy, , legacy, D1, REX.W D1 /5, SHR r/m64| 1, g=5 64b o64 op=r64_or_mem;imm8_const_1
Sal_rm16_1, legacy, , legacy, D1, o16 D1 /6, SAL r/m16| 1, g=6 16b 32b 64b o16 op=r16_or_mem;imm8_const_1
Sal_rm32_1, legacy, , legacy, D1, o32 D1 /6, SAL r/m32| 1, g=6 16b 32b 64b o32 op=r32_or_mem;imm8_const_1
Sal_rm64_1, legacy, , legacy, D1, REX.W D1 /6, SAL r/m64| 1, g=6 64b o64 op=r64_or_mem;imm8_const_1
Sar_rm16_1, legacy, , legacy, D1, o16 D1 /7, SAR r/m16| 1, g=7 16b 32b 64b o16 op=r16_or_mem;imm8_const_1
Sar_rm32_1, legacy, , legacy, D1, o32 D1 /7, SAR r/m32| 1, g=7 16b 32b 64b o32 op=r32_or_mem;imm8_const_1
Sar_rm64_1, legacy, , legacy, D1, REX.W D1 /7, SAR r/m64| 1, g=7 64b o64 op=r64_or_mem;imm8_const_1
Rol_rm8_CL, legacy, , legacy, D2, D2 /0, ROL r/m8| CL, g=0 16b 32b 64b op=r8_or_mem;cl
Ror_rm8_CL, legacy, , legacy, D2, D2 /1, ROR r/m8| CL, g=1 16b 32b 64b op=r8_or_mem;cl
Rcl_rm8_CL, legacy, , legacy, D2, D2 /2, RCL r/m8| CL, g=2 16b 32b 64b op=r8_or_mem;cl
Rcr_rm8_CL, legacy, , legacy, D2, D2 /3, RCR r/m8| CL, g=3 16b 32b 64b op=r8_or_mem;cl
Shl_rm8_CL, legacy, , legacy, D2, D2 /4, SHL r/m8| CL, g=4 16b 32b 64b op=r8_or_mem;cl
Shr_rm8_CL, legacy, , legacy, D2, D2 /5, SHR r/m8| CL, g=5 16b 32b 64b op=r8_or_mem;cl
Sal_rm8_CL, legacy, , legacy, D2, D2 /6, SAL r/m8| CL, g=6 16b 32b 64b op=r8_or_mem;cl
Sar_rm8_CL, legacy, , legacy, D2, D2 /7, SAR r/m8| CL, g=7 16b 32b 64b op=r8_or_mem;cl
Rol_rm16_CL, legacy, , legacy, D3, o16 D3 /0, ROL r/m16| CL, g=0 16b 32b 64b o16 op=r16_or_mem;cl
Rol_rm32_CL, legacy, , legacy, D3, o32 D3 /0, ROL r/m32| CL, g=0 16b 32b 64b o32 op=r32_or_mem;cl
Rol_rm64_CL, legacy, , legacy, D3, REX.W D3 /0, ROL r/m64| CL, g=0 64b o64 op=r64_or_mem;cl
Ror_rm16_CL, legacy, , legacy, D3, o16 D3 /1, ROR r/m16| CL, g=1 16b 32b 64b o16 op=r16_or_mem;cl
Ror_rm32_CL, legacy, , legacy, D3, o32 D3 /1, ROR r/m32| CL, g=1 16b 32b 64b o32 op=r32_or_mem;cl
Ror_rm64_CL, legacy, , legacy, D3, REX.W D3 /1, ROR r/m64| CL, g=1 64b o64 op=r64_or_mem;cl
Rcl_rm16_CL, legacy, , legacy, D3, o16 D3 /2, RCL r/m16| CL, g=2 16b 32b 64b o16 op=r16_or_mem;cl
Rcl_rm32_CL, legacy, , legacy, D3, o32 D3 /2, RCL r/m32| CL, g=2 16b 32b 64b o32 op=r32_or_mem;cl
Rcl_rm64_CL, legacy, , legacy, D3, REX.W D3 /2, RCL r/m64| CL, g=2 64b o64 op=r64_or_mem;cl
Rcr_rm16_CL, legacy, , legacy, D3, o16 D3 /3, RCR r/m16| CL, g=3 16b 32b 64b o16 op=r16_or_mem;cl
Rcr_rm32_CL, legacy, , legacy, D3, o32 D3 /3, RCR r/m32| CL, g=3 16b 32b 64b o32 op=r32_or_mem;cl
Rcr_rm64_CL, legacy, , legacy, D3, REX.W D3 /3, RCR r/m64| CL, g=3 64b o64 op=r64_or_mem;cl
Shl_rm16_CL, legacy, , legacy, D3, o16 D3 /4, SHL r/m16| CL, g=4 16b 32b 64b o16 op=r16_or_mem;cl
Shl_rm32_CL, legacy, , legacy, D3, o32 D3 /4, SHL r/m32| CL, g=4 16b 32b 64b o32 op=r32_or_mem;cl
Shl_rm64_CL, legacy, , legacy, D3, REX.W D3 /4, SHL r/m64| CL, g=4 64b o64 op=r64_or_mem;cl
Shr_rm16_CL, legacy, , legacy, D3, o16 D3 /5, SHR r/m16| CL, g=5 16b 32b 64b o16 op=r16_or_mem;cl
Shr_rm32_CL, legacy, , legacy, D3, o32 D3 /5, SHR r/m32| CL, g=5 16b 32b 64b o32 op=r32_or_mem;cl
Shr_rm64_CL, legacy, , legacy, D3, REX.W D3 /5, SHR r/m64| CL, g=5 64b o64 op=r64_or_mem;cl
Sal_rm16_CL, legacy, , legacy, D3, o16 D3 /6, SAL r/m16| CL, g=6 16b 32b 64b o16 op=r16_or_mem;cl
Sal_rm32_CL, legacy, , legacy, D3, o32 D3 /6, SAL r/m32| CL, g=6 16b 32b 64b o32 op=r32_or_mem;cl
Sal_rm64_CL, legacy, , legacy, D3, REX.W D3 /6, SAL r/m64| CL, g=6 64b o64 op=r64_or_mem;cl
Sar_rm16_CL, legacy, , legacy, D3, o16 D3 /7, SAR r/m16| CL, g=7 16b 32b 64b o16 op=r16_or_mem;cl
Sar_rm32_CL, legacy, , legacy, D3, o32 D3 /7, SAR r/m32| CL, g=7 16b 32b 64b o32 op=r32_or_mem;cl
Sar_rm64_CL, legacy, , legacy, D3, REX.W D3 /7, SAR r/m64| CL, g=7 64b o64 op=r64_or_mem;cl
Aam_imm8, legacy, , legacy, D4, D4 ib, AAM imm8, 16b 32b op=imm8
Aad_imm8, legacy, , legacy, D5, D5 ib, AAD imm8, 16b 32b op=imm8
Salc, legacy, , legacy, D6, D6, SALC, 16b 32b
Xlat_m8, legacy, , legacy, D7, D7, XLATB, 16b 32b 64b op=seg_rBX_al
Fadd_m32fp, legacy, , legacy, D8, D8 /0, FADD m32fp, g=0 16b 32b 64b op=mem
Fmul_m32fp, legacy, , legacy, D8, D8 /1, FMUL m32fp, g=1 16b 32b 64b op=mem
Fcom_m32fp, legacy, , legacy, D8, D8 /2, FCOM m32fp, g=2 16b 32b 64b op=mem
Fcomp_m32fp, legacy, , legacy, D8, D8 /3, FCOMP m32fp, g=3 16b 32b 64b op=mem
Fsub_m32fp, legacy, , legacy, D8, D8 /4, FSUB m32fp, g=4 16b 32b 64b op=mem
Fsubr_m32fp, legacy, , legacy, D8, D8 /5, FSUBR m32fp, g=5 16b 32b 64b op=mem
Fdiv_m32fp, legacy, , legacy, D8, D8 /6, FDIV m32fp, g=6 16b 32b 64b op=mem
Fdivr_m32fp, legacy, , legacy, D8, D8 /7, FDIVR m32fp, g=7 16b 32b 64b op=mem
Fadd_st0_sti, legacy, , legacy, D8C0, D8 C0+i, FADD ST(0)| ST(i), 16b 32b 64b op=st0;sti_opcode
Fmul_st0_sti, legacy, , legacy, D8C8, D8 C8+i, FMUL ST(0)| ST(i), 16b 32b 64b op=st0;sti_opcode
Fcom_st0_sti, legacy, , legacy, D8D0, D8 D0+i, FCOM ST(i), 16b 32b 64b op=st0;sti_opcode
Fcomp_st0_sti, legacy, , legacy, D8D8, D8 D8+i, FCOMP ST(i), 16b 32b 64b op=st0;sti_opcode
Fsub_st0_sti, legacy, , legacy, D8E0, D8 E0+i, FSUB ST(0)| ST(i), 16b 32b 64b op=st0;sti_opcode
Fsubr_st0_sti, legacy, , legacy, D8E8, D8 E8+i, FSUBR ST(0)| ST(i), 16b 32b 64b op=st0;sti_opcode
Fdiv_st0_sti, legacy, , legacy, D8F0, D8 F0+i, FDIV ST(0)| ST(i), 16b 32b 64b op=st0;sti_opcode
Fdivr_st0_sti, legacy, , legacy, D8F8, D8 F8+i, FDIVR ST(0)| ST(i), 16b 32b 64b op=st0;sti_opcode
Fld_m32fp, legacy, , legacy, D9, D9 /0, FLD m32fp, g=0 16b 32b 64b op=mem
Fst_m32fp, legacy, , legacy, D9, D9 /2, FST m32fp, g=2 16b 32b 64b op=mem
Fstp_m32fp, legacy, , legacy, D9, D9 /3, FSTP m32fp, g=3 16b 32b 64b op=mem
Fldenv_m14byte, legacy, , legacy, D9, o16 D9 /4, FLDENV m14byte, g=4 16b 32b 64b o16 op=mem
Fldenv_m28byte, legacy, , legacy, D9, o32 D9 /4, FLDENV m28byte, g=4 16b 32b 64b o32 op=mem
Fldcw_m2byte, legacy, , legacy, D9, D9 /5, FLDCW m2byte, g=5 16b 32b 64b op=mem
Fnstenv_m14byte, legacy, , legacy, D9, o16 D9 /6, FNSTENV m14byte, g=6 16b 32b 64b o16 op=mem
Fstenv_m14byte, legacy, , legacy, D9, 9B o16 D9 /6, FSTENV m14byte, g=6 16b 32b 64b fwait o16 op=mem
Fnstenv_m28byte, legacy, , legacy, D9, o32 D9 /6, FNSTENV m28byte, g=6 16b 32b 64b o32 op=mem
Fstenv_m28byte, legacy, , legacy, D9, 9B o32 D9 /6, FSTENV m28byte, g=6 16b 32b 64b fwait o32 op=mem
Fnstcw_m2byte, legacy, , legacy, D9, D9 /7, FNSTCW m2byte, g=7 16b 32b 64b op=mem
Fstcw_m2byte, legacy, , legacy, D9, 9B D9 /7, FSTCW m2byte, g=7 16b 32b 64b fwait op=mem
Fld_st0_sti, legacy, , legacy, D9C0, D9 C0+i, FLD ST(i), 16b 32b 64b op=st0;sti_opcode
Fxch_st0_sti, legacy, , legacy, D9C8, D9 C8+i, FXCH ST(i), 16b 32b 64b op=st0;sti_opcode
Fnop, legacy, , legacy, D9D0, D9 D0, FNOP, 16b 32b 64b
Fstpnce_sti, legacy, , legacy, D9D8, D9 D8+i, FSTPNCE ST(i), 16b 32b 64b op=sti_opcode
Fchs, legacy, , legacy, D9E0, D9 E0, FCHS, 16b 32b 64b
Fabs, legacy, , legacy, D9E1, D9 E1, FABS, 16b 32b 64b
Ftst, legacy, , legacy, D9E4, D9 E4, FTST, 16b 32b 64b
Fxam, legacy, , legacy, D9E5, D9 E5, FXAM, 16b 32b 64b
Fld1, legacy, , legacy, D9E8, D9 E8, FLD1, 16b 32b 64b
Fldl2t, legacy, , legacy, D9E9, D9 E9, FLDL2T, 16b 32b 64b
Fldl2e, legacy, , legacy, D9EA, D9 EA, FLDL2E, 16b 32b 64b
Fldpi, legacy, , legacy, D9EB, D9 EB, FLDPI, 16b 32b 64b
Fldlg2, legacy, , legacy, D9EC, D9 EC, FLDLG2, 16b 32b 64b
Fldln2, legacy, , legacy, D9ED, D9 ED, FLDLN2, 16b 32b 64b
Fldz, legacy, , legacy, D9EE, D9 EE, FLDZ, 16b 32b 64b
F2xm1, legacy, , legacy, D9F0, D9 F0, F2XM1, 16b 32b 64b
Fyl2x, legacy, , legacy, D9F1, D9 F1, FYL2X, 16b 32b 64b
Fptan, legacy, , legacy, D9F2, D9 F2, FPTAN, 16b 32b 64b
Fpatan, legacy, , legacy, D9F3, D9 F3, FPATAN, 16b 32b 64b
Fxtract, legacy, , legacy, D9F4, D9 F4, FXTRACT, 16b 32b 64b
Fprem1, legacy, , legacy, D9F5, D9 F5, FPREM1, 16b 32b 64b
Fdecstp, legacy, , legacy, D9F6, D9 F6, FDECSTP, 16b 32b 64b
Fincstp, legacy, , legacy, D9F7, D9 F7, FINCSTP, 16b 32b 64b
Fprem, legacy, , legacy, D9F8, D9 F8, FPREM, 16b 32b 64b
Fyl2xp1, legacy, , legacy, D9F9, D9 F9, FYL2XP1, 16b 32b 64b
Fsqrt, legacy, , legacy, D9FA, D9 FA, FSQRT, 16b 32b 64b
Fsincos, legacy, , legacy, D9FB, D9 FB, FSINCOS, 16b 32b 64b
Frndint, legacy, , legacy, D9FC, D9 FC, FRNDINT, 16b 32b 64b
Fscale, legacy, , legacy, D9FD, D9 FD, FSCALE, 16b 32b 64b
Fsin, legacy, , legacy, D9FE, D9 FE, FSIN, 16b 32b 64b
Fcos, legacy, , legacy, D9FF, D9 FF, FCOS, 16b 32b 64b
Fiadd_m32int, legacy, , legacy, DA, DA /0, FIADD m32int, g=0 16b 32b 64b op=mem
Fimul_m32int, legacy, , legacy, DA, DA /1, FIMUL m32int, g=1 16b 32b 64b op=mem
Ficom_m32int, legacy, , legacy, DA, DA /2, FICOM m32int, g=2 16b 32b 64b op=mem
Ficomp_m32int, legacy, , legacy, DA, DA /3, FICOMP m32int, g=3 16b 32b 64b op=mem
Fisub_m32int, legacy, , legacy, DA, DA /4, FISUB m32int, g=4 16b 32b 64b op=mem
Fisubr_m32int, legacy, , legacy, DA, DA /5, FISUBR m32int, g=5 16b 32b 64b op=mem
Fidiv_m32int, legacy, , legacy, DA, DA /6, FIDIV m32int, g=6 16b 32b 64b op=mem
Fidivr_m32int, legacy, , legacy, DA, DA /7, FIDIVR m32int, g=7 16b 32b 64b op=mem
Fcmovb_st0_sti, legacy, , legacy, DAC0, DA C0+i, FCMOVB ST(0)| ST(i), 16b 32b 64b op=st0;sti_opcode
Fcmove_st0_sti, legacy, , legacy, DAC8, DA C8+i, FCMOVE ST(0)| ST(i), 16b 32b 64b op=st0;sti_opcode
Fcmovbe_st0_sti, legacy, , legacy, DAD0, DA D0+i, FCMOVBE ST(0)| ST(i), 16b 32b 64b op=st0;sti_opcode
Fcmovu_st0_sti, legacy, , legacy, DAD8, DA D8+i, FCMOVU ST(0)| ST(i), 16b 32b 64b op=st0;sti_opcode
Fucompp, legacy, , legacy, DAE9, DA E9, FUCOMPP, 16b 32b 64b
Fild_m32int, legacy, , legacy, DB, DB /0, FILD m32int, g=0 16b 32b 64b op=mem
Fisttp_m32int, legacy, , legacy, DB, DB /1, FISTTP m32int, g=1 16b 32b 64b op=mem
Fist_m32int, legacy, , legacy, DB, DB /2, FIST m32int, g=2 16b 32b 64b op=mem
Fistp_m32int, legacy, , legacy, DB, DB /3, FISTP m32int, g=3 16b 32b 64b op=mem
Fld_m80fp, legacy, , legacy, DB, DB /5, FLD m80fp, g=5 16b 32b 64b op=mem
Fstp_m80fp, legacy, , legacy, DB, DB /7, FSTP m80fp, g=7 16b 32b 64b op=mem
Fcmovnb_st0_sti, legacy, , legacy, DBC0, DB C0+i, FCMOVNB ST(0)| ST(i), 16b 32b 64b op=st0;sti_opcode
Fcmovne_st0_sti, legacy, , legacy, DBC8, DB C8+i, FCMOVNE ST(0)| ST(i), 16b 32b 64b op=st0;sti_opcode
Fcmovnbe_st0_sti, legacy, , legacy, DBD0, DB D0+i, FCMOVNBE ST(0)| ST(i), 16b 32b 64b op=st0;sti_opcode
Fcmovnu_st0_sti, legacy, , legacy, DBD8, DB D8+i, FCMOVNU ST(0)| ST(i), 16b 32b 64b op=st0;sti_opcode
Fneni, legacy, , legacy, DBE0, DB E0, FNENI, 16b 32b 64b
Feni, legacy, , legacy, DBE0, 9B DB E0, FENI, 16b 32b 64b fwait
Fndisi, legacy, , legacy, DBE1, DB E1, FNDISI, 16b 32b 64b
Fdisi, legacy, , legacy, DBE1, 9B DB E1, FDISI, 16b 32b 64b fwait
Fnclex, legacy, , legacy, DBE2, DB E2, FNCLEX, 16b 32b 64b
Fclex, legacy, , legacy, DBE2, 9B DB E2, FCLEX, 16b 32b 64b fwait
Fninit, legacy, , legacy, DBE3, DB E3, FNINIT, 16b 32b 64b
Finit, legacy, , legacy, DBE3, 9B DB E3, FINIT, 16b 32b 64b fwait
Fnsetpm, legacy, , legacy, DBE4, DB E4, FNSETPM, 16b 32b 64b
Fsetpm, legacy, , legacy, DBE4, 9B DB E4, FSETPM, 16b 32b 64b fwait
Frstpm, legacy, , legacy, DBE5, DB E5, FRSTPM, 16b 32b
Fucomi_st0_sti, legacy, , legacy, DBE8, DB E8+i, FUCOMI ST| ST(i), 16b 32b 64b op=st0;sti_opcode
Fcomi_st0_sti, legacy, , legacy, DBF0, DB F0+i, FCOMI ST| ST(i), 16b 32b 64b op=st0;sti_opcode
Fadd_m64fp, legacy, , legacy, DC, DC /0, FADD m64fp, g=0 16b 32b 64b op=mem
Fmul_m64fp, legacy, , legacy, DC, DC /1, FMUL m64fp, g=1 16b 32b 64b op=mem
Fcom_m64fp, legacy, , legacy, DC, DC /2, FCOM m64fp, g=2 16b 32b 64b op=mem
Fcomp_m64fp, legacy, , legacy, DC, DC /3, FCOMP m64fp, g=3 16b 32b 64b op=mem
Fsub_m64fp, legacy, , legacy, DC, DC /4, FSUB m64fp, g=4 16b 32b 64b op=mem
Fsubr_m64fp, legacy, , legacy, DC, DC /5, FSUBR m64fp, g=5 16b 32b 64b op=mem
Fdiv_m64fp, legacy, , legacy, DC, DC /6, FDIV m64fp, g=6 16b 32b 64b op=mem
Fdivr_m64fp, legacy, , legacy, DC, DC /7, FDIVR m64fp, g=7 16b 32b 64b op=mem
Fadd_sti_st0, legacy, , legacy, DCC0, DC C0+i, FADD ST(i)| ST(0), 16b 32b 64b op=sti_opcode;st0
Fmul_sti_st0, legacy, , legacy, DCC8, DC C8+i, FMUL ST(i)| ST(0), 16b 32b 64b op=sti_opcode;st0
Fcom_st0_sti_DCD0, legacy, , legacy, DCD0, DC D0+i, FCOM ST(i), 16b 32b 64b op=st0;sti_opcode
Fcomp_st0_sti_DCD8, legacy, , legacy, DCD8, DC D8+i, FCOMP ST(i), 16b 32b 64b op=st0;sti_opcode
Fsubr_sti_st0, legacy, , legacy, DCE0, DC E0+i, FSUBR ST(i)| ST(0), 16b 32b 64b op=sti_opcode;st0
Fsub_sti_st0, legacy, , legacy, DCE8, DC E8+i, FSUB ST(i)| ST(0), 16b 32b 64b op=sti_opcode;st0
Fdivr_sti_st0, legacy, , legacy, DCF0, DC F0+i, FDIVR ST(i)| ST(0), 16b 32b 64b op=sti_opcode;st0
Fdiv_sti_st0, legacy, , legacy, DCF8, DC F8+i, FDIV ST(i)| ST(0), 16b 32b 64b op=sti_opcode;st0
Fld_m64fp, legacy, , legacy, DD, DD /0, FLD m64fp, g=0 16b 32b 64b op=mem
Fisttp_m64int, legacy, , legacy, DD, DD /1, FISTTP m64int, g=1 16b 32b 64b op=mem
Fst_m64fp, legacy, , legacy, DD, DD /2, FST m64fp, g=2 16b 32b 64b op=mem
Fstp_m64fp, legacy, , legacy, DD, DD /3, FSTP m64fp, g=3 16b 32b 64b op=mem
Frstor_m94byte, legacy, , legacy, DD, o16 DD /4, FRSTOR m94byte, g=4 16b 32b 64b o16 op=mem
Frstor_m108byte, legacy, , legacy, DD, o32 DD /4, FRSTOR m108byte, g=4 16b 32b 64b o32 op=mem
Fnsave_m94byte, legacy, , legacy, DD, o16 DD /6, FNSAVE m94byte, g=6 16b 32b 64b o16 op=mem
Fsave_m94byte, legacy, , legacy, DD, 9B o16 DD /6, FSAVE m94byte, g=6 16b 32b 64b fwait o16 op=mem
Fnsave_m108byte, legacy, , legacy, DD, o32 DD /6, FNSAVE m108byte, g=6 16b 32b 64b o32 op=mem
Fsave_m108byte, legacy, , legacy, DD, 9B o32 DD /6, FSAVE m108byte, g=6 16b 32b 64b fwait o32 op=mem
Fnstsw_m2byte, legacy, , legacy, DD, DD /7, FNSTSW m2byte, g=7 16b 32b 64b op=mem
Fstsw_m2byte, legacy, , legacy, DD, 9B DD /7, FSTSW m2byte, g=7 16b 32b 64b fwait op=mem
Ffree_sti, legacy, , legacy, DDC0, DD C0+i, FFREE ST(i), 16b 32b 64b op=sti_opcode
Fxch_st0_sti_DDC8, legacy, , legacy, DDC8, DD C8+i, FXCH ST(i), 16b 32b 64b op=st0;sti_opcode
Fst_sti, legacy, , legacy, DDD0, DD D0+i, FST ST(i), 16b 32b 64b op=sti_opcode
Fstp_sti, legacy, , legacy, DDD8, DD D8+i, FSTP ST(i), 16b 32b 64b op=sti_opcode
Fucom_st0_sti, legacy, , legacy, DDE0, DD E0+i, FUCOM ST(i), 16b 32b 64b op=st0;sti_opcode
Fucomp_st0_sti, legacy, , legacy, DDE8, DD E8+i, FUCOMP ST(i), 16b 32b 64b op=st0;sti_opcode
Fiadd_m16int, legacy, , legacy, DE, DE /0, FIADD m16int, g=0 16b 32b 64b op=mem
Fimul_m16int, legacy, , legacy, DE, DE /1, FIMUL m16int, g=1 16b 32b 64b op=mem
Ficom_m16int, legacy, , legacy, DE, DE /2, FICOM m16int, g=2 16b 32b 64b op=mem
Ficomp_m16int, legacy, , legacy, DE, DE /3, FICOMP m16int, g=3 16b 32b 64b op=mem
Fisub_m16int, legacy, , legacy, DE, DE /4, FISUB m16int, g=4 16b 32b 64b op=mem
Fisubr_m16int, legacy, , legacy, DE, DE /5, FISUBR m16int, g=5 16b 32b 64b op=mem
Fidiv_m16int, legacy, , legacy, DE, DE /6, FIDIV m16int, g=6 16b 32b 64b op=mem
Fidivr_m16int, legacy, , legacy, DE, DE /7, FIDIVR m16int, g=7 16b 32b 64b op=mem
Faddp_sti_st0, legacy, , legacy, DEC0, DE C0+i, FADDP ST(i)| ST(0), 16b 32b 64b op=sti_opcode;st0
Fmulp_sti_st0, legacy, , legacy, DEC8, DE C8+i, FMULP ST(i)| ST(0), 16b 32b 64b op=sti_opcode;st0
Fcomp_st0_sti_DED0, legacy, , legacy, DED0, DE D0+i, FCOMP ST(i), 16b 32b 64b op=st0;sti_opcode
Fcompp, legacy, , legacy, DED9, DE D9, FCOMPP, 16b 32b 64b
Fsubrp_sti_st0, legacy, , legacy, DEE0, DE E0+i, FSUBRP ST(i)| ST(0), 16b 32b 64b op=sti_opcode;st0
Fsubp_sti_st0, legacy, , legacy, DEE8, DE E8+i, FSUBP ST(i)| ST(0), 16b 32b 64b op=sti_opcode;st0
Fdivrp_sti_st0, legacy, , legacy, DEF0, DE F0+i, FDIVRP ST(i)| ST(0), 16b 32b 64b op=sti_opcode;st0
Fdivp_sti_st0, legacy, , legacy, DEF8, DE F8+i, FDIVP ST(i)| ST(0), 16b 32b 64b op=sti_opcode;st0
Fild_m16int, legacy, , legacy, DF, DF /0, FILD m16int, g=0 16b 32b 64b op=mem
Fisttp_m16int, legacy, , legacy, DF, DF /1, FISTTP m16int, g=1 16b 32b 64b op=mem
Fist_m16int, legacy, , legacy, DF, DF /2, FIST m16int, g=2 16b 32b 64b op=mem
Fistp_m16int, legacy, , legacy, DF, DF /3, FISTP m16int, g=3 16b 32b 64b op=mem
Fbld_m80bcd, legacy, , legacy, DF, DF /4, FBLD m80bcd, g=4 16b 32b 64b op=mem
Fild_m64int, legacy, , legacy, DF, DF /5, FILD m64int, g=5 16b 32b 64b op=mem
Fbstp_m80bcd, legacy, , legacy, DF, DF /6, FBSTP m80bcd, g=6 16b 32b 64b op=mem
Fistp_m64int, legacy, , legacy, DF, DF /7, FISTP m64int, g=7 16b 32b 64b op=mem
Ffreep_sti, legacy, , legacy, DFC0, DF C0+i, FFREEP ST(i), 16b 32b 64b op=sti_opcode
Fxch_st0_sti_DFC8, legacy, , legacy, DFC8, DF C8+i, FXCH ST(i), 16b 32b 64b op=st0;sti_opcode
Fstp_sti_DFD0, legacy, , legacy, DFD0, DF D0+i, FSTP ST(i), 16b 32b 64b op=sti_opcode
Fstp_sti_DFD8, legacy, , legacy, DFD8, DF D8+i, FSTP ST(i), 16b 32b 64b op=sti_opcode
Fnstsw_AX, legacy, , legacy, DFE0, DF E0, FNSTSW AX, 16b 32b 64b op=ax
Fstsw_AX, legacy, , legacy, DFE0, 9B DF E0, FSTSW AX, 16b 32b 64b fwait op=ax
Fstdw_AX, legacy, , legacy, DFE1, DF E1, FSTDW AX, 16b 32b op=ax
Fstsg_AX, legacy, , legacy, DFE2, DF E2, FSTSG AX, 16b 32b op=ax
Fucomip_st0_sti, legacy, , legacy, DFE8, DF E8+i, FUCOMIP ST| ST(i), 16b 32b 64b op=st0;sti_opcode
Fcomip_st0_sti, legacy, , legacy, DFF0, DF F0+i, FCOMIP ST| ST(i), 16b 32b 64b op=st0;sti_opcode
Loopne_rel8_16_CX, legacy, , legacy, E0, a16 o16 E0 cb, LOOPNE rel8, 16b 32b o16 a16 op=br16_1
Loopne_rel8_32_CX, legacy, , legacy, E0, a16 o32 E0 cb, LOOPNE rel8, 16b 32b o32 a16 op=br32_1
Loopne_rel8_16_ECX, legacy, , legacy, E0, a32 o16 E0 cb, LOOPNE rel8, 16b 32b 64b o16 a32 op=br16_1
Loopne_rel8_32_ECX, legacy, , legacy, E0, a32 o32 E0 cb, LOOPNE rel8, 16b 32b o32 a32 op=br32_1
Loopne_rel8_64_ECX, legacy, , legacy, E0, a32 E0 cb, LOOPNE rel8, 64b a32 op=br64_1
Loopne_rel8_16_RCX, legacy, , legacy, E0, o16 E0 cb, LOOPNE rel8, 64b o16 op=br16_1
Loopne_rel8_64_RCX, legacy, , legacy, E0, E0 cb, LOOPNE rel8, 64b op=br64_1
Loope_rel8_16_CX, legacy, , legacy, E1, a16 o16 E1 cb, LOOPE rel8, 16b 32b o16 a16 op=br16_1
Loope_rel8_32_CX, legacy, , legacy, E1, a16 o32 E1 cb, LOOPE rel8, 16b 32b o32 a16 op=br32_1
Loope_rel8_16_ECX, legacy, , legacy, E1, a32 o16 E1 cb, LOOPE rel8, 16b 32b 64b o16 a32 op=br16_1
Loope_rel8_32_ECX, legacy, , legacy, E1, a32 o32 E1 cb, LOOPE rel8, 16b 32b o32 a32 op=br32_1
Loope_rel8_64_ECX, legacy, , legacy, E1, a32 E1 cb, LOOPE rel8, 64b a32 op=br64_1
Loope_rel8_16_RCX, legacy, , legacy, E1, o16 E1 cb, LOOPE rel8, 64b o16 op=br16_1
Loope_rel8_64_RCX, legacy, , legacy, E1, E1 cb, LOOPE rel8, 64b op=br64_1
Loop_rel8_16_CX, legacy, , legacy, E2, a16 o16 E2 cb, LOOP rel8, 16b 32b o16 a16 op=br16_1
Loop_rel8_32_CX, legacy, , legacy, E2, a16 o32 E2 cb, LOOP rel8, 16b 32b o32 a16 op=br32_1
Loop_rel8_16_ECX, legacy, , legacy, E2, a32 o16 E2 cb, LOOP rel8, 16b 32b 64b o16 a32 op=br16_1
Loop_rel8_32_ECX, legacy, , legacy, E2, a32 o32 E2 cb, LOOP rel8, 16b 32b o32 a32 op=br32_1
Loop_rel8_64_ECX, legacy, , legacy, E2, a32 E2 cb, LOOP rel8, 64b a32 op=br64_1
Loop_rel8_16_RCX, legacy, , legacy, E2, o16 E2 cb, LOOP rel8, 64b o16 op=br16_1
Loop_rel8_64_RCX, legacy, , legacy, E2, E2 cb, LOOP rel8, 64b op=br64_1
Jcxz_rel8_16, legacy, , legacy, E3, a16 o16 E3 cb, JCXZ rel8, 16b 32b o16 a16 op=br16_1
Jcxz_rel8_32, legacy, , legacy, E3, a16 o32 E3 cb, JCXZ rel8, 16b 32b o32 a16 op=br32_1
Jecxz_rel8_16, legacy, , legacy, E3, a32 o16 E3 cb, JECXZ rel8, 16b 32b 64b o16 a32 op=br16_1
Jecxz_rel8_32, legacy, , legacy, E3, a32 o32 E3 cb, JECXZ rel8, 16b 32b o32 a32 op=br32_1
Jecxz_rel8_64, legacy, , legacy, E3, a32 E3 cb, JECXZ rel8, 64b a32 op=br64_1
Jrcxz_rel8_16, legacy, , legacy, E3, o16 E3 cb, JRCXZ rel8, 64b o16 op=br16_1
Jrcxz_rel8_64, legacy, , legacy, E3, E3 cb, JRCXZ rel8, 64b op=br64_1
In_AL_imm8, legacy, , legacy, E4, E4 ib, IN AL| imm8, 16b 32b 64b op=al;imm8
In_AX_imm8, legacy, , legacy, E5, o16 E5 ib, IN AX| imm8, 16b 32b 64b o16 op=ax;imm8
In_EAX_imm8, legacy, , legacy, E5, o32 E5 ib, IN EAX| imm8, 16b 32b 64b o32 op=eax;imm8
Out_imm8_AL, legacy, , legacy, E6, E6 ib, OUT imm8| AL, 16b 32b 64b op=imm8;al
Out_imm8_AX, legacy, , legacy, E7, o16 E7 ib, OUT imm8| AX, 16b 32b 64b o16 op=imm8;ax
Out_imm8_EAX, legacy, , legacy, E7, o32 E7 ib, OUT imm8| EAX, 16b 32b 64b o32 op=imm8;eax
Call_rel16, legacy, , legacy, E8, o16 E8 cw, CALL rel16, 16b 32b 64b o16 op=br16_2 bnd
Call_rel32_32, legacy, , legacy, E8, o32 E8 cd, CALL rel32, 16b 32b o32 op=br32_4 bnd
Call_rel32_64, legacy, , legacy, E8, E8 cd, CALL rel32, 64b op=br64_4 bnd
Jmp_rel16, legacy, , legacy, E9, o16 E9 cw, JMP rel16, 16b 32b 64b o16 op=br16_2 bnd
Jmp_rel32_32, legacy, , legacy, E9, o32 E9 cd, JMP rel32, 16b 32b o32 op=br32_4 bnd
Jmp_rel32_64, legacy, , legacy, E9, E9 cd, JMP rel32, 64b op=br64_4 bnd
Jmp_ptr1616, legacy, , legacy, EA, o16 EA cd, JMP ptr16:16, 16b 32b o16 op=farbr2_2
Jmp_ptr1632, legacy, , legacy, EA, o32 EA cp, JMP ptr16:32, 16b 32b o32 op=farbr4_2
Jmp_rel8_16, legacy, , legacy, EB, o16 EB cb, JMP rel8, 16b 32b 64b o16 op=br16_1
Jmp_rel8_32, legacy, , legacy, EB, o32 EB cb, JMP rel8, 16b 32b o32 op=br32_1
Jmp_rel8_64, legacy, , legacy, EB, EB cb, JMP rel8, 64b op=br64_1
In_AL_DX, legacy, , legacy, EC, EC, IN AL| DX, 16b 32b 64b op=al;dx
In_AX_DX, legacy, , legacy, ED, o16 ED, IN AX| DX, 16b 32b 64b o16 op=ax;dx
In_EAX_DX, legacy, , legacy, ED, o32 ED, IN EAX| DX, 16b 32b 64b o32 op=eax;dx
Out_DX_AL, legacy, , legacy, EE, EE, OUT DX| AL, 16b 32b 64b op=dx;al
Out_DX_AX, legacy, , legacy, EF, o16 EF, OUT DX| AX, 16b 32b 64b o16 op=dx;ax
Out_DX_EAX, legacy, , legacy, EF, o32 EF, OUT DX| EAX, 16b 32b 64b o32 op=dx;eax
Int1, legacy, , legacy, F1, F1, INT1, 16b 32b 64b
Hlt, legacy, , legacy, F4, F4, HLT, 16b 32b 64b
Cmc, legacy, , legacy, F5, F5, CMC, 16b 32b 64b
Test_rm8_imm8, legacy, , legacy, F6, F6 /0 ib, TEST r/m8| imm8, g=0 16b 32b 64b op=r8_or_mem;imm8
Test_rm8_imm8_F6r1, legacy, , legacy, F6, F6 /1 ib, TEST r/m8| imm8, g=1 16b 32b 64b op=r8_or_mem;imm8
Not_rm8, legacy, , legacy, F6, F6 /2, NOT r/m8, g=2 16b 32b 64b op=r8_or_mem lock xacquire xrelease
Neg_rm8, legacy, , legacy, F6, F6 /3, NEG r/m8, g=3 16b 32b 64b op=r8_or_mem lock xacquire xrelease
Mul_rm8, legacy, , legacy, F6, F6 /4, MUL r/m8, g=4 16b 32b 64b op=r8_or_mem
Imul_rm8, legacy, , legacy, F6, F6 /5, IMUL r/m8, g=5 16b 32b 64b op=r8_or_mem
Div_rm8, legacy, , legacy, F6, F6 /6, DIV r/m8, g=6 16b 32b 64b op=r8_or_mem
Idiv_rm8, legacy, , legacy, F6, F6 /7, IDIV r/m8, g=7 16b 32b 64b op=r8_or_mem
Test_rm16_imm16, legacy, , legacy, F7, o16 F7 /0 iw, TEST r/m16| imm16, g=0 16b 32b 64b o16 op=r16_or_mem;imm16
Test_rm32_imm32, legacy, , legacy, F7, o32 F7 /0 id, TEST r/m32| imm32, g=0 16b 32b 64b o32 op=r32_or_mem;imm32
Test_rm64_imm32, legacy, , legacy, F7, REX.W F7 /0 id, TEST r/m64| imm32, g=0 64b o64 op=r64_or_mem;imm32sex64
Test_rm16_imm16_F7r1, legacy, , legacy, F7, o16 F7 /1 iw, TEST r/m16| imm16, g=1 16b 32b 64b o16 op=r16_or_mem;imm16
Test_rm32_imm32_F7r1, legacy, , legacy, F7, o32 F7 /1 id, TEST r/m32| imm32, g=1 16b 32b 64b o32 op=r32_or_mem;imm32
Test_rm64_imm32_F7r1, legacy, , legacy, F7, REX.W F7 /1 id, TEST r/m64| imm32, g=1 64b o64 op=r64_or_mem;imm32sex64
Not_rm16, legacy, , legacy, F7, o16 F7 /2, NOT r/m16, g=2 16b 32b 64b o16 op=r16_or_mem lock xacquire xrelease
Not_rm32, legacy, , legacy, F7, o32 F7 /2, NOT r/m32, g=2 16b 32b 64b o32 op=r32_or_mem lock xacquire xrelease
Not_rm64, legacy, , legacy, F7, REX.W F7 /2, NOT r/m64, g=2 64b o64 op=r64_or_mem lock xacquire xrelease
Neg_rm16, legacy, , legacy, F7, o16 F7 /3, NEG r/m16, g=3 16b 32b 64b o16 op=r16_or_mem lock xacquire xrelease
Neg_rm32, legacy, , legacy, F7, o32 F7 /3, NEG r/m32, g=3 16b 32b 64b o32 op=r32_or_mem lock xacquire xrelease
Neg_rm64, legacy, , legacy, F7, REX.W F7 /3, NEG r/m64, g=3 64b o64 op=r64_or_mem lock xacquire xrelease
Mul_rm16, legacy, , legacy, F7, o16 F7 /4, MUL r/m16, g=4 16b 32b 64b o16 op=r16_or_mem
Mul_rm32, legacy, , legacy, F7, o32 F7 /4, MUL r/m32, g=4 16b 32b 64b o32 op=r32_or_mem
Mul_rm64, legacy, , legacy, F7, REX.W F7 /4, MUL r/m64, g=4 64b o64 op=r64_or_mem
Imul_rm16, legacy, , legacy, F7, o16 F7 /5, IMUL r/m16, g=5 16b 32b 64b o16 op=r16_or_mem
Imul_rm32, legacy, , legacy, F7, o32 F7 /5, IMUL r/m32, g=5 16b 32b 64b o32 op=r32_or_mem
Imul_rm64, legacy, , legacy, F7, REX.W F7 /5, IMUL r/m64, g=5 64b o64 op=r64_or_mem
Div_rm16, legacy, , legacy, F7, o16 F7 /6, DIV r/m16, g=6 16b 32b 64b o16 op=r16_or_mem
Div_rm32, legacy, , legacy, F7, o32 F7 /6, DIV r/m32, g=6 16b 32b 64b o32 op=r32_or_mem
Div_rm64, legacy, , legacy, F7, REX.W F7 /6, DIV r/m64, g=6 64b o64 op=r64_or_mem
Idiv_rm16, legacy, , legacy, F7, o16 F7 /7, IDIV r/m16, g=7 16b 32b 64b o16 op=r16_or_mem
Idiv_rm32, legacy, , legacy, F7, o32 F7 /7, IDIV r/m32, g=7 16b 32b 64b o32 op=r32_or_mem
Idiv_rm64, legacy, , legacy, F7, REX.W F7 /7, IDIV r/m64, g=7 64b o64 op=r64_or_mem
Clc, legacy, , legacy, F8, F8, CLC, 16b 32b 64b
Stc, legacy, , legacy, F9, F9, STC, 16b 32b 64b
Cli, legacy, , legacy, FA, FA, CLI, 16b 32b 64b
Sti, legacy, , legacy, FB, FB, STI, 16b 32b 64b
Cld, legacy, , legacy, FC, FC, CLD, 16b 32b 64b
Std, legacy, , legacy, FD, FD, STD, 16b 32b 64b
Inc_rm8, legacy, , legacy, FE, FE /0, INC r/m8, g=0 16b 32b 64b op=r8_or_mem lock xacquire xrelease
Dec_rm8, legacy, , legacy, FE, FE /1, DEC r/m8, g=1 16b 32b 64b op=r8_or_mem lock xacquire xrelease
Inc_rm16, legacy, , legacy, FF, o16 FF /0, INC r/m16, g=0 16b 32b 64b o16 op=r16_or_mem lock xacquire xrelease
Inc_rm32, legacy, , legacy, FF, o32 FF /0, INC r/m32, g=0 16b 32b 64b o32 op=r32_or_mem lock xacquire xrelease
Inc_rm64, legacy, , legacy, FF, REX.W FF /0, INC r/m64, g=0 64b o64 op=r64_or_mem lock xacquire xrelease
Dec_rm16, legacy, , legacy, FF, o16 FF /1, DEC r/m16, g=1 16b 32b 64b o16 op=r16_or_mem lock xacquire xrelease
Dec_rm32, legacy, , legacy, FF, o32 FF /1, DEC r/m32, g=1 16b 32b 64b o32 op=r32_or_mem lock xacquire xrelease
Dec_rm64, legacy, , legacy, FF, REX.W FF /1, DEC r/m64, g=1 64b o64 op=r64_or_mem lock xacquire xrelease
Call_rm16, legacy, , legacy, FF, o16 FF /2, CALL r/m16, g=2 16b 32b 64b o16 op=r16_or_mem bnd notrack
Call_rm32, legacy, , legacy, FF, o32 FF /2, CALL r/m32, g=2 16b 32b o32 op=r32_or_mem bnd notrack
Call_rm64, legacy, , legacy, FF, FF /2, CALL r/m64, g=2 64b op=r64_or_mem bnd notrack
Call_m1616, legacy, , legacy, FF, o16 FF /3, CALL m16:16, g=3 16b 32b 64b o16 op=mem
Call_m1632, legacy, , legacy, FF, o32 FF /3, CALL m16:32, g=3 16b 32b 64b o32 op=mem
Call_m1664, legacy, , legacy, FF, REX.W FF /3, CALL m16:64, g=3 64b o64 op=mem
Jmp_rm16, legacy, , legacy, FF, o16 FF /4, JMP r/m16, g=4 16b 32b 64b o16 op=r16_or_mem bnd notrack
Jmp_rm32, legacy, , legacy, FF, o32 FF /4, JMP r/m32, g=4 16b 32b o32 op=r32_or_mem bnd notrack
Jmp_rm64, legacy, , legacy, FF, FF /4, JMP r/m64, g=4 64b op=r64_or_mem bnd notrack
Jmp_m1616, legacy, , legacy, FF, o16 FF /5, JMP m16:16, g=5 16b 32b 64b o16 op=mem
Jmp_m1632, legacy, , legacy, FF, o32 FF /5, JMP m16:32, g=5 16b 32b 64b o32 op=mem
Jmp_m1664, legacy, , legacy, FF, REX.W FF /5, JMP m16:64, g=5 64b o64 op=mem
Push_rm16, legacy, , legacy, FF, o16 FF /6, PUSH r/m16, g=6 16b 32b 64b o16 op=r16_or_mem
Push_rm32, legacy, , legacy, FF, o32 FF /6, PUSH r/m32, g=6 16b 32b o32 op=r32_or_mem
Push_rm64, legacy, , legacy, FF, FF /6, PUSH r/m64, g=6 64b op=r64_or_mem
Sldt_rm16, legacy, , 0F, 00, o16 0F 00 /0, SLDT r/m16, g=0 16b 32b 64b o16 op=r16_or_mem
Sldt_r32m16, legacy, , 0F, 00, o32 0F 00 /0, SLDT r32/m16, g=0 16b 32b 64b o32 op=r32_or_mem
Sldt_r64m16, legacy, , 0F, 00, REX.W 0F 00 /0, SLDT r64/m16, g=0 64b o64 op=r64_or_mem
Str_rm16, legacy, , 0F, 00, o16 0F 00 /1, STR r/m16, g=1 16b 32b 64b o16 op=r16_or_mem
Str_r32m16, legacy, , 0F, 00, o32 0F 00 /1, STR r32/m16, g=1 16b 32b 64b o32 op=r32_or_mem
Str_r64m16, legacy, , 0F, 00, REX.W 0F 00 /1, STR r64/m16, g=1 64b o64 op=r64_or_mem
Lldt_rm16, legacy, , 0F, 00, o16 0F 00 /2, LLDT r/m16, g=2 16b 32b 64b o16 op=r16_or_mem
Lldt_r32m16, legacy, , 0F, 00, o32 0F 00 /2, LLDT r32/m16, g=2 16b 32b 64b o32 op=r32_or_mem
Lldt_r64m16, legacy, , 0F, 00, REX.W 0F 00 /2, LLDT r64/m16, g=2 64b o64 op=r64_or_mem
Ltr_rm16, legacy, , 0F, 00, o16 0F 00 /3, LTR r/m16, g=3 16b 32b 64b o16 op=r16_or_mem
Ltr_r32m16, legacy, , 0F, 00, o32 0F 00 /3, LTR r32/m16, g=3 16b 32b 64b o32 op=r32_or_mem
Ltr_r64m16, legacy, , 0F, 00, REX.W 0F 00 /3, LTR r64/m16, g=3 64b o64 op=r64_or_mem
Verr_rm16, legacy, , 0F, 00, o16 0F 00 /4, VERR r/m16, g=4 16b 32b 64b o16 op=r16_or_mem
Verr_r32m16, legacy, , 0F, 00, o32 0F 00 /4, VERR r32/m16, g=4 16b 32b 64b o32 op=r32_or_mem
Verr_r64m16, legacy, , 0F, 00, REX.W 0F 00 /4, VERR r64/m16, g=4 64b o64 op=r64_or_mem
Verw_rm16, legacy, , 0F, 00, o16 0F 00 /5, VERW r/m16, g=5 16b 32b 64b o16 op=r16_or_mem
Verw_r32m16, legacy, , 0F, 00, o32 0F 00 /5, VERW r32/m16, g=5 16b 32b 64b o32 op=r32_or_mem
Verw_r64m16, legacy, , 0F, 00, REX.W 0F 00 /5, VERW r64/m16, g=5 64b o64 op=r64_or_mem
Jmpe_rm16, legacy, , 0F, 00, o16 0F 00 /6, JMPE r/m16, g=6 16b 32b o16 op=r16_or_mem
Jmpe_rm32, legacy, , 0F, 00, o32 0F 00 /6, JMPE r/m32, g=6 16b 32b o32 op=r32_or_mem
Sgdt_m1632_16, legacy, , 0F, 01, o16 0F 01 /0, SGDT m, g=0 16b 32b o16 op=mem
Sgdt_m1632, legacy, , 0F, 01, o32 0F 01 /0, SGDT m, g=0 16b 32b o32 op=mem
Sgdt_m1664, legacy, , 0F, 01, 0F 01 /0, SGDT m, g=0 64b op=mem
Sidt_m1632_16, legacy, , 0F, 01, o16 0F 01 /1, SIDT m, g=1 16b 32b o16 op=mem
Sidt_m1632, legacy, , 0F, 01, o32 0F 01 /1, SIDT m, g=1 16b 32b o32 op=mem
Sidt_m1664, legacy, , 0F, 01, 0F 01 /1, SIDT m, g=1 64b op=mem
Lgdt_m1632_16, legacy, , 0F, 01, o16 0F 01 /2, LGDT m16&32, g=2 16b 32b o16 op=mem
Lgdt_m1632, legacy, , 0F, 01, o32 0F 01 /2, LGDT m16&32, g=2 16b 32b o32 op=mem
Lgdt_m1664, legacy, , 0F, 01, 0F 01 /2, LGDT m16&64, g=2 64b op=mem
Lidt_m1632_16, legacy, , 0F, 01, o16 0F 01 /3, LIDT m16&32, g=3 16b 32b o16 op=mem
Lidt_m1632, legacy, , 0F, 01, o32 0F 01 /3, LIDT m16&32, g=3 16b 32b o32 op=mem
Lidt_m1664, legacy, , 0F, 01, 0F 01 /3, LIDT m16&64, g=3 64b op=mem
Smsw_rm16, legacy, , 0F, 01, o16 0F 01 /4, SMSW r/m16, g=4 16b 32b 64b o16 op=r16_or_mem
Smsw_r32m16, legacy, , 0F, 01, o32 0F 01 /4, SMSW r32/m16, g=4 16b 32b 64b o32 op=r32_or_mem
Smsw_r64m16, legacy, , 0F, 01, REX.W 0F 01 /4, SMSW r64/m16, g=4 64b o64 op=r64_or_mem
Rstorssp_m64, legacy, F3, 0F, 01, F3 0F 01 /5, RSTORSSP m64, g=5 16b 32b 64b op=mem
Lmsw_rm16, legacy, , 0F, 01, o16 0F 01 /6, LMSW r/m16, g=6 16b 32b 64b o16 op=r16_or_mem
Lmsw_r32m16, legacy, , 0F, 01, o32 0F 01 /6, LMSW r32/m16, g=6 16b 32b 64b o32 op=r32_or_mem
Lmsw_r64m16, legacy, , 0F, 01, REX.W 0F 01 /6, LMSW r64/m16, g=6 64b o64 op=r64_or_mem
Invlpg_m, legacy, , 0F, 01, 0F 01 /7, INVLPG m, g=7 16b 32b 64b op=mem
Enclv, legacy, NP, 0F, 01C0, NP 0F 01 C0, ENCLV, 16b 32b 64b
Vmcall, legacy, NP, 0F, 01C1, NP 0F 01 C1, VMCALL, 16b 32b 64b
Vmlaunch, legacy, NP, 0F, 01C2, NP 0F 01 C2, VMLAUNCH, 16b 32b 64b
Vmresume, legacy, NP, 0F, 01C3, NP 0F 01 C3, VMRESUME, 16b 32b 64b
Vmxoff, legacy, NP, 0F, 01C4, NP 0F 01 C4, VMXOFF, 16b 32b 64b
Pconfig, legacy, NP, 0F, 01C5, NP 0F 01 C5, PCONFIG, 16b 32b 64b
Monitorw, legacy, NP, 0F, 01C8, a16 NP 0F 01 C8, MONITOR, 16b 32b a16
Monitord, legacy, NP, 0F, 01C8, a32 NP 0F 01 C8, MONITOR, 16b 32b 64b a32
Monitorq, legacy, NP, 0F, 01C8, NP 0F 01 C8, MONITOR, 64b
Mwait, legacy, NP, 0F, 01C9, NP 0F 01 C9, MWAIT, 16b 32b 64b
Clac, legacy, NP, 0F, 01CA, NP 0F 01 CA, CLAC, 16b 32b 64b
Stac, legacy, NP, 0F, 01CB, NP 0F 01 CB, STAC, 16b 32b 64b
Encls, legacy, NP, 0F, 01CF, NP 0F 01 CF, ENCLS, 16b 32b 64b
Xgetbv, legacy, NP, 0F, 01D0, NP 0F 01 D0, XGETBV, 16b 32b 64b
Xsetbv, legacy, NP, 0F, 01D1, NP 0F 01 D1, XSETBV, 16b 32b 64b
Vmfunc, legacy, NP, 0F, 01D4, NP 0F 01 D4, VMFUNC, 16b 32b 64b
Xend, legacy, NP, 0F, 01D5, NP 0F 01 D5, XEND, 16b 32b 64b
Xtest, legacy, NP, 0F, 01D6, NP 0F 01 D6, XTEST, 16b 32b 64b
Enclu, legacy, NP, 0F, 01D7, NP 0F 01 D7, ENCLU, 16b 32b 64b
Vmrunw, legacy, , 0F, 01D8, a16 0F 01 D8, VMRUN, 16b 32b a16
Vmrund, legacy, , 0F, 01D8, a32 0F 01 D8, VMRUN, 16b 32b 64b a32
Vmrunq, legacy, , 0F, 01D8, 0F 01 D8, VMRUN, 64b
Vmmcall, legacy, , 0F, 01D9, 0F 01 D9, VMMCALL, 16b 32b 64b
Vmloadw, legacy, , 0F, 01DA, a16 0F 01 DA, VMLOAD, 16b 32b a16
Vmloadd, legacy, , 0F, 01DA, a32 0F 01 DA, VMLOAD, 16b 32b 64b a32
Vmloadq, legacy, , 0F, 01DA, 0F 01 DA, VMLOAD, 64b
Vmsavew, legacy, , 0F, 01DB, a16 0F 01 DB, VMSAVE, 16b 32b a16
Vmsaved, legacy, , 0F, 01DB, a32 0F 01 DB, VMSAVE, 16b 32b 64b a32
Vmsaveq, legacy, , 0F, 01DB, 0F 01 DB, VMSAVE, 64b
Stgi, legacy, , 0F, 01DC, 0F 01 DC, STGI, 16b 32b 64b
Clgi, legacy, , 0F, 01DD, 0F 01 DD, CLGI, 16b 32b 64b
Skinit, legacy, , 0F, 01DE, 0F 01 DE, SKINIT, 16b 32b 64b
Invlpgaw, legacy, , 0F, 01DF, a16 0F 01 DF, INVLPGA, 16b 32b a16
Invlpgad, legacy, , 0F, 01DF, a32 0F 01 DF, INVLPGA, 16b 32b 64b a32
Invlpgaq, legacy, , 0F, 01DF, 0F 01 DF, INVLPGA, 64b
Setssbsy, legacy, F3, 0F, 01E8, F3 0F 01 E8, SETSSBSY, 16b 32b 64b
Saveprevssp, legacy, F3, 0F, 01EA, F3 0F 01 EA, SAVEPREVSSP, 16b 32b 64b
Rdpkru, legacy, NP, 0F, 01EE, NP 0F 01 EE, RDPKRU, 16b 32b 64b
Wrpkru, legacy, NP, 0F, 01EF, NP 0F 01 EF, WRPKRU, 16b 32b 64b
Swapgs, legacy, , 0F, 01F8, 0F 01 F8, SWAPGS, 64b
Rdtscp, legacy, , 0F, 01F9, 0F 01 F9, RDTSCP, 16b 32b 64b
Monitorxw, legacy, NP, 0F, 01FA, a16 NP 0F 01 FA, MONITORX, 16b 32b a16
Monitorxd, legacy, NP, 0F, 01FA, a32 NP 0F 01 FA, MONITORX, 16b 32b 64b a32
Monitorxq, legacy, NP, 0F, 01FA, NP 0F 01 FA, MONITORX, 64b
Mcommit, legacy, F3, 0F, 01FA, F3 0F 01 FA, MCOMMIT, 16b 32b 64b
Mwaitx, legacy, , 0F, 01FB, 0F 01 FB, MWAITX, 16b 32b 64b
Clzerow, legacy, , 0F, 01FC, a16 0F 01 FC, CLZERO, 16b 32b a16
Clzerod, legacy, , 0F, 01FC, a32 0F 01 FC, CLZERO, 16b 32b 64b a32
Clzeroq, legacy, , 0F, 01FC, 0F 01 FC, CLZERO, 64b
Rdpru, legacy, , 0F, 01FD, 0F 01 FD, RDPRU, 16b 32b 64b
Lar_r16_rm16, legacy, , 0F, 02, o16 0F 02 /r, LAR r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Lar_r32_r32m16, legacy, , 0F, 02, o32 0F 02 /r, LAR r32| r32/m16, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Lar_r64_r64m16, legacy, , 0F, 02, REX.W 0F 02 /r, LAR r64| r64/m16, 64b o64 op=r64_reg;r64_or_mem
Lsl_r16_rm16, legacy, , 0F, 03, o16 0F 03 /r, LSL r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Lsl_r32_r32m16, legacy, , 0F, 03, o32 0F 03 /r, LSL r32| r32/m16, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Lsl_r64_r64m16, legacy, , 0F, 03, REX.W 0F 03 /r, LSL r64| r64/m16, 64b o64 op=r64_reg;r64_or_mem
Loadallreset286, legacy, , 0F, 04, 0F 04, LOADALL, 16b 32b
Loadall286, legacy, , 0F, 05, 0F 05, LOADALL, 16b 32b
Syscall, legacy, , 0F, 05, 0F 05, SYSCALL, 16b 32b 64b
Clts, legacy, , 0F, 06, 0F 06, CLTS, 16b 32b 64b
Loadall386, legacy, , 0F, 07, 0F 07, LOADALL, 16b 32b
Sysretd, legacy, , 0F, 07, 0F 07, SYSRET, 16b 32b 64b
Sysretq, legacy, , 0F, 07, REX.W 0F 07, SYSRET, 64b o64
Invd, legacy, , 0F, 08, 0F 08, INVD, 16b 32b 64b
Wbinvd, legacy, , 0F, 09, 0F 09, WBINVD, 16b 32b 64b
Wbnoinvd, legacy, F3, 0F, 09, F3 0F 09, WBNOINVD, 16b 32b 64b
Cl1invmb, legacy, , 0F, 0A, 0F 0A, CL1INVMB, 16b 32b 64b
Ud2, legacy, , 0F, 0B, 0F 0B, UD2, 16b 32b 64b
ReservedNop_rm16_r16_0F0D, legacy, , 0F, 0D, o16 0F 0D /r, RESERVEDNOP r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg
ReservedNop_rm32_r32_0F0D, legacy, , 0F, 0D, o32 0F 0D /r, RESERVEDNOP r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg
ReservedNop_rm64_r64_0F0D, legacy, , 0F, 0D, REX.W 0F 0D /r, RESERVEDNOP r/m64| r64, 64b o64 op=r64_or_mem;r64_reg
Prefetch_m8, legacy, , 0F, 0D, 0F 0D /0, PREFETCH m8, g=0 16b 32b 64b op=mem
Prefetchw_m8, legacy, , 0F, 0D, 0F 0D /1, PREFETCHW m8, g=1 16b 32b 64b op=mem
Prefetchwt1_m8, legacy, , 0F, 0D, 0F 0D /2, PREFETCHWT1 m8, g=2 16b 32b 64b op=mem
Femms, legacy, , 0F, 0E, 0F 0E, FEMMS, 16b 32b 64b
Umov_rm8_r8, legacy, , 0F, 10, 0F 10 /r, UMOV r/m8| r8, 16b 32b op=r8_or_mem;r8_reg
Umov_rm16_r16, legacy, , 0F, 11, o16 0F 11 /r, UMOV r/m16| r16, 16b 32b o16 op=r16_or_mem;r16_reg
Umov_rm32_r32, legacy, , 0F, 11, o32 0F 11 /r, UMOV r/m32| r32, 16b 32b o32 op=r32_or_mem;r32_reg
Umov_r8_rm8, legacy, , 0F, 12, 0F 12 /r, UMOV r8| r/m8, 16b 32b op=r8_reg;r8_or_mem
Umov_r16_rm16, legacy, , 0F, 13, o16 0F 13 /r, UMOV r16| r/m16, 16b 32b o16 op=r16_reg;r16_or_mem
Umov_r32_rm32, legacy, , 0F, 13, o32 0F 13 /r, UMOV r32| r/m32, 16b 32b o32 op=r32_reg;r32_or_mem
Movups_xmm_xmmm128, legacy, NP, 0F, 10, NP 0F 10 /r, MOVUPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmovups_xmm_xmmm128, VEX, NP, 0F, 10, VEX.128.0F.WIG 10 /r, VMOVUPS xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vmovups_ymm_ymmm256, VEX, NP, 0F, 10, VEX.256.0F.WIG 10 /r, VMOVUPS ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
EVEX_Vmovups_xmm_k1z_xmmm128, EVEX, NP, 0F, 10, EVEX.128.0F.W0 10 /r, VMOVUPS xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vmovups_ymm_k1z_ymmm256, EVEX, NP, 0F, 10, EVEX.256.0F.W0 10 /r, VMOVUPS ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vmovups_zmm_k1z_zmmm512, EVEX, NP, 0F, 10, EVEX.512.0F.W0 10 /r, VMOVUPS zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_Mem_512 k z
Movupd_xmm_xmmm128, legacy, 66, 0F, 10, 66 0F 10 /r, MOVUPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmovupd_xmm_xmmm128, VEX, 66, 0F, 10, VEX.128.66.0F.WIG 10 /r, VMOVUPD xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vmovupd_ymm_ymmm256, VEX, 66, 0F, 10, VEX.256.66.0F.WIG 10 /r, VMOVUPD ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
EVEX_Vmovupd_xmm_k1z_xmmm128, EVEX, 66, 0F, 10, EVEX.128.66.0F.W1 10 /r, VMOVUPD xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vmovupd_ymm_k1z_ymmm256, EVEX, 66, 0F, 10, EVEX.256.66.0F.W1 10 /r, VMOVUPD ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vmovupd_zmm_k1z_zmmm512, EVEX, 66, 0F, 10, EVEX.512.66.0F.W1 10 /r, VMOVUPD zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_Mem_512 k z
Movss_xmm_xmmm32, legacy, F3, 0F, 10, F3 0F 10 /r, MOVSS xmm1| xmm2/m32, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmovss_xmm_xmm_xmm, VEX, F3, 0F, 10, VEX.LIG.F3.0F.WIG 10 /r, VMOVSS xmm1| xmm2| xmm3, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_rm
VEX_Vmovss_xmm_m32, VEX, F3, 0F, 10, VEX.LIG.F3.0F.WIG 10 /r, VMOVSS xmm1| m32, 16b 32b 64b LIG WIG op=xmm_reg;mem
EVEX_Vmovss_xmm_k1z_xmm_xmm, EVEX, F3, 0F, 10, EVEX.LIG.F3.0F.W0 10 /r, VMOVSS xmm1 {k1}{z}| xmm2| xmm3, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_rm tt=Tuple1_Scalar k z
EVEX_Vmovss_xmm_k1z_m32, EVEX, F3, 0F, 10, EVEX.LIG.F3.0F.W0 10 /r, VMOVSS xmm1 {k1}{z}| m32, 16b 32b 64b LIG W0 op=xmm_reg;mem tt=Tuple1_Scalar k z
Movsd_xmm_xmmm64, legacy, F2, 0F, 10, F2 0F 10 /r, MOVSD xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmovsd_xmm_xmm_xmm, VEX, F2, 0F, 10, VEX.LIG.F2.0F.WIG 10 /r, VMOVSD xmm1| xmm2| xmm3, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_rm
VEX_Vmovsd_xmm_m64, VEX, F2, 0F, 10, VEX.LIG.F2.0F.WIG 10 /r, VMOVSD xmm1| m64, 16b 32b 64b LIG WIG op=xmm_reg;mem
EVEX_Vmovsd_xmm_k1z_xmm_xmm, EVEX, F2, 0F, 10, EVEX.LIG.F2.0F.W1 10 /r, VMOVSD xmm1 {k1}{z}| xmm2| xmm3, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_rm tt=Tuple1_Scalar k z
EVEX_Vmovsd_xmm_k1z_m64, EVEX, F2, 0F, 10, EVEX.LIG.F2.0F.W1 10 /r, VMOVSD xmm1 {k1}{z}| m64, 16b 32b 64b LIG W1 op=xmm_reg;mem tt=Tuple1_Scalar k z
Movups_xmmm128_xmm, legacy, NP, 0F, 11, NP 0F 11 /r, MOVUPS xmm2/m128| xmm1, 16b 32b 64b op=xmm_or_mem;xmm_reg
VEX_Vmovups_xmmm128_xmm, VEX, NP, 0F, 11, VEX.128.0F.WIG 11 /r, VMOVUPS xmm2/m128| xmm1, 16b 32b 64b L128 WIG op=xmm_or_mem;xmm_reg
VEX_Vmovups_ymmm256_ymm, VEX, NP, 0F, 11, VEX.256.0F.WIG 11 /r, VMOVUPS ymm2/m256| ymm1, 16b 32b 64b L256 WIG op=ymm_or_mem;ymm_reg
EVEX_Vmovups_xmmm128_k1z_xmm, EVEX, NP, 0F, 11, EVEX.128.0F.W0 11 /r, VMOVUPS xmm2/m128 {k1}{z}| xmm1, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Full_Mem_128 k z
EVEX_Vmovups_ymmm256_k1z_ymm, EVEX, NP, 0F, 11, EVEX.256.0F.W0 11 /r, VMOVUPS ymm2/m256 {k1}{z}| ymm1, 16b 32b 64b L256 W0 op=ymm_or_mem;ymm_reg tt=Full_Mem_256 k z
EVEX_Vmovups_zmmm512_k1z_zmm, EVEX, NP, 0F, 11, EVEX.512.0F.W0 11 /r, VMOVUPS zmm2/m512 {k1}{z}| zmm1, 16b 32b 64b L512 W0 op=zmm_or_mem;zmm_reg tt=Full_Mem_512 k z
Movupd_xmmm128_xmm, legacy, 66, 0F, 11, 66 0F 11 /r, MOVUPD xmm2/m128| xmm1, 16b 32b 64b op=xmm_or_mem;xmm_reg
VEX_Vmovupd_xmmm128_xmm, VEX, 66, 0F, 11, VEX.128.66.0F.WIG 11 /r, VMOVUPD xmm2/m128| xmm1, 16b 32b 64b L128 WIG op=xmm_or_mem;xmm_reg
VEX_Vmovupd_ymmm256_ymm, VEX, 66, 0F, 11, VEX.256.66.0F.WIG 11 /r, VMOVUPD ymm2/m256| ymm1, 16b 32b 64b L256 WIG op=ymm_or_mem;ymm_reg
EVEX_Vmovupd_xmmm128_k1z_xmm, EVEX, 66, 0F, 11, EVEX.128.66.0F.W1 11 /r, VMOVUPD xmm2/m128 {k1}{z}| xmm1, 16b 32b 64b L128 W1 op=xmm_or_mem;xmm_reg tt=Full_Mem_128 k z
EVEX_Vmovupd_ymmm256_k1z_ymm, EVEX, 66, 0F, 11, EVEX.256.66.0F.W1 11 /r, VMOVUPD ymm2/m256 {k1}{z}| ymm1, 16b 32b 64b L256 W1 op=ymm_or_mem;ymm_reg tt=Full_Mem_256 k z
EVEX_Vmovupd_zmmm512_k1z_zmm, EVEX, 66, 0F, 11, EVEX.512.66.0F.W1 11 /r, VMOVUPD zmm2/m512 {k1}{z}| zmm1, 16b 32b 64b L512 W1 op=zmm_or_mem;zmm_reg tt=Full_Mem_512 k z
Movss_xmmm32_xmm, legacy, F3, 0F, 11, F3 0F 11 /r, MOVSS xmm2/m32| xmm1, 16b 32b 64b op=xmm_or_mem;xmm_reg
VEX_Vmovss_xmm_xmm_xmm_0F11, VEX, F3, 0F, 11, VEX.LIG.F3.0F.WIG 11 /r, VMOVSS xmm1| xmm2| xmm3, 16b 32b 64b LIG WIG op=xmm_rm;xmm_vvvv;xmm_reg
VEX_Vmovss_m32_xmm, VEX, F3, 0F, 11, VEX.LIG.F3.0F.WIG 11 /r, VMOVSS m32| xmm1, 16b 32b 64b LIG WIG op=mem;xmm_reg
EVEX_Vmovss_xmm_k1z_xmm_xmm_0F11, EVEX, F3, 0F, 11, EVEX.LIG.F3.0F.W0 11 /r, VMOVSS xmm1 {k1}{z}| xmm2| xmm3, 16b 32b 64b LIG W0 op=xmm_rm;xmm_vvvv;xmm_reg tt=Tuple1_Scalar k z
EVEX_Vmovss_m32_k1_xmm, EVEX, F3, 0F, 11, EVEX.LIG.F3.0F.W0 11 /r, VMOVSS m32 {k1}| xmm1, 16b 32b 64b LIG W0 op=mem;xmm_reg tt=Tuple1_Scalar k
Movsd_xmmm64_xmm, legacy, F2, 0F, 11, F2 0F 11 /r, MOVSD xmm1/m64| xmm2, 16b 32b 64b op=xmm_or_mem;xmm_reg
VEX_Vmovsd_xmm_xmm_xmm_0F11, VEX, F2, 0F, 11, VEX.LIG.F2.0F.WIG 11 /r, VMOVSD xmm1| xmm2| xmm3, 16b 32b 64b LIG WIG op=xmm_rm;xmm_vvvv;xmm_reg
VEX_Vmovsd_m64_xmm, VEX, F2, 0F, 11, VEX.LIG.F2.0F.WIG 11 /r, VMOVSD m64| xmm1, 16b 32b 64b LIG WIG op=mem;xmm_reg
EVEX_Vmovsd_xmm_k1z_xmm_xmm_0F11, EVEX, F2, 0F, 11, EVEX.LIG.F2.0F.W1 11 /r, VMOVSD xmm1 {k1}{z}| xmm2| xmm3, 16b 32b 64b LIG W1 op=xmm_rm;xmm_vvvv;xmm_reg tt=Tuple1_Scalar k z
EVEX_Vmovsd_m64_k1_xmm, EVEX, F2, 0F, 11, EVEX.LIG.F2.0F.W1 11 /r, VMOVSD m64 {k1}| xmm1, 16b 32b 64b LIG W1 op=mem;xmm_reg tt=Tuple1_Scalar k
Movhlps_xmm_xmm, legacy, NP, 0F, 12, NP 0F 12 /r, MOVHLPS xmm1| xmm2, 16b 32b 64b op=xmm_reg;xmm_rm
Movlps_xmm_m64, legacy, NP, 0F, 12, NP 0F 12 /r, MOVLPS xmm1| m64, 16b 32b 64b op=xmm_reg;mem
VEX_Vmovhlps_xmm_xmm_xmm, VEX, NP, 0F, 12, VEX.128.0F.WIG 12 /r, VMOVHLPS xmm1| xmm2| xmm3, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_rm
VEX_Vmovlps_xmm_xmm_m64, VEX, NP, 0F, 12, VEX.128.0F.WIG 12 /r, VMOVLPS xmm2| xmm1| m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;mem
EVEX_Vmovhlps_xmm_xmm_xmm, EVEX, NP, 0F, 12, EVEX.128.0F.W0 12 /r, VMOVHLPS xmm1| xmm2| xmm3, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_rm tt=Tuple2
EVEX_Vmovlps_xmm_xmm_m64, EVEX, NP, 0F, 12, EVEX.128.0F.W0 12 /r, VMOVLPS xmm2| xmm1| m64, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;mem tt=Tuple2
Movlpd_xmm_m64, legacy, 66, 0F, 12, 66 0F 12 /r, MOVLPD xmm1| m64, 16b 32b 64b op=xmm_reg;mem
VEX_Vmovlpd_xmm_xmm_m64, VEX, 66, 0F, 12, VEX.128.66.0F.WIG 12 /r, VMOVLPD xmm2| xmm1| m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;mem
EVEX_Vmovlpd_xmm_xmm_m64, EVEX, 66, 0F, 12, EVEX.128.66.0F.W1 12 /r, VMOVLPD xmm2| xmm1| m64, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;mem tt=Tuple1_Scalar
Movsldup_xmm_xmmm128, legacy, F3, 0F, 12, F3 0F 12 /r, MOVSLDUP xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmovsldup_xmm_xmmm128, VEX, F3, 0F, 12, VEX.128.F3.0F.WIG 12 /r, VMOVSLDUP xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vmovsldup_ymm_ymmm256, VEX, F3, 0F, 12, VEX.256.F3.0F.WIG 12 /r, VMOVSLDUP ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
EVEX_Vmovsldup_xmm_k1z_xmmm128, EVEX, F3, 0F, 12, EVEX.128.F3.0F.W0 12 /r, VMOVSLDUP xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vmovsldup_ymm_k1z_ymmm256, EVEX, F3, 0F, 12, EVEX.256.F3.0F.W0 12 /r, VMOVSLDUP ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vmovsldup_zmm_k1z_zmmm512, EVEX, F3, 0F, 12, EVEX.512.F3.0F.W0 12 /r, VMOVSLDUP zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_Mem_512 k z
Movddup_xmm_xmmm64, legacy, F2, 0F, 12, F2 0F 12 /r, MOVDDUP xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmovddup_xmm_xmmm64, VEX, F2, 0F, 12, VEX.128.F2.0F.WIG 12 /r, VMOVDDUP xmm1| xmm2/m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vmovddup_ymm_ymmm256, VEX, F2, 0F, 12, VEX.256.F2.0F.WIG 12 /r, VMOVDDUP ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
EVEX_Vmovddup_xmm_k1z_xmmm64, EVEX, F2, 0F, 12, EVEX.128.F2.0F.W1 12 /r, VMOVDDUP xmm1 {k1}{z}| xmm2/m64, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=MOVDDUP_128 k z
EVEX_Vmovddup_ymm_k1z_ymmm256, EVEX, F2, 0F, 12, EVEX.256.F2.0F.W1 12 /r, VMOVDDUP ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=MOVDDUP_256 k z
EVEX_Vmovddup_zmm_k1z_zmmm512, EVEX, F2, 0F, 12, EVEX.512.F2.0F.W1 12 /r, VMOVDDUP zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=MOVDDUP_512 k z
Movlps_m64_xmm, legacy, NP, 0F, 13, NP 0F 13 /r, MOVLPS m64| xmm1, 16b 32b 64b op=mem;xmm_reg
VEX_Vmovlps_m64_xmm, VEX, NP, 0F, 13, VEX.128.0F.WIG 13 /r, VMOVLPS m64| xmm1, 16b 32b 64b L128 WIG op=mem;xmm_reg
EVEX_Vmovlps_m64_xmm, EVEX, NP, 0F, 13, EVEX.128.0F.W0 13 /r, VMOVLPS m64| xmm1, 16b 32b 64b L128 W0 op=mem;xmm_reg tt=Tuple2
Movlpd_m64_xmm, legacy, 66, 0F, 13, 66 0F 13 /r, MOVLPD m64| xmm1, 16b 32b 64b op=mem;xmm_reg
VEX_Vmovlpd_m64_xmm, VEX, 66, 0F, 13, VEX.128.66.0F.WIG 13 /r, VMOVLPD m64| xmm1, 16b 32b 64b L128 WIG op=mem;xmm_reg
EVEX_Vmovlpd_m64_xmm, EVEX, 66, 0F, 13, EVEX.128.66.0F.W1 13 /r, VMOVLPD m64| xmm1, 16b 32b 64b L128 W1 op=mem;xmm_reg tt=Tuple1_Scalar
Unpcklps_xmm_xmmm128, legacy, NP, 0F, 14, NP 0F 14 /r, UNPCKLPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vunpcklps_xmm_xmm_xmmm128, VEX, NP, 0F, 14, VEX.128.0F.WIG 14 /r, VUNPCKLPS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vunpcklps_ymm_ymm_ymmm256, VEX, NP, 0F, 14, VEX.256.0F.WIG 14 /r, VUNPCKLPS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vunpcklps_xmm_k1z_xmm_xmmm128b32, EVEX, NP, 0F, 14, EVEX.128.0F.W0 14 /r, VUNPCKLPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vunpcklps_ymm_k1z_ymm_ymmm256b32, EVEX, NP, 0F, 14, EVEX.256.0F.W0 14 /r, VUNPCKLPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vunpcklps_zmm_k1z_zmm_zmmm512b32, EVEX, NP, 0F, 14, EVEX.512.0F.W0 14 /r, VUNPCKLPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Unpcklpd_xmm_xmmm128, legacy, 66, 0F, 14, 66 0F 14 /r, UNPCKLPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vunpcklpd_xmm_xmm_xmmm128, VEX, 66, 0F, 14, VEX.128.66.0F.WIG 14 /r, VUNPCKLPD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vunpcklpd_ymm_ymm_ymmm256, VEX, 66, 0F, 14, VEX.256.66.0F.WIG 14 /r, VUNPCKLPD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vunpcklpd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, 14, EVEX.128.66.0F.W1 14 /r, VUNPCKLPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vunpcklpd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, 14, EVEX.256.66.0F.W1 14 /r, VUNPCKLPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vunpcklpd_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F, 14, EVEX.512.66.0F.W1 14 /r, VUNPCKLPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Unpckhps_xmm_xmmm128, legacy, NP, 0F, 15, NP 0F 15 /r, UNPCKHPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vunpckhps_xmm_xmm_xmmm128, VEX, NP, 0F, 15, VEX.128.0F.WIG 15 /r, VUNPCKHPS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vunpckhps_ymm_ymm_ymmm256, VEX, NP, 0F, 15, VEX.256.0F.WIG 15 /r, VUNPCKHPS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vunpckhps_xmm_k1z_xmm_xmmm128b32, EVEX, NP, 0F, 15, EVEX.128.0F.W0 15 /r, VUNPCKHPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vunpckhps_ymm_k1z_ymm_ymmm256b32, EVEX, NP, 0F, 15, EVEX.256.0F.W0 15 /r, VUNPCKHPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vunpckhps_zmm_k1z_zmm_zmmm512b32, EVEX, NP, 0F, 15, EVEX.512.0F.W0 15 /r, VUNPCKHPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Unpckhpd_xmm_xmmm128, legacy, 66, 0F, 15, 66 0F 15 /r, UNPCKHPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vunpckhpd_xmm_xmm_xmmm128, VEX, 66, 0F, 15, VEX.128.66.0F.WIG 15 /r, VUNPCKHPD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vunpckhpd_ymm_ymm_ymmm256, VEX, 66, 0F, 15, VEX.256.66.0F.WIG 15 /r, VUNPCKHPD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vunpckhpd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, 15, EVEX.128.66.0F.W1 15 /r, VUNPCKHPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vunpckhpd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, 15, EVEX.256.66.0F.W1 15 /r, VUNPCKHPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vunpckhpd_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F, 15, EVEX.512.66.0F.W1 15 /r, VUNPCKHPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Movlhps_xmm_xmm, legacy, NP, 0F, 16, NP 0F 16 /r, MOVLHPS xmm1| xmm2, 16b 32b 64b op=xmm_reg;xmm_rm
VEX_Vmovlhps_xmm_xmm_xmm, VEX, NP, 0F, 16, VEX.128.0F.WIG 16 /r, VMOVLHPS xmm1| xmm2| xmm3, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_rm
EVEX_Vmovlhps_xmm_xmm_xmm, EVEX, NP, 0F, 16, EVEX.128.0F.W0 16 /r, VMOVLHPS xmm1| xmm2| xmm3, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_rm tt=Tuple2
Movhps_xmm_m64, legacy, NP, 0F, 16, NP 0F 16 /r, MOVHPS xmm1| m64, 16b 32b 64b op=xmm_reg;mem
VEX_Vmovhps_xmm_xmm_m64, VEX, NP, 0F, 16, VEX.128.0F.WIG 16 /r, VMOVHPS xmm2| xmm1| m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;mem
EVEX_Vmovhps_xmm_xmm_m64, EVEX, NP, 0F, 16, EVEX.128.0F.W0 16 /r, VMOVHPS xmm2| xmm1| m64, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;mem tt=Tuple2
Movhpd_xmm_m64, legacy, 66, 0F, 16, 66 0F 16 /r, MOVHPD xmm1| m64, 16b 32b 64b op=xmm_reg;mem
VEX_Vmovhpd_xmm_xmm_m64, VEX, 66, 0F, 16, VEX.128.66.0F.WIG 16 /r, VMOVHPD xmm2| xmm1| m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;mem
EVEX_Vmovhpd_xmm_xmm_m64, EVEX, 66, 0F, 16, EVEX.128.66.0F.W1 16 /r, VMOVHPD xmm2| xmm1| m64, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;mem tt=Tuple1_Scalar
Movshdup_xmm_xmmm128, legacy, F3, 0F, 16, F3 0F 16 /r, MOVSHDUP xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmovshdup_xmm_xmmm128, VEX, F3, 0F, 16, VEX.128.F3.0F.WIG 16 /r, VMOVSHDUP xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vmovshdup_ymm_ymmm256, VEX, F3, 0F, 16, VEX.256.F3.0F.WIG 16 /r, VMOVSHDUP ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
EVEX_Vmovshdup_xmm_k1z_xmmm128, EVEX, F3, 0F, 16, EVEX.128.F3.0F.W0 16 /r, VMOVSHDUP xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vmovshdup_ymm_k1z_ymmm256, EVEX, F3, 0F, 16, EVEX.256.F3.0F.W0 16 /r, VMOVSHDUP ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vmovshdup_zmm_k1z_zmmm512, EVEX, F3, 0F, 16, EVEX.512.F3.0F.W0 16 /r, VMOVSHDUP zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_Mem_512 k z
Movhps_m64_xmm, legacy, NP, 0F, 17, NP 0F 17 /r, MOVHPS m64| xmm1, 16b 32b 64b op=mem;xmm_reg
VEX_Vmovhps_m64_xmm, VEX, NP, 0F, 17, VEX.128.0F.WIG 17 /r, VMOVHPS m64| xmm1, 16b 32b 64b L128 WIG op=mem;xmm_reg
EVEX_Vmovhps_m64_xmm, EVEX, NP, 0F, 17, EVEX.128.0F.W0 17 /r, VMOVHPS m64| xmm1, 16b 32b 64b L128 W0 op=mem;xmm_reg tt=Tuple2
Movhpd_m64_xmm, legacy, 66, 0F, 17, 66 0F 17 /r, MOVHPD m64| xmm1, 16b 32b 64b op=mem;xmm_reg
VEX_Vmovhpd_m64_xmm, VEX, 66, 0F, 17, VEX.128.66.0F.WIG 17 /r, VMOVHPD m64| xmm1, 16b 32b 64b L128 WIG op=mem;xmm_reg
EVEX_Vmovhpd_m64_xmm, EVEX, 66, 0F, 17, EVEX.128.66.0F.W1 17 /r, VMOVHPD m64| xmm1, 16b 32b 64b L128 W1 op=mem;xmm_reg tt=Tuple1_Scalar
ReservedNop_rm16_r16_0F18, legacy, , 0F, 18, o16 0F 18 /r, RESERVEDNOP r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg
ReservedNop_rm32_r32_0F18, legacy, , 0F, 18, o32 0F 18 /r, RESERVEDNOP r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg
ReservedNop_rm64_r64_0F18, legacy, , 0F, 18, REX.W 0F 18 /r, RESERVEDNOP r/m64| r64, 64b o64 op=r64_or_mem;r64_reg
ReservedNop_rm16_r16_0F19, legacy, , 0F, 19, o16 0F 19 /r, RESERVEDNOP r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg
ReservedNop_rm32_r32_0F19, legacy, , 0F, 19, o32 0F 19 /r, RESERVEDNOP r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg
ReservedNop_rm64_r64_0F19, legacy, , 0F, 19, REX.W 0F 19 /r, RESERVEDNOP r/m64| r64, 64b o64 op=r64_or_mem;r64_reg
ReservedNop_rm16_r16_0F1A, legacy, , 0F, 1A, o16 0F 1A /r, RESERVEDNOP r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg
ReservedNop_rm32_r32_0F1A, legacy, , 0F, 1A, o32 0F 1A /r, RESERVEDNOP r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg
ReservedNop_rm64_r64_0F1A, legacy, , 0F, 1A, REX.W 0F 1A /r, RESERVEDNOP r/m64| r64, 64b o64 op=r64_or_mem;r64_reg
ReservedNop_rm16_r16_0F1B, legacy, , 0F, 1B, o16 0F 1B /r, RESERVEDNOP r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg
ReservedNop_rm32_r32_0F1B, legacy, , 0F, 1B, o32 0F 1B /r, RESERVEDNOP r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg
ReservedNop_rm64_r64_0F1B, legacy, , 0F, 1B, REX.W 0F 1B /r, RESERVEDNOP r/m64| r64, 64b o64 op=r64_or_mem;r64_reg
ReservedNop_rm16_r16_0F1C, legacy, , 0F, 1C, o16 0F 1C /r, RESERVEDNOP r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg
ReservedNop_rm32_r32_0F1C, legacy, , 0F, 1C, o32 0F 1C /r, RESERVEDNOP r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg
ReservedNop_rm64_r64_0F1C, legacy, , 0F, 1C, REX.W 0F 1C /r, RESERVEDNOP r/m64| r64, 64b o64 op=r64_or_mem;r64_reg
ReservedNop_rm16_r16_0F1D, legacy, , 0F, 1D, o16 0F 1D /r, RESERVEDNOP r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg
ReservedNop_rm32_r32_0F1D, legacy, , 0F, 1D, o32 0F 1D /r, RESERVEDNOP r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg
ReservedNop_rm64_r64_0F1D, legacy, , 0F, 1D, REX.W 0F 1D /r, RESERVEDNOP r/m64| r64, 64b o64 op=r64_or_mem;r64_reg
ReservedNop_rm16_r16_0F1E, legacy, , 0F, 1E, o16 0F 1E /r, RESERVEDNOP r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg
ReservedNop_rm32_r32_0F1E, legacy, , 0F, 1E, o32 0F 1E /r, RESERVEDNOP r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg
ReservedNop_rm64_r64_0F1E, legacy, , 0F, 1E, REX.W 0F 1E /r, RESERVEDNOP r/m64| r64, 64b o64 op=r64_or_mem;r64_reg
ReservedNop_rm16_r16_0F1F, legacy, , 0F, 1F, o16 0F 1F /r, RESERVEDNOP r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg
ReservedNop_rm32_r32_0F1F, legacy, , 0F, 1F, o32 0F 1F /r, RESERVEDNOP r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg
ReservedNop_rm64_r64_0F1F, legacy, , 0F, 1F, REX.W 0F 1F /r, RESERVEDNOP r/m64| r64, 64b o64 op=r64_or_mem;r64_reg
Prefetchnta_m8, legacy, , 0F, 18, 0F 18 /0, PREFETCHNTA m8, g=0 16b 32b 64b op=mem
Prefetcht0_m8, legacy, , 0F, 18, 0F 18 /1, PREFETCHT0 m8, g=1 16b 32b 64b op=mem
Prefetcht1_m8, legacy, , 0F, 18, 0F 18 /2, PREFETCHT1 m8, g=2 16b 32b 64b op=mem
Prefetcht2_m8, legacy, , 0F, 18, 0F 18 /3, PREFETCHT2 m8, g=3 16b 32b 64b op=mem
Bndldx_bnd_mib, legacy, NP, 0F, 1A, NP 0F 1A /r, BNDLDX bnd| mib, 16b 32b 64b op=bnd_reg;mem_mib
Bndmov_bnd_bndm64, legacy, 66, 0F, 1A, 66 0F 1A /r, BNDMOV bnd1| bnd2/m64, 16b 32b op=bnd_reg;bnd_or_mem_mpx
Bndmov_bnd_bndm128, legacy, 66, 0F, 1A, 66 0F 1A /r, BNDMOV bnd1| bnd2/m128, 64b op=bnd_reg;bnd_or_mem_mpx
Bndcl_bnd_rm32, legacy, F3, 0F, 1A, F3 0F 1A /r, BNDCL bnd| r/m32, 16b 32b op=bnd_reg;r32_or_mem_mpx
Bndcl_bnd_rm64, legacy, F3, 0F, 1A, F3 0F 1A /r, BNDCL bnd| r/m64, 64b op=bnd_reg;r64_or_mem_mpx
Bndcu_bnd_rm32, legacy, F2, 0F, 1A, F2 0F 1A /r, BNDCU bnd| r/m32, 16b 32b op=bnd_reg;r32_or_mem_mpx
Bndcu_bnd_rm64, legacy, F2, 0F, 1A, F2 0F 1A /r, BNDCU bnd| r/m64, 64b op=bnd_reg;r64_or_mem_mpx
Bndstx_mib_bnd, legacy, NP, 0F, 1B, NP 0F 1B /r, BNDSTX mib| bnd, 16b 32b 64b op=mem_mib;bnd_reg
Bndmov_bndm64_bnd, legacy, 66, 0F, 1B, 66 0F 1B /r, BNDMOV bnd1/m64| bnd2, 16b 32b op=bnd_or_mem_mpx;bnd_reg
Bndmov_bndm128_bnd, legacy, 66, 0F, 1B, 66 0F 1B /r, BNDMOV bnd1/m128| bnd2, 64b op=bnd_or_mem_mpx;bnd_reg
Bndmk_bnd_m32, legacy, F3, 0F, 1B, F3 0F 1B /r, BNDMK bnd| m32, 16b 32b op=bnd_reg;mem_mpx
Bndmk_bnd_m64, legacy, F3, 0F, 1B, F3 0F 1B /r, BNDMK bnd| m64, 64b op=bnd_reg;mem_mpx
Bndcn_bnd_rm32, legacy, F2, 0F, 1B, F2 0F 1B /r, BNDCN bnd| r/m32, 16b 32b op=bnd_reg;r32_or_mem_mpx
Bndcn_bnd_rm64, legacy, F2, 0F, 1B, F2 0F 1B /r, BNDCN bnd| r/m64, 64b op=bnd_reg;r64_or_mem_mpx
Cldemote_m8, legacy, NP, 0F, 1C, NP 0F 1C /0, CLDEMOTE m8, g=0 16b 32b 64b op=mem
Rdsspd_r32, legacy, F3, 0F, 1E, F3 0F 1E /1, RDSSPD r32, g=1 16b 32b 64b op=r32_rm
Rdsspq_r64, legacy, F3, 0F, 1E, F3 REX.W 0F 1E /1, RDSSPQ r64, g=1 64b o64 op=r64_rm
Endbr64, legacy, F3, 0F, 1EFA, F3 0F 1E FA, ENDBR64, 16b 32b 64b
Endbr32, legacy, F3, 0F, 1EFB, F3 0F 1E FB, ENDBR32, 16b 32b 64b
Nop_rm16, legacy, , 0F, 1F, o16 0F 1F /0, NOP r/m16, g=0 16b 32b 64b o16 op=r16_or_mem
Nop_rm32, legacy, , 0F, 1F, o32 0F 1F /0, NOP r/m32, g=0 16b 32b 64b o32 op=r32_or_mem
Nop_rm64, legacy, , 0F, 1F, REX.W 0F 1F /0, NOP r/m64, g=0 64b o64 op=r64_or_mem
Mov_r32_cr, legacy, , 0F, 20, 0F 20 /r, MOV r32| cr, 16b 32b op=r32_rm;cr_reg
Mov_r64_cr, legacy, , 0F, 20, 0F 20 /r, MOV r64| cr, 64b op=r64_rm;cr_reg
Mov_r32_dr, legacy, , 0F, 21, 0F 21 /r, MOV r32| dr, 16b 32b op=r32_rm;dr_reg
Mov_r64_dr, legacy, , 0F, 21, 0F 21 /r, MOV r64| dr, 64b op=r64_rm;dr_reg
Mov_cr_r32, legacy, , 0F, 22, 0F 22 /r, MOV cr| r32, 16b 32b op=cr_reg;r32_rm
Mov_cr_r64, legacy, , 0F, 22, 0F 22 /r, MOV cr| r64, 64b op=cr_reg;r64_rm
Mov_dr_r32, legacy, , 0F, 23, 0F 23 /r, MOV dr| r32, 16b 32b op=dr_reg;r32_rm
Mov_dr_r64, legacy, , 0F, 23, 0F 23 /r, MOV dr| r64, 64b op=dr_reg;r64_rm
Mov_r32_tr, legacy, , 0F, 24, 0F 24 /r, MOV r32| tr, 16b 32b op=r32_rm;tr_reg
Mov_tr_r32, legacy, , 0F, 26, 0F 26 /r, MOV tr| r32, 16b 32b op=tr_reg;r32_rm
Movaps_xmm_xmmm128, legacy, NP, 0F, 28, NP 0F 28 /r, MOVAPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmovaps_xmm_xmmm128, VEX, NP, 0F, 28, VEX.128.0F.WIG 28 /r, VMOVAPS xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vmovaps_ymm_ymmm256, VEX, NP, 0F, 28, VEX.256.0F.WIG 28 /r, VMOVAPS ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
EVEX_Vmovaps_xmm_k1z_xmmm128, EVEX, NP, 0F, 28, EVEX.128.0F.W0 28 /r, VMOVAPS xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vmovaps_ymm_k1z_ymmm256, EVEX, NP, 0F, 28, EVEX.256.0F.W0 28 /r, VMOVAPS ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vmovaps_zmm_k1z_zmmm512, EVEX, NP, 0F, 28, EVEX.512.0F.W0 28 /r, VMOVAPS zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_Mem_512 k z
Movapd_xmm_xmmm128, legacy, 66, 0F, 28, 66 0F 28 /r, MOVAPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmovapd_xmm_xmmm128, VEX, 66, 0F, 28, VEX.128.66.0F.WIG 28 /r, VMOVAPD xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vmovapd_ymm_ymmm256, VEX, 66, 0F, 28, VEX.256.66.0F.WIG 28 /r, VMOVAPD ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
EVEX_Vmovapd_xmm_k1z_xmmm128, EVEX, 66, 0F, 28, EVEX.128.66.0F.W1 28 /r, VMOVAPD xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vmovapd_ymm_k1z_ymmm256, EVEX, 66, 0F, 28, EVEX.256.66.0F.W1 28 /r, VMOVAPD ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vmovapd_zmm_k1z_zmmm512, EVEX, 66, 0F, 28, EVEX.512.66.0F.W1 28 /r, VMOVAPD zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_Mem_512 k z
Movaps_xmmm128_xmm, legacy, NP, 0F, 29, NP 0F 29 /r, MOVAPS xmm2/m128| xmm1, 16b 32b 64b op=xmm_or_mem;xmm_reg
VEX_Vmovaps_xmmm128_xmm, VEX, NP, 0F, 29, VEX.128.0F.WIG 29 /r, VMOVAPS xmm2/m128| xmm1, 16b 32b 64b L128 WIG op=xmm_or_mem;xmm_reg
VEX_Vmovaps_ymmm256_ymm, VEX, NP, 0F, 29, VEX.256.0F.WIG 29 /r, VMOVAPS ymm2/m256| ymm1, 16b 32b 64b L256 WIG op=ymm_or_mem;ymm_reg
EVEX_Vmovaps_xmmm128_k1z_xmm, EVEX, NP, 0F, 29, EVEX.128.0F.W0 29 /r, VMOVAPS xmm2/m128 {k1}{z}| xmm1, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Full_Mem_128 k z
EVEX_Vmovaps_ymmm256_k1z_ymm, EVEX, NP, 0F, 29, EVEX.256.0F.W0 29 /r, VMOVAPS ymm2/m256 {k1}{z}| ymm1, 16b 32b 64b L256 W0 op=ymm_or_mem;ymm_reg tt=Full_Mem_256 k z
EVEX_Vmovaps_zmmm512_k1z_zmm, EVEX, NP, 0F, 29, EVEX.512.0F.W0 29 /r, VMOVAPS zmm2/m512 {k1}{z}| zmm1, 16b 32b 64b L512 W0 op=zmm_or_mem;zmm_reg tt=Full_Mem_512 k z
Movapd_xmmm128_xmm, legacy, 66, 0F, 29, 66 0F 29 /r, MOVAPD xmm2/m128| xmm1, 16b 32b 64b op=xmm_or_mem;xmm_reg
VEX_Vmovapd_xmmm128_xmm, VEX, 66, 0F, 29, VEX.128.66.0F.WIG 29 /r, VMOVAPD xmm2/m128| xmm1, 16b 32b 64b L128 WIG op=xmm_or_mem;xmm_reg
VEX_Vmovapd_ymmm256_ymm, VEX, 66, 0F, 29, VEX.256.66.0F.WIG 29 /r, VMOVAPD ymm2/m256| ymm1, 16b 32b 64b L256 WIG op=ymm_or_mem;ymm_reg
EVEX_Vmovapd_xmmm128_k1z_xmm, EVEX, 66, 0F, 29, EVEX.128.66.0F.W1 29 /r, VMOVAPD xmm2/m128 {k1}{z}| xmm1, 16b 32b 64b L128 W1 op=xmm_or_mem;xmm_reg tt=Full_Mem_128 k z
EVEX_Vmovapd_ymmm256_k1z_ymm, EVEX, 66, 0F, 29, EVEX.256.66.0F.W1 29 /r, VMOVAPD ymm2/m256 {k1}{z}| ymm1, 16b 32b 64b L256 W1 op=ymm_or_mem;ymm_reg tt=Full_Mem_256 k z
EVEX_Vmovapd_zmmm512_k1z_zmm, EVEX, 66, 0F, 29, EVEX.512.66.0F.W1 29 /r, VMOVAPD zmm2/m512 {k1}{z}| zmm1, 16b 32b 64b L512 W1 op=zmm_or_mem;zmm_reg tt=Full_Mem_512 k z
Cvtpi2ps_xmm_mmm64, legacy, NP, 0F, 2A, NP 0F 2A /r, CVTPI2PS xmm| mm/m64, 16b 32b 64b op=xmm_reg;mm_or_mem
Cvtpi2pd_xmm_mmm64, legacy, 66, 0F, 2A, 66 0F 2A /r, CVTPI2PD xmm| mm/m64, 16b 32b 64b op=xmm_reg;mm_or_mem
Cvtsi2ss_xmm_rm32, legacy, F3, 0F, 2A, F3 0F 2A /r, CVTSI2SS xmm1| r/m32, 16b 32b 64b op=xmm_reg;r32_or_mem
Cvtsi2ss_xmm_rm64, legacy, F3, 0F, 2A, F3 REX.W 0F 2A /r, CVTSI2SS xmm1| r/m64, 64b o64 op=xmm_reg;r64_or_mem
VEX_Vcvtsi2ss_xmm_xmm_rm32, VEX, F3, 0F, 2A, VEX.LIG.F3.0F.W0 2A /r, VCVTSI2SS xmm1| xmm2| r/m32, 16b 32b 64b LIG WIG32 op=xmm_reg;xmm_vvvv;r32_or_mem
VEX_Vcvtsi2ss_xmm_xmm_rm64, VEX, F3, 0F, 2A, VEX.LIG.F3.0F.W1 2A /r, VCVTSI2SS xmm1| xmm2| r/m64, 64b LIG W1 op=xmm_reg;xmm_vvvv;r64_or_mem
EVEX_Vcvtsi2ss_xmm_xmm_rm32_er, EVEX, F3, 0F, 2A, EVEX.LIG.F3.0F.W0 2A /r, VCVTSI2SS xmm1| xmm2| r/m32{er}, 16b 32b 64b LIG WIG32 op=xmm_reg;xmm_vvvv;r32_or_mem tt=Tuple1_Scalar er
EVEX_Vcvtsi2ss_xmm_xmm_rm64_er, EVEX, F3, 0F, 2A, EVEX.LIG.F3.0F.W1 2A /r, VCVTSI2SS xmm1| xmm2| r/m64{er}, 64b LIG W1 op=xmm_reg;xmm_vvvv;r64_or_mem tt=Tuple1_Scalar er
Cvtsi2sd_xmm_rm32, legacy, F2, 0F, 2A, F2 0F 2A /r, CVTSI2SD xmm1| r/m32, 16b 32b 64b op=xmm_reg;r32_or_mem
Cvtsi2sd_xmm_rm64, legacy, F2, 0F, 2A, F2 REX.W 0F 2A /r, CVTSI2SD xmm1| r/m64, 64b o64 op=xmm_reg;r64_or_mem
VEX_Vcvtsi2sd_xmm_xmm_rm32, VEX, F2, 0F, 2A, VEX.LIG.F2.0F.W0 2A /r, VCVTSI2SD xmm1| xmm2| r/m32, 16b 32b 64b LIG WIG32 op=xmm_reg;xmm_vvvv;r32_or_mem
VEX_Vcvtsi2sd_xmm_xmm_rm64, VEX, F2, 0F, 2A, VEX.LIG.F2.0F.W1 2A /r, VCVTSI2SD xmm1| xmm2| r/m64, 64b LIG W1 op=xmm_reg;xmm_vvvv;r64_or_mem
EVEX_Vcvtsi2sd_xmm_xmm_rm32_er, EVEX, F2, 0F, 2A, EVEX.LIG.F2.0F.W0 2A /r, VCVTSI2SD xmm1| xmm2| r/m32, 16b 32b 64b LIG WIG32 op=xmm_reg;xmm_vvvv;r32_or_mem tt=Tuple1_Scalar er
EVEX_Vcvtsi2sd_xmm_xmm_rm64_er, EVEX, F2, 0F, 2A, EVEX.LIG.F2.0F.W1 2A /r, VCVTSI2SD xmm1| xmm2| r/m64{er}, 64b LIG W1 op=xmm_reg;xmm_vvvv;r64_or_mem tt=Tuple1_Scalar er
Movntps_m128_xmm, legacy, NP, 0F, 2B, NP 0F 2B /r, MOVNTPS m128| xmm1, 16b 32b 64b op=mem;xmm_reg
VEX_Vmovntps_m128_xmm, VEX, NP, 0F, 2B, VEX.128.0F.WIG 2B /r, VMOVNTPS m128| xmm1, 16b 32b 64b L128 WIG op=mem;xmm_reg
VEX_Vmovntps_m256_ymm, VEX, NP, 0F, 2B, VEX.256.0F.WIG 2B /r, VMOVNTPS m256| ymm1, 16b 32b 64b L256 WIG op=mem;ymm_reg
EVEX_Vmovntps_m128_xmm, EVEX, NP, 0F, 2B, EVEX.128.0F.W0 2B /r, VMOVNTPS m128| xmm1, 16b 32b 64b L128 W0 op=mem;xmm_reg tt=Full_Mem_128
EVEX_Vmovntps_m256_ymm, EVEX, NP, 0F, 2B, EVEX.256.0F.W0 2B /r, VMOVNTPS m256| ymm1, 16b 32b 64b L256 W0 op=mem;ymm_reg tt=Full_Mem_256
EVEX_Vmovntps_m512_zmm, EVEX, NP, 0F, 2B, EVEX.512.0F.W0 2B /r, VMOVNTPS m512| zmm1, 16b 32b 64b L512 W0 op=mem;zmm_reg tt=Full_Mem_512
Movntpd_m128_xmm, legacy, 66, 0F, 2B, 66 0F 2B /r, MOVNTPD m128| xmm1, 16b 32b 64b op=mem;xmm_reg
VEX_Vmovntpd_m128_xmm, VEX, 66, 0F, 2B, VEX.128.66.0F.WIG 2B /r, VMOVNTPD m128| xmm1, 16b 32b 64b L128 WIG op=mem;xmm_reg
VEX_Vmovntpd_m256_ymm, VEX, 66, 0F, 2B, VEX.256.66.0F.WIG 2B /r, VMOVNTPD m256| ymm1, 16b 32b 64b L256 WIG op=mem;ymm_reg
EVEX_Vmovntpd_m128_xmm, EVEX, 66, 0F, 2B, EVEX.128.66.0F.W1 2B /r, VMOVNTPD m128| xmm1, 16b 32b 64b L128 W1 op=mem;xmm_reg tt=Full_Mem_128
EVEX_Vmovntpd_m256_ymm, EVEX, 66, 0F, 2B, EVEX.256.66.0F.W1 2B /r, VMOVNTPD m256| ymm1, 16b 32b 64b L256 W1 op=mem;ymm_reg tt=Full_Mem_256
EVEX_Vmovntpd_m512_zmm, EVEX, 66, 0F, 2B, EVEX.512.66.0F.W1 2B /r, VMOVNTPD m512| zmm1, 16b 32b 64b L512 W1 op=mem;zmm_reg tt=Full_Mem_512
Movntss_m32_xmm, legacy, F3, 0F, 2B, F3 0F 2B /r, MOVNTSS m32| xmm1, 16b 32b 64b op=mem;xmm_reg
Movntsd_m64_xmm, legacy, F2, 0F, 2B, F2 0F 2B /r, MOVNTSD m64| xmm1, 16b 32b 64b op=mem;xmm_reg
Cvttps2pi_mm_xmmm64, legacy, NP, 0F, 2C, NP 0F 2C /r, CVTTPS2PI mm| xmm/m64, 16b 32b 64b op=mm_reg;xmm_or_mem
Cvttpd2pi_mm_xmmm128, legacy, 66, 0F, 2C, 66 0F 2C /r, CVTTPD2PI mm| xmm/m128, 16b 32b 64b op=mm_reg;xmm_or_mem
Cvttss2si_r32_xmmm32, legacy, F3, 0F, 2C, F3 0F 2C /r, CVTTSS2SI r32| xmm1/m32, 16b 32b 64b op=r32_reg;xmm_or_mem
Cvttss2si_r64_xmmm32, legacy, F3, 0F, 2C, F3 REX.W 0F 2C /r, CVTTSS2SI r64| xmm1/m32, 64b o64 op=r64_reg;xmm_or_mem
VEX_Vcvttss2si_r32_xmmm32, VEX, F3, 0F, 2C, VEX.LIG.F3.0F.W0 2C /r, VCVTTSS2SI r32| xmm1/m32, 16b 32b 64b LIG WIG32 op=r32_reg;xmm_or_mem
VEX_Vcvttss2si_r64_xmmm32, VEX, F3, 0F, 2C, VEX.LIG.F3.0F.W1 2C /r, VCVTTSS2SI r64| xmm1/m32, 64b LIG W1 op=r64_reg;xmm_or_mem
EVEX_Vcvttss2si_r32_xmmm32_sae, EVEX, F3, 0F, 2C, EVEX.LIG.F3.0F.W0 2C /r, VCVTTSS2SI r32| xmm1/m32{sae}, 16b 32b 64b LIG WIG32 op=r32_reg;xmm_or_mem tt=Tuple1_Scalar_4 sae
EVEX_Vcvttss2si_r64_xmmm32_sae, EVEX, F3, 0F, 2C, EVEX.LIG.F3.0F.W1 2C /r, VCVTTSS2SI r64| xmm1/m32{sae}, 64b LIG W1 op=r64_reg;xmm_or_mem tt=Tuple1_Scalar_4 sae
Cvttsd2si_r32_xmmm64, legacy, F2, 0F, 2C, F2 0F 2C /r, CVTTSD2SI r32| xmm1/m64, 16b 32b 64b op=r32_reg;xmm_or_mem
Cvttsd2si_r64_xmmm64, legacy, F2, 0F, 2C, F2 REX.W 0F 2C /r, CVTTSD2SI r64| xmm1/m64, 64b o64 op=r64_reg;xmm_or_mem
VEX_Vcvttsd2si_r32_xmmm64, VEX, F2, 0F, 2C, VEX.LIG.F2.0F.W0 2C /r, VCVTTSD2SI r32| xmm1/m64, 16b 32b 64b LIG WIG32 op=r32_reg;xmm_or_mem
VEX_Vcvttsd2si_r64_xmmm64, VEX, F2, 0F, 2C, VEX.LIG.F2.0F.W1 2C /r, VCVTTSD2SI r64| xmm1/m64, 64b LIG W1 op=r64_reg;xmm_or_mem
EVEX_Vcvttsd2si_r32_xmmm64_sae, EVEX, F2, 0F, 2C, EVEX.LIG.F2.0F.W0 2C /r, VCVTTSD2SI r32| xmm1/m64{sae}, 16b 32b 64b LIG WIG32 op=r32_reg;xmm_or_mem tt=Tuple1_Scalar_8 sae
EVEX_Vcvttsd2si_r64_xmmm64_sae, EVEX, F2, 0F, 2C, EVEX.LIG.F2.0F.W1 2C /r, VCVTTSD2SI r64| xmm1/m64{sae}, 64b LIG W1 op=r64_reg;xmm_or_mem tt=Tuple1_Scalar_8 sae
Cvtps2pi_mm_xmmm64, legacy, NP, 0F, 2D, NP 0F 2D /r, CVTPS2PI mm| xmm/m64, 16b 32b 64b op=mm_reg;xmm_or_mem
Cvtpd2pi_mm_xmmm128, legacy, 66, 0F, 2D, 66 0F 2D /r, CVTPD2PI mm| xmm/m128, 16b 32b 64b op=mm_reg;xmm_or_mem
Cvtss2si_r32_xmmm32, legacy, F3, 0F, 2D, F3 0F 2D /r, CVTSS2SI r32| xmm1/m32, 16b 32b 64b op=r32_reg;xmm_or_mem
Cvtss2si_r64_xmmm32, legacy, F3, 0F, 2D, F3 REX.W 0F 2D /r, CVTSS2SI r64| xmm1/m32, 64b o64 op=r64_reg;xmm_or_mem
VEX_Vcvtss2si_r32_xmmm32, VEX, F3, 0F, 2D, VEX.LIG.F3.0F.W0 2D /r, VCVTSS2SI r32| xmm1/m32, 16b 32b 64b LIG WIG32 op=r32_reg;xmm_or_mem
VEX_Vcvtss2si_r64_xmmm32, VEX, F3, 0F, 2D, VEX.LIG.F3.0F.W1 2D /r, VCVTSS2SI r64| xmm1/m32, 64b LIG W1 op=r64_reg;xmm_or_mem
EVEX_Vcvtss2si_r32_xmmm32_er, EVEX, F3, 0F, 2D, EVEX.LIG.F3.0F.W0 2D /r, VCVTSS2SI r32| xmm1/m32{er}, 16b 32b 64b LIG WIG32 op=r32_reg;xmm_or_mem tt=Tuple1_Scalar_4 er
EVEX_Vcvtss2si_r64_xmmm32_er, EVEX, F3, 0F, 2D, EVEX.LIG.F3.0F.W1 2D /r, VCVTSS2SI r64| xmm1/m32{er}, 64b LIG W1 op=r64_reg;xmm_or_mem tt=Tuple1_Scalar_4 er
Cvtsd2si_r32_xmmm64, legacy, F2, 0F, 2D, F2 0F 2D /r, CVTSD2SI r32| xmm1/m64, 16b 32b 64b op=r32_reg;xmm_or_mem
Cvtsd2si_r64_xmmm64, legacy, F2, 0F, 2D, F2 REX.W 0F 2D /r, CVTSD2SI r64| xmm1/m64, 64b o64 op=r64_reg;xmm_or_mem
VEX_Vcvtsd2si_r32_xmmm64, VEX, F2, 0F, 2D, VEX.LIG.F2.0F.W0 2D /r, VCVTSD2SI r32| xmm1/m64, 16b 32b 64b LIG WIG32 op=r32_reg;xmm_or_mem
VEX_Vcvtsd2si_r64_xmmm64, VEX, F2, 0F, 2D, VEX.LIG.F2.0F.W1 2D /r, VCVTSD2SI r64| xmm1/m64, 64b LIG W1 op=r64_reg;xmm_or_mem
EVEX_Vcvtsd2si_r32_xmmm64_er, EVEX, F2, 0F, 2D, EVEX.LIG.F2.0F.W0 2D /r, VCVTSD2SI r32| xmm1/m64{er}, 16b 32b 64b LIG WIG32 op=r32_reg;xmm_or_mem tt=Tuple1_Scalar_8 er
EVEX_Vcvtsd2si_r64_xmmm64_er, EVEX, F2, 0F, 2D, EVEX.LIG.F2.0F.W1 2D /r, VCVTSD2SI r64| xmm1/m64{er}, 64b LIG W1 op=r64_reg;xmm_or_mem tt=Tuple1_Scalar_8 er
Ucomiss_xmm_xmmm32, legacy, NP, 0F, 2E, NP 0F 2E /r, UCOMISS xmm1| xmm2/m32, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vucomiss_xmm_xmmm32, VEX, NP, 0F, 2E, VEX.LIG.0F.WIG 2E /r, VUCOMISS xmm1| xmm2/m32, 16b 32b 64b LIG WIG op=xmm_reg;xmm_or_mem
EVEX_Vucomiss_xmm_xmmm32_sae, EVEX, NP, 0F, 2E, EVEX.LIG.0F.W0 2E /r, VUCOMISS xmm1| xmm2/m32{sae}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_or_mem tt=Tuple1_Scalar sae
Ucomisd_xmm_xmmm64, legacy, 66, 0F, 2E, 66 0F 2E /r, UCOMISD xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vucomisd_xmm_xmmm64, VEX, 66, 0F, 2E, VEX.LIG.66.0F.WIG 2E /r, VUCOMISD xmm1| xmm2/m64, 16b 32b 64b LIG WIG op=xmm_reg;xmm_or_mem
EVEX_Vucomisd_xmm_xmmm64_sae, EVEX, 66, 0F, 2E, EVEX.LIG.66.0F.W1 2E /r, VUCOMISD xmm1| xmm2/m64{sae}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_or_mem tt=Tuple1_Scalar sae
Comiss_xmm_xmmm32, legacy, NP, 0F, 2F, NP 0F 2F /r, COMISS xmm1| xmm2/m32, 16b 32b 64b op=xmm_reg;xmm_or_mem
Comisd_xmm_xmmm64, legacy, 66, 0F, 2F, 66 0F 2F /r, COMISD xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vcomiss_xmm_xmmm32, VEX, NP, 0F, 2F, VEX.LIG.0F.WIG 2F /r, VCOMISS xmm1| xmm2/m32, 16b 32b 64b LIG WIG op=xmm_reg;xmm_or_mem
VEX_Vcomisd_xmm_xmmm64, VEX, 66, 0F, 2F, VEX.LIG.66.0F.WIG 2F /r, VCOMISD xmm1| xmm2/m64, 16b 32b 64b LIG WIG op=xmm_reg;xmm_or_mem
EVEX_Vcomiss_xmm_xmmm32_sae, EVEX, NP, 0F, 2F, EVEX.LIG.0F.W0 2F /r, VCOMISS xmm1| xmm2/m32{sae}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_or_mem tt=Tuple1_Scalar sae
EVEX_Vcomisd_xmm_xmmm64_sae, EVEX, 66, 0F, 2F, EVEX.LIG.66.0F.W1 2F /r, VCOMISD xmm1| xmm2/m64{sae}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_or_mem tt=Tuple1_Scalar sae
Wrmsr, legacy, , 0F, 30, 0F 30, WRMSR, 16b 32b 64b
Rdtsc, legacy, , 0F, 31, 0F 31, RDTSC, 16b 32b 64b
Rdmsr, legacy, , 0F, 32, 0F 32, RDMSR, 16b 32b 64b
Rdpmc, legacy, , 0F, 33, 0F 33, RDPMC, 16b 32b 64b
Sysenter, legacy, , 0F, 34, 0F 34, SYSENTER, 16b 32b 64b
Sysexitd, legacy, , 0F, 35, 0F 35, SYSEXIT, 16b 32b 64b
Sysexitq, legacy, , 0F, 35, REX.W 0F 35, SYSEXIT, 64b o64
Getsec, legacy, NP, 0F, 37, NP 0F 37, GETSEC, 16b 32b 64b
Cmovo_r16_rm16, legacy, , 0F, 40, o16 0F 40 /r, CMOVO r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Cmovo_r32_rm32, legacy, , 0F, 40, o32 0F 40 /r, CMOVO r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Cmovo_r64_rm64, legacy, , 0F, 40, REX.W 0F 40 /r, CMOVO r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Cmovno_r16_rm16, legacy, , 0F, 41, o16 0F 41 /r, CMOVNO r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Cmovno_r32_rm32, legacy, , 0F, 41, o32 0F 41 /r, CMOVNO r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Cmovno_r64_rm64, legacy, , 0F, 41, REX.W 0F 41 /r, CMOVNO r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Cmovb_r16_rm16, legacy, , 0F, 42, o16 0F 42 /r, CMOVB r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Cmovb_r32_rm32, legacy, , 0F, 42, o32 0F 42 /r, CMOVB r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Cmovb_r64_rm64, legacy, , 0F, 42, REX.W 0F 42 /r, CMOVB r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Cmovae_r16_rm16, legacy, , 0F, 43, o16 0F 43 /r, CMOVAE r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Cmovae_r32_rm32, legacy, , 0F, 43, o32 0F 43 /r, CMOVAE r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Cmovae_r64_rm64, legacy, , 0F, 43, REX.W 0F 43 /r, CMOVAE r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Cmove_r16_rm16, legacy, , 0F, 44, o16 0F 44 /r, CMOVE r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Cmove_r32_rm32, legacy, , 0F, 44, o32 0F 44 /r, CMOVE r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Cmove_r64_rm64, legacy, , 0F, 44, REX.W 0F 44 /r, CMOVE r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Cmovne_r16_rm16, legacy, , 0F, 45, o16 0F 45 /r, CMOVNE r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Cmovne_r32_rm32, legacy, , 0F, 45, o32 0F 45 /r, CMOVNE r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Cmovne_r64_rm64, legacy, , 0F, 45, REX.W 0F 45 /r, CMOVNE r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Cmovbe_r16_rm16, legacy, , 0F, 46, o16 0F 46 /r, CMOVBE r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Cmovbe_r32_rm32, legacy, , 0F, 46, o32 0F 46 /r, CMOVBE r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Cmovbe_r64_rm64, legacy, , 0F, 46, REX.W 0F 46 /r, CMOVBE r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Cmova_r16_rm16, legacy, , 0F, 47, o16 0F 47 /r, CMOVA r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Cmova_r32_rm32, legacy, , 0F, 47, o32 0F 47 /r, CMOVA r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Cmova_r64_rm64, legacy, , 0F, 47, REX.W 0F 47 /r, CMOVA r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Cmovs_r16_rm16, legacy, , 0F, 48, o16 0F 48 /r, CMOVS r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Cmovs_r32_rm32, legacy, , 0F, 48, o32 0F 48 /r, CMOVS r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Cmovs_r64_rm64, legacy, , 0F, 48, REX.W 0F 48 /r, CMOVS r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Cmovns_r16_rm16, legacy, , 0F, 49, o16 0F 49 /r, CMOVNS r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Cmovns_r32_rm32, legacy, , 0F, 49, o32 0F 49 /r, CMOVNS r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Cmovns_r64_rm64, legacy, , 0F, 49, REX.W 0F 49 /r, CMOVNS r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Cmovp_r16_rm16, legacy, , 0F, 4A, o16 0F 4A /r, CMOVP r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Cmovp_r32_rm32, legacy, , 0F, 4A, o32 0F 4A /r, CMOVP r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Cmovp_r64_rm64, legacy, , 0F, 4A, REX.W 0F 4A /r, CMOVP r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Cmovnp_r16_rm16, legacy, , 0F, 4B, o16 0F 4B /r, CMOVNP r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Cmovnp_r32_rm32, legacy, , 0F, 4B, o32 0F 4B /r, CMOVNP r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Cmovnp_r64_rm64, legacy, , 0F, 4B, REX.W 0F 4B /r, CMOVNP r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Cmovl_r16_rm16, legacy, , 0F, 4C, o16 0F 4C /r, CMOVL r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Cmovl_r32_rm32, legacy, , 0F, 4C, o32 0F 4C /r, CMOVL r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Cmovl_r64_rm64, legacy, , 0F, 4C, REX.W 0F 4C /r, CMOVL r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Cmovge_r16_rm16, legacy, , 0F, 4D, o16 0F 4D /r, CMOVGE r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Cmovge_r32_rm32, legacy, , 0F, 4D, o32 0F 4D /r, CMOVGE r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Cmovge_r64_rm64, legacy, , 0F, 4D, REX.W 0F 4D /r, CMOVGE r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Cmovle_r16_rm16, legacy, , 0F, 4E, o16 0F 4E /r, CMOVLE r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Cmovle_r32_rm32, legacy, , 0F, 4E, o32 0F 4E /r, CMOVLE r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Cmovle_r64_rm64, legacy, , 0F, 4E, REX.W 0F 4E /r, CMOVLE r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Cmovg_r16_rm16, legacy, , 0F, 4F, o16 0F 4F /r, CMOVG r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Cmovg_r32_rm32, legacy, , 0F, 4F, o32 0F 4F /r, CMOVG r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Cmovg_r64_rm64, legacy, , 0F, 4F, REX.W 0F 4F /r, CMOVG r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
VEX_Kandw_k_k_k, VEX, NP, 0F, 41, VEX.L1.0F.W0 41 /r, KANDW k1| k2| k3, 16b 32b 64b L1 W0 op=k_reg;k_vvvv;k_rm
VEX_Kandq_k_k_k, VEX, NP, 0F, 41, VEX.L1.0F.W1 41 /r, KANDQ k1| k2| k3, 16b 32b 64b L1 W1 op=k_reg;k_vvvv;k_rm
VEX_Kandb_k_k_k, VEX, 66, 0F, 41, VEX.L1.66.0F.W0 41 /r, KANDB k1| k2| k3, 16b 32b 64b L1 W0 op=k_reg;k_vvvv;k_rm
VEX_Kandd_k_k_k, VEX, 66, 0F, 41, VEX.L1.66.0F.W1 41 /r, KANDD k1| k2| k3, 16b 32b 64b L1 W1 op=k_reg;k_vvvv;k_rm
VEX_Kandnw_k_k_k, VEX, NP, 0F, 42, VEX.L1.0F.W0 42 /r, KANDNW k1| k2| k3, 16b 32b 64b L1 W0 op=k_reg;k_vvvv;k_rm
VEX_Kandnq_k_k_k, VEX, NP, 0F, 42, VEX.L1.0F.W1 42 /r, KANDNQ k1| k2| k3, 16b 32b 64b L1 W1 op=k_reg;k_vvvv;k_rm
VEX_Kandnb_k_k_k, VEX, 66, 0F, 42, VEX.L1.66.0F.W0 42 /r, KANDNB k1| k2| k3, 16b 32b 64b L1 W0 op=k_reg;k_vvvv;k_rm
VEX_Kandnd_k_k_k, VEX, 66, 0F, 42, VEX.L1.66.0F.W1 42 /r, KANDND k1| k2| k3, 16b 32b 64b L1 W1 op=k_reg;k_vvvv;k_rm
VEX_Knotw_k_k, VEX, NP, 0F, 44, VEX.L0.0F.W0 44 /r, KNOTW k1| k2, 16b 32b 64b L0 W0 op=k_reg;k_rm
VEX_Knotq_k_k, VEX, NP, 0F, 44, VEX.L0.0F.W1 44 /r, KNOTQ k1| k2, 16b 32b 64b L0 W1 op=k_reg;k_rm
VEX_Knotb_k_k, VEX, 66, 0F, 44, VEX.L0.66.0F.W0 44 /r, KNOTB k1| k2, 16b 32b 64b L0 W0 op=k_reg;k_rm
VEX_Knotd_k_k, VEX, 66, 0F, 44, VEX.L0.66.0F.W1 44 /r, KNOTD k1| k2, 16b 32b 64b L0 W1 op=k_reg;k_rm
VEX_Korw_k_k_k, VEX, NP, 0F, 45, VEX.L1.0F.W0 45 /r, KORW k1| k2| k3, 16b 32b 64b L1 W0 op=k_reg;k_vvvv;k_rm
VEX_Korq_k_k_k, VEX, NP, 0F, 45, VEX.L1.0F.W1 45 /r, KORQ k1| k2| k3, 16b 32b 64b L1 W1 op=k_reg;k_vvvv;k_rm
VEX_Korb_k_k_k, VEX, 66, 0F, 45, VEX.L1.66.0F.W0 45 /r, KORB k1| k2| k3, 16b 32b 64b L1 W0 op=k_reg;k_vvvv;k_rm
VEX_Kord_k_k_k, VEX, 66, 0F, 45, VEX.L1.66.0F.W1 45 /r, KORD k1| k2| k3, 16b 32b 64b L1 W1 op=k_reg;k_vvvv;k_rm
VEX_Kxnorw_k_k_k, VEX, NP, 0F, 46, VEX.L1.0F.W0 46 /r, KXNORW k1| k2| k3, 16b 32b 64b L1 W0 op=k_reg;k_vvvv;k_rm
VEX_Kxnorq_k_k_k, VEX, NP, 0F, 46, VEX.L1.0F.W1 46 /r, KXNORQ k1| k2| k3, 16b 32b 64b L1 W1 op=k_reg;k_vvvv;k_rm
VEX_Kxnorb_k_k_k, VEX, 66, 0F, 46, VEX.L1.66.0F.W0 46 /r, KXNORB k1| k2| k3, 16b 32b 64b L1 W0 op=k_reg;k_vvvv;k_rm
VEX_Kxnord_k_k_k, VEX, 66, 0F, 46, VEX.L1.66.0F.W1 46 /r, KXNORD k1| k2| k3, 16b 32b 64b L1 W1 op=k_reg;k_vvvv;k_rm
VEX_Kxorw_k_k_k, VEX, NP, 0F, 47, VEX.L1.0F.W0 47 /r, KXORW k1| k2| k3, 16b 32b 64b L1 W0 op=k_reg;k_vvvv;k_rm
VEX_Kxorq_k_k_k, VEX, NP, 0F, 47, VEX.L1.0F.W1 47 /r, KXORQ k1| k2| k3, 16b 32b 64b L1 W1 op=k_reg;k_vvvv;k_rm
VEX_Kxorb_k_k_k, VEX, 66, 0F, 47, VEX.L1.66.0F.W0 47 /r, KXORB k1| k2| k3, 16b 32b 64b L1 W0 op=k_reg;k_vvvv;k_rm
VEX_Kxord_k_k_k, VEX, 66, 0F, 47, VEX.L1.66.0F.W1 47 /r, KXORD k1| k2| k3, 16b 32b 64b L1 W1 op=k_reg;k_vvvv;k_rm
VEX_Kaddw_k_k_k, VEX, NP, 0F, 4A, VEX.L1.0F.W0 4A /r, KADDW k1| k2| k3, 16b 32b 64b L1 W0 op=k_reg;k_vvvv;k_rm
VEX_Kaddq_k_k_k, VEX, NP, 0F, 4A, VEX.L1.0F.W1 4A /r, KADDQ k1| k2| k3, 16b 32b 64b L1 W1 op=k_reg;k_vvvv;k_rm
VEX_Kaddb_k_k_k, VEX, 66, 0F, 4A, VEX.L1.66.0F.W0 4A /r, KADDB k1| k2| k3, 16b 32b 64b L1 W0 op=k_reg;k_vvvv;k_rm
VEX_Kaddd_k_k_k, VEX, 66, 0F, 4A, VEX.L1.66.0F.W1 4A /r, KADDD k1| k2| k3, 16b 32b 64b L1 W1 op=k_reg;k_vvvv;k_rm
VEX_Kunpckwd_k_k_k, VEX, NP, 0F, 4B, VEX.L1.0F.W0 4B /r, KUNPCKWD k1| k2| k3, 16b 32b 64b L1 W0 op=k_reg;k_vvvv;k_rm
VEX_Kunpckdq_k_k_k, VEX, NP, 0F, 4B, VEX.L1.0F.W1 4B /r, KUNPCKDQ k1| k2| k3, 16b 32b 64b L1 W1 op=k_reg;k_vvvv;k_rm
VEX_Kunpckbw_k_k_k, VEX, 66, 0F, 4B, VEX.L1.66.0F.W0 4B /r, KUNPCKBW k1| k2| k3, 16b 32b 64b L1 W0 op=k_reg;k_vvvv;k_rm
Movmskps_r32_xmm, legacy, NP, 0F, 50, NP 0F 50 /r, MOVMSKPS r32| xmm, 16b 32b 64b op=r32_reg;xmm_rm
Movmskps_r64_xmm, legacy, NP, 0F, 50, NP REX.W 0F 50 /r, MOVMSKPS r64| xmm, 64b o64 op=r64_reg;xmm_rm
VEX_Vmovmskps_r32_xmm, VEX, NP, 0F, 50, VEX.128.0F.W0 50 /r, VMOVMSKPS r32| xmm2, 16b 32b 64b L128 WIG32 op=r32_reg;xmm_rm
VEX_Vmovmskps_r64_xmm, VEX, NP, 0F, 50, VEX.128.0F.W1 50 /r, VMOVMSKPS r64| xmm2, 64b L128 W1 op=r64_reg;xmm_rm
VEX_Vmovmskps_r32_ymm, VEX, NP, 0F, 50, VEX.256.0F.W0 50 /r, VMOVMSKPS r32| ymm2, 16b 32b 64b L256 WIG32 op=r32_reg;ymm_rm
VEX_Vmovmskps_r64_ymm, VEX, NP, 0F, 50, VEX.256.0F.W1 50 /r, VMOVMSKPS r64| ymm2, 64b L256 W1 op=r64_reg;ymm_rm
Movmskpd_r32_xmm, legacy, 66, 0F, 50, 66 0F 50 /r, MOVMSKPD r32| xmm, 16b 32b 64b op=r32_reg;xmm_rm
Movmskpd_r64_xmm, legacy, 66, 0F, 50, 66 REX.W 0F 50 /r, MOVMSKPD r64| xmm, 64b o64 op=r64_reg;xmm_rm
VEX_Vmovmskpd_r32_xmm, VEX, 66, 0F, 50, VEX.128.66.0F.W0 50 /r, VMOVMSKPD r32| xmm2, 16b 32b 64b L128 WIG32 op=r32_reg;xmm_rm
VEX_Vmovmskpd_r64_xmm, VEX, 66, 0F, 50, VEX.128.66.0F.W1 50 /r, VMOVMSKPD r64| xmm2, 64b L128 W1 op=r64_reg;xmm_rm
VEX_Vmovmskpd_r32_ymm, VEX, 66, 0F, 50, VEX.256.66.0F.W0 50 /r, VMOVMSKPD r32| ymm2, 16b 32b 64b L256 WIG32 op=r32_reg;ymm_rm
VEX_Vmovmskpd_r64_ymm, VEX, 66, 0F, 50, VEX.256.66.0F.W1 50 /r, VMOVMSKPD r64| ymm2, 64b L256 W1 op=r64_reg;ymm_rm
Sqrtps_xmm_xmmm128, legacy, NP, 0F, 51, NP 0F 51 /r, SQRTPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vsqrtps_xmm_xmmm128, VEX, NP, 0F, 51, VEX.128.0F.WIG 51 /r, VSQRTPS xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vsqrtps_ymm_ymmm256, VEX, NP, 0F, 51, VEX.256.0F.WIG 51 /r, VSQRTPS ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
EVEX_Vsqrtps_xmm_k1z_xmmm128b32, EVEX, NP, 0F, 51, EVEX.128.0F.W0 51 /r, VSQRTPS xmm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vsqrtps_ymm_k1z_ymmm256b32, EVEX, NP, 0F, 51, EVEX.256.0F.W0 51 /r, VSQRTPS ymm1 {k1}{z}| ymm2/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vsqrtps_zmm_k1z_zmmm512b32_er, EVEX, NP, 0F, 51, EVEX.512.0F.W0 51 /r, VSQRTPS zmm1 {k1}{z}| zmm2/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_512 b er k z
Sqrtpd_xmm_xmmm128, legacy, 66, 0F, 51, 66 0F 51 /r, SQRTPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vsqrtpd_xmm_xmmm128, VEX, 66, 0F, 51, VEX.128.66.0F.WIG 51 /r, VSQRTPD xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vsqrtpd_ymm_ymmm256, VEX, 66, 0F, 51, VEX.256.66.0F.WIG 51 /r, VSQRTPD ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
EVEX_Vsqrtpd_xmm_k1z_xmmm128b64, EVEX, 66, 0F, 51, EVEX.128.66.0F.W1 51 /r, VSQRTPD xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vsqrtpd_ymm_k1z_ymmm256b64, EVEX, 66, 0F, 51, EVEX.256.66.0F.W1 51 /r, VSQRTPD ymm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vsqrtpd_zmm_k1z_zmmm512b64_er, EVEX, 66, 0F, 51, EVEX.512.66.0F.W1 51 /r, VSQRTPD zmm1 {k1}{z}| zmm2/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_512 b er k z
Sqrtss_xmm_xmmm32, legacy, F3, 0F, 51, F3 0F 51 /r, SQRTSS xmm1| xmm2/m32, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vsqrtss_xmm_xmm_xmmm32, VEX, F3, 0F, 51, VEX.LIG.F3.0F.WIG 51 /r, VSQRTSS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vsqrtss_xmm_k1z_xmm_xmmm32_er, EVEX, F3, 0F, 51, EVEX.LIG.F3.0F.W0 51 /r, VSQRTSS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
Sqrtsd_xmm_xmmm64, legacy, F2, 0F, 51, F2 0F 51 /r, SQRTSD xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vsqrtsd_xmm_xmm_xmmm64, VEX, F2, 0F, 51, VEX.LIG.F2.0F.WIG 51 /r, VSQRTSD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vsqrtsd_xmm_k1z_xmm_xmmm64_er, EVEX, F2, 0F, 51, EVEX.LIG.F2.0F.W1 51 /r, VSQRTSD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
Rsqrtps_xmm_xmmm128, legacy, NP, 0F, 52, NP 0F 52 /r, RSQRTPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vrsqrtps_xmm_xmmm128, VEX, NP, 0F, 52, VEX.128.0F.WIG 52 /r, VRSQRTPS xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vrsqrtps_ymm_ymmm256, VEX, NP, 0F, 52, VEX.256.0F.WIG 52 /r, VRSQRTPS ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
Rsqrtss_xmm_xmmm32, legacy, F3, 0F, 52, F3 0F 52 /r, RSQRTSS xmm1| xmm2/m32, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vrsqrtss_xmm_xmm_xmmm32, VEX, F3, 0F, 52, VEX.LIG.F3.0F.WIG 52 /r, VRSQRTSS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
Rcpps_xmm_xmmm128, legacy, NP, 0F, 53, NP 0F 53 /r, RCPPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vrcpps_xmm_xmmm128, VEX, NP, 0F, 53, VEX.128.0F.WIG 53 /r, VRCPPS xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vrcpps_ymm_ymmm256, VEX, NP, 0F, 53, VEX.256.0F.WIG 53 /r, VRCPPS ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
Rcpss_xmm_xmmm32, legacy, F3, 0F, 53, F3 0F 53 /r, RCPSS xmm1| xmm2/m32, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vrcpss_xmm_xmm_xmmm32, VEX, F3, 0F, 53, VEX.LIG.F3.0F.WIG 53 /r, VRCPSS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
Andps_xmm_xmmm128, legacy, NP, 0F, 54, NP 0F 54 /r, ANDPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vandps_xmm_xmm_xmmm128, VEX, NP, 0F, 54, VEX.128.0F.WIG 54 /r, VANDPS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vandps_ymm_ymm_ymmm256, VEX, NP, 0F, 54, VEX.256.0F.WIG 54 /r, VANDPS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vandps_xmm_k1z_xmm_xmmm128b32, EVEX, NP, 0F, 54, EVEX.128.0F.W0 54 /r, VANDPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vandps_ymm_k1z_ymm_ymmm256b32, EVEX, NP, 0F, 54, EVEX.256.0F.W0 54 /r, VANDPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vandps_zmm_k1z_zmm_zmmm512b32, EVEX, NP, 0F, 54, EVEX.512.0F.W0 54 /r, VANDPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Andpd_xmm_xmmm128, legacy, 66, 0F, 54, 66 0F 54 /r, ANDPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vandpd_xmm_xmm_xmmm128, VEX, 66, 0F, 54, VEX.128.66.0F.WIG 54 /r, VANDPD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vandpd_ymm_ymm_ymmm256, VEX, 66, 0F, 54, VEX.256.66.0F.WIG 54 /r, VANDPD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vandpd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, 54, EVEX.128.66.0F.W1 54 /r, VANDPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vandpd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, 54, EVEX.256.66.0F.W1 54 /r, VANDPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vandpd_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F, 54, EVEX.512.66.0F.W1 54 /r, VANDPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Andnps_xmm_xmmm128, legacy, NP, 0F, 55, NP 0F 55 /r, ANDNPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vandnps_xmm_xmm_xmmm128, VEX, NP, 0F, 55, VEX.128.0F.WIG 55 /r, VANDNPS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vandnps_ymm_ymm_ymmm256, VEX, NP, 0F, 55, VEX.256.0F.WIG 55 /r, VANDNPS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vandnps_xmm_k1z_xmm_xmmm128b32, EVEX, NP, 0F, 55, EVEX.128.0F.W0 55 /r, VANDNPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vandnps_ymm_k1z_ymm_ymmm256b32, EVEX, NP, 0F, 55, EVEX.256.0F.W0 55 /r, VANDNPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vandnps_zmm_k1z_zmm_zmmm512b32, EVEX, NP, 0F, 55, EVEX.512.0F.W0 55 /r, VANDNPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Andnpd_xmm_xmmm128, legacy, 66, 0F, 55, 66 0F 55 /r, ANDNPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vandnpd_xmm_xmm_xmmm128, VEX, 66, 0F, 55, VEX.128.66.0F.WIG 55 /r, VANDNPD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vandnpd_ymm_ymm_ymmm256, VEX, 66, 0F, 55, VEX.256.66.0F.WIG 55 /r, VANDNPD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vandnpd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, 55, EVEX.128.66.0F.W1 55 /r, VANDNPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vandnpd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, 55, EVEX.256.66.0F.W1 55 /r, VANDNPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vandnpd_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F, 55, EVEX.512.66.0F.W1 55 /r, VANDNPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Orps_xmm_xmmm128, legacy, NP, 0F, 56, NP 0F 56 /r, ORPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vorps_xmm_xmm_xmmm128, VEX, NP, 0F, 56, VEX.128.0F.WIG 56 /r, VORPS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vorps_ymm_ymm_ymmm256, VEX, NP, 0F, 56, VEX.256.0F.WIG 56 /r, VORPS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vorps_xmm_k1z_xmm_xmmm128b32, EVEX, NP, 0F, 56, EVEX.128.0F.W0 56 /r, VORPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vorps_ymm_k1z_ymm_ymmm256b32, EVEX, NP, 0F, 56, EVEX.256.0F.W0 56 /r, VORPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vorps_zmm_k1z_zmm_zmmm512b32, EVEX, NP, 0F, 56, EVEX.512.0F.W0 56 /r, VORPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Orpd_xmm_xmmm128, legacy, 66, 0F, 56, 66 0F 56 /r, ORPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vorpd_xmm_xmm_xmmm128, VEX, 66, 0F, 56, VEX.128.66.0F.WIG 56 /r, VORPD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vorpd_ymm_ymm_ymmm256, VEX, 66, 0F, 56, VEX.256.66.0F.WIG 56 /r, VORPD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vorpd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, 56, EVEX.128.66.0F.W1 56 /r, VORPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vorpd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, 56, EVEX.256.66.0F.W1 56 /r, VORPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vorpd_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F, 56, EVEX.512.66.0F.W1 56 /r, VORPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Xorps_xmm_xmmm128, legacy, NP, 0F, 57, NP 0F 57 /r, XORPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vxorps_xmm_xmm_xmmm128, VEX, NP, 0F, 57, VEX.128.0F.WIG 57 /r, VXORPS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vxorps_ymm_ymm_ymmm256, VEX, NP, 0F, 57, VEX.256.0F.WIG 57 /r, VXORPS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vxorps_xmm_k1z_xmm_xmmm128b32, EVEX, NP, 0F, 57, EVEX.128.0F.W0 57 /r, VXORPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vxorps_ymm_k1z_ymm_ymmm256b32, EVEX, NP, 0F, 57, EVEX.256.0F.W0 57 /r, VXORPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vxorps_zmm_k1z_zmm_zmmm512b32, EVEX, NP, 0F, 57, EVEX.512.0F.W0 57 /r, VXORPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Xorpd_xmm_xmmm128, legacy, 66, 0F, 57, 66 0F 57 /r, XORPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vxorpd_xmm_xmm_xmmm128, VEX, 66, 0F, 57, VEX.128.66.0F.WIG 57 /r, VXORPD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vxorpd_ymm_ymm_ymmm256, VEX, 66, 0F, 57, VEX.256.66.0F.WIG 57 /r, VXORPD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vxorpd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, 57, EVEX.128.66.0F.W1 57 /r, VXORPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vxorpd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, 57, EVEX.256.66.0F.W1 57 /r, VXORPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vxorpd_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F, 57, EVEX.512.66.0F.W1 57 /r, VXORPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Addps_xmm_xmmm128, legacy, NP, 0F, 58, NP 0F 58 /r, ADDPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vaddps_xmm_xmm_xmmm128, VEX, NP, 0F, 58, VEX.128.0F.WIG 58 /r, VADDPS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vaddps_ymm_ymm_ymmm256, VEX, NP, 0F, 58, VEX.256.0F.WIG 58 /r, VADDPS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vaddps_xmm_k1z_xmm_xmmm128b32, EVEX, NP, 0F, 58, EVEX.128.0F.W0 58 /r, VADDPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vaddps_ymm_k1z_ymm_ymmm256b32, EVEX, NP, 0F, 58, EVEX.256.0F.W0 58 /r, VADDPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vaddps_zmm_k1z_zmm_zmmm512b32_er, EVEX, NP, 0F, 58, EVEX.512.0F.W0 58 /r, VADDPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
Addpd_xmm_xmmm128, legacy, 66, 0F, 58, 66 0F 58 /r, ADDPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vaddpd_xmm_xmm_xmmm128, VEX, 66, 0F, 58, VEX.128.66.0F.WIG 58 /r, VADDPD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vaddpd_ymm_ymm_ymmm256, VEX, 66, 0F, 58, VEX.256.66.0F.WIG 58 /r, VADDPD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vaddpd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, 58, EVEX.128.66.0F.W1 58 /r, VADDPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vaddpd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, 58, EVEX.256.66.0F.W1 58 /r, VADDPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vaddpd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F, 58, EVEX.512.66.0F.W1 58 /r, VADDPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
Addss_xmm_xmmm32, legacy, F3, 0F, 58, F3 0F 58 /r, ADDSS xmm1| xmm2/m32, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vaddss_xmm_xmm_xmmm32, VEX, F3, 0F, 58, VEX.LIG.F3.0F.WIG 58 /r, VADDSS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vaddss_xmm_k1z_xmm_xmmm32_er, EVEX, F3, 0F, 58, EVEX.LIG.F3.0F.W0 58 /r, VADDSS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
Addsd_xmm_xmmm64, legacy, F2, 0F, 58, F2 0F 58 /r, ADDSD xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vaddsd_xmm_xmm_xmmm64, VEX, F2, 0F, 58, VEX.LIG.F2.0F.WIG 58 /r, VADDSD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vaddsd_xmm_k1z_xmm_xmmm64_er, EVEX, F2, 0F, 58, EVEX.LIG.F2.0F.W1 58 /r, VADDSD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
Mulps_xmm_xmmm128, legacy, NP, 0F, 59, NP 0F 59 /r, MULPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmulps_xmm_xmm_xmmm128, VEX, NP, 0F, 59, VEX.128.0F.WIG 59 /r, VMULPS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vmulps_ymm_ymm_ymmm256, VEX, NP, 0F, 59, VEX.256.0F.WIG 59 /r, VMULPS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vmulps_xmm_k1z_xmm_xmmm128b32, EVEX, NP, 0F, 59, EVEX.128.0F.W0 59 /r, VMULPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vmulps_ymm_k1z_ymm_ymmm256b32, EVEX, NP, 0F, 59, EVEX.256.0F.W0 59 /r, VMULPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vmulps_zmm_k1z_zmm_zmmm512b32_er, EVEX, NP, 0F, 59, EVEX.512.0F.W0 59 /r, VMULPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
Mulpd_xmm_xmmm128, legacy, 66, 0F, 59, 66 0F 59 /r, MULPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmulpd_xmm_xmm_xmmm128, VEX, 66, 0F, 59, VEX.128.66.0F.WIG 59 /r, VMULPD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vmulpd_ymm_ymm_ymmm256, VEX, 66, 0F, 59, VEX.256.66.0F.WIG 59 /r, VMULPD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vmulpd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, 59, EVEX.128.66.0F.W1 59 /r, VMULPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vmulpd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, 59, EVEX.256.66.0F.W1 59 /r, VMULPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vmulpd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F, 59, EVEX.512.66.0F.W1 59 /r, VMULPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
Mulss_xmm_xmmm32, legacy, F3, 0F, 59, F3 0F 59 /r, MULSS xmm1| xmm2/m32, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmulss_xmm_xmm_xmmm32, VEX, F3, 0F, 59, VEX.LIG.F3.0F.WIG 59 /r, VMULSS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vmulss_xmm_k1z_xmm_xmmm32_er, EVEX, F3, 0F, 59, EVEX.LIG.F3.0F.W0 59 /r, VMULSS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
Mulsd_xmm_xmmm64, legacy, F2, 0F, 59, F2 0F 59 /r, MULSD xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmulsd_xmm_xmm_xmmm64, VEX, F2, 0F, 59, VEX.LIG.F2.0F.WIG 59 /r, VMULSD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vmulsd_xmm_k1z_xmm_xmmm64_er, EVEX, F2, 0F, 59, EVEX.LIG.F2.0F.W1 59 /r, VMULSD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
Cvtps2pd_xmm_xmmm64, legacy, NP, 0F, 5A, NP 0F 5A /r, CVTPS2PD xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vcvtps2pd_xmm_xmmm64, VEX, NP, 0F, 5A, VEX.128.0F.WIG 5A /r, VCVTPS2PD xmm1| xmm2/m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vcvtps2pd_ymm_xmmm128, VEX, NP, 0F, 5A, VEX.256.0F.WIG 5A /r, VCVTPS2PD ymm1| xmm2/m128, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem
EVEX_Vcvtps2pd_xmm_k1z_xmmm64b32, EVEX, NP, 0F, 5A, EVEX.128.0F.W0 5A /r, VCVTPS2PD xmm1 {k1}{z}| xmm2/m64/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Half_128 b k z
EVEX_Vcvtps2pd_ymm_k1z_xmmm128b32, EVEX, NP, 0F, 5A, EVEX.256.0F.W0 5A /r, VCVTPS2PD ymm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem tt=Half_256 b k z
EVEX_Vcvtps2pd_zmm_k1z_ymmm256b32_sae, EVEX, NP, 0F, 5A, EVEX.512.0F.W0 5A /r, VCVTPS2PD zmm1 {k1}{z}| ymm2/m256/m32bcst{sae}, 16b 32b 64b L512 W0 op=zmm_reg;ymm_or_mem tt=Half_512 b sae k z
Cvtpd2ps_xmm_xmmm128, legacy, 66, 0F, 5A, 66 0F 5A /r, CVTPD2PS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vcvtpd2ps_xmm_xmmm128, VEX, 66, 0F, 5A, VEX.128.66.0F.WIG 5A /r, VCVTPD2PS xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vcvtpd2ps_xmm_ymmm256, VEX, 66, 0F, 5A, VEX.256.66.0F.WIG 5A /r, VCVTPD2PS xmm1| ymm2/m256, 16b 32b 64b L256 WIG op=xmm_reg;ymm_or_mem
EVEX_Vcvtpd2ps_xmm_k1z_xmmm128b64, EVEX, 66, 0F, 5A, EVEX.128.66.0F.W1 5A /r, VCVTPD2PS xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvtpd2ps_xmm_k1z_ymmm256b64, EVEX, 66, 0F, 5A, EVEX.256.66.0F.W1 5A /r, VCVTPD2PS xmm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=xmm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvtpd2ps_ymm_k1z_zmmm512b64_er, EVEX, 66, 0F, 5A, EVEX.512.66.0F.W1 5A /r, VCVTPD2PS ymm1 {k1}{z}| zmm2/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=ymm_reg;zmm_or_mem tt=Full_512 b er k z
Cvtss2sd_xmm_xmmm32, legacy, F3, 0F, 5A, F3 0F 5A /r, CVTSS2SD xmm1| xmm2/m32, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vcvtss2sd_xmm_xmm_xmmm32, VEX, F3, 0F, 5A, VEX.LIG.F3.0F.WIG 5A /r, VCVTSS2SD xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vcvtss2sd_xmm_k1z_xmm_xmmm32_sae, EVEX, F3, 0F, 5A, EVEX.LIG.F3.0F.W0 5A /r, VCVTSS2SD xmm1 {k1}{z}| xmm2| xmm3/m32{sae}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar sae k z
Cvtsd2ss_xmm_xmmm64, legacy, F2, 0F, 5A, F2 0F 5A /r, CVTSD2SS xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vcvtsd2ss_xmm_xmm_xmmm64, VEX, F2, 0F, 5A, VEX.LIG.F2.0F.WIG 5A /r, VCVTSD2SS xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vcvtsd2ss_xmm_k1z_xmm_xmmm64_er, EVEX, F2, 0F, 5A, EVEX.LIG.F2.0F.W1 5A /r, VCVTSD2SS xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
Cvtdq2ps_xmm_xmmm128, legacy, NP, 0F, 5B, NP 0F 5B /r, CVTDQ2PS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vcvtdq2ps_xmm_xmmm128, VEX, NP, 0F, 5B, VEX.128.0F.WIG 5B /r, VCVTDQ2PS xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vcvtdq2ps_ymm_ymmm256, VEX, NP, 0F, 5B, VEX.256.0F.WIG 5B /r, VCVTDQ2PS ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
EVEX_Vcvtdq2ps_xmm_k1z_xmmm128b32, EVEX, NP, 0F, 5B, EVEX.128.0F.W0 5B /r, VCVTDQ2PS xmm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvtdq2ps_ymm_k1z_ymmm256b32, EVEX, NP, 0F, 5B, EVEX.256.0F.W0 5B /r, VCVTDQ2PS ymm1 {k1}{z}| ymm2/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvtdq2ps_zmm_k1z_zmmm512b32_er, EVEX, NP, 0F, 5B, EVEX.512.0F.W0 5B /r, VCVTDQ2PS zmm1 {k1}{z}| zmm2/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_512 b er k z
EVEX_Vcvtqq2ps_xmm_k1z_xmmm128b64, EVEX, NP, 0F, 5B, EVEX.128.0F.W1 5B /r, VCVTQQ2PS xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvtqq2ps_xmm_k1z_ymmm256b64, EVEX, NP, 0F, 5B, EVEX.256.0F.W1 5B /r, VCVTQQ2PS xmm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=xmm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvtqq2ps_ymm_k1z_zmmm512b64_er, EVEX, NP, 0F, 5B, EVEX.512.0F.W1 5B /r, VCVTQQ2PS ymm1 {k1}{z}| zmm2/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=ymm_reg;zmm_or_mem tt=Full_512 b er k z
Cvtps2dq_xmm_xmmm128, legacy, 66, 0F, 5B, 66 0F 5B /r, CVTPS2DQ xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vcvtps2dq_xmm_xmmm128, VEX, 66, 0F, 5B, VEX.128.66.0F.WIG 5B /r, VCVTPS2DQ xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vcvtps2dq_ymm_ymmm256, VEX, 66, 0F, 5B, VEX.256.66.0F.WIG 5B /r, VCVTPS2DQ ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
EVEX_Vcvtps2dq_xmm_k1z_xmmm128b32, EVEX, 66, 0F, 5B, EVEX.128.66.0F.W0 5B /r, VCVTPS2DQ xmm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvtps2dq_ymm_k1z_ymmm256b32, EVEX, 66, 0F, 5B, EVEX.256.66.0F.W0 5B /r, VCVTPS2DQ ymm1 {k1}{z}| ymm2/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvtps2dq_zmm_k1z_zmmm512b32_er, EVEX, 66, 0F, 5B, EVEX.512.66.0F.W0 5B /r, VCVTPS2DQ zmm1 {k1}{z}| zmm2/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_512 b er k z
Cvttps2dq_xmm_xmmm128, legacy, F3, 0F, 5B, F3 0F 5B /r, CVTTPS2DQ xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vcvttps2dq_xmm_xmmm128, VEX, F3, 0F, 5B, VEX.128.F3.0F.WIG 5B /r, VCVTTPS2DQ xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vcvttps2dq_ymm_ymmm256, VEX, F3, 0F, 5B, VEX.256.F3.0F.WIG 5B /r, VCVTTPS2DQ ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
EVEX_Vcvttps2dq_xmm_k1z_xmmm128b32, EVEX, F3, 0F, 5B, EVEX.128.F3.0F.W0 5B /r, VCVTTPS2DQ xmm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvttps2dq_ymm_k1z_ymmm256b32, EVEX, F3, 0F, 5B, EVEX.256.F3.0F.W0 5B /r, VCVTTPS2DQ ymm1 {k1}{z}| ymm2/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvttps2dq_zmm_k1z_zmmm512b32_sae, EVEX, F3, 0F, 5B, EVEX.512.F3.0F.W0 5B /r, VCVTTPS2DQ zmm1 {k1}{z}| zmm2/m512/m32bcst{sae}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_512 b sae k z
Subps_xmm_xmmm128, legacy, NP, 0F, 5C, NP 0F 5C /r, SUBPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vsubps_xmm_xmm_xmmm128, VEX, NP, 0F, 5C, VEX.128.0F.WIG 5C /r, VSUBPS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vsubps_ymm_ymm_ymmm256, VEX, NP, 0F, 5C, VEX.256.0F.WIG 5C /r, VSUBPS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vsubps_xmm_k1z_xmm_xmmm128b32, EVEX, NP, 0F, 5C, EVEX.128.0F.W0 5C /r, VSUBPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vsubps_ymm_k1z_ymm_ymmm256b32, EVEX, NP, 0F, 5C, EVEX.256.0F.W0 5C /r, VSUBPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vsubps_zmm_k1z_zmm_zmmm512b32_er, EVEX, NP, 0F, 5C, EVEX.512.0F.W0 5C /r, VSUBPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
Subpd_xmm_xmmm128, legacy, 66, 0F, 5C, 66 0F 5C /r, SUBPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vsubpd_xmm_xmm_xmmm128, VEX, 66, 0F, 5C, VEX.128.66.0F.WIG 5C /r, VSUBPD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vsubpd_ymm_ymm_ymmm256, VEX, 66, 0F, 5C, VEX.256.66.0F.WIG 5C /r, VSUBPD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vsubpd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, 5C, EVEX.128.66.0F.W1 5C /r, VSUBPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vsubpd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, 5C, EVEX.256.66.0F.W1 5C /r, VSUBPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vsubpd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F, 5C, EVEX.512.66.0F.W1 5C /r, VSUBPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
Subss_xmm_xmmm32, legacy, F3, 0F, 5C, F3 0F 5C /r, SUBSS xmm1| xmm2/m32, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vsubss_xmm_xmm_xmmm32, VEX, F3, 0F, 5C, VEX.LIG.F3.0F.WIG 5C /r, VSUBSS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vsubss_xmm_k1z_xmm_xmmm32_er, EVEX, F3, 0F, 5C, EVEX.LIG.F3.0F.W0 5C /r, VSUBSS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
Subsd_xmm_xmmm64, legacy, F2, 0F, 5C, F2 0F 5C /r, SUBSD xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vsubsd_xmm_xmm_xmmm64, VEX, F2, 0F, 5C, VEX.LIG.F2.0F.WIG 5C /r, VSUBSD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vsubsd_xmm_k1z_xmm_xmmm64_er, EVEX, F2, 0F, 5C, EVEX.LIG.F2.0F.W1 5C /r, VSUBSD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
Minps_xmm_xmmm128, legacy, NP, 0F, 5D, NP 0F 5D /r, MINPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vminps_xmm_xmm_xmmm128, VEX, NP, 0F, 5D, VEX.128.0F.WIG 5D /r, VMINPS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vminps_ymm_ymm_ymmm256, VEX, NP, 0F, 5D, VEX.256.0F.WIG 5D /r, VMINPS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vminps_xmm_k1z_xmm_xmmm128b32, EVEX, NP, 0F, 5D, EVEX.128.0F.W0 5D /r, VMINPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vminps_ymm_k1z_ymm_ymmm256b32, EVEX, NP, 0F, 5D, EVEX.256.0F.W0 5D /r, VMINPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vminps_zmm_k1z_zmm_zmmm512b32_sae, EVEX, NP, 0F, 5D, EVEX.512.0F.W0 5D /r, VMINPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{sae}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b sae k z
Minpd_xmm_xmmm128, legacy, 66, 0F, 5D, 66 0F 5D /r, MINPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vminpd_xmm_xmm_xmmm128, VEX, 66, 0F, 5D, VEX.128.66.0F.WIG 5D /r, VMINPD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vminpd_ymm_ymm_ymmm256, VEX, 66, 0F, 5D, VEX.256.66.0F.WIG 5D /r, VMINPD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vminpd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, 5D, EVEX.128.66.0F.W1 5D /r, VMINPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vminpd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, 5D, EVEX.256.66.0F.W1 5D /r, VMINPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vminpd_zmm_k1z_zmm_zmmm512b64_sae, EVEX, 66, 0F, 5D, EVEX.512.66.0F.W1 5D /r, VMINPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{sae}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b sae k z
Minss_xmm_xmmm32, legacy, F3, 0F, 5D, F3 0F 5D /r, MINSS xmm1| xmm2/m32, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vminss_xmm_xmm_xmmm32, VEX, F3, 0F, 5D, VEX.LIG.F3.0F.WIG 5D /r, VMINSS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vminss_xmm_k1z_xmm_xmmm32_sae, EVEX, F3, 0F, 5D, EVEX.LIG.F3.0F.W0 5D /r, VMINSS xmm1 {k1}{z}| xmm2| xmm3/m32{sae}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar sae k z
Minsd_xmm_xmmm64, legacy, F2, 0F, 5D, F2 0F 5D /r, MINSD xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vminsd_xmm_xmm_xmmm64, VEX, F2, 0F, 5D, VEX.LIG.F2.0F.WIG 5D /r, VMINSD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vminsd_xmm_k1z_xmm_xmmm64_sae, EVEX, F2, 0F, 5D, EVEX.LIG.F2.0F.W1 5D /r, VMINSD xmm1 {k1}{z}| xmm2| xmm3/m64{sae}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar sae k z
Divps_xmm_xmmm128, legacy, NP, 0F, 5E, NP 0F 5E /r, DIVPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vdivps_xmm_xmm_xmmm128, VEX, NP, 0F, 5E, VEX.128.0F.WIG 5E /r, VDIVPS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vdivps_ymm_ymm_ymmm256, VEX, NP, 0F, 5E, VEX.256.0F.WIG 5E /r, VDIVPS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vdivps_xmm_k1z_xmm_xmmm128b32, EVEX, NP, 0F, 5E, EVEX.128.0F.W0 5E /r, VDIVPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vdivps_ymm_k1z_ymm_ymmm256b32, EVEX, NP, 0F, 5E, EVEX.256.0F.W0 5E /r, VDIVPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vdivps_zmm_k1z_zmm_zmmm512b32_er, EVEX, NP, 0F, 5E, EVEX.512.0F.W0 5E /r, VDIVPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
Divpd_xmm_xmmm128, legacy, 66, 0F, 5E, 66 0F 5E /r, DIVPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vdivpd_xmm_xmm_xmmm128, VEX, 66, 0F, 5E, VEX.128.66.0F.WIG 5E /r, VDIVPD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vdivpd_ymm_ymm_ymmm256, VEX, 66, 0F, 5E, VEX.256.66.0F.WIG 5E /r, VDIVPD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vdivpd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, 5E, EVEX.128.66.0F.W1 5E /r, VDIVPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vdivpd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, 5E, EVEX.256.66.0F.W1 5E /r, VDIVPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vdivpd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F, 5E, EVEX.512.66.0F.W1 5E /r, VDIVPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
Divss_xmm_xmmm32, legacy, F3, 0F, 5E, F3 0F 5E /r, DIVSS xmm1| xmm2/m32, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vdivss_xmm_xmm_xmmm32, VEX, F3, 0F, 5E, VEX.LIG.F3.0F.WIG 5E /r, VDIVSS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vdivss_xmm_k1z_xmm_xmmm32_er, EVEX, F3, 0F, 5E, EVEX.LIG.F3.0F.W0 5E /r, VDIVSS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
Divsd_xmm_xmmm64, legacy, F2, 0F, 5E, F2 0F 5E /r, DIVSD xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vdivsd_xmm_xmm_xmmm64, VEX, F2, 0F, 5E, VEX.LIG.F2.0F.WIG 5E /r, VDIVSD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vdivsd_xmm_k1z_xmm_xmmm64_er, EVEX, F2, 0F, 5E, EVEX.LIG.F2.0F.W1 5E /r, VDIVSD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
Maxps_xmm_xmmm128, legacy, NP, 0F, 5F, NP 0F 5F /r, MAXPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmaxps_xmm_xmm_xmmm128, VEX, NP, 0F, 5F, VEX.128.0F.WIG 5F /r, VMAXPS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vmaxps_ymm_ymm_ymmm256, VEX, NP, 0F, 5F, VEX.256.0F.WIG 5F /r, VMAXPS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vmaxps_xmm_k1z_xmm_xmmm128b32, EVEX, NP, 0F, 5F, EVEX.128.0F.W0 5F /r, VMAXPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vmaxps_ymm_k1z_ymm_ymmm256b32, EVEX, NP, 0F, 5F, EVEX.256.0F.W0 5F /r, VMAXPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vmaxps_zmm_k1z_zmm_zmmm512b32_sae, EVEX, NP, 0F, 5F, EVEX.512.0F.W0 5F /r, VMAXPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{sae}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b sae k z
Maxpd_xmm_xmmm128, legacy, 66, 0F, 5F, 66 0F 5F /r, MAXPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmaxpd_xmm_xmm_xmmm128, VEX, 66, 0F, 5F, VEX.128.66.0F.WIG 5F /r, VMAXPD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vmaxpd_ymm_ymm_ymmm256, VEX, 66, 0F, 5F, VEX.256.66.0F.WIG 5F /r, VMAXPD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vmaxpd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, 5F, EVEX.128.66.0F.W1 5F /r, VMAXPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vmaxpd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, 5F, EVEX.256.66.0F.W1 5F /r, VMAXPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vmaxpd_zmm_k1z_zmm_zmmm512b64_sae, EVEX, 66, 0F, 5F, EVEX.512.66.0F.W1 5F /r, VMAXPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{sae}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b sae k z
Maxss_xmm_xmmm32, legacy, F3, 0F, 5F, F3 0F 5F /r, MAXSS xmm1| xmm2/m32, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmaxss_xmm_xmm_xmmm32, VEX, F3, 0F, 5F, VEX.LIG.F3.0F.WIG 5F /r, VMAXSS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vmaxss_xmm_k1z_xmm_xmmm32_sae, EVEX, F3, 0F, 5F, EVEX.LIG.F3.0F.W0 5F /r, VMAXSS xmm1 {k1}{z}| xmm2| xmm3/m32{sae}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar sae k z
Maxsd_xmm_xmmm64, legacy, F2, 0F, 5F, F2 0F 5F /r, MAXSD xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmaxsd_xmm_xmm_xmmm64, VEX, F2, 0F, 5F, VEX.LIG.F2.0F.WIG 5F /r, VMAXSD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vmaxsd_xmm_k1z_xmm_xmmm64_sae, EVEX, F2, 0F, 5F, EVEX.LIG.F2.0F.W1 5F /r, VMAXSD xmm1 {k1}{z}| xmm2| xmm3/m64{sae}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar sae k z
Punpcklbw_mm_mmm32, legacy, NP, 0F, 60, NP 0F 60 /r, PUNPCKLBW mm| mm/m32, 16b 32b 64b op=mm_reg;mm_or_mem
Punpcklbw_xmm_xmmm128, legacy, 66, 0F, 60, 66 0F 60 /r, PUNPCKLBW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpunpcklbw_xmm_xmm_xmmm128, VEX, 66, 0F, 60, VEX.128.66.0F.WIG 60 /r, VPUNPCKLBW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpunpcklbw_ymm_ymm_ymmm256, VEX, 66, 0F, 60, VEX.256.66.0F.WIG 60 /r, VPUNPCKLBW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpunpcklbw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, 60, EVEX.128.66.0F.WIG 60 /r, VPUNPCKLBW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpunpcklbw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, 60, EVEX.256.66.0F.WIG 60 /r, VPUNPCKLBW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpunpcklbw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, 60, EVEX.512.66.0F.WIG 60 /r, VPUNPCKLBW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Punpcklwd_mm_mmm32, legacy, NP, 0F, 61, NP 0F 61 /r, PUNPCKLWD mm| mm/m32, 16b 32b 64b op=mm_reg;mm_or_mem
Punpcklwd_xmm_xmmm128, legacy, 66, 0F, 61, 66 0F 61 /r, PUNPCKLWD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpunpcklwd_xmm_xmm_xmmm128, VEX, 66, 0F, 61, VEX.128.66.0F.WIG 61 /r, VPUNPCKLWD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpunpcklwd_ymm_ymm_ymmm256, VEX, 66, 0F, 61, VEX.256.66.0F.WIG 61 /r, VPUNPCKLWD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpunpcklwd_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, 61, EVEX.128.66.0F.WIG 61 /r, VPUNPCKLWD xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpunpcklwd_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, 61, EVEX.256.66.0F.WIG 61 /r, VPUNPCKLWD ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpunpcklwd_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, 61, EVEX.512.66.0F.WIG 61 /r, VPUNPCKLWD zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Punpckldq_mm_mmm32, legacy, NP, 0F, 62, NP 0F 62 /r, PUNPCKLDQ mm| mm/m32, 16b 32b 64b op=mm_reg;mm_or_mem
Punpckldq_xmm_xmmm128, legacy, 66, 0F, 62, 66 0F 62 /r, PUNPCKLDQ xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpunpckldq_xmm_xmm_xmmm128, VEX, 66, 0F, 62, VEX.128.66.0F.WIG 62 /r, VPUNPCKLDQ xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpunpckldq_ymm_ymm_ymmm256, VEX, 66, 0F, 62, VEX.256.66.0F.WIG 62 /r, VPUNPCKLDQ ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpunpckldq_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F, 62, EVEX.128.66.0F.W0 62 /r, VPUNPCKLDQ xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpunpckldq_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F, 62, EVEX.256.66.0F.W0 62 /r, VPUNPCKLDQ ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpunpckldq_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F, 62, EVEX.512.66.0F.W0 62 /r, VPUNPCKLDQ zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Packsswb_mm_mmm64, legacy, NP, 0F, 63, NP 0F 63 /r, PACKSSWB mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Packsswb_xmm_xmmm128, legacy, 66, 0F, 63, 66 0F 63 /r, PACKSSWB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpacksswb_xmm_xmm_xmmm128, VEX, 66, 0F, 63, VEX.128.66.0F.WIG 63 /r, VPACKSSWB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpacksswb_ymm_ymm_ymmm256, VEX, 66, 0F, 63, VEX.256.66.0F.WIG 63 /r, VPACKSSWB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpacksswb_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, 63, EVEX.128.66.0F.WIG 63 /r, VPACKSSWB xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpacksswb_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, 63, EVEX.256.66.0F.WIG 63 /r, VPACKSSWB ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpacksswb_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, 63, EVEX.512.66.0F.WIG 63 /r, VPACKSSWB zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Pcmpgtb_mm_mmm64, legacy, NP, 0F, 64, NP 0F 64 /r, PCMPGTB mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pcmpgtb_xmm_xmmm128, legacy, 66, 0F, 64, 66 0F 64 /r, PCMPGTB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpcmpgtb_xmm_xmm_xmmm128, VEX, 66, 0F, 64, VEX.128.66.0F.WIG 64 /r, VPCMPGTB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpcmpgtb_ymm_ymm_ymmm256, VEX, 66, 0F, 64, VEX.256.66.0F.WIG 64 /r, VPCMPGTB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpcmpgtb_k_k1_xmm_xmmm128, EVEX, 66, 0F, 64, EVEX.128.66.0F.WIG 64 /r, VPCMPGTB k1 {k2}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=k_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k
EVEX_Vpcmpgtb_k_k1_ymm_ymmm256, EVEX, 66, 0F, 64, EVEX.256.66.0F.WIG 64 /r, VPCMPGTB k1 {k2}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=k_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k
EVEX_Vpcmpgtb_k_k1_zmm_zmmm512, EVEX, 66, 0F, 64, EVEX.512.66.0F.WIG 64 /r, VPCMPGTB k1 {k2}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=k_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k
Pcmpgtw_mm_mmm64, legacy, NP, 0F, 65, NP 0F 65 /r, PCMPGTW mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pcmpgtw_xmm_xmmm128, legacy, 66, 0F, 65, 66 0F 65 /r, PCMPGTW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpcmpgtw_xmm_xmm_xmmm128, VEX, 66, 0F, 65, VEX.128.66.0F.WIG 65 /r, VPCMPGTW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpcmpgtw_ymm_ymm_ymmm256, VEX, 66, 0F, 65, VEX.256.66.0F.WIG 65 /r, VPCMPGTW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpcmpgtw_k_k1_xmm_xmmm128, EVEX, 66, 0F, 65, EVEX.128.66.0F.WIG 65 /r, VPCMPGTW k1 {k2}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=k_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k
EVEX_Vpcmpgtw_k_k1_ymm_ymmm256, EVEX, 66, 0F, 65, EVEX.256.66.0F.WIG 65 /r, VPCMPGTW k1 {k2}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=k_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k
EVEX_Vpcmpgtw_k_k1_zmm_zmmm512, EVEX, 66, 0F, 65, EVEX.512.66.0F.WIG 65 /r, VPCMPGTW k1 {k2}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=k_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k
Pcmpgtd_mm_mmm64, legacy, NP, 0F, 66, NP 0F 66 /r, PCMPGTD mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pcmpgtd_xmm_xmmm128, legacy, 66, 0F, 66, 66 0F 66 /r, PCMPGTD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpcmpgtd_xmm_xmm_xmmm128, VEX, 66, 0F, 66, VEX.128.66.0F.WIG 66 /r, VPCMPGTD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpcmpgtd_ymm_ymm_ymmm256, VEX, 66, 0F, 66, VEX.256.66.0F.WIG 66 /r, VPCMPGTD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpcmpgtd_k_k1_xmm_xmmm128b32, EVEX, 66, 0F, 66, EVEX.128.66.0F.W0 66 /r, VPCMPGTD k1 {k2}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=k_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k
EVEX_Vpcmpgtd_k_k1_ymm_ymmm256b32, EVEX, 66, 0F, 66, EVEX.256.66.0F.W0 66 /r, VPCMPGTD k1 {k2}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=k_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k
EVEX_Vpcmpgtd_k_k1_zmm_zmmm512b32, EVEX, 66, 0F, 66, EVEX.512.66.0F.W0 66 /r, VPCMPGTD k1 {k2}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=k_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k
Packuswb_mm_mmm64, legacy, NP, 0F, 67, NP 0F 67 /r, PACKUSWB mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Packuswb_xmm_xmmm128, legacy, 66, 0F, 67, 66 0F 67 /r, PACKUSWB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpackuswb_xmm_xmm_xmmm128, VEX, 66, 0F, 67, VEX.128.66.0F.WIG 67 /r, VPACKUSWB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpackuswb_ymm_ymm_ymmm256, VEX, 66, 0F, 67, VEX.256.66.0F.WIG 67 /r, VPACKUSWB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpackuswb_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, 67, EVEX.128.66.0F.WIG 67 /r, VPACKUSWB xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpackuswb_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, 67, EVEX.256.66.0F.WIG 67 /r, VPACKUSWB ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpackuswb_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, 67, EVEX.512.66.0F.WIG 67 /r, VPACKUSWB zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Punpckhbw_mm_mmm64, legacy, NP, 0F, 68, NP 0F 68 /r, PUNPCKHBW mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Punpckhbw_xmm_xmmm128, legacy, 66, 0F, 68, 66 0F 68 /r, PUNPCKHBW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpunpckhbw_xmm_xmm_xmmm128, VEX, 66, 0F, 68, VEX.128.66.0F.WIG 68 /r, VPUNPCKHBW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpunpckhbw_ymm_ymm_ymmm256, VEX, 66, 0F, 68, VEX.256.66.0F.WIG 68 /r, VPUNPCKHBW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpunpckhbw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, 68, EVEX.128.66.0F.WIG 68 /r, VPUNPCKHBW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpunpckhbw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, 68, EVEX.256.66.0F.WIG 68 /r, VPUNPCKHBW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpunpckhbw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, 68, EVEX.512.66.0F.WIG 68 /r, VPUNPCKHBW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Punpckhwd_mm_mmm64, legacy, NP, 0F, 69, NP 0F 69 /r, PUNPCKHWD mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Punpckhwd_xmm_xmmm128, legacy, 66, 0F, 69, 66 0F 69 /r, PUNPCKHWD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpunpckhwd_xmm_xmm_xmmm128, VEX, 66, 0F, 69, VEX.128.66.0F.WIG 69 /r, VPUNPCKHWD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpunpckhwd_ymm_ymm_ymmm256, VEX, 66, 0F, 69, VEX.256.66.0F.WIG 69 /r, VPUNPCKHWD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpunpckhwd_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, 69, EVEX.128.66.0F.WIG 69 /r, VPUNPCKHWD xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpunpckhwd_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, 69, EVEX.256.66.0F.WIG 69 /r, VPUNPCKHWD ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpunpckhwd_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, 69, EVEX.512.66.0F.WIG 69 /r, VPUNPCKHWD zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Punpckhdq_mm_mmm64, legacy, NP, 0F, 6A, NP 0F 6A /r, PUNPCKHDQ mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Punpckhdq_xmm_xmmm128, legacy, 66, 0F, 6A, 66 0F 6A /r, PUNPCKHDQ xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpunpckhdq_xmm_xmm_xmmm128, VEX, 66, 0F, 6A, VEX.128.66.0F.WIG 6A /r, VPUNPCKHDQ xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpunpckhdq_ymm_ymm_ymmm256, VEX, 66, 0F, 6A, VEX.256.66.0F.WIG 6A /r, VPUNPCKHDQ ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpunpckhdq_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F, 6A, EVEX.128.66.0F.W0 6A /r, VPUNPCKHDQ xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpunpckhdq_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F, 6A, EVEX.256.66.0F.W0 6A /r, VPUNPCKHDQ ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpunpckhdq_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F, 6A, EVEX.512.66.0F.W0 6A /r, VPUNPCKHDQ zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Packssdw_mm_mmm64, legacy, NP, 0F, 6B, NP 0F 6B /r, PACKSSDW mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Packssdw_xmm_xmmm128, legacy, 66, 0F, 6B, 66 0F 6B /r, PACKSSDW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpackssdw_xmm_xmm_xmmm128, VEX, 66, 0F, 6B, VEX.128.66.0F.WIG 6B /r, VPACKSSDW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpackssdw_ymm_ymm_ymmm256, VEX, 66, 0F, 6B, VEX.256.66.0F.WIG 6B /r, VPACKSSDW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpackssdw_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F, 6B, EVEX.128.66.0F.W0 6B /r, VPACKSSDW xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpackssdw_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F, 6B, EVEX.256.66.0F.W0 6B /r, VPACKSSDW ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpackssdw_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F, 6B, EVEX.512.66.0F.W0 6B /r, VPACKSSDW zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Punpcklqdq_xmm_xmmm128, legacy, 66, 0F, 6C, 66 0F 6C /r, PUNPCKLQDQ xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpunpcklqdq_xmm_xmm_xmmm128, VEX, 66, 0F, 6C, VEX.128.66.0F.WIG 6C /r, VPUNPCKLQDQ xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpunpcklqdq_ymm_ymm_ymmm256, VEX, 66, 0F, 6C, VEX.256.66.0F.WIG 6C /r, VPUNPCKLQDQ ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpunpcklqdq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, 6C, EVEX.128.66.0F.W1 6C /r, VPUNPCKLQDQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpunpcklqdq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, 6C, EVEX.256.66.0F.W1 6C /r, VPUNPCKLQDQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpunpcklqdq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F, 6C, EVEX.512.66.0F.W1 6C /r, VPUNPCKLQDQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Punpckhqdq_xmm_xmmm128, legacy, 66, 0F, 6D, 66 0F 6D /r, PUNPCKHQDQ xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpunpckhqdq_xmm_xmm_xmmm128, VEX, 66, 0F, 6D, VEX.128.66.0F.WIG 6D /r, VPUNPCKHQDQ xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpunpckhqdq_ymm_ymm_ymmm256, VEX, 66, 0F, 6D, VEX.256.66.0F.WIG 6D /r, VPUNPCKHQDQ ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpunpckhqdq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, 6D, EVEX.128.66.0F.W1 6D /r, VPUNPCKHQDQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpunpckhqdq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, 6D, EVEX.256.66.0F.W1 6D /r, VPUNPCKHQDQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpunpckhqdq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F, 6D, EVEX.512.66.0F.W1 6D /r, VPUNPCKHQDQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Movd_mm_rm32, legacy, NP, 0F, 6E, NP 0F 6E /r, MOVD mm| r/m32, 16b 32b 64b op=mm_reg;r32_or_mem
Movq_mm_rm64, legacy, NP, 0F, 6E, NP REX.W 0F 6E /r, MOVQ mm| r/m64, 64b o64 op=mm_reg;r64_or_mem
Movd_xmm_rm32, legacy, 66, 0F, 6E, 66 0F 6E /r, MOVD xmm| r/m32, 16b 32b 64b op=xmm_reg;r32_or_mem
Movq_xmm_rm64, legacy, 66, 0F, 6E, 66 REX.W 0F 6E /r, MOVQ xmm| r/m64, 64b o64 op=xmm_reg;r64_or_mem
VEX_Vmovd_xmm_rm32, VEX, 66, 0F, 6E, VEX.128.66.0F.W0 6E /r, VMOVD xmm1| r/m32, 16b 32b 64b L128 WIG32 op=xmm_reg;r32_or_mem
VEX_Vmovq_xmm_rm64, VEX, 66, 0F, 6E, VEX.128.66.0F.W1 6E /r, VMOVQ xmm1| r/m64, 64b L128 W1 op=xmm_reg;r64_or_mem
EVEX_Vmovd_xmm_rm32, EVEX, 66, 0F, 6E, EVEX.128.66.0F.W0 6E /r, VMOVD xmm1| r/m32, 16b 32b 64b L128 WIG32 op=xmm_reg;r32_or_mem tt=Tuple1_Scalar
EVEX_Vmovq_xmm_rm64, EVEX, 66, 0F, 6E, EVEX.128.66.0F.W1 6E /r, VMOVQ xmm1| r/m64, 64b L128 W1 op=xmm_reg;r64_or_mem tt=Tuple1_Scalar
Movq_mm_mmm64, legacy, NP, 0F, 6F, NP 0F 6F /r, MOVQ mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Movdqa_xmm_xmmm128, legacy, 66, 0F, 6F, 66 0F 6F /r, MOVDQA xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmovdqa_xmm_xmmm128, VEX, 66, 0F, 6F, VEX.128.66.0F.WIG 6F /r, VMOVDQA xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vmovdqa_ymm_ymmm256, VEX, 66, 0F, 6F, VEX.256.66.0F.WIG 6F /r, VMOVDQA ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
EVEX_Vmovdqa32_xmm_k1z_xmmm128, EVEX, 66, 0F, 6F, EVEX.128.66.0F.W0 6F /r, VMOVDQA32 xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vmovdqa32_ymm_k1z_ymmm256, EVEX, 66, 0F, 6F, EVEX.256.66.0F.W0 6F /r, VMOVDQA32 ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vmovdqa32_zmm_k1z_zmmm512, EVEX, 66, 0F, 6F, EVEX.512.66.0F.W0 6F /r, VMOVDQA32 zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vmovdqa64_xmm_k1z_xmmm128, EVEX, 66, 0F, 6F, EVEX.128.66.0F.W1 6F /r, VMOVDQA64 xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vmovdqa64_ymm_k1z_ymmm256, EVEX, 66, 0F, 6F, EVEX.256.66.0F.W1 6F /r, VMOVDQA64 ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vmovdqa64_zmm_k1z_zmmm512, EVEX, 66, 0F, 6F, EVEX.512.66.0F.W1 6F /r, VMOVDQA64 zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_Mem_512 k z
Movdqu_xmm_xmmm128, legacy, F3, 0F, 6F, F3 0F 6F /r, MOVDQU xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmovdqu_xmm_xmmm128, VEX, F3, 0F, 6F, VEX.128.F3.0F.WIG 6F /r, VMOVDQU xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vmovdqu_ymm_ymmm256, VEX, F3, 0F, 6F, VEX.256.F3.0F.WIG 6F /r, VMOVDQU ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
EVEX_Vmovdqu32_xmm_k1z_xmmm128, EVEX, F3, 0F, 6F, EVEX.128.F3.0F.W0 6F /r, VMOVDQU32 xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vmovdqu32_ymm_k1z_ymmm256, EVEX, F3, 0F, 6F, EVEX.256.F3.0F.W0 6F /r, VMOVDQU32 ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vmovdqu32_zmm_k1z_zmmm512, EVEX, F3, 0F, 6F, EVEX.512.F3.0F.W0 6F /r, VMOVDQU32 zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vmovdqu64_xmm_k1z_xmmm128, EVEX, F3, 0F, 6F, EVEX.128.F3.0F.W1 6F /r, VMOVDQU64 xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vmovdqu64_ymm_k1z_ymmm256, EVEX, F3, 0F, 6F, EVEX.256.F3.0F.W1 6F /r, VMOVDQU64 ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vmovdqu64_zmm_k1z_zmmm512, EVEX, F3, 0F, 6F, EVEX.512.F3.0F.W1 6F /r, VMOVDQU64 zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vmovdqu8_xmm_k1z_xmmm128, EVEX, F2, 0F, 6F, EVEX.128.F2.0F.W0 6F /r, VMOVDQU8 xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vmovdqu8_ymm_k1z_ymmm256, EVEX, F2, 0F, 6F, EVEX.256.F2.0F.W0 6F /r, VMOVDQU8 ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vmovdqu8_zmm_k1z_zmmm512, EVEX, F2, 0F, 6F, EVEX.512.F2.0F.W0 6F /r, VMOVDQU8 zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vmovdqu16_xmm_k1z_xmmm128, EVEX, F2, 0F, 6F, EVEX.128.F2.0F.W1 6F /r, VMOVDQU16 xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vmovdqu16_ymm_k1z_ymmm256, EVEX, F2, 0F, 6F, EVEX.256.F2.0F.W1 6F /r, VMOVDQU16 ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vmovdqu16_zmm_k1z_zmmm512, EVEX, F2, 0F, 6F, EVEX.512.F2.0F.W1 6F /r, VMOVDQU16 zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_Mem_512 k z
Pshufw_mm_mmm64_imm8, legacy, NP, 0F, 70, NP 0F 70 /r ib, PSHUFW mm1| mm2/m64| imm8, 16b 32b 64b op=mm_reg;mm_or_mem;imm8
Pshufd_xmm_xmmm128_imm8, legacy, 66, 0F, 70, 66 0F 70 /r ib, PSHUFD xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vpshufd_xmm_xmmm128_imm8, VEX, 66, 0F, 70, VEX.128.66.0F.WIG 70 /r ib, VPSHUFD xmm1| xmm2/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem;imm8
VEX_Vpshufd_ymm_ymmm256_imm8, VEX, 66, 0F, 70, VEX.256.66.0F.WIG 70 /r ib, VPSHUFD ymm1| ymm2/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem;imm8
EVEX_Vpshufd_xmm_k1z_xmmm128b32_imm8, EVEX, 66, 0F, 70, EVEX.128.66.0F.W0 70 /r ib, VPSHUFD xmm1 {k1}{z}| xmm2/m128/m32bcst| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vpshufd_ymm_k1z_ymmm256b32_imm8, EVEX, 66, 0F, 70, EVEX.256.66.0F.W0 70 /r ib, VPSHUFD ymm1 {k1}{z}| ymm2/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vpshufd_zmm_k1z_zmmm512b32_imm8, EVEX, 66, 0F, 70, EVEX.512.66.0F.W0 70 /r ib, VPSHUFD zmm1 {k1}{z}| zmm2/m512/m32bcst| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem;imm8 tt=Full_512 b k z
Pshufhw_xmm_xmmm128_imm8, legacy, F3, 0F, 70, F3 0F 70 /r ib, PSHUFHW xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vpshufhw_xmm_xmmm128_imm8, VEX, F3, 0F, 70, VEX.128.F3.0F.WIG 70 /r ib, VPSHUFHW xmm1| xmm2/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem;imm8
VEX_Vpshufhw_ymm_ymmm256_imm8, VEX, F3, 0F, 70, VEX.256.F3.0F.WIG 70 /r ib, VPSHUFHW ymm1| ymm2/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem;imm8
EVEX_Vpshufhw_xmm_k1z_xmmm128_imm8, EVEX, F3, 0F, 70, EVEX.128.F3.0F.WIG 70 /r ib, VPSHUFHW xmm1 {k1}{z}| xmm2/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem;imm8 tt=Full_Mem_128 k z
EVEX_Vpshufhw_ymm_k1z_ymmm256_imm8, EVEX, F3, 0F, 70, EVEX.256.F3.0F.WIG 70 /r ib, VPSHUFHW ymm1 {k1}{z}| ymm2/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem;imm8 tt=Full_Mem_256 k z
EVEX_Vpshufhw_zmm_k1z_zmmm512_imm8, EVEX, F3, 0F, 70, EVEX.512.F3.0F.WIG 70 /r ib, VPSHUFHW zmm1 {k1}{z}| zmm2/m512| imm8, 16b 32b 64b L512 WIG op=zmm_reg;zmm_or_mem;imm8 tt=Full_Mem_512 k z
Pshuflw_xmm_xmmm128_imm8, legacy, F2, 0F, 70, F2 0F 70 /r ib, PSHUFLW xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vpshuflw_xmm_xmmm128_imm8, VEX, F2, 0F, 70, VEX.128.F2.0F.WIG 70 /r ib, VPSHUFLW xmm1| xmm2/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem;imm8
VEX_Vpshuflw_ymm_ymmm256_imm8, VEX, F2, 0F, 70, VEX.256.F2.0F.WIG 70 /r ib, VPSHUFLW ymm1| ymm2/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem;imm8
EVEX_Vpshuflw_xmm_k1z_xmmm128_imm8, EVEX, F2, 0F, 70, EVEX.128.F2.0F.WIG 70 /r ib, VPSHUFLW xmm1 {k1}{z}| xmm2/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem;imm8 tt=Full_Mem_128 k z
EVEX_Vpshuflw_ymm_k1z_ymmm256_imm8, EVEX, F2, 0F, 70, EVEX.256.F2.0F.WIG 70 /r ib, VPSHUFLW ymm1 {k1}{z}| ymm2/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem;imm8 tt=Full_Mem_256 k z
EVEX_Vpshuflw_zmm_k1z_zmmm512_imm8, EVEX, F2, 0F, 70, EVEX.512.F2.0F.WIG 70 /r ib, VPSHUFLW zmm1 {k1}{z}| zmm2/m512| imm8, 16b 32b 64b L512 WIG op=zmm_reg;zmm_or_mem;imm8 tt=Full_Mem_512 k z
Psrlw_mm_imm8, legacy, NP, 0F, 71, NP 0F 71 /2 ib, PSRLW mm| imm8, g=2 16b 32b 64b op=mm_rm;imm8
Psrlw_xmm_imm8, legacy, 66, 0F, 71, 66 0F 71 /2 ib, PSRLW xmm1| imm8, g=2 16b 32b 64b op=xmm_rm;imm8
VEX_Vpsrlw_xmm_xmm_imm8, VEX, 66, 0F, 71, VEX.128.66.0F.WIG 71 /2 ib, VPSRLW xmm1| xmm2| imm8, g=2 16b 32b 64b L128 WIG op=xmm_vvvv;xmm_rm;imm8
VEX_Vpsrlw_ymm_ymm_imm8, VEX, 66, 0F, 71, VEX.256.66.0F.WIG 71 /2 ib, VPSRLW ymm1| ymm2| imm8, g=2 16b 32b 64b L256 WIG op=ymm_vvvv;ymm_rm;imm8
EVEX_Vpsrlw_xmm_k1z_xmmm128_imm8, EVEX, 66, 0F, 71, EVEX.128.66.0F.WIG 71 /2 ib, VPSRLW xmm1 {k1}{z}| xmm2/m128| imm8, g=2 16b 32b 64b L128 WIG op=xmm_vvvv;xmm_or_mem;imm8 tt=Full_Mem_128 k z
EVEX_Vpsrlw_ymm_k1z_ymmm256_imm8, EVEX, 66, 0F, 71, EVEX.256.66.0F.WIG 71 /2 ib, VPSRLW ymm1 {k1}{z}| ymm2/m256| imm8, g=2 16b 32b 64b L256 WIG op=ymm_vvvv;ymm_or_mem;imm8 tt=Full_Mem_256 k z
EVEX_Vpsrlw_zmm_k1z_zmmm512_imm8, EVEX, 66, 0F, 71, EVEX.512.66.0F.WIG 71 /2 ib, VPSRLW zmm1 {k1}{z}| zmm2/m512| imm8, g=2 16b 32b 64b L512 WIG op=zmm_vvvv;zmm_or_mem;imm8 tt=Full_Mem_512 k z
Psraw_mm_imm8, legacy, NP, 0F, 71, NP 0F 71 /4 ib, PSRAW mm| imm8, g=4 16b 32b 64b op=mm_rm;imm8
Psraw_xmm_imm8, legacy, 66, 0F, 71, 66 0F 71 /4 ib, PSRAW xmm1| imm8, g=4 16b 32b 64b op=xmm_rm;imm8
VEX_Vpsraw_xmm_xmm_imm8, VEX, 66, 0F, 71, VEX.128.66.0F.WIG 71 /4 ib, VPSRAW xmm1| xmm2| imm8, g=4 16b 32b 64b L128 WIG op=xmm_vvvv;xmm_rm;imm8
VEX_Vpsraw_ymm_ymm_imm8, VEX, 66, 0F, 71, VEX.256.66.0F.WIG 71 /4 ib, VPSRAW ymm1| ymm2| imm8, g=4 16b 32b 64b L256 WIG op=ymm_vvvv;ymm_rm;imm8
EVEX_Vpsraw_xmm_k1z_xmmm128_imm8, EVEX, 66, 0F, 71, EVEX.128.66.0F.WIG 71 /4 ib, VPSRAW xmm1 {k1}{z}| xmm2/m128| imm8, g=4 16b 32b 64b L128 WIG op=xmm_vvvv;xmm_or_mem;imm8 tt=Full_Mem_128 k z
EVEX_Vpsraw_ymm_k1z_ymmm256_imm8, EVEX, 66, 0F, 71, EVEX.256.66.0F.WIG 71 /4 ib, VPSRAW ymm1 {k1}{z}| ymm2/m256| imm8, g=4 16b 32b 64b L256 WIG op=ymm_vvvv;ymm_or_mem;imm8 tt=Full_Mem_256 k z
EVEX_Vpsraw_zmm_k1z_zmmm512_imm8, EVEX, 66, 0F, 71, EVEX.512.66.0F.WIG 71 /4 ib, VPSRAW zmm1 {k1}{z}| zmm2/m512| imm8, g=4 16b 32b 64b L512 WIG op=zmm_vvvv;zmm_or_mem;imm8 tt=Full_Mem_512 k z
Psllw_mm_imm8, legacy, NP, 0F, 71, NP 0F 71 /6 ib, PSLLW mm1| imm8, g=6 16b 32b 64b op=mm_rm;imm8
Psllw_xmm_imm8, legacy, 66, 0F, 71, 66 0F 71 /6 ib, PSLLW xmm1| imm8, g=6 16b 32b 64b op=xmm_rm;imm8
VEX_Vpsllw_xmm_xmm_imm8, VEX, 66, 0F, 71, VEX.128.66.0F.WIG 71 /6 ib, VPSLLW xmm1| xmm2| imm8, g=6 16b 32b 64b L128 WIG op=xmm_vvvv;xmm_rm;imm8
VEX_Vpsllw_ymm_ymm_imm8, VEX, 66, 0F, 71, VEX.256.66.0F.WIG 71 /6 ib, VPSLLW ymm1| ymm2| imm8, g=6 16b 32b 64b L256 WIG op=ymm_vvvv;ymm_rm;imm8
EVEX_Vpsllw_xmm_k1z_xmmm128_imm8, EVEX, 66, 0F, 71, EVEX.128.66.0F.WIG 71 /6 ib, VPSLLW xmm1 {k1}{z}| xmm2/m128| imm8, g=6 16b 32b 64b L128 WIG op=xmm_vvvv;xmm_or_mem;imm8 tt=Full_Mem_128 k z
EVEX_Vpsllw_ymm_k1z_ymmm256_imm8, EVEX, 66, 0F, 71, EVEX.256.66.0F.WIG 71 /6 ib, VPSLLW ymm1 {k1}{z}| ymm2/m256| imm8, g=6 16b 32b 64b L256 WIG op=ymm_vvvv;ymm_or_mem;imm8 tt=Full_Mem_256 k z
EVEX_Vpsllw_zmm_k1z_zmmm512_imm8, EVEX, 66, 0F, 71, EVEX.512.66.0F.WIG 71 /6 ib, VPSLLW zmm1 {k1}{z}| zmm2/m512| imm8, g=6 16b 32b 64b L512 WIG op=zmm_vvvv;zmm_or_mem;imm8 tt=Full_Mem_512 k z
EVEX_Vprord_xmm_k1z_xmmm128b32_imm8, EVEX, 66, 0F, 72, EVEX.128.66.0F.W0 72 /0 ib, VPRORD xmm1 {k1}{z}| xmm2/m128/m32bcst| imm8, g=0 16b 32b 64b L128 W0 op=xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vprord_ymm_k1z_ymmm256b32_imm8, EVEX, 66, 0F, 72, EVEX.256.66.0F.W0 72 /0 ib, VPRORD ymm1 {k1}{z}| ymm2/m256/m32bcst| imm8, g=0 16b 32b 64b L256 W0 op=ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vprord_zmm_k1z_zmmm512b32_imm8, EVEX, 66, 0F, 72, EVEX.512.66.0F.W0 72 /0 ib, VPRORD zmm1 {k1}{z}| zmm2/m512/m32bcst| imm8, g=0 16b 32b 64b L512 W0 op=zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
EVEX_Vprorq_xmm_k1z_xmmm128b64_imm8, EVEX, 66, 0F, 72, EVEX.128.66.0F.W1 72 /0 ib, VPRORQ xmm1 {k1}{z}| xmm2/m128/m64bcst| imm8, g=0 16b 32b 64b L128 W1 op=xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vprorq_ymm_k1z_ymmm256b64_imm8, EVEX, 66, 0F, 72, EVEX.256.66.0F.W1 72 /0 ib, VPRORQ ymm1 {k1}{z}| ymm2/m256/m64bcst| imm8, g=0 16b 32b 64b L256 W1 op=ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vprorq_zmm_k1z_zmmm512b64_imm8, EVEX, 66, 0F, 72, EVEX.512.66.0F.W1 72 /0 ib, VPRORQ zmm1 {k1}{z}| zmm2/m512/m64bcst| imm8, g=0 16b 32b 64b L512 W1 op=zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
EVEX_Vprold_xmm_k1z_xmmm128b32_imm8, EVEX, 66, 0F, 72, EVEX.128.66.0F.W0 72 /1 ib, VPROLD xmm1 {k1}{z}| xmm2/m128/m32bcst| imm8, g=1 16b 32b 64b L128 W0 op=xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vprold_ymm_k1z_ymmm256b32_imm8, EVEX, 66, 0F, 72, EVEX.256.66.0F.W0 72 /1 ib, VPROLD ymm1 {k1}{z}| ymm2/m256/m32bcst| imm8, g=1 16b 32b 64b L256 W0 op=ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vprold_zmm_k1z_zmmm512b32_imm8, EVEX, 66, 0F, 72, EVEX.512.66.0F.W0 72 /1 ib, VPROLD zmm1 {k1}{z}| zmm2/m512/m32bcst| imm8, g=1 16b 32b 64b L512 W0 op=zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
EVEX_Vprolq_xmm_k1z_xmmm128b64_imm8, EVEX, 66, 0F, 72, EVEX.128.66.0F.W1 72 /1 ib, VPROLQ xmm1 {k1}{z}| xmm2/m128/m64bcst| imm8, g=1 16b 32b 64b L128 W1 op=xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vprolq_ymm_k1z_ymmm256b64_imm8, EVEX, 66, 0F, 72, EVEX.256.66.0F.W1 72 /1 ib, VPROLQ ymm1 {k1}{z}| ymm2/m256/m64bcst| imm8, g=1 16b 32b 64b L256 W1 op=ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vprolq_zmm_k1z_zmmm512b64_imm8, EVEX, 66, 0F, 72, EVEX.512.66.0F.W1 72 /1 ib, VPROLQ zmm1 {k1}{z}| zmm2/m512/m64bcst| imm8, g=1 16b 32b 64b L512 W1 op=zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
Psrld_mm_imm8, legacy, NP, 0F, 72, NP 0F 72 /2 ib, PSRLD mm| imm8, g=2 16b 32b 64b op=mm_rm;imm8
Psrld_xmm_imm8, legacy, 66, 0F, 72, 66 0F 72 /2 ib, PSRLD xmm1| imm8, g=2 16b 32b 64b op=xmm_rm;imm8
VEX_Vpsrld_xmm_xmm_imm8, VEX, 66, 0F, 72, VEX.128.66.0F.WIG 72 /2 ib, VPSRLD xmm1| xmm2| imm8, g=2 16b 32b 64b L128 WIG op=xmm_vvvv;xmm_rm;imm8
VEX_Vpsrld_ymm_ymm_imm8, VEX, 66, 0F, 72, VEX.256.66.0F.WIG 72 /2 ib, VPSRLD ymm1| ymm2| imm8, g=2 16b 32b 64b L256 WIG op=ymm_vvvv;ymm_rm;imm8
EVEX_Vpsrld_xmm_k1z_xmmm128b32_imm8, EVEX, 66, 0F, 72, EVEX.128.66.0F.W0 72 /2 ib, VPSRLD xmm1 {k1}{z}| xmm2/m128/m32bcst| imm8, g=2 16b 32b 64b L128 W0 op=xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vpsrld_ymm_k1z_ymmm256b32_imm8, EVEX, 66, 0F, 72, EVEX.256.66.0F.W0 72 /2 ib, VPSRLD ymm1 {k1}{z}| ymm2/m256/m32bcst| imm8, g=2 16b 32b 64b L256 W0 op=ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vpsrld_zmm_k1z_zmmm512b32_imm8, EVEX, 66, 0F, 72, EVEX.512.66.0F.W0 72 /2 ib, VPSRLD zmm1 {k1}{z}| zmm2/m512/m32bcst| imm8, g=2 16b 32b 64b L512 W0 op=zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
Psrad_mm_imm8, legacy, NP, 0F, 72, NP 0F 72 /4 ib, PSRAD mm| imm8, g=4 16b 32b 64b op=mm_rm;imm8
Psrad_xmm_imm8, legacy, 66, 0F, 72, 66 0F 72 /4 ib, PSRAD xmm1| imm8, g=4 16b 32b 64b op=xmm_rm;imm8
VEX_Vpsrad_xmm_xmm_imm8, VEX, 66, 0F, 72, VEX.128.66.0F.WIG 72 /4 ib, VPSRAD xmm1| xmm2| imm8, g=4 16b 32b 64b L128 WIG op=xmm_vvvv;xmm_rm;imm8
VEX_Vpsrad_ymm_ymm_imm8, VEX, 66, 0F, 72, VEX.256.66.0F.WIG 72 /4 ib, VPSRAD ymm1| ymm2| imm8, g=4 16b 32b 64b L256 WIG op=ymm_vvvv;ymm_rm;imm8
EVEX_Vpsrad_xmm_k1z_xmmm128b32_imm8, EVEX, 66, 0F, 72, EVEX.128.66.0F.W0 72 /4 ib, VPSRAD xmm1 {k1}{z}| xmm2/m128/m32bcst| imm8, g=4 16b 32b 64b L128 W0 op=xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vpsrad_ymm_k1z_ymmm256b32_imm8, EVEX, 66, 0F, 72, EVEX.256.66.0F.W0 72 /4 ib, VPSRAD ymm1 {k1}{z}| ymm2/m256/m32bcst| imm8, g=4 16b 32b 64b L256 W0 op=ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vpsrad_zmm_k1z_zmmm512b32_imm8, EVEX, 66, 0F, 72, EVEX.512.66.0F.W0 72 /4 ib, VPSRAD zmm1 {k1}{z}| zmm2/m512/m32bcst| imm8, g=4 16b 32b 64b L512 W0 op=zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
EVEX_Vpsraq_xmm_k1z_xmmm128b64_imm8, EVEX, 66, 0F, 72, EVEX.128.66.0F.W1 72 /4 ib, VPSRAQ xmm1 {k1}{z}| xmm2/m128/m64bcst| imm8, g=4 16b 32b 64b L128 W1 op=xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vpsraq_ymm_k1z_ymmm256b64_imm8, EVEX, 66, 0F, 72, EVEX.256.66.0F.W1 72 /4 ib, VPSRAQ ymm1 {k1}{z}| ymm2/m256/m64bcst| imm8, g=4 16b 32b 64b L256 W1 op=ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vpsraq_zmm_k1z_zmmm512b64_imm8, EVEX, 66, 0F, 72, EVEX.512.66.0F.W1 72 /4 ib, VPSRAQ zmm1 {k1}{z}| zmm2/m512/m64bcst| imm8, g=4 16b 32b 64b L512 W1 op=zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
Pslld_mm_imm8, legacy, NP, 0F, 72, NP 0F 72 /6 ib, PSLLD mm| imm8, g=6 16b 32b 64b op=mm_rm;imm8
Pslld_xmm_imm8, legacy, 66, 0F, 72, 66 0F 72 /6 ib, PSLLD xmm1| imm8, g=6 16b 32b 64b op=xmm_rm;imm8
VEX_Vpslld_xmm_xmm_imm8, VEX, 66, 0F, 72, VEX.128.66.0F.WIG 72 /6 ib, VPSLLD xmm1| xmm2| imm8, g=6 16b 32b 64b L128 WIG op=xmm_vvvv;xmm_rm;imm8
VEX_Vpslld_ymm_ymm_imm8, VEX, 66, 0F, 72, VEX.256.66.0F.WIG 72 /6 ib, VPSLLD ymm1| ymm2| imm8, g=6 16b 32b 64b L256 WIG op=ymm_vvvv;ymm_rm;imm8
EVEX_Vpslld_xmm_k1z_xmmm128b32_imm8, EVEX, 66, 0F, 72, EVEX.128.66.0F.W0 72 /6 ib, VPSLLD xmm1 {k1}{z}| xmm2/m128/m32bcst| imm8, g=6 16b 32b 64b L128 W0 op=xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vpslld_ymm_k1z_ymmm256b32_imm8, EVEX, 66, 0F, 72, EVEX.256.66.0F.W0 72 /6 ib, VPSLLD ymm1 {k1}{z}| ymm2/m256/m32bcst| imm8, g=6 16b 32b 64b L256 W0 op=ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vpslld_zmm_k1z_zmmm512b32_imm8, EVEX, 66, 0F, 72, EVEX.512.66.0F.W0 72 /6 ib, VPSLLD zmm1 {k1}{z}| zmm2/m512/m32bcst| imm8, g=6 16b 32b 64b L512 W0 op=zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
Psrlq_mm_imm8, legacy, NP, 0F, 73, NP 0F 73 /2 ib, PSRLQ mm| imm8, g=2 16b 32b 64b op=mm_rm;imm8
Psrlq_xmm_imm8, legacy, 66, 0F, 73, 66 0F 73 /2 ib, PSRLQ xmm1| imm8, g=2 16b 32b 64b op=xmm_rm;imm8
VEX_Vpsrlq_xmm_xmm_imm8, VEX, 66, 0F, 73, VEX.128.66.0F.WIG 73 /2 ib, VPSRLQ xmm1| xmm2| imm8, g=2 16b 32b 64b L128 WIG op=xmm_vvvv;xmm_rm;imm8
VEX_Vpsrlq_ymm_ymm_imm8, VEX, 66, 0F, 73, VEX.256.66.0F.WIG 73 /2 ib, VPSRLQ ymm1| ymm2| imm8, g=2 16b 32b 64b L256 WIG op=ymm_vvvv;ymm_rm;imm8
EVEX_Vpsrlq_xmm_k1z_xmmm128b64_imm8, EVEX, 66, 0F, 73, EVEX.128.66.0F.W1 73 /2 ib, VPSRLQ xmm1 {k1}{z}| xmm2/m128/m64bcst| imm8, g=2 16b 32b 64b L128 W1 op=xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vpsrlq_ymm_k1z_ymmm256b64_imm8, EVEX, 66, 0F, 73, EVEX.256.66.0F.W1 73 /2 ib, VPSRLQ ymm1 {k1}{z}| ymm2/m256/m64bcst| imm8, g=2 16b 32b 64b L256 W1 op=ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vpsrlq_zmm_k1z_zmmm512b64_imm8, EVEX, 66, 0F, 73, EVEX.512.66.0F.W1 73 /2 ib, VPSRLQ zmm1 {k1}{z}| zmm2/m512/m64bcst| imm8, g=2 16b 32b 64b L512 W1 op=zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
Psrldq_xmm_imm8, legacy, 66, 0F, 73, 66 0F 73 /3 ib, PSRLDQ xmm1| imm8, g=3 16b 32b 64b op=xmm_rm;imm8
VEX_Vpsrldq_xmm_xmm_imm8, VEX, 66, 0F, 73, VEX.128.66.0F.WIG 73 /3 ib, VPSRLDQ xmm1| xmm2| imm8, g=3 16b 32b 64b L128 WIG op=xmm_vvvv;xmm_rm;imm8
VEX_Vpsrldq_ymm_ymm_imm8, VEX, 66, 0F, 73, VEX.256.66.0F.WIG 73 /3 ib, VPSRLDQ ymm1| ymm2| imm8, g=3 16b 32b 64b L256 WIG op=ymm_vvvv;ymm_rm;imm8
EVEX_Vpsrldq_xmm_xmmm128_imm8, EVEX, 66, 0F, 73, EVEX.128.66.0F.WIG 73 /3 ib, VPSRLDQ xmm1| xmm2/m128| imm8, g=3 16b 32b 64b L128 WIG op=xmm_vvvv;xmm_or_mem;imm8 tt=Full_Mem_128
EVEX_Vpsrldq_ymm_ymmm256_imm8, EVEX, 66, 0F, 73, EVEX.256.66.0F.WIG 73 /3 ib, VPSRLDQ ymm1| ymm2/m256| imm8, g=3 16b 32b 64b L256 WIG op=ymm_vvvv;ymm_or_mem;imm8 tt=Full_Mem_256
EVEX_Vpsrldq_zmm_zmmm512_imm8, EVEX, 66, 0F, 73, EVEX.512.66.0F.WIG 73 /3 ib, VPSRLDQ zmm1| zmm2/m512| imm8, g=3 16b 32b 64b L512 WIG op=zmm_vvvv;zmm_or_mem;imm8 tt=Full_Mem_512
Psllq_mm_imm8, legacy, NP, 0F, 73, NP 0F 73 /6 ib, PSLLQ mm| imm8, g=6 16b 32b 64b op=mm_rm;imm8
Psllq_xmm_imm8, legacy, 66, 0F, 73, 66 0F 73 /6 ib, PSLLQ xmm1| imm8, g=6 16b 32b 64b op=xmm_rm;imm8
VEX_Vpsllq_xmm_xmm_imm8, VEX, 66, 0F, 73, VEX.128.66.0F.WIG 73 /6 ib, VPSLLQ xmm1| xmm2| imm8, g=6 16b 32b 64b L128 WIG op=xmm_vvvv;xmm_rm;imm8
VEX_Vpsllq_ymm_ymm_imm8, VEX, 66, 0F, 73, VEX.256.66.0F.WIG 73 /6 ib, VPSLLQ ymm1| ymm2| imm8, g=6 16b 32b 64b L256 WIG op=ymm_vvvv;ymm_rm;imm8
EVEX_Vpsllq_xmm_k1z_xmmm128b64_imm8, EVEX, 66, 0F, 73, EVEX.128.66.0F.W1 73 /6 ib, VPSLLQ xmm1 {k1}{z}| xmm2/m128/m64bcst| imm8, g=6 16b 32b 64b L128 W1 op=xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vpsllq_ymm_k1z_ymmm256b64_imm8, EVEX, 66, 0F, 73, EVEX.256.66.0F.W1 73 /6 ib, VPSLLQ ymm1 {k1}{z}| ymm2/m256/m64bcst| imm8, g=6 16b 32b 64b L256 W1 op=ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vpsllq_zmm_k1z_zmmm512b64_imm8, EVEX, 66, 0F, 73, EVEX.512.66.0F.W1 73 /6 ib, VPSLLQ zmm1 {k1}{z}| zmm2/m512/m64bcst| imm8, g=6 16b 32b 64b L512 W1 op=zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
Pslldq_xmm_imm8, legacy, 66, 0F, 73, 66 0F 73 /7 ib, PSLLDQ xmm1| imm8, g=7 16b 32b 64b op=xmm_rm;imm8
VEX_Vpslldq_xmm_xmm_imm8, VEX, 66, 0F, 73, VEX.128.66.0F.WIG 73 /7 ib, VPSLLDQ xmm1| xmm2| imm8, g=7 16b 32b 64b L128 WIG op=xmm_vvvv;xmm_rm;imm8
VEX_Vpslldq_ymm_ymm_imm8, VEX, 66, 0F, 73, VEX.256.66.0F.WIG 73 /7 ib, VPSLLDQ ymm1| ymm2| imm8, g=7 16b 32b 64b L256 WIG op=ymm_vvvv;ymm_rm;imm8
EVEX_Vpslldq_xmm_xmmm128_imm8, EVEX, 66, 0F, 73, EVEX.128.66.0F.WIG 73 /7 ib, VPSLLDQ xmm1| xmm2/m128| imm8, g=7 16b 32b 64b L128 WIG op=xmm_vvvv;xmm_or_mem;imm8 tt=Full_Mem_128
EVEX_Vpslldq_ymm_ymmm256_imm8, EVEX, 66, 0F, 73, EVEX.256.66.0F.WIG 73 /7 ib, VPSLLDQ ymm1| ymm2/m256| imm8, g=7 16b 32b 64b L256 WIG op=ymm_vvvv;ymm_or_mem;imm8 tt=Full_Mem_256
EVEX_Vpslldq_zmm_zmmm512_imm8, EVEX, 66, 0F, 73, EVEX.512.66.0F.WIG 73 /7 ib, VPSLLDQ zmm1| zmm2/m512| imm8, g=7 16b 32b 64b L512 WIG op=zmm_vvvv;zmm_or_mem;imm8 tt=Full_Mem_512
Pcmpeqb_mm_mmm64, legacy, NP, 0F, 74, NP 0F 74 /r, PCMPEQB mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pcmpeqb_xmm_xmmm128, legacy, 66, 0F, 74, 66 0F 74 /r, PCMPEQB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpcmpeqb_xmm_xmm_xmmm128, VEX, 66, 0F, 74, VEX.128.66.0F.WIG 74 /r, VPCMPEQB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpcmpeqb_ymm_ymm_ymmm256, VEX, 66, 0F, 74, VEX.256.66.0F.WIG 74 /r, VPCMPEQB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpcmpeqb_k_k1_xmm_xmmm128, EVEX, 66, 0F, 74, EVEX.128.66.0F.WIG 74 /r, VPCMPEQB k1 {k2}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=k_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k
EVEX_Vpcmpeqb_k_k1_ymm_ymmm256, EVEX, 66, 0F, 74, EVEX.256.66.0F.WIG 74 /r, VPCMPEQB k1 {k2}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=k_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k
EVEX_Vpcmpeqb_k_k1_zmm_zmmm512, EVEX, 66, 0F, 74, EVEX.512.66.0F.WIG 74 /r, VPCMPEQB k1 {k2}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=k_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k
Pcmpeqw_mm_mmm64, legacy, NP, 0F, 75, NP 0F 75 /r, PCMPEQW mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pcmpeqw_xmm_xmmm128, legacy, 66, 0F, 75, 66 0F 75 /r, PCMPEQW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpcmpeqw_xmm_xmm_xmmm128, VEX, 66, 0F, 75, VEX.128.66.0F.WIG 75 /r, VPCMPEQW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpcmpeqw_ymm_ymm_ymmm256, VEX, 66, 0F, 75, VEX.256.66.0F.WIG 75 /r, VPCMPEQW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpcmpeqw_k_k1_xmm_xmmm128, EVEX, 66, 0F, 75, EVEX.128.66.0F.WIG 75 /r, VPCMPEQW k1 {k2}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=k_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k
EVEX_Vpcmpeqw_k_k1_ymm_ymmm256, EVEX, 66, 0F, 75, EVEX.256.66.0F.WIG 75 /r, VPCMPEQW k1 {k2}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=k_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k
EVEX_Vpcmpeqw_k_k1_zmm_zmmm512, EVEX, 66, 0F, 75, EVEX.512.66.0F.WIG 75 /r, VPCMPEQW k1 {k2}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=k_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k
Pcmpeqd_mm_mmm64, legacy, NP, 0F, 76, NP 0F 76 /r, PCMPEQD mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pcmpeqd_xmm_xmmm128, legacy, 66, 0F, 76, 66 0F 76 /r, PCMPEQD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpcmpeqd_xmm_xmm_xmmm128, VEX, 66, 0F, 76, VEX.128.66.0F.WIG 76 /r, VPCMPEQD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpcmpeqd_ymm_ymm_ymmm256, VEX, 66, 0F, 76, VEX.256.66.0F.WIG 76 /r, VPCMPEQD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpcmpeqd_k_k1_xmm_xmmm128b32, EVEX, 66, 0F, 76, EVEX.128.66.0F.W0 76 /r, VPCMPEQD k1 {k2}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=k_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k
EVEX_Vpcmpeqd_k_k1_ymm_ymmm256b32, EVEX, 66, 0F, 76, EVEX.256.66.0F.W0 76 /r, VPCMPEQD k1 {k2}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=k_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k
EVEX_Vpcmpeqd_k_k1_zmm_zmmm512b32, EVEX, 66, 0F, 76, EVEX.512.66.0F.W0 76 /r, VPCMPEQD k1 {k2}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=k_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k
Emms, legacy, NP, 0F, 77, NP 0F 77, EMMS, 16b 32b 64b
VEX_Vzeroupper, VEX, NP, 0F, 77, VEX.128.0F.WIG 77, VZEROUPPER, 16b 32b 64b L128 WIG
VEX_Vzeroall, VEX, NP, 0F, 77, VEX.256.0F.WIG 77, VZEROALL, 16b 32b 64b L256 WIG
Vmread_rm32_r32, legacy, NP, 0F, 78, NP 0F 78 /r, VMREAD r/m32| r32, 16b 32b op=r32_or_mem;r32_reg
Vmread_rm64_r64, legacy, NP, 0F, 78, NP 0F 78 /r, VMREAD r/m64| r64, 64b op=r64_or_mem;r64_reg
EVEX_Vcvttps2udq_xmm_k1z_xmmm128b32, EVEX, NP, 0F, 78, EVEX.128.0F.W0 78 /r, VCVTTPS2UDQ xmm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvttps2udq_ymm_k1z_ymmm256b32, EVEX, NP, 0F, 78, EVEX.256.0F.W0 78 /r, VCVTTPS2UDQ ymm1 {k1}{z}| ymm2/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvttps2udq_zmm_k1z_zmmm512b32_sae, EVEX, NP, 0F, 78, EVEX.512.0F.W0 78 /r, VCVTTPS2UDQ zmm1 {k1}{z}| zmm2/m512/m32bcst{sae}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_512 b sae k z
EVEX_Vcvttpd2udq_xmm_k1z_xmmm128b64, EVEX, NP, 0F, 78, EVEX.128.0F.W1 78 /r, VCVTTPD2UDQ xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvttpd2udq_xmm_k1z_ymmm256b64, EVEX, NP, 0F, 78, EVEX.256.0F.W1 78 /r, VCVTTPD2UDQ xmm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=xmm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvttpd2udq_ymm_k1z_zmmm512b64_sae, EVEX, NP, 0F, 78, EVEX.512.0F.W1 78 /r, VCVTTPD2UDQ ymm1 {k1}{z}| zmm2/m512/m64bcst{sae}, 16b 32b 64b L512 W1 op=ymm_reg;zmm_or_mem tt=Full_512 b sae k z
Extrq_xmm_imm8_imm8, legacy, 66, 0F, 78, 66 0F 78 /0 ib ib, EXTRQ xmm1| imm8| imm8, g=0 16b 32b 64b op=xmm_rm;imm8;imm8
EVEX_Vcvttps2uqq_xmm_k1z_xmmm64b32, EVEX, 66, 0F, 78, EVEX.128.66.0F.W0 78 /r, VCVTTPS2UQQ xmm1 {k1}{z}| xmm2/m64/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Half_128 b k z
EVEX_Vcvttps2uqq_ymm_k1z_xmmm128b32, EVEX, 66, 0F, 78, EVEX.256.66.0F.W0 78 /r, VCVTTPS2UQQ ymm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem tt=Half_256 b k z
EVEX_Vcvttps2uqq_zmm_k1z_ymmm256b32_sae, EVEX, 66, 0F, 78, EVEX.512.66.0F.W0 78 /r, VCVTTPS2UQQ zmm1 {k1}{z}| ymm2/m256/m32bcst{sae}, 16b 32b 64b L512 W0 op=zmm_reg;ymm_or_mem tt=Half_512 b sae k z
EVEX_Vcvttpd2uqq_xmm_k1z_xmmm128b64, EVEX, 66, 0F, 78, EVEX.128.66.0F.W1 78 /r, VCVTTPD2UQQ xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvttpd2uqq_ymm_k1z_ymmm256b64, EVEX, 66, 0F, 78, EVEX.256.66.0F.W1 78 /r, VCVTTPD2UQQ ymm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvttpd2uqq_zmm_k1z_zmmm512b64_sae, EVEX, 66, 0F, 78, EVEX.512.66.0F.W1 78 /r, VCVTTPD2UQQ zmm1 {k1}{z}| zmm2/m512/m64bcst{sae}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_512 b sae k z
EVEX_Vcvttss2usi_r32_xmmm32_sae, EVEX, F3, 0F, 78, EVEX.LIG.F3.0F.W0 78 /r, VCVTTSS2USI r32| xmm1/m32{sae}, 16b 32b 64b LIG WIG32 op=r32_reg;xmm_or_mem tt=Tuple1_Fixed_4 sae
EVEX_Vcvttss2usi_r64_xmmm32_sae, EVEX, F3, 0F, 78, EVEX.LIG.F3.0F.W1 78 /r, VCVTTSS2USI r64| xmm1/m32{sae}, 64b LIG W1 op=r64_reg;xmm_or_mem tt=Tuple1_Fixed_4 sae
Insertq_xmm_xmm_imm8_imm8, legacy, F2, 0F, 78, F2 0F 78 /r ib ib, INSERTQ xmm1| xmm2| imm8| imm8, 16b 32b 64b op=xmm_reg;xmm_rm;imm8;imm8
EVEX_Vcvttsd2usi_r32_xmmm64_sae, EVEX, F2, 0F, 78, EVEX.LIG.F2.0F.W0 78 /r, VCVTTSD2USI r32| xmm1/m64{sae}, 16b 32b 64b LIG WIG32 op=r32_reg;xmm_or_mem tt=Tuple1_Fixed_8 sae
EVEX_Vcvttsd2usi_r64_xmmm64_sae, EVEX, F2, 0F, 78, EVEX.LIG.F2.0F.W1 78 /r, VCVTTSD2USI r64| xmm1/m64{sae}, 64b LIG W1 op=r64_reg;xmm_or_mem tt=Tuple1_Fixed_8 sae
Vmwrite_r32_rm32, legacy, NP, 0F, 79, NP 0F 79 /r, VMWRITE r32| r/m32, 16b 32b op=r32_reg;r32_or_mem
Vmwrite_r64_rm64, legacy, NP, 0F, 79, NP 0F 79 /r, VMWRITE r64| r/m64, 64b op=r64_reg;r64_or_mem
EVEX_Vcvtps2udq_xmm_k1z_xmmm128b32, EVEX, NP, 0F, 79, EVEX.128.0F.W0 79 /r, VCVTPS2UDQ xmm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvtps2udq_ymm_k1z_ymmm256b32, EVEX, NP, 0F, 79, EVEX.256.0F.W0 79 /r, VCVTPS2UDQ ymm1 {k1}{z}| ymm2/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvtps2udq_zmm_k1z_zmmm512b32_er, EVEX, NP, 0F, 79, EVEX.512.0F.W0 79 /r, VCVTPS2UDQ zmm1 {k1}{z}| zmm2/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_512 b er k z
EVEX_Vcvtpd2udq_xmm_k1z_xmmm128b64, EVEX, NP, 0F, 79, EVEX.128.0F.W1 79 /r, VCVTPD2UDQ xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvtpd2udq_xmm_k1z_ymmm256b64, EVEX, NP, 0F, 79, EVEX.256.0F.W1 79 /r, VCVTPD2UDQ xmm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=xmm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvtpd2udq_ymm_k1z_zmmm512b64_er, EVEX, NP, 0F, 79, EVEX.512.0F.W1 79 /r, VCVTPD2UDQ ymm1 {k1}{z}| zmm2/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=ymm_reg;zmm_or_mem tt=Full_512 b er k z
Extrq_xmm_xmm, legacy, 66, 0F, 79, 66 0F 79 /r, EXTRQ xmm1| xmm2, 16b 32b 64b op=xmm_reg;xmm_rm
EVEX_Vcvtps2uqq_xmm_k1z_xmmm64b32, EVEX, 66, 0F, 79, EVEX.128.66.0F.W0 79 /r, VCVTPS2UQQ xmm1 {k1}{z}| xmm2/m64/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Half_128 b k z
EVEX_Vcvtps2uqq_ymm_k1z_xmmm128b32, EVEX, 66, 0F, 79, EVEX.256.66.0F.W0 79 /r, VCVTPS2UQQ ymm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem tt=Half_256 b k z
EVEX_Vcvtps2uqq_zmm_k1z_ymmm256b32_er, EVEX, 66, 0F, 79, EVEX.512.66.0F.W0 79 /r, VCVTPS2UQQ zmm1 {k1}{z}| ymm2/m256/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;ymm_or_mem tt=Half_512 b er k z
EVEX_Vcvtpd2uqq_xmm_k1z_xmmm128b64, EVEX, 66, 0F, 79, EVEX.128.66.0F.W1 79 /r, VCVTPD2UQQ xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvtpd2uqq_ymm_k1z_ymmm256b64, EVEX, 66, 0F, 79, EVEX.256.66.0F.W1 79 /r, VCVTPD2UQQ ymm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvtpd2uqq_zmm_k1z_zmmm512b64_er, EVEX, 66, 0F, 79, EVEX.512.66.0F.W1 79 /r, VCVTPD2UQQ zmm1 {k1}{z}| zmm2/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_512 b er k z
EVEX_Vcvtss2usi_r32_xmmm32_er, EVEX, F3, 0F, 79, EVEX.LIG.F3.0F.W0 79 /r, VCVTSS2USI r32| xmm1/m32{er}, 16b 32b 64b LIG WIG32 op=r32_reg;xmm_or_mem tt=Tuple1_Fixed_4 er
EVEX_Vcvtss2usi_r64_xmmm32_er, EVEX, F3, 0F, 79, EVEX.LIG.F3.0F.W1 79 /r, VCVTSS2USI r64| xmm1/m32{er}, 64b LIG W1 op=r64_reg;xmm_or_mem tt=Tuple1_Fixed_4 er
Insertq_xmm_xmm, legacy, F2, 0F, 79, F2 0F 79 /r, INSERTQ xmm1| xmm2, 16b 32b 64b op=xmm_reg;xmm_rm
EVEX_Vcvtsd2usi_r32_xmmm64_er, EVEX, F2, 0F, 79, EVEX.LIG.F2.0F.W0 79 /r, VCVTSD2USI r32| xmm1/m64{er}, 16b 32b 64b LIG WIG32 op=r32_reg;xmm_or_mem tt=Tuple1_Fixed_8 er
EVEX_Vcvtsd2usi_r64_xmmm64_er, EVEX, F2, 0F, 79, EVEX.LIG.F2.0F.W1 79 /r, VCVTSD2USI r64| xmm1/m64{er}, 64b LIG W1 op=r64_reg;xmm_or_mem tt=Tuple1_Fixed_8 er
EVEX_Vcvttps2qq_xmm_k1z_xmmm64b32, EVEX, 66, 0F, 7A, EVEX.128.66.0F.W0 7A /r, VCVTTPS2QQ xmm1 {k1}{z}| xmm2/m64/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Half_128 b k z
EVEX_Vcvttps2qq_ymm_k1z_xmmm128b32, EVEX, 66, 0F, 7A, EVEX.256.66.0F.W0 7A /r, VCVTTPS2QQ ymm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem tt=Half_256 b k z
EVEX_Vcvttps2qq_zmm_k1z_ymmm256b32_sae, EVEX, 66, 0F, 7A, EVEX.512.66.0F.W0 7A /r, VCVTTPS2QQ zmm1 {k1}{z}| ymm2/m256/m32bcst{sae}, 16b 32b 64b L512 W0 op=zmm_reg;ymm_or_mem tt=Half_512 b sae k z
EVEX_Vcvttpd2qq_xmm_k1z_xmmm128b64, EVEX, 66, 0F, 7A, EVEX.128.66.0F.W1 7A /r, VCVTTPD2QQ xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvttpd2qq_ymm_k1z_ymmm256b64, EVEX, 66, 0F, 7A, EVEX.256.66.0F.W1 7A /r, VCVTTPD2QQ ymm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvttpd2qq_zmm_k1z_zmmm512b64_sae, EVEX, 66, 0F, 7A, EVEX.512.66.0F.W1 7A /r, VCVTTPD2QQ zmm1 {k1}{z}| zmm2/m512/m64bcst{sae}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_512 b sae k z
EVEX_Vcvtudq2pd_xmm_k1z_xmmm64b32, EVEX, F3, 0F, 7A, EVEX.128.F3.0F.W0 7A /r, VCVTUDQ2PD xmm1 {k1}{z}| xmm2/m64/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Half_128 b k z
EVEX_Vcvtudq2pd_ymm_k1z_xmmm128b32, EVEX, F3, 0F, 7A, EVEX.256.F3.0F.W0 7A /r, VCVTUDQ2PD ymm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem tt=Half_256 b k z
EVEX_Vcvtudq2pd_zmm_k1z_ymmm256b32, EVEX, F3, 0F, 7A, EVEX.512.F3.0F.W0 7A /r, VCVTUDQ2PD zmm1 {k1}{z}| ymm2/m256/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;ymm_or_mem tt=Half_512 b k z
EVEX_Vcvtuqq2pd_xmm_k1z_xmmm128b64, EVEX, F3, 0F, 7A, EVEX.128.F3.0F.W1 7A /r, VCVTUQQ2PD xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvtuqq2pd_ymm_k1z_ymmm256b64, EVEX, F3, 0F, 7A, EVEX.256.F3.0F.W1 7A /r, VCVTUQQ2PD ymm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvtuqq2pd_zmm_k1z_zmmm512b64_er, EVEX, F3, 0F, 7A, EVEX.512.F3.0F.W1 7A /r, VCVTUQQ2PD zmm1 {k1}{z}| zmm2/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_512 b er k z
EVEX_Vcvtudq2ps_xmm_k1z_xmmm128b32, EVEX, F2, 0F, 7A, EVEX.128.F2.0F.W0 7A /r, VCVTUDQ2PS xmm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvtudq2ps_ymm_k1z_ymmm256b32, EVEX, F2, 0F, 7A, EVEX.256.F2.0F.W0 7A /r, VCVTUDQ2PS ymm1 {k1}{z}| ymm2/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvtudq2ps_zmm_k1z_zmmm512b32_er, EVEX, F2, 0F, 7A, EVEX.512.F2.0F.W0 7A /r, VCVTUDQ2PS zmm1 {k1}{z}| zmm2/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_512 b er k z
EVEX_Vcvtuqq2ps_xmm_k1z_xmmm128b64, EVEX, F2, 0F, 7A, EVEX.128.F2.0F.W1 7A /r, VCVTUQQ2PS xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvtuqq2ps_xmm_k1z_ymmm256b64, EVEX, F2, 0F, 7A, EVEX.256.F2.0F.W1 7A /r, VCVTUQQ2PS xmm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=xmm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvtuqq2ps_ymm_k1z_zmmm512b64_er, EVEX, F2, 0F, 7A, EVEX.512.F2.0F.W1 7A /r, VCVTUQQ2PS ymm1 {k1}{z}| zmm2/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=ymm_reg;zmm_or_mem tt=Full_512 b er k z
EVEX_Vcvtps2qq_xmm_k1z_xmmm64b32, EVEX, 66, 0F, 7B, EVEX.128.66.0F.W0 7B /r, VCVTPS2QQ xmm1 {k1}{z}| xmm2/m64/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Half_128 b k z
EVEX_Vcvtps2qq_ymm_k1z_xmmm128b32, EVEX, 66, 0F, 7B, EVEX.256.66.0F.W0 7B /r, VCVTPS2QQ ymm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem tt=Half_256 b k z
EVEX_Vcvtps2qq_zmm_k1z_ymmm256b32_er, EVEX, 66, 0F, 7B, EVEX.512.66.0F.W0 7B /r, VCVTPS2QQ zmm1 {k1}{z}| ymm2/m256/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;ymm_or_mem tt=Half_512 b er k z
EVEX_Vcvtpd2qq_xmm_k1z_xmmm128b64, EVEX, 66, 0F, 7B, EVEX.128.66.0F.W1 7B /r, VCVTPD2QQ xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvtpd2qq_ymm_k1z_ymmm256b64, EVEX, 66, 0F, 7B, EVEX.256.66.0F.W1 7B /r, VCVTPD2QQ ymm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvtpd2qq_zmm_k1z_zmmm512b64_er, EVEX, 66, 0F, 7B, EVEX.512.66.0F.W1 7B /r, VCVTPD2QQ zmm1 {k1}{z}| zmm2/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_512 b er k z
EVEX_Vcvtusi2ss_xmm_xmm_rm32_er, EVEX, F3, 0F, 7B, EVEX.LIG.F3.0F.W0 7B /r, VCVTUSI2SS xmm1| xmm2| r/m32{er}, 16b 32b 64b LIG WIG32 op=xmm_reg;xmm_vvvv;r32_or_mem tt=Tuple1_Fixed_4 er
EVEX_Vcvtusi2ss_xmm_xmm_rm64_er, EVEX, F3, 0F, 7B, EVEX.LIG.F3.0F.W1 7B /r, VCVTUSI2SS xmm1| xmm2| r/m64{er}, 64b LIG W1 op=xmm_reg;xmm_vvvv;r64_or_mem tt=Tuple1_Fixed_8 er
EVEX_Vcvtusi2sd_xmm_xmm_rm32_er, EVEX, F2, 0F, 7B, EVEX.LIG.F2.0F.W0 7B /r, VCVTUSI2SD xmm1| xmm2| r/m32, 16b 32b 64b LIG WIG32 op=xmm_reg;xmm_vvvv;r32_or_mem tt=Tuple1_Fixed_4 er
EVEX_Vcvtusi2sd_xmm_xmm_rm64_er, EVEX, F2, 0F, 7B, EVEX.LIG.F2.0F.W1 7B /r, VCVTUSI2SD xmm1| xmm2| r/m64{er}, 64b LIG W1 op=xmm_reg;xmm_vvvv;r64_or_mem tt=Tuple1_Fixed_8 er
Haddpd_xmm_xmmm128, legacy, 66, 0F, 7C, 66 0F 7C /r, HADDPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vhaddpd_xmm_xmm_xmmm128, VEX, 66, 0F, 7C, VEX.128.66.0F.WIG 7C /r, VHADDPD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vhaddpd_ymm_ymm_ymmm256, VEX, 66, 0F, 7C, VEX.256.66.0F.WIG 7C /r, VHADDPD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
Haddps_xmm_xmmm128, legacy, F2, 0F, 7C, F2 0F 7C /r, HADDPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vhaddps_xmm_xmm_xmmm128, VEX, F2, 0F, 7C, VEX.128.F2.0F.WIG 7C /r, VHADDPS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vhaddps_ymm_ymm_ymmm256, VEX, F2, 0F, 7C, VEX.256.F2.0F.WIG 7C /r, VHADDPS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
Hsubpd_xmm_xmmm128, legacy, 66, 0F, 7D, 66 0F 7D /r, HSUBPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vhsubpd_xmm_xmm_xmmm128, VEX, 66, 0F, 7D, VEX.128.66.0F.WIG 7D /r, VHSUBPD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vhsubpd_ymm_ymm_ymmm256, VEX, 66, 0F, 7D, VEX.256.66.0F.WIG 7D /r, VHSUBPD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
Hsubps_xmm_xmmm128, legacy, F2, 0F, 7D, F2 0F 7D /r, HSUBPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vhsubps_xmm_xmm_xmmm128, VEX, F2, 0F, 7D, VEX.128.F2.0F.WIG 7D /r, VHSUBPS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vhsubps_ymm_ymm_ymmm256, VEX, F2, 0F, 7D, VEX.256.F2.0F.WIG 7D /r, VHSUBPS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
Movd_rm32_mm, legacy, NP, 0F, 7E, NP 0F 7E /r, MOVD r/m32| mm, 16b 32b 64b op=r32_or_mem;mm_reg
Movq_rm64_mm, legacy, NP, 0F, 7E, NP REX.W 0F 7E /r, MOVQ r/m64| mm, 64b o64 op=r64_or_mem;mm_reg
Movd_rm32_xmm, legacy, 66, 0F, 7E, 66 0F 7E /r, MOVD r/m32| xmm, 16b 32b 64b op=r32_or_mem;xmm_reg
Movq_rm64_xmm, legacy, 66, 0F, 7E, 66 REX.W 0F 7E /r, MOVQ r/m64| xmm, 64b o64 op=r64_or_mem;xmm_reg
VEX_Vmovd_rm32_xmm, VEX, 66, 0F, 7E, VEX.128.66.0F.W0 7E /r, VMOVD r/m32| xmm1, 16b 32b 64b L128 WIG32 op=r32_or_mem;xmm_reg
VEX_Vmovq_rm64_xmm, VEX, 66, 0F, 7E, VEX.128.66.0F.W1 7E /r, VMOVQ r/m64| xmm1, 64b L128 W1 op=r64_or_mem;xmm_reg
EVEX_Vmovd_rm32_xmm, EVEX, 66, 0F, 7E, EVEX.128.66.0F.W0 7E /r, VMOVD r/m32| xmm1, 16b 32b 64b L128 WIG32 op=r32_or_mem;xmm_reg tt=Tuple1_Scalar
EVEX_Vmovq_rm64_xmm, EVEX, 66, 0F, 7E, EVEX.128.66.0F.W1 7E /r, VMOVQ r/m64| xmm1, 64b L128 W1 op=r64_or_mem;xmm_reg tt=Tuple1_Scalar
Movq_xmm_xmmm64, legacy, F3, 0F, 7E, F3 0F 7E /r, MOVQ xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vmovq_xmm_xmmm64, VEX, F3, 0F, 7E, VEX.128.F3.0F.WIG 7E /r, VMOVQ xmm1| xmm2/m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
EVEX_Vmovq_xmm_xmmm64, EVEX, F3, 0F, 7E, EVEX.128.F3.0F.W1 7E /r, VMOVQ xmm1| xmm2/m64, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Tuple1_Scalar
Movq_mmm64_mm, legacy, NP, 0F, 7F, NP 0F 7F /r, MOVQ mm/m64| mm, 16b 32b 64b op=mm_or_mem;mm_reg
Movdqa_xmmm128_xmm, legacy, 66, 0F, 7F, 66 0F 7F /r, MOVDQA xmm2/m128| xmm1, 16b 32b 64b op=xmm_or_mem;xmm_reg
VEX_Vmovdqa_xmmm128_xmm, VEX, 66, 0F, 7F, VEX.128.66.0F.WIG 7F /r, VMOVDQA xmm2/m128| xmm1, 16b 32b 64b L128 WIG op=xmm_or_mem;xmm_reg
VEX_Vmovdqa_ymmm256_ymm, VEX, 66, 0F, 7F, VEX.256.66.0F.WIG 7F /r, VMOVDQA ymm2/m256| ymm1, 16b 32b 64b L256 WIG op=ymm_or_mem;ymm_reg
EVEX_Vmovdqa32_xmmm128_k1z_xmm, EVEX, 66, 0F, 7F, EVEX.128.66.0F.W0 7F /r, VMOVDQA32 xmm2/m128 {k1}{z}| xmm1, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Full_Mem_128 k z
EVEX_Vmovdqa32_ymmm256_k1z_ymm, EVEX, 66, 0F, 7F, EVEX.256.66.0F.W0 7F /r, VMOVDQA32 ymm2/m256 {k1}{z}| ymm1, 16b 32b 64b L256 W0 op=ymm_or_mem;ymm_reg tt=Full_Mem_256 k z
EVEX_Vmovdqa32_zmmm512_k1z_zmm, EVEX, 66, 0F, 7F, EVEX.512.66.0F.W0 7F /r, VMOVDQA32 zmm2/m512 {k1}{z}| zmm1, 16b 32b 64b L512 W0 op=zmm_or_mem;zmm_reg tt=Full_Mem_512 k z
EVEX_Vmovdqa64_xmmm128_k1z_xmm, EVEX, 66, 0F, 7F, EVEX.128.66.0F.W1 7F /r, VMOVDQA64 xmm2/m128 {k1}{z}| xmm1, 16b 32b 64b L128 W1 op=xmm_or_mem;xmm_reg tt=Full_Mem_128 k z
EVEX_Vmovdqa64_ymmm256_k1z_ymm, EVEX, 66, 0F, 7F, EVEX.256.66.0F.W1 7F /r, VMOVDQA64 ymm2/m256 {k1}{z}| ymm1, 16b 32b 64b L256 W1 op=ymm_or_mem;ymm_reg tt=Full_Mem_256 k z
EVEX_Vmovdqa64_zmmm512_k1z_zmm, EVEX, 66, 0F, 7F, EVEX.512.66.0F.W1 7F /r, VMOVDQA64 zmm2/m512 {k1}{z}| zmm1, 16b 32b 64b L512 W1 op=zmm_or_mem;zmm_reg tt=Full_Mem_512 k z
Movdqu_xmmm128_xmm, legacy, F3, 0F, 7F, F3 0F 7F /r, MOVDQU xmm2/m128| xmm1, 16b 32b 64b op=xmm_or_mem;xmm_reg
VEX_Vmovdqu_xmmm128_xmm, VEX, F3, 0F, 7F, VEX.128.F3.0F.WIG 7F /r, VMOVDQU xmm2/m128| xmm1, 16b 32b 64b L128 WIG op=xmm_or_mem;xmm_reg
VEX_Vmovdqu_ymmm256_ymm, VEX, F3, 0F, 7F, VEX.256.F3.0F.WIG 7F /r, VMOVDQU ymm2/m256| ymm1, 16b 32b 64b L256 WIG op=ymm_or_mem;ymm_reg
EVEX_Vmovdqu32_xmmm128_k1z_xmm, EVEX, F3, 0F, 7F, EVEX.128.F3.0F.W0 7F /r, VMOVDQU32 xmm2/m128 {k1}{z}| xmm1, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Full_Mem_128 k z
EVEX_Vmovdqu32_ymmm256_k1z_ymm, EVEX, F3, 0F, 7F, EVEX.256.F3.0F.W0 7F /r, VMOVDQU32 ymm2/m256 {k1}{z}| ymm1, 16b 32b 64b L256 W0 op=ymm_or_mem;ymm_reg tt=Full_Mem_256 k z
EVEX_Vmovdqu32_zmmm512_k1z_zmm, EVEX, F3, 0F, 7F, EVEX.512.F3.0F.W0 7F /r, VMOVDQU32 zmm2/m512 {k1}{z}| zmm1, 16b 32b 64b L512 W0 op=zmm_or_mem;zmm_reg tt=Full_Mem_512 k z
EVEX_Vmovdqu64_xmmm128_k1z_xmm, EVEX, F3, 0F, 7F, EVEX.128.F3.0F.W1 7F /r, VMOVDQU64 xmm2/m128 {k1}{z}| xmm1, 16b 32b 64b L128 W1 op=xmm_or_mem;xmm_reg tt=Full_Mem_128 k z
EVEX_Vmovdqu64_ymmm256_k1z_ymm, EVEX, F3, 0F, 7F, EVEX.256.F3.0F.W1 7F /r, VMOVDQU64 ymm2/m256 {k1}{z}| ymm1, 16b 32b 64b L256 W1 op=ymm_or_mem;ymm_reg tt=Full_Mem_256 k z
EVEX_Vmovdqu64_zmmm512_k1z_zmm, EVEX, F3, 0F, 7F, EVEX.512.F3.0F.W1 7F /r, VMOVDQU64 zmm2/m512 {k1}{z}| zmm1, 16b 32b 64b L512 W1 op=zmm_or_mem;zmm_reg tt=Full_Mem_512 k z
EVEX_Vmovdqu8_xmmm128_k1z_xmm, EVEX, F2, 0F, 7F, EVEX.128.F2.0F.W0 7F /r, VMOVDQU8 xmm2/m128 {k1}{z}| xmm1, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Full_Mem_128 k z
EVEX_Vmovdqu8_ymmm256_k1z_ymm, EVEX, F2, 0F, 7F, EVEX.256.F2.0F.W0 7F /r, VMOVDQU8 ymm2/m256 {k1}{z}| ymm1, 16b 32b 64b L256 W0 op=ymm_or_mem;ymm_reg tt=Full_Mem_256 k z
EVEX_Vmovdqu8_zmmm512_k1z_zmm, EVEX, F2, 0F, 7F, EVEX.512.F2.0F.W0 7F /r, VMOVDQU8 zmm2/m512 {k1}{z}| zmm1, 16b 32b 64b L512 W0 op=zmm_or_mem;zmm_reg tt=Full_Mem_512 k z
EVEX_Vmovdqu16_xmmm128_k1z_xmm, EVEX, F2, 0F, 7F, EVEX.128.F2.0F.W1 7F /r, VMOVDQU16 xmm2/m128 {k1}{z}| xmm1, 16b 32b 64b L128 W1 op=xmm_or_mem;xmm_reg tt=Full_Mem_128 k z
EVEX_Vmovdqu16_ymmm256_k1z_ymm, EVEX, F2, 0F, 7F, EVEX.256.F2.0F.W1 7F /r, VMOVDQU16 ymm2/m256 {k1}{z}| ymm1, 16b 32b 64b L256 W1 op=ymm_or_mem;ymm_reg tt=Full_Mem_256 k z
EVEX_Vmovdqu16_zmmm512_k1z_zmm, EVEX, F2, 0F, 7F, EVEX.512.F2.0F.W1 7F /r, VMOVDQU16 zmm2/m512 {k1}{z}| zmm1, 16b 32b 64b L512 W1 op=zmm_or_mem;zmm_reg tt=Full_Mem_512 k z
Jo_rel16, legacy, , 0F, 80, o16 0F 80 cw, JO rel16, 16b 32b 64b o16 op=br16_2 bnd ht
Jo_rel32_32, legacy, , 0F, 80, o32 0F 80 cd, JO rel32, 16b 32b o32 op=br32_4 bnd ht
Jo_rel32_64, legacy, , 0F, 80, 0F 80 cd, JO rel32, 64b op=br64_4 bnd ht
Jno_rel16, legacy, , 0F, 81, o16 0F 81 cw, JNO rel16, 16b 32b 64b o16 op=br16_2 bnd ht
Jno_rel32_32, legacy, , 0F, 81, o32 0F 81 cd, JNO rel32, 16b 32b o32 op=br32_4 bnd ht
Jno_rel32_64, legacy, , 0F, 81, 0F 81 cd, JNO rel32, 64b op=br64_4 bnd ht
Jb_rel16, legacy, , 0F, 82, o16 0F 82 cw, JB rel16, 16b 32b 64b o16 op=br16_2 bnd ht
Jb_rel32_32, legacy, , 0F, 82, o32 0F 82 cd, JB rel32, 16b 32b o32 op=br32_4 bnd ht
Jb_rel32_64, legacy, , 0F, 82, 0F 82 cd, JB rel32, 64b op=br64_4 bnd ht
Jae_rel16, legacy, , 0F, 83, o16 0F 83 cw, JAE rel16, 16b 32b 64b o16 op=br16_2 bnd ht
Jae_rel32_32, legacy, , 0F, 83, o32 0F 83 cd, JAE rel32, 16b 32b o32 op=br32_4 bnd ht
Jae_rel32_64, legacy, , 0F, 83, 0F 83 cd, JAE rel32, 64b op=br64_4 bnd ht
Je_rel16, legacy, , 0F, 84, o16 0F 84 cw, JE rel16, 16b 32b 64b o16 op=br16_2 bnd ht
Je_rel32_32, legacy, , 0F, 84, o32 0F 84 cd, JE rel32, 16b 32b o32 op=br32_4 bnd ht
Je_rel32_64, legacy, , 0F, 84, 0F 84 cd, JE rel32, 64b op=br64_4 bnd ht
Jne_rel16, legacy, , 0F, 85, o16 0F 85 cw, JNE rel16, 16b 32b 64b o16 op=br16_2 bnd ht
Jne_rel32_32, legacy, , 0F, 85, o32 0F 85 cd, JNE rel32, 16b 32b o32 op=br32_4 bnd ht
Jne_rel32_64, legacy, , 0F, 85, 0F 85 cd, JNE rel32, 64b op=br64_4 bnd ht
Jbe_rel16, legacy, , 0F, 86, o16 0F 86 cw, JBE rel16, 16b 32b 64b o16 op=br16_2 bnd ht
Jbe_rel32_32, legacy, , 0F, 86, o32 0F 86 cd, JBE rel32, 16b 32b o32 op=br32_4 bnd ht
Jbe_rel32_64, legacy, , 0F, 86, 0F 86 cd, JBE rel32, 64b op=br64_4 bnd ht
Ja_rel16, legacy, , 0F, 87, o16 0F 87 cw, JA rel16, 16b 32b 64b o16 op=br16_2 bnd ht
Ja_rel32_32, legacy, , 0F, 87, o32 0F 87 cd, JA rel32, 16b 32b o32 op=br32_4 bnd ht
Ja_rel32_64, legacy, , 0F, 87, 0F 87 cd, JA rel32, 64b op=br64_4 bnd ht
Js_rel16, legacy, , 0F, 88, o16 0F 88 cw, JS rel16, 16b 32b 64b o16 op=br16_2 bnd ht
Js_rel32_32, legacy, , 0F, 88, o32 0F 88 cd, JS rel32, 16b 32b o32 op=br32_4 bnd ht
Js_rel32_64, legacy, , 0F, 88, 0F 88 cd, JS rel32, 64b op=br64_4 bnd ht
Jns_rel16, legacy, , 0F, 89, o16 0F 89 cw, JNS rel16, 16b 32b 64b o16 op=br16_2 bnd ht
Jns_rel32_32, legacy, , 0F, 89, o32 0F 89 cd, JNS rel32, 16b 32b o32 op=br32_4 bnd ht
Jns_rel32_64, legacy, , 0F, 89, 0F 89 cd, JNS rel32, 64b op=br64_4 bnd ht
Jp_rel16, legacy, , 0F, 8A, o16 0F 8A cw, JP rel16, 16b 32b 64b o16 op=br16_2 bnd ht
Jp_rel32_32, legacy, , 0F, 8A, o32 0F 8A cd, JP rel32, 16b 32b o32 op=br32_4 bnd ht
Jp_rel32_64, legacy, , 0F, 8A, 0F 8A cd, JP rel32, 64b op=br64_4 bnd ht
Jnp_rel16, legacy, , 0F, 8B, o16 0F 8B cw, JNP rel16, 16b 32b 64b o16 op=br16_2 bnd ht
Jnp_rel32_32, legacy, , 0F, 8B, o32 0F 8B cd, JNP rel32, 16b 32b o32 op=br32_4 bnd ht
Jnp_rel32_64, legacy, , 0F, 8B, 0F 8B cd, JNP rel32, 64b op=br64_4 bnd ht
Jl_rel16, legacy, , 0F, 8C, o16 0F 8C cw, JL rel16, 16b 32b 64b o16 op=br16_2 bnd ht
Jl_rel32_32, legacy, , 0F, 8C, o32 0F 8C cd, JL rel32, 16b 32b o32 op=br32_4 bnd ht
Jl_rel32_64, legacy, , 0F, 8C, 0F 8C cd, JL rel32, 64b op=br64_4 bnd ht
Jge_rel16, legacy, , 0F, 8D, o16 0F 8D cw, JGE rel16, 16b 32b 64b o16 op=br16_2 bnd ht
Jge_rel32_32, legacy, , 0F, 8D, o32 0F 8D cd, JGE rel32, 16b 32b o32 op=br32_4 bnd ht
Jge_rel32_64, legacy, , 0F, 8D, 0F 8D cd, JGE rel32, 64b op=br64_4 bnd ht
Jle_rel16, legacy, , 0F, 8E, o16 0F 8E cw, JLE rel16, 16b 32b 64b o16 op=br16_2 bnd ht
Jle_rel32_32, legacy, , 0F, 8E, o32 0F 8E cd, JLE rel32, 16b 32b o32 op=br32_4 bnd ht
Jle_rel32_64, legacy, , 0F, 8E, 0F 8E cd, JLE rel32, 64b op=br64_4 bnd ht
Jg_rel16, legacy, , 0F, 8F, o16 0F 8F cw, JG rel16, 16b 32b 64b o16 op=br16_2 bnd ht
Jg_rel32_32, legacy, , 0F, 8F, o32 0F 8F cd, JG rel32, 16b 32b o32 op=br32_4 bnd ht
Jg_rel32_64, legacy, , 0F, 8F, 0F 8F cd, JG rel32, 64b op=br64_4 bnd ht
Seto_rm8, legacy, , 0F, 90, 0F 90 /r, SETO r/m8, 16b 32b 64b op=r8_or_mem
Setno_rm8, legacy, , 0F, 91, 0F 91 /r, SETNO r/m8, 16b 32b 64b op=r8_or_mem
Setb_rm8, legacy, , 0F, 92, 0F 92 /r, SETB r/m8, 16b 32b 64b op=r8_or_mem
Setae_rm8, legacy, , 0F, 93, 0F 93 /r, SETAE r/m8, 16b 32b 64b op=r8_or_mem
Sete_rm8, legacy, , 0F, 94, 0F 94 /r, SETE r/m8, 16b 32b 64b op=r8_or_mem
Setne_rm8, legacy, , 0F, 95, 0F 95 /r, SETNE r/m8, 16b 32b 64b op=r8_or_mem
Setbe_rm8, legacy, , 0F, 96, 0F 96 /r, SETBE r/m8, 16b 32b 64b op=r8_or_mem
Seta_rm8, legacy, , 0F, 97, 0F 97 /r, SETA r/m8, 16b 32b 64b op=r8_or_mem
Sets_rm8, legacy, , 0F, 98, 0F 98 /r, SETS r/m8, 16b 32b 64b op=r8_or_mem
Setns_rm8, legacy, , 0F, 99, 0F 99 /r, SETNS r/m8, 16b 32b 64b op=r8_or_mem
Setp_rm8, legacy, , 0F, 9A, 0F 9A /r, SETP r/m8, 16b 32b 64b op=r8_or_mem
Setnp_rm8, legacy, , 0F, 9B, 0F 9B /r, SETNP r/m8, 16b 32b 64b op=r8_or_mem
Setl_rm8, legacy, , 0F, 9C, 0F 9C /r, SETL r/m8, 16b 32b 64b op=r8_or_mem
Setge_rm8, legacy, , 0F, 9D, 0F 9D /r, SETGE r/m8, 16b 32b 64b op=r8_or_mem
Setle_rm8, legacy, , 0F, 9E, 0F 9E /r, SETLE r/m8, 16b 32b 64b op=r8_or_mem
Setg_rm8, legacy, , 0F, 9F, 0F 9F /r, SETG r/m8, 16b 32b 64b op=r8_or_mem
VEX_Kmovw_k_km16, VEX, NP, 0F, 90, VEX.L0.0F.W0 90 /r, KMOVW k1| k2/m16, 16b 32b 64b L0 W0 op=k_reg;k_or_mem
VEX_Kmovq_k_km64, VEX, NP, 0F, 90, VEX.L0.0F.W1 90 /r, KMOVQ k1| k2/m64, 16b 32b 64b L0 W1 op=k_reg;k_or_mem
VEX_Kmovb_k_km8, VEX, 66, 0F, 90, VEX.L0.66.0F.W0 90 /r, KMOVB k1| k2/m8, 16b 32b 64b L0 W0 op=k_reg;k_or_mem
VEX_Kmovd_k_km32, VEX, 66, 0F, 90, VEX.L0.66.0F.W1 90 /r, KMOVD k1| k2/m32, 16b 32b 64b L0 W1 op=k_reg;k_or_mem
VEX_Kmovw_m16_k, VEX, NP, 0F, 91, VEX.L0.0F.W0 91 /r, KMOVW m16| k1, 16b 32b 64b L0 W0 op=mem;k_reg
VEX_Kmovq_m64_k, VEX, NP, 0F, 91, VEX.L0.0F.W1 91 /r, KMOVQ m64| k1, 16b 32b 64b L0 W1 op=mem;k_reg
VEX_Kmovb_m8_k, VEX, 66, 0F, 91, VEX.L0.66.0F.W0 91 /r, KMOVB m8| k1, 16b 32b 64b L0 W0 op=mem;k_reg
VEX_Kmovd_m32_k, VEX, 66, 0F, 91, VEX.L0.66.0F.W1 91 /r, KMOVD m32| k1, 16b 32b 64b L0 W1 op=mem;k_reg
VEX_Kmovw_k_r32, VEX, NP, 0F, 92, VEX.L0.0F.W0 92 /r, KMOVW k1| r32, 16b 32b 64b L0 W0 op=k_reg;r32_rm
VEX_Kmovb_k_r32, VEX, 66, 0F, 92, VEX.L0.66.0F.W0 92 /r, KMOVB k1| r32, 16b 32b 64b L0 W0 op=k_reg;r32_rm
VEX_Kmovd_k_r32, VEX, F2, 0F, 92, VEX.L0.F2.0F.W0 92 /r, KMOVD k1| r32, 16b 32b 64b L0 W0 op=k_reg;r32_rm
VEX_Kmovq_k_r64, VEX, F2, 0F, 92, VEX.L0.F2.0F.W1 92 /r, KMOVQ k1| r64, 64b L0 W1 op=k_reg;r64_rm
VEX_Kmovw_r32_k, VEX, NP, 0F, 93, VEX.L0.0F.W0 93 /r, KMOVW r32| k1, 16b 32b 64b L0 W0 op=r32_reg;k_rm
VEX_Kmovb_r32_k, VEX, 66, 0F, 93, VEX.L0.66.0F.W0 93 /r, KMOVB r32| k1, 16b 32b 64b L0 W0 op=r32_reg;k_rm
VEX_Kmovd_r32_k, VEX, F2, 0F, 93, VEX.L0.F2.0F.W0 93 /r, KMOVD r32| k1, 16b 32b 64b L0 W0 op=r32_reg;k_rm
VEX_Kmovq_r64_k, VEX, F2, 0F, 93, VEX.L0.F2.0F.W1 93 /r, KMOVQ r64| k1, 64b L0 W1 op=r64_reg;k_rm
VEX_Kortestw_k_k, VEX, NP, 0F, 98, VEX.L0.0F.W0 98 /r, KORTESTW k1| k2, 16b 32b 64b L0 W0 op=k_reg;k_rm
VEX_Kortestq_k_k, VEX, NP, 0F, 98, VEX.L0.0F.W1 98 /r, KORTESTQ k1| k2, 16b 32b 64b L0 W1 op=k_reg;k_rm
VEX_Kortestb_k_k, VEX, 66, 0F, 98, VEX.L0.66.0F.W0 98 /r, KORTESTB k1| k2, 16b 32b 64b L0 W0 op=k_reg;k_rm
VEX_Kortestd_k_k, VEX, 66, 0F, 98, VEX.L0.66.0F.W1 98 /r, KORTESTD k1| k2, 16b 32b 64b L0 W1 op=k_reg;k_rm
VEX_Ktestw_k_k, VEX, NP, 0F, 99, VEX.L0.0F.W0 99 /r, KTESTW k1| k2, 16b 32b 64b L0 W0 op=k_reg;k_rm
VEX_Ktestq_k_k, VEX, NP, 0F, 99, VEX.L0.0F.W1 99 /r, KTESTQ k1| k2, 16b 32b 64b L0 W1 op=k_reg;k_rm
VEX_Ktestb_k_k, VEX, 66, 0F, 99, VEX.L0.66.0F.W0 99 /r, KTESTB k1| k2, 16b 32b 64b L0 W0 op=k_reg;k_rm
VEX_Ktestd_k_k, VEX, 66, 0F, 99, VEX.L0.66.0F.W1 99 /r, KTESTD k1| k2, 16b 32b 64b L0 W1 op=k_reg;k_rm
Pushw_FS, legacy, , 0F, A0, o16 0F A0, PUSH FS, 16b 32b 64b o16 op=fs
Pushd_FS, legacy, , 0F, A0, o32 0F A0, PUSH FS, 16b 32b o32 op=fs
Pushq_FS, legacy, , 0F, A0, 0F A0, PUSH FS, 64b op=fs
Popw_FS, legacy, , 0F, A1, o16 0F A1, POP FS, 16b 32b 64b o16 op=fs
Popd_FS, legacy, , 0F, A1, o32 0F A1, POP FS, 16b 32b o32 op=fs
Popq_FS, legacy, , 0F, A1, 0F A1, POP FS, 64b op=fs
Cpuid, legacy, , 0F, A2, 0F A2, CPUID, 16b 32b 64b
Bt_rm16_r16, legacy, , 0F, A3, o16 0F A3 /r, BT r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg
Bt_rm32_r32, legacy, , 0F, A3, o32 0F A3 /r, BT r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg
Bt_rm64_r64, legacy, , 0F, A3, REX.W 0F A3 /r, BT r/m64| r64, 64b o64 op=r64_or_mem;r64_reg
Shld_rm16_r16_imm8, legacy, , 0F, A4, o16 0F A4 /r ib, SHLD r/m16| r16| imm8, 16b 32b 64b o16 op=r16_or_mem;r16_reg;imm8
Shld_rm32_r32_imm8, legacy, , 0F, A4, o32 0F A4 /r ib, SHLD r/m32| r32| imm8, 16b 32b 64b o32 op=r32_or_mem;r32_reg;imm8
Shld_rm64_r64_imm8, legacy, , 0F, A4, REX.W 0F A4 /r ib, SHLD r/m64| r64| imm8, 64b o64 op=r64_or_mem;r64_reg;imm8
Shld_rm16_r16_CL, legacy, , 0F, A5, o16 0F A5 /r, SHLD r/m16| r16| CL, 16b 32b 64b o16 op=r16_or_mem;r16_reg;cl
Shld_rm32_r32_CL, legacy, , 0F, A5, o32 0F A5 /r, SHLD r/m32| r32| CL, 16b 32b 64b o32 op=r32_or_mem;r32_reg;cl
Shld_rm64_r64_CL, legacy, , 0F, A5, REX.W 0F A5 /r, SHLD r/m64| r64| CL, 64b o64 op=r64_or_mem;r64_reg;cl
Montmul_16, legacy, , 0F, A6C0, a16 0F A6 C0, MONTMUL, 16b 32b a16 rep
Montmul_32, legacy, , 0F, A6C0, a32 0F A6 C0, MONTMUL, 16b 32b 64b a32 rep
Montmul_64, legacy, , 0F, A6C0, 0F A6 C0, MONTMUL, 64b rep
Xsha1_16, legacy, , 0F, A6C8, a16 0F A6 C8, XSHA1, 16b 32b a16 rep
Xsha1_32, legacy, , 0F, A6C8, a32 0F A6 C8, XSHA1, 16b 32b 64b a32 rep
Xsha1_64, legacy, , 0F, A6C8, 0F A6 C8, XSHA1, 64b rep
Xsha256_16, legacy, , 0F, A6D0, a16 0F A6 D0, XSHA256, 16b 32b a16 rep
Xsha256_32, legacy, , 0F, A6D0, a32 0F A6 D0, XSHA256, 16b 32b 64b a32 rep
Xsha256_64, legacy, , 0F, A6D0, 0F A6 D0, XSHA256, 64b rep
Xbts_r16_rm16, legacy, , 0F, A6, o16 0F A6 /r, XBTS r16| r/m16, 16b 32b o16 op=r16_reg;r16_or_mem
Xbts_r32_rm32, legacy, , 0F, A6, o32 0F A6 /r, XBTS r32| r/m32, 16b 32b o32 op=r32_reg;r32_or_mem
Xstore_16, legacy, , 0F, A7C0, a16 0F A7 C0, XSTORE, 16b 32b a16 rep
Xstore_32, legacy, , 0F, A7C0, a32 0F A7 C0, XSTORE, 16b 32b 64b a32 rep
Xstore_64, legacy, , 0F, A7C0, 0F A7 C0, XSTORE, 64b rep
XcryptEcb_16, legacy, , 0F, A7C8, a16 0F A7 C8, XCRYPTECB, 16b 32b a16 rep
XcryptEcb_32, legacy, , 0F, A7C8, a32 0F A7 C8, XCRYPTECB, 16b 32b 64b a32 rep
XcryptEcb_64, legacy, , 0F, A7C8, 0F A7 C8, XCRYPTECB, 64b rep
XcryptCbc_16, legacy, , 0F, A7D0, a16 0F A7 D0, XCRYPTCBC, 16b 32b a16 rep
XcryptCbc_32, legacy, , 0F, A7D0, a32 0F A7 D0, XCRYPTCBC, 16b 32b 64b a32 rep
XcryptCbc_64, legacy, , 0F, A7D0, 0F A7 D0, XCRYPTCBC, 64b rep
XcryptCtr_16, legacy, , 0F, A7D8, a16 0F A7 D8, XCRYPTCTR, 16b 32b a16 rep
XcryptCtr_32, legacy, , 0F, A7D8, a32 0F A7 D8, XCRYPTCTR, 16b 32b 64b a32 rep
XcryptCtr_64, legacy, , 0F, A7D8, 0F A7 D8, XCRYPTCTR, 64b rep
XcryptCfb_16, legacy, , 0F, A7E0, a16 0F A7 E0, XCRYPTCFB, 16b 32b a16 rep
XcryptCfb_32, legacy, , 0F, A7E0, a32 0F A7 E0, XCRYPTCFB, 16b 32b 64b a32 rep
XcryptCfb_64, legacy, , 0F, A7E0, 0F A7 E0, XCRYPTCFB, 64b rep
XcryptOfb_16, legacy, , 0F, A7E8, a16 0F A7 E8, XCRYPTOFB, 16b 32b a16 rep
XcryptOfb_32, legacy, , 0F, A7E8, a32 0F A7 E8, XCRYPTOFB, 16b 32b 64b a32 rep
XcryptOfb_64, legacy, , 0F, A7E8, 0F A7 E8, XCRYPTOFB, 64b rep
Ibts_rm16_r16, legacy, , 0F, A7, o16 0F A7 /r, IBTS r/m16| r16, 16b 32b o16 op=r16_or_mem;r16_reg
Ibts_rm32_r32, legacy, , 0F, A7, o32 0F A7 /r, IBTS r/m32| r32, 16b 32b o32 op=r32_or_mem;r32_reg
Cmpxchg486_rm8_r8, legacy, , 0F, A6, 0F A6 /r, CMPXCHG r/m8| r8, 16b 32b op=r8_or_mem;r8_reg
Cmpxchg486_rm16_r16, legacy, , 0F, A7, o16 0F A7 /r, CMPXCHG r/m16| r16, 16b 32b o16 op=r16_or_mem;r16_reg
Cmpxchg486_rm32_r32, legacy, , 0F, A7, o32 0F A7 /r, CMPXCHG r/m32| r32, 16b 32b o32 op=r32_or_mem;r32_reg
Pushw_GS, legacy, , 0F, A8, o16 0F A8, PUSH GS, 16b 32b 64b o16 op=gs
Pushd_GS, legacy, , 0F, A8, o32 0F A8, PUSH GS, 16b 32b o32 op=gs
Pushq_GS, legacy, , 0F, A8, 0F A8, PUSH GS, 64b op=gs
Popw_GS, legacy, , 0F, A9, o16 0F A9, POP GS, 16b 32b 64b o16 op=gs
Popd_GS, legacy, , 0F, A9, o32 0F A9, POP GS, 16b 32b o32 op=gs
Popq_GS, legacy, , 0F, A9, 0F A9, POP GS, 64b op=gs
Rsm, legacy, , 0F, AA, 0F AA, RSM, 16b 32b 64b
Bts_rm16_r16, legacy, , 0F, AB, o16 0F AB /r, BTS r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg lock xacquire xrelease
Bts_rm32_r32, legacy, , 0F, AB, o32 0F AB /r, BTS r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg lock xacquire xrelease
Bts_rm64_r64, legacy, , 0F, AB, REX.W 0F AB /r, BTS r/m64| r64, 64b o64 op=r64_or_mem;r64_reg lock xacquire xrelease
Shrd_rm16_r16_imm8, legacy, , 0F, AC, o16 0F AC /r ib, SHRD r/m16| r16| imm8, 16b 32b 64b o16 op=r16_or_mem;r16_reg;imm8
Shrd_rm32_r32_imm8, legacy, , 0F, AC, o32 0F AC /r ib, SHRD r/m32| r32| imm8, 16b 32b 64b o32 op=r32_or_mem;r32_reg;imm8
Shrd_rm64_r64_imm8, legacy, , 0F, AC, REX.W 0F AC /r ib, SHRD r/m64| r64| imm8, 64b o64 op=r64_or_mem;r64_reg;imm8
Shrd_rm16_r16_CL, legacy, , 0F, AD, o16 0F AD /r, SHRD r/m16| r16| CL, 16b 32b 64b o16 op=r16_or_mem;r16_reg;cl
Shrd_rm32_r32_CL, legacy, , 0F, AD, o32 0F AD /r, SHRD r/m32| r32| CL, 16b 32b 64b o32 op=r32_or_mem;r32_reg;cl
Shrd_rm64_r64_CL, legacy, , 0F, AD, REX.W 0F AD /r, SHRD r/m64| r64| CL, 64b o64 op=r64_or_mem;r64_reg;cl
Fxsave_m512byte, legacy, NP, 0F, AE, NP 0F AE /0, FXSAVE m512byte, g=0 16b 32b 64b op=mem
Fxsave64_m512byte, legacy, NP, 0F, AE, NP REX.W 0F AE /0, FXSAVE64 m512byte, g=0 64b o64 op=mem
Rdfsbase_r32, legacy, F3, 0F, AE, F3 0F AE /0, RDFSBASE r32, g=0 64b op=r32_rm
Rdfsbase_r64, legacy, F3, 0F, AE, F3 REX.W 0F AE /0, RDFSBASE r64, g=0 64b o64 op=r64_rm
Fxrstor_m512byte, legacy, NP, 0F, AE, NP 0F AE /1, FXRSTOR m512byte, g=1 16b 32b 64b op=mem
Fxrstor64_m512byte, legacy, NP, 0F, AE, NP REX.W 0F AE /1, FXRSTOR64 m512byte, g=1 64b o64 op=mem
Rdgsbase_r32, legacy, F3, 0F, AE, F3 0F AE /1, RDGSBASE r32, g=1 64b op=r32_rm
Rdgsbase_r64, legacy, F3, 0F, AE, F3 REX.W 0F AE /1, RDGSBASE r64, g=1 64b o64 op=r64_rm
Ldmxcsr_m32, legacy, NP, 0F, AE, NP 0F AE /2, LDMXCSR m32, g=2 16b 32b 64b op=mem
Wrfsbase_r32, legacy, F3, 0F, AE, F3 0F AE /2, WRFSBASE r32, g=2 64b op=r32_rm
Wrfsbase_r64, legacy, F3, 0F, AE, F3 REX.W 0F AE /2, WRFSBASE r64, g=2 64b o64 op=r64_rm
VEX_Vldmxcsr_m32, VEX, NP, 0F, AE, VEX.LZ.0F.WIG AE /2, VLDMXCSR m32, g=2 16b 32b 64b L0 WIG op=mem
Stmxcsr_m32, legacy, NP, 0F, AE, NP 0F AE /3, STMXCSR m32, g=3 16b 32b 64b op=mem
Wrgsbase_r32, legacy, F3, 0F, AE, F3 0F AE /3, WRGSBASE r32, g=3 64b op=r32_rm
Wrgsbase_r64, legacy, F3, 0F, AE, F3 REX.W 0F AE /3, WRGSBASE r64, g=3 64b o64 op=r64_rm
VEX_Vstmxcsr_m32, VEX, NP, 0F, AE, VEX.LZ.0F.WIG AE /3, VSTMXCSR m32, g=3 16b 32b 64b L0 WIG op=mem
Xsave_mem, legacy, NP, 0F, AE, NP 0F AE /4, XSAVE mem, g=4 16b 32b 64b op=mem
Xsave64_mem, legacy, NP, 0F, AE, NP REX.W 0F AE /4, XSAVE64 mem, g=4 64b o64 op=mem
Ptwrite_rm32, legacy, F3, 0F, AE, F3 0F AE /4, PTWRITE r/m32, g=4 16b 32b 64b op=r32_or_mem
Ptwrite_rm64, legacy, F3, 0F, AE, F3 REX.W 0F AE /4, PTWRITE r/m64, g=4 64b o64 op=r64_or_mem
Xrstor_mem, legacy, NP, 0F, AE, NP 0F AE /5, XRSTOR mem, g=5 16b 32b 64b op=mem
Xrstor64_mem, legacy, NP, 0F, AE, NP REX.W 0F AE /5, XRSTOR64 mem, g=5 64b o64 op=mem
Incsspd_r32, legacy, F3, 0F, AE, F3 0F AE /5, INCSSPD r32, g=5 16b 32b 64b op=r32_rm
Incsspq_r64, legacy, F3, 0F, AE, F3 REX.W 0F AE /5, INCSSPQ r64, g=5 64b o64 op=r64_rm
Xsaveopt_mem, legacy, NP, 0F, AE, NP 0F AE /6, XSAVEOPT mem, g=6 16b 32b 64b op=mem
Xsaveopt64_mem, legacy, NP, 0F, AE, NP REX.W 0F AE /6, XSAVEOPT64 mem, g=6 64b o64 op=mem
Clwb_m8, legacy, 66, 0F, AE, 66 0F AE /6, CLWB m8, g=6 16b 32b 64b op=mem
Tpause_r32, legacy, 66, 0F, AE, 66 0F AE /6, TPAUSE r32| <edx>| <eax>, g=6 16b 32b 64b op=r32_rm
Tpause_r64, legacy, 66, 0F, AE, 66 REX.W 0F AE /6, TPAUSE r64| <edx>| <eax>, g=6 64b o64 op=r64_rm
Clrssbsy_m64, legacy, F3, 0F, AE, F3 0F AE /6, CLRSSBSY m64, g=6 16b 32b 64b op=mem
Umonitor_r16, legacy, F3, 0F, AE, a16 F3 0F AE /6, UMONITOR r16, g=6 16b 32b a16 op=r16_rm
Umonitor_r32, legacy, F3, 0F, AE, a32 F3 0F AE /6, UMONITOR r32, g=6 16b 32b 64b a32 op=r32_rm
Umonitor_r64, legacy, F3, 0F, AE, F3 0F AE /6, UMONITOR r64, g=6 64b op=r64_rm
Umwait_r32, legacy, F2, 0F, AE, F2 0F AE /6, UMWAIT r32| <edx>| <eax>, g=6 16b 32b 64b op=r32_rm
Umwait_r64, legacy, F2, 0F, AE, F2 REX.W 0F AE /6, UMWAIT r64| <edx>| <eax>, g=6 64b o64 op=r64_rm
Clflush_m8, legacy, NP, 0F, AE, NP 0F AE /7, CLFLUSH m8, g=7 16b 32b 64b op=mem
Clflushopt_m8, legacy, 66, 0F, AE, 66 0F AE /7, CLFLUSHOPT m8, g=7 16b 32b 64b op=mem
Lfence, legacy, NP, 0F, AEE8, NP 0F AE E8, LFENCE, 16b 32b 64b
Lfence_E9, legacy, NP, 0F, AEE9, NP 0F AE E9, LFENCE, 16b 32b 64b
Lfence_EA, legacy, NP, 0F, AEEA, NP 0F AE EA, LFENCE, 16b 32b 64b
Lfence_EB, legacy, NP, 0F, AEEB, NP 0F AE EB, LFENCE, 16b 32b 64b
Lfence_EC, legacy, NP, 0F, AEEC, NP 0F AE EC, LFENCE, 16b 32b 64b
Lfence_ED, legacy, NP, 0F, AEED, NP 0F AE ED, LFENCE, 16b 32b 64b
Lfence_EE, legacy, NP, 0F, AEEE, NP 0F AE EE, LFENCE, 16b 32b 64b
Lfence_EF, legacy, NP, 0F, AEEF, NP 0F AE EF, LFENCE, 16b 32b 64b
Mfence, legacy, NP, 0F, AEF0, NP 0F AE F0, MFENCE, 16b 32b 64b
Mfence_F1, legacy, NP, 0F, AEF1, NP 0F AE F1, MFENCE, 16b 32b 64b
Mfence_F2, legacy, NP, 0F, AEF2, NP 0F AE F2, MFENCE, 16b 32b 64b
Mfence_F3, legacy, NP, 0F, AEF3, NP 0F AE F3, MFENCE, 16b 32b 64b
Mfence_F4, legacy, NP, 0F, AEF4, NP 0F AE F4, MFENCE, 16b 32b 64b
Mfence_F5, legacy, NP, 0F, AEF5, NP 0F AE F5, MFENCE, 16b 32b 64b
Mfence_F6, legacy, NP, 0F, AEF6, NP 0F AE F6, MFENCE, 16b 32b 64b
Mfence_F7, legacy, NP, 0F, AEF7, NP 0F AE F7, MFENCE, 16b 32b 64b
Sfence, legacy, NP, 0F, AEF8, NP 0F AE F8, SFENCE, 16b 32b 64b
Sfence_F9, legacy, NP, 0F, AEF9, NP 0F AE F9, SFENCE, 16b 32b 64b
Sfence_FA, legacy, NP, 0F, AEFA, NP 0F AE FA, SFENCE, 16b 32b 64b
Sfence_FB, legacy, NP, 0F, AEFB, NP 0F AE FB, SFENCE, 16b 32b 64b
Sfence_FC, legacy, NP, 0F, AEFC, NP 0F AE FC, SFENCE, 16b 32b 64b
Sfence_FD, legacy, NP, 0F, AEFD, NP 0F AE FD, SFENCE, 16b 32b 64b
Sfence_FE, legacy, NP, 0F, AEFE, NP 0F AE FE, SFENCE, 16b 32b 64b
Sfence_FF, legacy, NP, 0F, AEFF, NP 0F AE FF, SFENCE, 16b 32b 64b
Pcommit, legacy, 66, 0F, AEF8, 66 0F AE F8, PCOMMIT, 16b 32b 64b
Imul_r16_rm16, legacy, , 0F, AF, o16 0F AF /r, IMUL r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Imul_r32_rm32, legacy, , 0F, AF, o32 0F AF /r, IMUL r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Imul_r64_rm64, legacy, , 0F, AF, REX.W 0F AF /r, IMUL r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Cmpxchg_rm8_r8, legacy, , 0F, B0, 0F B0 /r, CMPXCHG r/m8| r8, 16b 32b 64b op=r8_or_mem;r8_reg lock xacquire xrelease
Cmpxchg_rm16_r16, legacy, , 0F, B1, o16 0F B1 /r, CMPXCHG r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg lock xacquire xrelease
Cmpxchg_rm32_r32, legacy, , 0F, B1, o32 0F B1 /r, CMPXCHG r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg lock xacquire xrelease
Cmpxchg_rm64_r64, legacy, , 0F, B1, REX.W 0F B1 /r, CMPXCHG r/m64| r64, 64b o64 op=r64_or_mem;r64_reg lock xacquire xrelease
Lss_r16_m1616, legacy, , 0F, B2, o16 0F B2 /r, LSS r16| m16:16, 16b 32b 64b o16 op=r16_reg;mem
Lss_r32_m1632, legacy, , 0F, B2, o32 0F B2 /r, LSS r32| m16:32, 16b 32b 64b o32 op=r32_reg;mem
Lss_r64_m1664, legacy, , 0F, B2, REX.W 0F B2 /r, LSS r64| m16:64, 64b o64 op=r64_reg;mem
Btr_rm16_r16, legacy, , 0F, B3, o16 0F B3 /r, BTR r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg lock xacquire xrelease
Btr_rm32_r32, legacy, , 0F, B3, o32 0F B3 /r, BTR r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg lock xacquire xrelease
Btr_rm64_r64, legacy, , 0F, B3, REX.W 0F B3 /r, BTR r/m64| r64, 64b o64 op=r64_or_mem;r64_reg lock xacquire xrelease
Lfs_r16_m1616, legacy, , 0F, B4, o16 0F B4 /r, LFS r16| m16:16, 16b 32b 64b o16 op=r16_reg;mem
Lfs_r32_m1632, legacy, , 0F, B4, o32 0F B4 /r, LFS r32| m16:32, 16b 32b 64b o32 op=r32_reg;mem
Lfs_r64_m1664, legacy, , 0F, B4, REX.W 0F B4 /r, LFS r64| m16:64, 64b o64 op=r64_reg;mem
Lgs_r16_m1616, legacy, , 0F, B5, o16 0F B5 /r, LGS r16| m16:16, 16b 32b 64b o16 op=r16_reg;mem
Lgs_r32_m1632, legacy, , 0F, B5, o32 0F B5 /r, LGS r32| m16:32, 16b 32b 64b o32 op=r32_reg;mem
Lgs_r64_m1664, legacy, , 0F, B5, REX.W 0F B5 /r, LGS r64| m16:64, 64b o64 op=r64_reg;mem
Movzx_r16_rm8, legacy, , 0F, B6, o16 0F B6 /r, MOVZX r16| r/m8, 16b 32b 64b o16 op=r16_reg;r8_or_mem
Movzx_r32_rm8, legacy, , 0F, B6, o32 0F B6 /r, MOVZX r32| r/m8, 16b 32b 64b o32 op=r32_reg;r8_or_mem
Movzx_r64_rm8, legacy, , 0F, B6, REX.W 0F B6 /r, MOVZX r64| r/m8, 64b o64 op=r64_reg;r8_or_mem
Movzx_r16_rm16, legacy, , 0F, B7, o16 0F B7 /r, MOVZX r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Movzx_r32_rm16, legacy, , 0F, B7, o32 0F B7 /r, MOVZX r32| r/m16, 16b 32b 64b o32 op=r32_reg;r16_or_mem
Movzx_r64_rm16, legacy, , 0F, B7, REX.W 0F B7 /r, MOVZX r64| r/m16, 64b o64 op=r64_reg;r16_or_mem
Jmpe_disp16, legacy, , 0F, B8, o16 0F B8 cw, JMPE disp16, 16b 32b o16 op=brdisp_2
Jmpe_disp32, legacy, , 0F, B8, o32 0F B8 cd, JMPE disp32, 16b 32b o32 op=brdisp_4
Popcnt_r16_rm16, legacy, F3, 0F, B8, o16 F3 0F B8 /r, POPCNT r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Popcnt_r32_rm32, legacy, F3, 0F, B8, o32 F3 0F B8 /r, POPCNT r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Popcnt_r64_rm64, legacy, F3, 0F, B8, F3 REX.W 0F B8 /r, POPCNT r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Ud1_r16_rm16, legacy, , 0F, B9, o16 0F B9 /r, UD1 r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Ud1_r32_rm32, legacy, , 0F, B9, o32 0F B9 /r, UD1 r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Ud1_r64_rm64, legacy, , 0F, B9, REX.W 0F B9 /r, UD1 r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Bt_rm16_imm8, legacy, , 0F, BA, o16 0F BA /4 ib, BT r/m16| imm8, g=4 16b 32b 64b o16 op=r16_or_mem;imm8
Bt_rm32_imm8, legacy, , 0F, BA, o32 0F BA /4 ib, BT r/m32| imm8, g=4 16b 32b 64b o32 op=r32_or_mem;imm8
Bt_rm64_imm8, legacy, , 0F, BA, REX.W 0F BA /4 ib, BT r/m64| imm8, g=4 64b o64 op=r64_or_mem;imm8
Bts_rm16_imm8, legacy, , 0F, BA, o16 0F BA /5 ib, BTS r/m16| imm8, g=5 16b 32b 64b o16 op=r16_or_mem;imm8 lock xacquire xrelease
Bts_rm32_imm8, legacy, , 0F, BA, o32 0F BA /5 ib, BTS r/m32| imm8, g=5 16b 32b 64b o32 op=r32_or_mem;imm8 lock xacquire xrelease
Bts_rm64_imm8, legacy, , 0F, BA, REX.W 0F BA /5 ib, BTS r/m64| imm8, g=5 64b o64 op=r64_or_mem;imm8 lock xacquire xrelease
Btr_rm16_imm8, legacy, , 0F, BA, o16 0F BA /6 ib, BTR r/m16| imm8, g=6 16b 32b 64b o16 op=r16_or_mem;imm8 lock xacquire xrelease
Btr_rm32_imm8, legacy, , 0F, BA, o32 0F BA /6 ib, BTR r/m32| imm8, g=6 16b 32b 64b o32 op=r32_or_mem;imm8 lock xacquire xrelease
Btr_rm64_imm8, legacy, , 0F, BA, REX.W 0F BA /6 ib, BTR r/m64| imm8, g=6 64b o64 op=r64_or_mem;imm8 lock xacquire xrelease
Btc_rm16_imm8, legacy, , 0F, BA, o16 0F BA /7 ib, BTC r/m16| imm8, g=7 16b 32b 64b o16 op=r16_or_mem;imm8 lock xacquire xrelease
Btc_rm32_imm8, legacy, , 0F, BA, o32 0F BA /7 ib, BTC r/m32| imm8, g=7 16b 32b 64b o32 op=r32_or_mem;imm8 lock xacquire xrelease
Btc_rm64_imm8, legacy, , 0F, BA, REX.W 0F BA /7 ib, BTC r/m64| imm8, g=7 64b o64 op=r64_or_mem;imm8 lock xacquire xrelease
Btc_rm16_r16, legacy, , 0F, BB, o16 0F BB /r, BTC r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg lock xacquire xrelease
Btc_rm32_r32, legacy, , 0F, BB, o32 0F BB /r, BTC r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg lock xacquire xrelease
Btc_rm64_r64, legacy, , 0F, BB, REX.W 0F BB /r, BTC r/m64| r64, 64b o64 op=r64_or_mem;r64_reg lock xacquire xrelease
Bsf_r16_rm16, legacy, , 0F, BC, o16 0F BC /r, BSF r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Bsf_r32_rm32, legacy, , 0F, BC, o32 0F BC /r, BSF r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Bsf_r64_rm64, legacy, , 0F, BC, REX.W 0F BC /r, BSF r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Tzcnt_r16_rm16, legacy, F3, 0F, BC, o16 F3 0F BC /r, TZCNT r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Tzcnt_r32_rm32, legacy, F3, 0F, BC, o32 F3 0F BC /r, TZCNT r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Tzcnt_r64_rm64, legacy, F3, 0F, BC, F3 REX.W 0F BC /r, TZCNT r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Bsr_r16_rm16, legacy, , 0F, BD, o16 0F BD /r, BSR r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Bsr_r32_rm32, legacy, , 0F, BD, o32 0F BD /r, BSR r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Bsr_r64_rm64, legacy, , 0F, BD, REX.W 0F BD /r, BSR r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Lzcnt_r16_rm16, legacy, F3, 0F, BD, o16 F3 0F BD /r, LZCNT r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Lzcnt_r32_rm32, legacy, F3, 0F, BD, o32 F3 0F BD /r, LZCNT r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Lzcnt_r64_rm64, legacy, F3, 0F, BD, F3 REX.W 0F BD /r, LZCNT r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Movsx_r16_rm8, legacy, , 0F, BE, o16 0F BE /r, MOVSX r16| r/m8, 16b 32b 64b o16 op=r16_reg;r8_or_mem
Movsx_r32_rm8, legacy, , 0F, BE, o32 0F BE /r, MOVSX r32| r/m8, 16b 32b 64b o32 op=r32_reg;r8_or_mem
Movsx_r64_rm8, legacy, , 0F, BE, REX.W 0F BE /r, MOVSX r64| r/m8, 64b o64 op=r64_reg;r8_or_mem
Movsx_r16_rm16, legacy, , 0F, BF, o16 0F BF /r, MOVSX r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Movsx_r32_rm16, legacy, , 0F, BF, o32 0F BF /r, MOVSX r32| r/m16, 16b 32b 64b o32 op=r32_reg;r16_or_mem
Movsx_r64_rm16, legacy, , 0F, BF, REX.W 0F BF /r, MOVSX r64| r/m16, 64b o64 op=r64_reg;r16_or_mem
Xadd_rm8_r8, legacy, , 0F, C0, 0F C0 /r, XADD r/m8| r8, 16b 32b 64b op=r8_or_mem;r8_reg lock xacquire xrelease
Xadd_rm16_r16, legacy, , 0F, C1, o16 0F C1 /r, XADD r/m16| r16, 16b 32b 64b o16 op=r16_or_mem;r16_reg lock xacquire xrelease
Xadd_rm32_r32, legacy, , 0F, C1, o32 0F C1 /r, XADD r/m32| r32, 16b 32b 64b o32 op=r32_or_mem;r32_reg lock xacquire xrelease
Xadd_rm64_r64, legacy, , 0F, C1, REX.W 0F C1 /r, XADD r/m64| r64, 64b o64 op=r64_or_mem;r64_reg lock xacquire xrelease
Cmpps_xmm_xmmm128_imm8, legacy, NP, 0F, C2, NP 0F C2 /r ib, CMPPS xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vcmpps_xmm_xmm_xmmm128_imm8, VEX, NP, 0F, C2, VEX.128.0F.WIG C2 /r ib, VCMPPS xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
VEX_Vcmpps_ymm_ymm_ymmm256_imm8, VEX, NP, 0F, C2, VEX.256.0F.WIG C2 /r ib, VCMPPS ymm1| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8
EVEX_Vcmpps_k_k1_xmm_xmmm128b32_imm8, EVEX, NP, 0F, C2, EVEX.128.0F.W0 C2 /r ib, VCMPPS k1 {k2}| xmm2| xmm3/m128/m32bcst| imm8, 16b 32b 64b L128 W0 op=k_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k
EVEX_Vcmpps_k_k1_ymm_ymmm256b32_imm8, EVEX, NP, 0F, C2, EVEX.256.0F.W0 C2 /r ib, VCMPPS k1 {k2}| ymm2| ymm3/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=k_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k
EVEX_Vcmpps_k_k1_zmm_zmmm512b32_imm8_sae, EVEX, NP, 0F, C2, EVEX.512.0F.W0 C2 /r ib, VCMPPS k1 {k2}| zmm2| zmm3/m512/m32bcst{sae}| imm8, 16b 32b 64b L512 W0 op=k_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b sae k
Cmppd_xmm_xmmm128_imm8, legacy, 66, 0F, C2, 66 0F C2 /r ib, CMPPD xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vcmppd_xmm_xmm_xmmm128_imm8, VEX, 66, 0F, C2, VEX.128.66.0F.WIG C2 /r ib, VCMPPD xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
VEX_Vcmppd_ymm_ymm_ymmm256_imm8, VEX, 66, 0F, C2, VEX.256.66.0F.WIG C2 /r ib, VCMPPD ymm1| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8
EVEX_Vcmppd_k_k1_xmm_xmmm128b64_imm8, EVEX, 66, 0F, C2, EVEX.128.66.0F.W1 C2 /r ib, VCMPPD k1 {k2}| xmm2| xmm3/m128/m64bcst| imm8, 16b 32b 64b L128 W1 op=k_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k
EVEX_Vcmppd_k_k1_ymm_ymmm256b64_imm8, EVEX, 66, 0F, C2, EVEX.256.66.0F.W1 C2 /r ib, VCMPPD k1 {k2}| ymm2| ymm3/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=k_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k
EVEX_Vcmppd_k_k1_zmm_zmmm512b64_imm8_sae, EVEX, 66, 0F, C2, EVEX.512.66.0F.W1 C2 /r ib, VCMPPD k1 {k2}| zmm2| zmm3/m512/m64bcst{sae}| imm8, 16b 32b 64b L512 W1 op=k_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b sae k
Cmpss_xmm_xmmm32_imm8, legacy, F3, 0F, C2, F3 0F C2 /r ib, CMPSS xmm1| xmm2/m32| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vcmpss_xmm_xmm_xmmm32_imm8, VEX, F3, 0F, C2, VEX.LIG.F3.0F.WIG C2 /r ib, VCMPSS xmm1| xmm2| xmm3/m32| imm8, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
EVEX_Vcmpss_k_k1_xmm_xmmm32_imm8_sae, EVEX, F3, 0F, C2, EVEX.LIG.F3.0F.W0 C2 /r ib, VCMPSS k1 {k2}| xmm2| xmm3/m32{sae}| imm8, 16b 32b 64b LIG W0 op=k_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Tuple1_Scalar sae k
Cmpsd_xmm_xmmm64_imm8, legacy, F2, 0F, C2, F2 0F C2 /r ib, CMPSD xmm1| xmm2/m64| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vcmpsd_xmm_xmm_xmmm64_imm8, VEX, F2, 0F, C2, VEX.LIG.F2.0F.WIG C2 /r ib, VCMPSD xmm1| xmm2| xmm3/m64| imm8, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
EVEX_Vcmpsd_k_k1_xmm_xmmm64_imm8_sae, EVEX, F2, 0F, C2, EVEX.LIG.F2.0F.W1 C2 /r ib, VCMPSD k1 {k2}| xmm2| xmm3/m64{sae}| imm8, 16b 32b 64b LIG W1 op=k_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Tuple1_Scalar sae k
Movnti_m32_r32, legacy, NP, 0F, C3, NP 0F C3 /r, MOVNTI m32| r32, 16b 32b 64b op=mem;r32_reg
Movnti_m64_r64, legacy, NP, 0F, C3, NP REX.W 0F C3 /r, MOVNTI m64| r64, 64b o64 op=mem;r64_reg
Pinsrw_mm_r32m16_imm8, legacy, NP, 0F, C4, NP 0F C4 /r ib, PINSRW mm| r32/m16| imm8, 16b 32b 64b op=mm_reg;r32_or_mem;imm8
Pinsrw_mm_r64m16_imm8, legacy, NP, 0F, C4, NP REX.W 0F C4 /r ib, PINSRW mm| r64/m16| imm8, 64b o64 op=mm_reg;r64_or_mem;imm8
Pinsrw_xmm_r32m16_imm8, legacy, 66, 0F, C4, 66 0F C4 /r ib, PINSRW xmm| r32/m16| imm8, 16b 32b 64b op=xmm_reg;r32_or_mem;imm8
Pinsrw_xmm_r64m16_imm8, legacy, 66, 0F, C4, 66 REX.W 0F C4 /r ib, PINSRW xmm| r64/m16| imm8, 64b o64 op=xmm_reg;r64_or_mem;imm8
VEX_Vpinsrw_xmm_xmm_r32m16_imm8, VEX, 66, 0F, C4, VEX.128.66.0F.W0 C4 /r ib, VPINSRW xmm1| xmm2| r32/m16| imm8, 16b 32b 64b L128 WIG32 op=xmm_reg;xmm_vvvv;r32_or_mem;imm8
VEX_Vpinsrw_xmm_xmm_r64m16_imm8, VEX, 66, 0F, C4, VEX.128.66.0F.W1 C4 /r ib, VPINSRW xmm1| xmm2| r64/m16| imm8, 64b L128 W1 op=xmm_reg;xmm_vvvv;r64_or_mem;imm8
EVEX_Vpinsrw_xmm_xmm_r32m16_imm8, EVEX, 66, 0F, C4, EVEX.128.66.0F.W0 C4 /r ib, VPINSRW xmm1| xmm2| r32/m16| imm8, 16b 32b 64b L128 WIG32 op=xmm_reg;xmm_vvvv;r32_or_mem;imm8 tt=Tuple1_Scalar_2
EVEX_Vpinsrw_xmm_xmm_r64m16_imm8, EVEX, 66, 0F, C4, EVEX.128.66.0F.W1 C4 /r ib, VPINSRW xmm1| xmm2| r64/m16| imm8, 64b L128 W1 op=xmm_reg;xmm_vvvv;r64_or_mem;imm8 tt=Tuple1_Scalar_2
Pextrw_r32_mm_imm8, legacy, NP, 0F, C5, NP 0F C5 /r ib, PEXTRW r32| mm| imm8, 16b 32b 64b op=r32_reg;mm_rm;imm8
Pextrw_r64_mm_imm8, legacy, NP, 0F, C5, NP REX.W 0F C5 /r ib, PEXTRW r64| mm| imm8, 64b o64 op=r64_reg;mm_rm;imm8
Pextrw_r32_xmm_imm8, legacy, 66, 0F, C5, 66 0F C5 /r ib, PEXTRW r32| xmm| imm8, 16b 32b 64b op=r32_reg;xmm_rm;imm8
Pextrw_r64_xmm_imm8, legacy, 66, 0F, C5, 66 REX.W 0F C5 /r ib, PEXTRW r64| xmm| imm8, 64b o64 op=r64_reg;xmm_rm;imm8
VEX_Vpextrw_r32_xmm_imm8, VEX, 66, 0F, C5, VEX.128.66.0F.W0 C5 /r ib, VPEXTRW r32| xmm1| imm8, 16b 32b 64b L128 WIG32 op=r32_reg;xmm_rm;imm8
VEX_Vpextrw_r64_xmm_imm8, VEX, 66, 0F, C5, VEX.128.66.0F.W1 C5 /r ib, VPEXTRW r64| xmm1| imm8, 64b L128 W1 op=r64_reg;xmm_rm;imm8
EVEX_Vpextrw_r32_xmm_imm8, EVEX, 66, 0F, C5, EVEX.128.66.0F.W0 C5 /r ib, VPEXTRW r32| xmm1| imm8, 16b 32b 64b L128 WIG32 op=r32_reg;xmm_rm;imm8
EVEX_Vpextrw_r64_xmm_imm8, EVEX, 66, 0F, C5, EVEX.128.66.0F.W1 C5 /r ib, VPEXTRW r64| xmm1| imm8, 64b L128 W1 op=r64_reg;xmm_rm;imm8
Shufps_xmm_xmmm128_imm8, legacy, NP, 0F, C6, NP 0F C6 /r ib, SHUFPS xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vshufps_xmm_xmm_xmmm128_imm8, VEX, NP, 0F, C6, VEX.128.0F.WIG C6 /r ib, VSHUFPS xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
VEX_Vshufps_ymm_ymm_ymmm256_imm8, VEX, NP, 0F, C6, VEX.256.0F.WIG C6 /r ib, VSHUFPS ymm1| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8
EVEX_Vshufps_xmm_k1z_xmm_xmmm128b32_imm8, EVEX, NP, 0F, C6, EVEX.128.0F.W0 C6 /r ib, VSHUFPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vshufps_ymm_k1z_ymm_ymmm256b32_imm8, EVEX, NP, 0F, C6, EVEX.256.0F.W0 C6 /r ib, VSHUFPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vshufps_zmm_k1z_zmm_zmmm512b32_imm8, EVEX, NP, 0F, C6, EVEX.512.0F.W0 C6 /r ib, VSHUFPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
Shufpd_xmm_xmmm128_imm8, legacy, 66, 0F, C6, 66 0F C6 /r ib, SHUFPD xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vshufpd_xmm_xmm_xmmm128_imm8, VEX, 66, 0F, C6, VEX.128.66.0F.WIG C6 /r ib, VSHUFPD xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
VEX_Vshufpd_ymm_ymm_ymmm256_imm8, VEX, 66, 0F, C6, VEX.256.66.0F.WIG C6 /r ib, VSHUFPD ymm1| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8
EVEX_Vshufpd_xmm_k1z_xmm_xmmm128b64_imm8, EVEX, 66, 0F, C6, EVEX.128.66.0F.W1 C6 /r ib, VSHUFPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst| imm8, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vshufpd_ymm_k1z_ymm_ymmm256b64_imm8, EVEX, 66, 0F, C6, EVEX.256.66.0F.W1 C6 /r ib, VSHUFPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vshufpd_zmm_k1z_zmm_zmmm512b64_imm8, EVEX, 66, 0F, C6, EVEX.512.66.0F.W1 C6 /r ib, VSHUFPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
Cmpxchg8b_m64, legacy, , 0F, C7, 0F C7 /1, CMPXCHG8B m64, g=1 16b 32b 64b op=mem lock xacquire xrelease
Cmpxchg16b_m128, legacy, , 0F, C7, REX.W 0F C7 /1, CMPXCHG16B m128, g=1 64b o64 op=mem lock
Xrstors_mem, legacy, NP, 0F, C7, NP 0F C7 /3, XRSTORS mem, g=3 16b 32b 64b op=mem
Xrstors64_mem, legacy, NP, 0F, C7, NP REX.W 0F C7 /3, XRSTORS64 mem, g=3 64b o64 op=mem
Xsavec_mem, legacy, NP, 0F, C7, NP 0F C7 /4, XSAVEC mem, g=4 16b 32b 64b op=mem
Xsavec64_mem, legacy, NP, 0F, C7, NP REX.W 0F C7 /4, XSAVEC64 mem, g=4 64b o64 op=mem
Xsaves_mem, legacy, NP, 0F, C7, NP 0F C7 /5, XSAVES mem, g=5 16b 32b 64b op=mem
Xsaves64_mem, legacy, NP, 0F, C7, NP REX.W 0F C7 /5, XSAVES64 mem, g=5 64b o64 op=mem
Vmptrld_m64, legacy, NP, 0F, C7, NP 0F C7 /6, VMPTRLD m64, g=6 16b 32b 64b op=mem
Vmclear_m64, legacy, 66, 0F, C7, 66 0F C7 /6, VMCLEAR m64, g=6 16b 32b 64b op=mem
Vmxon_m64, legacy, F3, 0F, C7, F3 0F C7 /6, VMXON m64, g=6 16b 32b 64b op=mem
Rdrand_r16, legacy, , 0F, C7, o16 0F C7 /6, RDRAND r16, g=6 16b 32b 64b o16 op=r16_rm
Rdrand_r32, legacy, , 0F, C7, o32 0F C7 /6, RDRAND r32, g=6 16b 32b 64b o32 op=r32_rm
Rdrand_r64, legacy, , 0F, C7, REX.W 0F C7 /6, RDRAND r64, g=6 64b o64 op=r64_rm
Vmptrst_m64, legacy, NP, 0F, C7, NP 0F C7 /7, VMPTRST m64, g=7 16b 32b 64b op=mem
Rdseed_r16, legacy, , 0F, C7, o16 0F C7 /7, RDSEED r16, g=7 16b 32b 64b o16 op=r16_rm
Rdseed_r32, legacy, , 0F, C7, o32 0F C7 /7, RDSEED r32, g=7 16b 32b 64b o32 op=r32_rm
Rdseed_r64, legacy, , 0F, C7, REX.W 0F C7 /7, RDSEED r64, g=7 64b o64 op=r64_rm
Rdpid_r32, legacy, F3, 0F, C7, F3 0F C7 /7, RDPID r32, g=7 16b 32b op=r32_rm
Rdpid_r64, legacy, F3, 0F, C7, F3 0F C7 /7, RDPID r64, g=7 64b op=r64_rm
Bswap_r16, legacy, , 0F, C8, o16 0F C8+rw, BSWAP r16, 16b 32b 64b o16 op=r16_opcode
Bswap_r32, legacy, , 0F, C8, o32 0F C8+rd, BSWAP r32, 16b 32b 64b o32 op=r32_opcode
Bswap_r64, legacy, , 0F, C8, REX.W 0F C8+ro, BSWAP r64, 64b o64 op=r64_opcode
Addsubpd_xmm_xmmm128, legacy, 66, 0F, D0, 66 0F D0 /r, ADDSUBPD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vaddsubpd_xmm_xmm_xmmm128, VEX, 66, 0F, D0, VEX.128.66.0F.WIG D0 /r, VADDSUBPD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vaddsubpd_ymm_ymm_ymmm256, VEX, 66, 0F, D0, VEX.256.66.0F.WIG D0 /r, VADDSUBPD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
Addsubps_xmm_xmmm128, legacy, F2, 0F, D0, F2 0F D0 /r, ADDSUBPS xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vaddsubps_xmm_xmm_xmmm128, VEX, F2, 0F, D0, VEX.128.F2.0F.WIG D0 /r, VADDSUBPS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vaddsubps_ymm_ymm_ymmm256, VEX, F2, 0F, D0, VEX.256.F2.0F.WIG D0 /r, VADDSUBPS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
Psrlw_mm_mmm64, legacy, NP, 0F, D1, NP 0F D1 /r, PSRLW mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psrlw_xmm_xmmm128, legacy, 66, 0F, D1, 66 0F D1 /r, PSRLW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsrlw_xmm_xmm_xmmm128, VEX, 66, 0F, D1, VEX.128.66.0F.WIG D1 /r, VPSRLW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsrlw_ymm_ymm_xmmm128, VEX, 66, 0F, D1, VEX.256.66.0F.WIG D1 /r, VPSRLW ymm1| ymm2| xmm3/m128, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;xmm_or_mem
EVEX_Vpsrlw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, D1, EVEX.128.66.0F.WIG D1 /r, VPSRLW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpsrlw_ymm_k1z_ymm_xmmm128, EVEX, 66, 0F, D1, EVEX.256.66.0F.WIG D1 /r, VPSRLW ymm1 {k1}{z}| ymm2| xmm3/m128, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpsrlw_zmm_k1z_zmm_xmmm128, EVEX, 66, 0F, D1, EVEX.512.66.0F.WIG D1 /r, VPSRLW zmm1 {k1}{z}| zmm2| xmm3/m128, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;xmm_or_mem tt=Mem128 k z
Psrld_mm_mmm64, legacy, NP, 0F, D2, NP 0F D2 /r, PSRLD mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psrld_xmm_xmmm128, legacy, 66, 0F, D2, 66 0F D2 /r, PSRLD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsrld_xmm_xmm_xmmm128, VEX, 66, 0F, D2, VEX.128.66.0F.WIG D2 /r, VPSRLD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsrld_ymm_ymm_xmmm128, VEX, 66, 0F, D2, VEX.256.66.0F.WIG D2 /r, VPSRLD ymm1| ymm2| xmm3/m128, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;xmm_or_mem
EVEX_Vpsrld_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, D2, EVEX.128.66.0F.W0 D2 /r, VPSRLD xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpsrld_ymm_k1z_ymm_xmmm128, EVEX, 66, 0F, D2, EVEX.256.66.0F.W0 D2 /r, VPSRLD ymm1 {k1}{z}| ymm2| xmm3/m128, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpsrld_zmm_k1z_zmm_xmmm128, EVEX, 66, 0F, D2, EVEX.512.66.0F.W0 D2 /r, VPSRLD zmm1 {k1}{z}| zmm2| xmm3/m128, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;xmm_or_mem tt=Mem128 k z
Psrlq_mm_mmm64, legacy, NP, 0F, D3, NP 0F D3 /r, PSRLQ mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psrlq_xmm_xmmm128, legacy, 66, 0F, D3, 66 0F D3 /r, PSRLQ xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsrlq_xmm_xmm_xmmm128, VEX, 66, 0F, D3, VEX.128.66.0F.WIG D3 /r, VPSRLQ xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsrlq_ymm_ymm_xmmm128, VEX, 66, 0F, D3, VEX.256.66.0F.WIG D3 /r, VPSRLQ ymm1| ymm2| xmm3/m128, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;xmm_or_mem
EVEX_Vpsrlq_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, D3, EVEX.128.66.0F.W1 D3 /r, VPSRLQ xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpsrlq_ymm_k1z_ymm_xmmm128, EVEX, 66, 0F, D3, EVEX.256.66.0F.W1 D3 /r, VPSRLQ ymm1 {k1}{z}| ymm2| xmm3/m128, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpsrlq_zmm_k1z_zmm_xmmm128, EVEX, 66, 0F, D3, EVEX.512.66.0F.W1 D3 /r, VPSRLQ zmm1 {k1}{z}| zmm2| xmm3/m128, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;xmm_or_mem tt=Mem128 k z
Paddq_mm_mmm64, legacy, NP, 0F, D4, NP 0F D4 /r, PADDQ mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Paddq_xmm_xmmm128, legacy, 66, 0F, D4, 66 0F D4 /r, PADDQ xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpaddq_xmm_xmm_xmmm128, VEX, 66, 0F, D4, VEX.128.66.0F.WIG D4 /r, VPADDQ xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpaddq_ymm_ymm_ymmm256, VEX, 66, 0F, D4, VEX.256.66.0F.WIG D4 /r, VPADDQ ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpaddq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, D4, EVEX.128.66.0F.W1 D4 /r, VPADDQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpaddq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, D4, EVEX.256.66.0F.W1 D4 /r, VPADDQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpaddq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F, D4, EVEX.512.66.0F.W1 D4 /r, VPADDQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Pmullw_mm_mmm64, legacy, NP, 0F, D5, NP 0F D5 /r, PMULLW mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pmullw_xmm_xmmm128, legacy, 66, 0F, D5, 66 0F D5 /r, PMULLW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmullw_xmm_xmm_xmmm128, VEX, 66, 0F, D5, VEX.128.66.0F.WIG D5 /r, VPMULLW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpmullw_ymm_ymm_ymmm256, VEX, 66, 0F, D5, VEX.256.66.0F.WIG D5 /r, VPMULLW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpmullw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, D5, EVEX.128.66.0F.WIG D5 /r, VPMULLW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpmullw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, D5, EVEX.256.66.0F.WIG D5 /r, VPMULLW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpmullw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, D5, EVEX.512.66.0F.WIG D5 /r, VPMULLW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Movq_xmmm64_xmm, legacy, 66, 0F, D6, 66 0F D6 /r, MOVQ xmm2/m64| xmm1, 16b 32b 64b op=xmm_or_mem;xmm_reg
VEX_Vmovq_xmmm64_xmm, VEX, 66, 0F, D6, VEX.128.66.0F.WIG D6 /r, VMOVQ xmm1/m64| xmm2, 16b 32b 64b L128 WIG op=xmm_or_mem;xmm_reg
EVEX_Vmovq_xmmm64_xmm, EVEX, 66, 0F, D6, EVEX.128.66.0F.W1 D6 /r, VMOVQ xmm1/m64| xmm2, 16b 32b 64b L128 W1 op=xmm_or_mem;xmm_reg tt=Tuple1_Scalar
Movq2dq_xmm_mm, legacy, F3, 0F, D6, F3 0F D6 /r, MOVQ2DQ xmm| mm, 16b 32b 64b op=xmm_reg;mm_rm
Movdq2q_mm_xmm, legacy, F2, 0F, D6, F2 0F D6 /r, MOVDQ2Q mm| xmm, 16b 32b 64b op=mm_reg;xmm_rm
Pmovmskb_r32_mm, legacy, NP, 0F, D7, NP 0F D7 /r, PMOVMSKB r32| mm, 16b 32b 64b op=r32_reg;mm_rm
Pmovmskb_r64_mm, legacy, NP, 0F, D7, NP REX.W 0F D7 /r, PMOVMSKB r64| mm, 64b o64 op=r64_reg;mm_rm
Pmovmskb_r32_xmm, legacy, 66, 0F, D7, 66 0F D7 /r, PMOVMSKB r32| xmm, 16b 32b 64b op=r32_reg;xmm_rm
Pmovmskb_r64_xmm, legacy, 66, 0F, D7, 66 REX.W 0F D7 /r, PMOVMSKB r64| xmm, 64b o64 op=r64_reg;xmm_rm
VEX_Vpmovmskb_r32_xmm, VEX, 66, 0F, D7, VEX.128.66.0F.W0 D7 /r, VPMOVMSKB r32| xmm1, 16b 32b 64b L128 WIG32 op=r32_reg;xmm_rm
VEX_Vpmovmskb_r64_xmm, VEX, 66, 0F, D7, VEX.128.66.0F.W1 D7 /r, VPMOVMSKB r64| xmm1, 64b L128 W1 op=r64_reg;xmm_rm
VEX_Vpmovmskb_r32_ymm, VEX, 66, 0F, D7, VEX.256.66.0F.W0 D7 /r, VPMOVMSKB r32| ymm1, 16b 32b 64b L256 WIG32 op=r32_reg;ymm_rm
VEX_Vpmovmskb_r64_ymm, VEX, 66, 0F, D7, VEX.256.66.0F.W1 D7 /r, VPMOVMSKB r64| ymm1, 64b L256 W1 op=r64_reg;ymm_rm
Psubusb_mm_mmm64, legacy, NP, 0F, D8, NP 0F D8 /r, PSUBUSB mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psubusb_xmm_xmmm128, legacy, 66, 0F, D8, 66 0F D8 /r, PSUBUSB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsubusb_xmm_xmm_xmmm128, VEX, 66, 0F, D8, VEX.128.66.0F.WIG D8 /r, VPSUBUSB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsubusb_ymm_ymm_ymmm256, VEX, 66, 0F, D8, VEX.256.66.0F.WIG D8 /r, VPSUBUSB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpsubusb_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, D8, EVEX.128.66.0F.WIG D8 /r, VPSUBUSB xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpsubusb_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, D8, EVEX.256.66.0F.WIG D8 /r, VPSUBUSB ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpsubusb_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, D8, EVEX.512.66.0F.WIG D8 /r, VPSUBUSB zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Psubusw_mm_mmm64, legacy, NP, 0F, D9, NP 0F D9 /r, PSUBUSW mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psubusw_xmm_xmmm128, legacy, 66, 0F, D9, 66 0F D9 /r, PSUBUSW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsubusw_xmm_xmm_xmmm128, VEX, 66, 0F, D9, VEX.128.66.0F.WIG D9 /r, VPSUBUSW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsubusw_ymm_ymm_ymmm256, VEX, 66, 0F, D9, VEX.256.66.0F.WIG D9 /r, VPSUBUSW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpsubusw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, D9, EVEX.128.66.0F.WIG D9 /r, VPSUBUSW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpsubusw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, D9, EVEX.256.66.0F.WIG D9 /r, VPSUBUSW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpsubusw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, D9, EVEX.512.66.0F.WIG D9 /r, VPSUBUSW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Pminub_mm_mmm64, legacy, NP, 0F, DA, NP 0F DA /r, PMINUB mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pminub_xmm_xmmm128, legacy, 66, 0F, DA, 66 0F DA /r, PMINUB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpminub_xmm_xmm_xmmm128, VEX, 66, 0F, DA, VEX.128.66.0F.WIG DA /r, VPMINUB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpminub_ymm_ymm_ymmm256, VEX, 66, 0F, DA, VEX.256.66.0F.WIG DA /r, VPMINUB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpminub_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, DA, EVEX.128.66.0F.WIG DA /r, VPMINUB xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpminub_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, DA, EVEX.256.66.0F.WIG DA /r, VPMINUB ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpminub_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, DA, EVEX.512.66.0F.WIG DA /r, VPMINUB zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Pand_mm_mmm64, legacy, NP, 0F, DB, NP 0F DB /r, PAND mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pand_xmm_xmmm128, legacy, 66, 0F, DB, 66 0F DB /r, PAND xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpand_xmm_xmm_xmmm128, VEX, 66, 0F, DB, VEX.128.66.0F.WIG DB /r, VPAND xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpand_ymm_ymm_ymmm256, VEX, 66, 0F, DB, VEX.256.66.0F.WIG DB /r, VPAND ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpandd_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F, DB, EVEX.128.66.0F.W0 DB /r, VPANDD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpandd_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F, DB, EVEX.256.66.0F.W0 DB /r, VPANDD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpandd_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F, DB, EVEX.512.66.0F.W0 DB /r, VPANDD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpandq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, DB, EVEX.128.66.0F.W1 DB /r, VPANDQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpandq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, DB, EVEX.256.66.0F.W1 DB /r, VPANDQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpandq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F, DB, EVEX.512.66.0F.W1 DB /r, VPANDQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Paddusb_mm_mmm64, legacy, NP, 0F, DC, NP 0F DC /r, PADDUSB mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Paddusb_xmm_xmmm128, legacy, 66, 0F, DC, 66 0F DC /r, PADDUSB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpaddusb_xmm_xmm_xmmm128, VEX, 66, 0F, DC, VEX.128.66.0F.WIG DC /r, VPADDUSB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpaddusb_ymm_ymm_ymmm256, VEX, 66, 0F, DC, VEX.256.66.0F.WIG DC /r, VPADDUSB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpaddusb_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, DC, EVEX.128.66.0F.WIG DC /r, VPADDUSB xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpaddusb_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, DC, EVEX.256.66.0F.WIG DC /r, VPADDUSB ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpaddusb_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, DC, EVEX.512.66.0F.WIG DC /r, VPADDUSB zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Paddusw_mm_mmm64, legacy, NP, 0F, DD, NP 0F DD /r, PADDUSW mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Paddusw_xmm_xmmm128, legacy, 66, 0F, DD, 66 0F DD /r, PADDUSW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpaddusw_xmm_xmm_xmmm128, VEX, 66, 0F, DD, VEX.128.66.0F.WIG DD /r, VPADDUSW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpaddusw_ymm_ymm_ymmm256, VEX, 66, 0F, DD, VEX.256.66.0F.WIG DD /r, VPADDUSW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpaddusw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, DD, EVEX.128.66.0F.WIG DD /r, VPADDUSW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpaddusw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, DD, EVEX.256.66.0F.WIG DD /r, VPADDUSW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpaddusw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, DD, EVEX.512.66.0F.WIG DD /r, VPADDUSW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Pmaxub_mm_mmm64, legacy, NP, 0F, DE, NP 0F DE /r, PMAXUB mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pmaxub_xmm_xmmm128, legacy, 66, 0F, DE, 66 0F DE /r, PMAXUB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmaxub_xmm_xmm_xmmm128, VEX, 66, 0F, DE, VEX.128.66.0F.WIG DE /r, VPMAXUB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpmaxub_ymm_ymm_ymmm256, VEX, 66, 0F, DE, VEX.256.66.0F.WIG DE /r, VPMAXUB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpmaxub_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, DE, EVEX.128.66.0F.WIG DE /r, VPMAXUB xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpmaxub_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, DE, EVEX.256.66.0F.WIG DE /r, VPMAXUB ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpmaxub_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, DE, EVEX.512.66.0F.WIG DE /r, VPMAXUB zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Pandn_mm_mmm64, legacy, NP, 0F, DF, NP 0F DF /r, PANDN mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pandn_xmm_xmmm128, legacy, 66, 0F, DF, 66 0F DF /r, PANDN xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpandn_xmm_xmm_xmmm128, VEX, 66, 0F, DF, VEX.128.66.0F.WIG DF /r, VPANDN xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpandn_ymm_ymm_ymmm256, VEX, 66, 0F, DF, VEX.256.66.0F.WIG DF /r, VPANDN ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpandnd_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F, DF, EVEX.128.66.0F.W0 DF /r, VPANDND xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpandnd_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F, DF, EVEX.256.66.0F.W0 DF /r, VPANDND ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpandnd_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F, DF, EVEX.512.66.0F.W0 DF /r, VPANDND zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpandnq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, DF, EVEX.128.66.0F.W1 DF /r, VPANDNQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpandnq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, DF, EVEX.256.66.0F.W1 DF /r, VPANDNQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpandnq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F, DF, EVEX.512.66.0F.W1 DF /r, VPANDNQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Pavgb_mm_mmm64, legacy, NP, 0F, E0, NP 0F E0 /r, PAVGB mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pavgb_xmm_xmmm128, legacy, 66, 0F, E0, 66 0F E0 /r, PAVGB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpavgb_xmm_xmm_xmmm128, VEX, 66, 0F, E0, VEX.128.66.0F.WIG E0 /r, VPAVGB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpavgb_ymm_ymm_ymmm256, VEX, 66, 0F, E0, VEX.256.66.0F.WIG E0 /r, VPAVGB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpavgb_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, E0, EVEX.128.66.0F.WIG E0 /r, VPAVGB xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpavgb_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, E0, EVEX.256.66.0F.WIG E0 /r, VPAVGB ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpavgb_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, E0, EVEX.512.66.0F.WIG E0 /r, VPAVGB zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Psraw_mm_mmm64, legacy, NP, 0F, E1, NP 0F E1 /r, PSRAW mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psraw_xmm_xmmm128, legacy, 66, 0F, E1, 66 0F E1 /r, PSRAW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsraw_xmm_xmm_xmmm128, VEX, 66, 0F, E1, VEX.128.66.0F.WIG E1 /r, VPSRAW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsraw_ymm_ymm_xmmm128, VEX, 66, 0F, E1, VEX.256.66.0F.WIG E1 /r, VPSRAW ymm1| ymm2| xmm3/m128, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;xmm_or_mem
EVEX_Vpsraw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, E1, EVEX.128.66.0F.WIG E1 /r, VPSRAW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpsraw_ymm_k1z_ymm_xmmm128, EVEX, 66, 0F, E1, EVEX.256.66.0F.WIG E1 /r, VPSRAW ymm1 {k1}{z}| ymm2| xmm3/m128, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpsraw_zmm_k1z_zmm_xmmm128, EVEX, 66, 0F, E1, EVEX.512.66.0F.WIG E1 /r, VPSRAW zmm1 {k1}{z}| zmm2| xmm3/m128, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;xmm_or_mem tt=Mem128 k z
Psrad_mm_mmm64, legacy, NP, 0F, E2, NP 0F E2 /r, PSRAD mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psrad_xmm_xmmm128, legacy, 66, 0F, E2, 66 0F E2 /r, PSRAD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsrad_xmm_xmm_xmmm128, VEX, 66, 0F, E2, VEX.128.66.0F.WIG E2 /r, VPSRAD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsrad_ymm_ymm_xmmm128, VEX, 66, 0F, E2, VEX.256.66.0F.WIG E2 /r, VPSRAD ymm1| ymm2| xmm3/m128, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;xmm_or_mem
EVEX_Vpsrad_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, E2, EVEX.128.66.0F.W0 E2 /r, VPSRAD xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpsrad_ymm_k1z_ymm_xmmm128, EVEX, 66, 0F, E2, EVEX.256.66.0F.W0 E2 /r, VPSRAD ymm1 {k1}{z}| ymm2| xmm3/m128, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpsrad_zmm_k1z_zmm_xmmm128, EVEX, 66, 0F, E2, EVEX.512.66.0F.W0 E2 /r, VPSRAD zmm1 {k1}{z}| zmm2| xmm3/m128, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpsraq_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, E2, EVEX.128.66.0F.W1 E2 /r, VPSRAQ xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpsraq_ymm_k1z_ymm_xmmm128, EVEX, 66, 0F, E2, EVEX.256.66.0F.W1 E2 /r, VPSRAQ ymm1 {k1}{z}| ymm2| xmm3/m128, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpsraq_zmm_k1z_zmm_xmmm128, EVEX, 66, 0F, E2, EVEX.512.66.0F.W1 E2 /r, VPSRAQ zmm1 {k1}{z}| zmm2| xmm3/m128, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;xmm_or_mem tt=Mem128 k z
Pavgw_mm_mmm64, legacy, NP, 0F, E3, NP 0F E3 /r, PAVGW mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pavgw_xmm_xmmm128, legacy, 66, 0F, E3, 66 0F E3 /r, PAVGW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpavgw_xmm_xmm_xmmm128, VEX, 66, 0F, E3, VEX.128.66.0F.WIG E3 /r, VPAVGW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpavgw_ymm_ymm_ymmm256, VEX, 66, 0F, E3, VEX.256.66.0F.WIG E3 /r, VPAVGW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpavgw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, E3, EVEX.128.66.0F.WIG E3 /r, VPAVGW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpavgw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, E3, EVEX.256.66.0F.WIG E3 /r, VPAVGW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpavgw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, E3, EVEX.512.66.0F.WIG E3 /r, VPAVGW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Pmulhuw_mm_mmm64, legacy, NP, 0F, E4, NP 0F E4 /r, PMULHUW mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pmulhuw_xmm_xmmm128, legacy, 66, 0F, E4, 66 0F E4 /r, PMULHUW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmulhuw_xmm_xmm_xmmm128, VEX, 66, 0F, E4, VEX.128.66.0F.WIG E4 /r, VPMULHUW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpmulhuw_ymm_ymm_ymmm256, VEX, 66, 0F, E4, VEX.256.66.0F.WIG E4 /r, VPMULHUW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpmulhuw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, E4, EVEX.128.66.0F.WIG E4 /r, VPMULHUW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpmulhuw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, E4, EVEX.256.66.0F.WIG E4 /r, VPMULHUW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpmulhuw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, E4, EVEX.512.66.0F.WIG E4 /r, VPMULHUW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Pmulhw_mm_mmm64, legacy, NP, 0F, E5, NP 0F E5 /r, PMULHW mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pmulhw_xmm_xmmm128, legacy, 66, 0F, E5, 66 0F E5 /r, PMULHW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmulhw_xmm_xmm_xmmm128, VEX, 66, 0F, E5, VEX.128.66.0F.WIG E5 /r, VPMULHW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpmulhw_ymm_ymm_ymmm256, VEX, 66, 0F, E5, VEX.256.66.0F.WIG E5 /r, VPMULHW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpmulhw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, E5, EVEX.128.66.0F.WIG E5 /r, VPMULHW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpmulhw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, E5, EVEX.256.66.0F.WIG E5 /r, VPMULHW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpmulhw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, E5, EVEX.512.66.0F.WIG E5 /r, VPMULHW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Cvttpd2dq_xmm_xmmm128, legacy, 66, 0F, E6, 66 0F E6 /r, CVTTPD2DQ xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vcvttpd2dq_xmm_xmmm128, VEX, 66, 0F, E6, VEX.128.66.0F.WIG E6 /r, VCVTTPD2DQ xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vcvttpd2dq_xmm_ymmm256, VEX, 66, 0F, E6, VEX.256.66.0F.WIG E6 /r, VCVTTPD2DQ xmm1| ymm2/m256, 16b 32b 64b L256 WIG op=xmm_reg;ymm_or_mem
EVEX_Vcvttpd2dq_xmm_k1z_xmmm128b64, EVEX, 66, 0F, E6, EVEX.128.66.0F.W1 E6 /r, VCVTTPD2DQ xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvttpd2dq_xmm_k1z_ymmm256b64, EVEX, 66, 0F, E6, EVEX.256.66.0F.W1 E6 /r, VCVTTPD2DQ xmm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=xmm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvttpd2dq_ymm_k1z_zmmm512b64_sae, EVEX, 66, 0F, E6, EVEX.512.66.0F.W1 E6 /r, VCVTTPD2DQ ymm1 {k1}{z}| zmm2/m512/m64bcst{sae}, 16b 32b 64b L512 W1 op=ymm_reg;zmm_or_mem tt=Full_512 b sae k z
Cvtdq2pd_xmm_xmmm64, legacy, F3, 0F, E6, F3 0F E6 /r, CVTDQ2PD xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vcvtdq2pd_xmm_xmmm64, VEX, F3, 0F, E6, VEX.128.F3.0F.WIG E6 /r, VCVTDQ2PD xmm1| xmm2/m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vcvtdq2pd_ymm_xmmm128, VEX, F3, 0F, E6, VEX.256.F3.0F.WIG E6 /r, VCVTDQ2PD ymm1| xmm2/m128, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem
EVEX_Vcvtdq2pd_xmm_k1z_xmmm64b32, EVEX, F3, 0F, E6, EVEX.128.F3.0F.W0 E6 /r, VCVTDQ2PD xmm1 {k1}{z}| xmm2/m64/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Half_128 b k z
EVEX_Vcvtdq2pd_ymm_k1z_xmmm128b32, EVEX, F3, 0F, E6, EVEX.256.F3.0F.W0 E6 /r, VCVTDQ2PD ymm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem tt=Half_256 b k z
EVEX_Vcvtdq2pd_zmm_k1z_ymmm256b32, EVEX, F3, 0F, E6, EVEX.512.F3.0F.W0 E6 /r, VCVTDQ2PD zmm1 {k1}{z}| ymm2/m256/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;ymm_or_mem tt=Half_512 b k z
EVEX_Vcvtqq2pd_xmm_k1z_xmmm128b64, EVEX, F3, 0F, E6, EVEX.128.F3.0F.W1 E6 /r, VCVTQQ2PD xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvtqq2pd_ymm_k1z_ymmm256b64, EVEX, F3, 0F, E6, EVEX.256.F3.0F.W1 E6 /r, VCVTQQ2PD ymm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvtqq2pd_zmm_k1z_zmmm512b64_er, EVEX, F3, 0F, E6, EVEX.512.F3.0F.W1 E6 /r, VCVTQQ2PD zmm1 {k1}{z}| zmm2/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_512 b er k z
Cvtpd2dq_xmm_xmmm128, legacy, F2, 0F, E6, F2 0F E6 /r, CVTPD2DQ xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vcvtpd2dq_xmm_xmmm128, VEX, F2, 0F, E6, VEX.128.F2.0F.WIG E6 /r, VCVTPD2DQ xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vcvtpd2dq_xmm_ymmm256, VEX, F2, 0F, E6, VEX.256.F2.0F.WIG E6 /r, VCVTPD2DQ xmm1| ymm2/m256, 16b 32b 64b L256 WIG op=xmm_reg;ymm_or_mem
EVEX_Vcvtpd2dq_xmm_k1z_xmmm128b64, EVEX, F2, 0F, E6, EVEX.128.F2.0F.W1 E6 /r, VCVTPD2DQ xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvtpd2dq_xmm_k1z_ymmm256b64, EVEX, F2, 0F, E6, EVEX.256.F2.0F.W1 E6 /r, VCVTPD2DQ xmm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=xmm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvtpd2dq_ymm_k1z_zmmm512b64_er, EVEX, F2, 0F, E6, EVEX.512.F2.0F.W1 E6 /r, VCVTPD2DQ ymm1 {k1}{z}| zmm2/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=ymm_reg;zmm_or_mem tt=Full_512 b er k z
Movntq_m64_mm, legacy, NP, 0F, E7, NP 0F E7 /r, MOVNTQ m64| mm, 16b 32b 64b op=mem;mm_reg
Movntdq_m128_xmm, legacy, 66, 0F, E7, 66 0F E7 /r, MOVNTDQ m128| xmm1, 16b 32b 64b op=mem;xmm_reg
VEX_Vmovntdq_m128_xmm, VEX, 66, 0F, E7, VEX.128.66.0F.WIG E7 /r, VMOVNTDQ m128| xmm1, 16b 32b 64b L128 WIG op=mem;xmm_reg
VEX_Vmovntdq_m256_ymm, VEX, 66, 0F, E7, VEX.256.66.0F.WIG E7 /r, VMOVNTDQ m256| ymm1, 16b 32b 64b L256 WIG op=mem;ymm_reg
EVEX_Vmovntdq_m128_xmm, EVEX, 66, 0F, E7, EVEX.128.66.0F.W0 E7 /r, VMOVNTDQ m128| xmm1, 16b 32b 64b L128 W0 op=mem;xmm_reg tt=Full_Mem_128
EVEX_Vmovntdq_m256_ymm, EVEX, 66, 0F, E7, EVEX.256.66.0F.W0 E7 /r, VMOVNTDQ m256| ymm1, 16b 32b 64b L256 W0 op=mem;ymm_reg tt=Full_Mem_256
EVEX_Vmovntdq_m512_zmm, EVEX, 66, 0F, E7, EVEX.512.66.0F.W0 E7 /r, VMOVNTDQ m512| zmm1, 16b 32b 64b L512 W0 op=mem;zmm_reg tt=Full_Mem_512
Psubsb_mm_mmm64, legacy, NP, 0F, E8, NP 0F E8 /r, PSUBSB mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psubsb_xmm_xmmm128, legacy, 66, 0F, E8, 66 0F E8 /r, PSUBSB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsubsb_xmm_xmm_xmmm128, VEX, 66, 0F, E8, VEX.128.66.0F.WIG E8 /r, VPSUBSB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsubsb_ymm_ymm_ymmm256, VEX, 66, 0F, E8, VEX.256.66.0F.WIG E8 /r, VPSUBSB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpsubsb_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, E8, EVEX.128.66.0F.WIG E8 /r, VPSUBSB xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpsubsb_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, E8, EVEX.256.66.0F.WIG E8 /r, VPSUBSB ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpsubsb_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, E8, EVEX.512.66.0F.WIG E8 /r, VPSUBSB zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Psubsw_mm_mmm64, legacy, NP, 0F, E9, NP 0F E9 /r, PSUBSW mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psubsw_xmm_xmmm128, legacy, 66, 0F, E9, 66 0F E9 /r, PSUBSW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsubsw_xmm_xmm_xmmm128, VEX, 66, 0F, E9, VEX.128.66.0F.WIG E9 /r, VPSUBSW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsubsw_ymm_ymm_ymmm256, VEX, 66, 0F, E9, VEX.256.66.0F.WIG E9 /r, VPSUBSW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpsubsw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, E9, EVEX.128.66.0F.WIG E9 /r, VPSUBSW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpsubsw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, E9, EVEX.256.66.0F.WIG E9 /r, VPSUBSW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpsubsw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, E9, EVEX.512.66.0F.WIG E9 /r, VPSUBSW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Pminsw_mm_mmm64, legacy, NP, 0F, EA, NP 0F EA /r, PMINSW mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pminsw_xmm_xmmm128, legacy, 66, 0F, EA, 66 0F EA /r, PMINSW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpminsw_xmm_xmm_xmmm128, VEX, 66, 0F, EA, VEX.128.66.0F.WIG EA /r, VPMINSW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpminsw_ymm_ymm_ymmm256, VEX, 66, 0F, EA, VEX.256.66.0F.WIG EA /r, VPMINSW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpminsw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, EA, EVEX.128.66.0F.WIG EA /r, VPMINSW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpminsw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, EA, EVEX.256.66.0F.WIG EA /r, VPMINSW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpminsw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, EA, EVEX.512.66.0F.WIG EA /r, VPMINSW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Por_mm_mmm64, legacy, NP, 0F, EB, NP 0F EB /r, POR mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Por_xmm_xmmm128, legacy, 66, 0F, EB, 66 0F EB /r, POR xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpor_xmm_xmm_xmmm128, VEX, 66, 0F, EB, VEX.128.66.0F.WIG EB /r, VPOR xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpor_ymm_ymm_ymmm256, VEX, 66, 0F, EB, VEX.256.66.0F.WIG EB /r, VPOR ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpord_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F, EB, EVEX.128.66.0F.W0 EB /r, VPORD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpord_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F, EB, EVEX.256.66.0F.W0 EB /r, VPORD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpord_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F, EB, EVEX.512.66.0F.W0 EB /r, VPORD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vporq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, EB, EVEX.128.66.0F.W1 EB /r, VPORQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vporq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, EB, EVEX.256.66.0F.W1 EB /r, VPORQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vporq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F, EB, EVEX.512.66.0F.W1 EB /r, VPORQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Paddsb_mm_mmm64, legacy, NP, 0F, EC, NP 0F EC /r, PADDSB mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Paddsb_xmm_xmmm128, legacy, 66, 0F, EC, 66 0F EC /r, PADDSB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpaddsb_xmm_xmm_xmmm128, VEX, 66, 0F, EC, VEX.128.66.0F.WIG EC /r, VPADDSB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpaddsb_ymm_ymm_ymmm256, VEX, 66, 0F, EC, VEX.256.66.0F.WIG EC /r, VPADDSB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpaddsb_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, EC, EVEX.128.66.0F.WIG EC /r, VPADDSB xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpaddsb_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, EC, EVEX.256.66.0F.WIG EC /r, VPADDSB ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpaddsb_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, EC, EVEX.512.66.0F.WIG EC /r, VPADDSB zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Paddsw_mm_mmm64, legacy, NP, 0F, ED, NP 0F ED /r, PADDSW mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Paddsw_xmm_xmmm128, legacy, 66, 0F, ED, 66 0F ED /r, PADDSW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpaddsw_xmm_xmm_xmmm128, VEX, 66, 0F, ED, VEX.128.66.0F.WIG ED /r, VPADDSW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpaddsw_ymm_ymm_ymmm256, VEX, 66, 0F, ED, VEX.256.66.0F.WIG ED /r, VPADDSW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpaddsw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, ED, EVEX.128.66.0F.WIG ED /r, VPADDSW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpaddsw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, ED, EVEX.256.66.0F.WIG ED /r, VPADDSW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpaddsw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, ED, EVEX.512.66.0F.WIG ED /r, VPADDSW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Pmaxsw_mm_mmm64, legacy, NP, 0F, EE, NP 0F EE /r, PMAXSW mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pmaxsw_xmm_xmmm128, legacy, 66, 0F, EE, 66 0F EE /r, PMAXSW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmaxsw_xmm_xmm_xmmm128, VEX, 66, 0F, EE, VEX.128.66.0F.WIG EE /r, VPMAXSW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpmaxsw_ymm_ymm_ymmm256, VEX, 66, 0F, EE, VEX.256.66.0F.WIG EE /r, VPMAXSW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpmaxsw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, EE, EVEX.128.66.0F.WIG EE /r, VPMAXSW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpmaxsw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, EE, EVEX.256.66.0F.WIG EE /r, VPMAXSW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpmaxsw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, EE, EVEX.512.66.0F.WIG EE /r, VPMAXSW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Pxor_mm_mmm64, legacy, NP, 0F, EF, NP 0F EF /r, PXOR mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pxor_xmm_xmmm128, legacy, 66, 0F, EF, 66 0F EF /r, PXOR xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpxor_xmm_xmm_xmmm128, VEX, 66, 0F, EF, VEX.128.66.0F.WIG EF /r, VPXOR xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpxor_ymm_ymm_ymmm256, VEX, 66, 0F, EF, VEX.256.66.0F.WIG EF /r, VPXOR ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpxord_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F, EF, EVEX.128.66.0F.W0 EF /r, VPXORD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpxord_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F, EF, EVEX.256.66.0F.W0 EF /r, VPXORD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpxord_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F, EF, EVEX.512.66.0F.W0 EF /r, VPXORD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpxorq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, EF, EVEX.128.66.0F.W1 EF /r, VPXORQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpxorq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, EF, EVEX.256.66.0F.W1 EF /r, VPXORQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpxorq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F, EF, EVEX.512.66.0F.W1 EF /r, VPXORQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Lddqu_xmm_m128, legacy, F2, 0F, F0, F2 0F F0 /r, LDDQU xmm1| m128, 16b 32b 64b op=xmm_reg;mem
VEX_Vlddqu_xmm_m128, VEX, F2, 0F, F0, VEX.128.F2.0F.WIG F0 /r, VLDDQU xmm1| m128, 16b 32b 64b L128 WIG op=xmm_reg;mem
VEX_Vlddqu_ymm_m256, VEX, F2, 0F, F0, VEX.256.F2.0F.WIG F0 /r, VLDDQU ymm1| m256, 16b 32b 64b L256 WIG op=ymm_reg;mem
Psllw_mm_mmm64, legacy, NP, 0F, F1, NP 0F F1 /r, PSLLW mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psllw_xmm_xmmm128, legacy, 66, 0F, F1, 66 0F F1 /r, PSLLW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsllw_xmm_xmm_xmmm128, VEX, 66, 0F, F1, VEX.128.66.0F.WIG F1 /r, VPSLLW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsllw_ymm_ymm_xmmm128, VEX, 66, 0F, F1, VEX.256.66.0F.WIG F1 /r, VPSLLW ymm1| ymm2| xmm3/m128, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;xmm_or_mem
EVEX_Vpsllw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, F1, EVEX.128.66.0F.WIG F1 /r, VPSLLW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpsllw_ymm_k1z_ymm_xmmm128, EVEX, 66, 0F, F1, EVEX.256.66.0F.WIG F1 /r, VPSLLW ymm1 {k1}{z}| ymm2| xmm3/m128, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpsllw_zmm_k1z_zmm_xmmm128, EVEX, 66, 0F, F1, EVEX.512.66.0F.WIG F1 /r, VPSLLW zmm1 {k1}{z}| zmm2| xmm3/m128, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;xmm_or_mem tt=Mem128 k z
Pslld_mm_mmm64, legacy, NP, 0F, F2, NP 0F F2 /r, PSLLD mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pslld_xmm_xmmm128, legacy, 66, 0F, F2, 66 0F F2 /r, PSLLD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpslld_xmm_xmm_xmmm128, VEX, 66, 0F, F2, VEX.128.66.0F.WIG F2 /r, VPSLLD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpslld_ymm_ymm_xmmm128, VEX, 66, 0F, F2, VEX.256.66.0F.WIG F2 /r, VPSLLD ymm1| ymm2| xmm3/m128, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;xmm_or_mem
EVEX_Vpslld_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, F2, EVEX.128.66.0F.W0 F2 /r, VPSLLD xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpslld_ymm_k1z_ymm_xmmm128, EVEX, 66, 0F, F2, EVEX.256.66.0F.W0 F2 /r, VPSLLD ymm1 {k1}{z}| ymm2| xmm3/m128, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpslld_zmm_k1z_zmm_xmmm128, EVEX, 66, 0F, F2, EVEX.512.66.0F.W0 F2 /r, VPSLLD zmm1 {k1}{z}| zmm2| xmm3/m128, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;xmm_or_mem tt=Mem128 k z
Psllq_mm_mmm64, legacy, NP, 0F, F3, NP 0F F3 /r, PSLLQ mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psllq_xmm_xmmm128, legacy, 66, 0F, F3, 66 0F F3 /r, PSLLQ xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsllq_xmm_xmm_xmmm128, VEX, 66, 0F, F3, VEX.128.66.0F.WIG F3 /r, VPSLLQ xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsllq_ymm_ymm_xmmm128, VEX, 66, 0F, F3, VEX.256.66.0F.WIG F3 /r, VPSLLQ ymm1| ymm2| xmm3/m128, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;xmm_or_mem
EVEX_Vpsllq_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, F3, EVEX.128.66.0F.W1 F3 /r, VPSLLQ xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpsllq_ymm_k1z_ymm_xmmm128, EVEX, 66, 0F, F3, EVEX.256.66.0F.W1 F3 /r, VPSLLQ ymm1 {k1}{z}| ymm2| xmm3/m128, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;xmm_or_mem tt=Mem128 k z
EVEX_Vpsllq_zmm_k1z_zmm_xmmm128, EVEX, 66, 0F, F3, EVEX.512.66.0F.W1 F3 /r, VPSLLQ zmm1 {k1}{z}| zmm2| xmm3/m128, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;xmm_or_mem tt=Mem128 k z
Pmuludq_mm_mmm64, legacy, NP, 0F, F4, NP 0F F4 /r, PMULUDQ mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pmuludq_xmm_xmmm128, legacy, 66, 0F, F4, 66 0F F4 /r, PMULUDQ xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmuludq_xmm_xmm_xmmm128, VEX, 66, 0F, F4, VEX.128.66.0F.WIG F4 /r, VPMULUDQ xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpmuludq_ymm_ymm_ymmm256, VEX, 66, 0F, F4, VEX.256.66.0F.WIG F4 /r, VPMULUDQ ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpmuludq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, F4, EVEX.128.66.0F.W1 F4 /r, VPMULUDQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpmuludq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, F4, EVEX.256.66.0F.W1 F4 /r, VPMULUDQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpmuludq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F, F4, EVEX.512.66.0F.W1 F4 /r, VPMULUDQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Pmaddwd_mm_mmm64, legacy, NP, 0F, F5, NP 0F F5 /r, PMADDWD mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pmaddwd_xmm_xmmm128, legacy, 66, 0F, F5, 66 0F F5 /r, PMADDWD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmaddwd_xmm_xmm_xmmm128, VEX, 66, 0F, F5, VEX.128.66.0F.WIG F5 /r, VPMADDWD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpmaddwd_ymm_ymm_ymmm256, VEX, 66, 0F, F5, VEX.256.66.0F.WIG F5 /r, VPMADDWD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpmaddwd_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, F5, EVEX.128.66.0F.WIG F5 /r, VPMADDWD xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpmaddwd_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, F5, EVEX.256.66.0F.WIG F5 /r, VPMADDWD ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpmaddwd_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, F5, EVEX.512.66.0F.WIG F5 /r, VPMADDWD zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Psadbw_mm_mmm64, legacy, NP, 0F, F6, NP 0F F6 /r, PSADBW mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psadbw_xmm_xmmm128, legacy, 66, 0F, F6, 66 0F F6 /r, PSADBW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsadbw_xmm_xmm_xmmm128, VEX, 66, 0F, F6, VEX.128.66.0F.WIG F6 /r, VPSADBW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsadbw_ymm_ymm_ymmm256, VEX, 66, 0F, F6, VEX.256.66.0F.WIG F6 /r, VPSADBW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpsadbw_xmm_xmm_xmmm128, EVEX, 66, 0F, F6, EVEX.128.66.0F.WIG F6 /r, VPSADBW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128
EVEX_Vpsadbw_ymm_ymm_ymmm256, EVEX, 66, 0F, F6, EVEX.256.66.0F.WIG F6 /r, VPSADBW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256
EVEX_Vpsadbw_zmm_zmm_zmmm512, EVEX, 66, 0F, F6, EVEX.512.66.0F.WIG F6 /r, VPSADBW zmm1| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512
Maskmovq_rDI_mm_mm, legacy, NP, 0F, F7, NP 0F F7 /r, MASKMOVQ mm1| mm2, 16b 32b 64b op=seg_rDI;mm_reg;mm_rm
Maskmovdqu_rDI_xmm_xmm, legacy, 66, 0F, F7, 66 0F F7 /r, MASKMOVDQU xmm1| xmm2, 16b 32b 64b op=seg_rDI;xmm_reg;xmm_rm
VEX_Vmaskmovdqu_rDI_xmm_xmm, VEX, 66, 0F, F7, VEX.128.66.0F.WIG F7 /r, VMASKMOVDQU xmm1| xmm2, 16b 32b 64b L128 WIG op=seg_rDI;xmm_reg;xmm_rm
Psubb_mm_mmm64, legacy, NP, 0F, F8, NP 0F F8 /r, PSUBB mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psubb_xmm_xmmm128, legacy, 66, 0F, F8, 66 0F F8 /r, PSUBB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsubb_xmm_xmm_xmmm128, VEX, 66, 0F, F8, VEX.128.66.0F.WIG F8 /r, VPSUBB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsubb_ymm_ymm_ymmm256, VEX, 66, 0F, F8, VEX.256.66.0F.WIG F8 /r, VPSUBB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpsubb_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, F8, EVEX.128.66.0F.WIG F8 /r, VPSUBB xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpsubb_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, F8, EVEX.256.66.0F.WIG F8 /r, VPSUBB ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpsubb_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, F8, EVEX.512.66.0F.WIG F8 /r, VPSUBB zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Psubw_mm_mmm64, legacy, NP, 0F, F9, NP 0F F9 /r, PSUBW mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psubw_xmm_xmmm128, legacy, 66, 0F, F9, 66 0F F9 /r, PSUBW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsubw_xmm_xmm_xmmm128, VEX, 66, 0F, F9, VEX.128.66.0F.WIG F9 /r, VPSUBW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsubw_ymm_ymm_ymmm256, VEX, 66, 0F, F9, VEX.256.66.0F.WIG F9 /r, VPSUBW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpsubw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, F9, EVEX.128.66.0F.WIG F9 /r, VPSUBW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpsubw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, F9, EVEX.256.66.0F.WIG F9 /r, VPSUBW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpsubw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, F9, EVEX.512.66.0F.WIG F9 /r, VPSUBW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Psubd_mm_mmm64, legacy, NP, 0F, FA, NP 0F FA /r, PSUBD mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psubd_xmm_xmmm128, legacy, 66, 0F, FA, 66 0F FA /r, PSUBD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsubd_xmm_xmm_xmmm128, VEX, 66, 0F, FA, VEX.128.66.0F.WIG FA /r, VPSUBD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsubd_ymm_ymm_ymmm256, VEX, 66, 0F, FA, VEX.256.66.0F.WIG FA /r, VPSUBD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpsubd_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F, FA, EVEX.128.66.0F.W0 FA /r, VPSUBD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpsubd_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F, FA, EVEX.256.66.0F.W0 FA /r, VPSUBD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpsubd_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F, FA, EVEX.512.66.0F.W0 FA /r, VPSUBD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Psubq_mm_mmm64, legacy, NP, 0F, FB, NP 0F FB /r, PSUBQ mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psubq_xmm_xmmm128, legacy, 66, 0F, FB, 66 0F FB /r, PSUBQ xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsubq_xmm_xmm_xmmm128, VEX, 66, 0F, FB, VEX.128.66.0F.WIG FB /r, VPSUBQ xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsubq_ymm_ymm_ymmm256, VEX, 66, 0F, FB, VEX.256.66.0F.WIG FB /r, VPSUBQ ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpsubq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F, FB, EVEX.128.66.0F.W1 FB /r, VPSUBQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpsubq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F, FB, EVEX.256.66.0F.W1 FB /r, VPSUBQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpsubq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F, FB, EVEX.512.66.0F.W1 FB /r, VPSUBQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Paddb_mm_mmm64, legacy, NP, 0F, FC, NP 0F FC /r, PADDB mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Paddb_xmm_xmmm128, legacy, 66, 0F, FC, 66 0F FC /r, PADDB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpaddb_xmm_xmm_xmmm128, VEX, 66, 0F, FC, VEX.128.66.0F.WIG FC /r, VPADDB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpaddb_ymm_ymm_ymmm256, VEX, 66, 0F, FC, VEX.256.66.0F.WIG FC /r, VPADDB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpaddb_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, FC, EVEX.128.66.0F.WIG FC /r, VPADDB xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpaddb_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, FC, EVEX.256.66.0F.WIG FC /r, VPADDB ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpaddb_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, FC, EVEX.512.66.0F.WIG FC /r, VPADDB zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Paddw_mm_mmm64, legacy, NP, 0F, FD, NP 0F FD /r, PADDW mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Paddw_xmm_xmmm128, legacy, 66, 0F, FD, 66 0F FD /r, PADDW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpaddw_xmm_xmm_xmmm128, VEX, 66, 0F, FD, VEX.128.66.0F.WIG FD /r, VPADDW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpaddw_ymm_ymm_ymmm256, VEX, 66, 0F, FD, VEX.256.66.0F.WIG FD /r, VPADDW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpaddw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F, FD, EVEX.128.66.0F.WIG FD /r, VPADDW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpaddw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F, FD, EVEX.256.66.0F.WIG FD /r, VPADDW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpaddw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F, FD, EVEX.512.66.0F.WIG FD /r, VPADDW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Paddd_mm_mmm64, legacy, NP, 0F, FE, NP 0F FE /r, PADDD mm| mm/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Paddd_xmm_xmmm128, legacy, 66, 0F, FE, 66 0F FE /r, PADDD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpaddd_xmm_xmm_xmmm128, VEX, 66, 0F, FE, VEX.128.66.0F.WIG FE /r, VPADDD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpaddd_ymm_ymm_ymmm256, VEX, 66, 0F, FE, VEX.256.66.0F.WIG FE /r, VPADDD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpaddd_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F, FE, EVEX.128.66.0F.W0 FE /r, VPADDD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpaddd_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F, FE, EVEX.256.66.0F.W0 FE /r, VPADDD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpaddd_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F, FE, EVEX.512.66.0F.W0 FE /r, VPADDD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Ud0_r16_rm16, legacy, , 0F, FF, o16 0F FF /r, UD0 r16| r/m16, 16b 32b 64b o16 op=r16_reg;r16_or_mem
Ud0_r32_rm32, legacy, , 0F, FF, o32 0F FF /r, UD0 r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Ud0_r64_rm64, legacy, , 0F, FF, REX.W 0F FF /r, UD0 r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Pshufb_mm_mmm64, legacy, NP, 0F38, 00, NP 0F 38 00 /r, PSHUFB mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pshufb_xmm_xmmm128, legacy, 66, 0F38, 00, 66 0F 38 00 /r, PSHUFB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpshufb_xmm_xmm_xmmm128, VEX, 66, 0F38, 00, VEX.128.66.0F38.WIG 00 /r, VPSHUFB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpshufb_ymm_ymm_ymmm256, VEX, 66, 0F38, 00, VEX.256.66.0F38.WIG 00 /r, VPSHUFB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpshufb_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 00, EVEX.128.66.0F38.WIG 00 /r, VPSHUFB xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpshufb_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 00, EVEX.256.66.0F38.WIG 00 /r, VPSHUFB ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpshufb_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 00, EVEX.512.66.0F38.WIG 00 /r, VPSHUFB zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Phaddw_mm_mmm64, legacy, NP, 0F38, 01, NP 0F 38 01 /r, PHADDW mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Phaddw_xmm_xmmm128, legacy, 66, 0F38, 01, 66 0F 38 01 /r, PHADDW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vphaddw_xmm_xmm_xmmm128, VEX, 66, 0F38, 01, VEX.128.66.0F38.WIG 01 /r, VPHADDW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vphaddw_ymm_ymm_ymmm256, VEX, 66, 0F38, 01, VEX.256.66.0F38.WIG 01 /r, VPHADDW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
Phaddd_mm_mmm64, legacy, NP, 0F38, 02, NP 0F 38 02 /r, PHADDD mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Phaddd_xmm_xmmm128, legacy, 66, 0F38, 02, 66 0F 38 02 /r, PHADDD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vphaddd_xmm_xmm_xmmm128, VEX, 66, 0F38, 02, VEX.128.66.0F38.WIG 02 /r, VPHADDD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vphaddd_ymm_ymm_ymmm256, VEX, 66, 0F38, 02, VEX.256.66.0F38.WIG 02 /r, VPHADDD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
Phaddsw_mm_mmm64, legacy, NP, 0F38, 03, NP 0F 38 03 /r, PHADDSW mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Phaddsw_xmm_xmmm128, legacy, 66, 0F38, 03, 66 0F 38 03 /r, PHADDSW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vphaddsw_xmm_xmm_xmmm128, VEX, 66, 0F38, 03, VEX.128.66.0F38.WIG 03 /r, VPHADDSW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vphaddsw_ymm_ymm_ymmm256, VEX, 66, 0F38, 03, VEX.256.66.0F38.WIG 03 /r, VPHADDSW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
Pmaddubsw_mm_mmm64, legacy, NP, 0F38, 04, NP 0F 38 04 /r, PMADDUBSW mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pmaddubsw_xmm_xmmm128, legacy, 66, 0F38, 04, 66 0F 38 04 /r, PMADDUBSW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmaddubsw_xmm_xmm_xmmm128, VEX, 66, 0F38, 04, VEX.128.66.0F38.WIG 04 /r, VPMADDUBSW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpmaddubsw_ymm_ymm_ymmm256, VEX, 66, 0F38, 04, VEX.256.66.0F38.WIG 04 /r, VPMADDUBSW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpmaddubsw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 04, EVEX.128.66.0F38.WIG 04 /r, VPMADDUBSW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpmaddubsw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 04, EVEX.256.66.0F38.WIG 04 /r, VPMADDUBSW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpmaddubsw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 04, EVEX.512.66.0F38.WIG 04 /r, VPMADDUBSW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Phsubw_mm_mmm64, legacy, NP, 0F38, 05, NP 0F 38 05 /r, PHSUBW mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Phsubw_xmm_xmmm128, legacy, 66, 0F38, 05, 66 0F 38 05 /r, PHSUBW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vphsubw_xmm_xmm_xmmm128, VEX, 66, 0F38, 05, VEX.128.66.0F38.WIG 05 /r, VPHSUBW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vphsubw_ymm_ymm_ymmm256, VEX, 66, 0F38, 05, VEX.256.66.0F38.WIG 05 /r, VPHSUBW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
Phsubd_mm_mmm64, legacy, NP, 0F38, 06, NP 0F 38 06 /r, PHSUBD mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Phsubd_xmm_xmmm128, legacy, 66, 0F38, 06, 66 0F 38 06 /r, PHSUBD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vphsubd_xmm_xmm_xmmm128, VEX, 66, 0F38, 06, VEX.128.66.0F38.WIG 06 /r, VPHSUBD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vphsubd_ymm_ymm_ymmm256, VEX, 66, 0F38, 06, VEX.256.66.0F38.WIG 06 /r, VPHSUBD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
Phsubsw_mm_mmm64, legacy, NP, 0F38, 07, NP 0F 38 07 /r, PHSUBSW mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Phsubsw_xmm_xmmm128, legacy, 66, 0F38, 07, 66 0F 38 07 /r, PHSUBSW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vphsubsw_xmm_xmm_xmmm128, VEX, 66, 0F38, 07, VEX.128.66.0F38.WIG 07 /r, VPHSUBSW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vphsubsw_ymm_ymm_ymmm256, VEX, 66, 0F38, 07, VEX.256.66.0F38.WIG 07 /r, VPHSUBSW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
Psignb_mm_mmm64, legacy, NP, 0F38, 08, NP 0F 38 08 /r, PSIGNB mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psignb_xmm_xmmm128, legacy, 66, 0F38, 08, 66 0F 38 08 /r, PSIGNB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsignb_xmm_xmm_xmmm128, VEX, 66, 0F38, 08, VEX.128.66.0F38.WIG 08 /r, VPSIGNB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsignb_ymm_ymm_ymmm256, VEX, 66, 0F38, 08, VEX.256.66.0F38.WIG 08 /r, VPSIGNB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
Psignw_mm_mmm64, legacy, NP, 0F38, 09, NP 0F 38 09 /r, PSIGNW mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psignw_xmm_xmmm128, legacy, 66, 0F38, 09, 66 0F 38 09 /r, PSIGNW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsignw_xmm_xmm_xmmm128, VEX, 66, 0F38, 09, VEX.128.66.0F38.WIG 09 /r, VPSIGNW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsignw_ymm_ymm_ymmm256, VEX, 66, 0F38, 09, VEX.256.66.0F38.WIG 09 /r, VPSIGNW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
Psignd_mm_mmm64, legacy, NP, 0F38, 0A, NP 0F 38 0A /r, PSIGND mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Psignd_xmm_xmmm128, legacy, 66, 0F38, 0A, 66 0F 38 0A /r, PSIGND xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpsignd_xmm_xmm_xmmm128, VEX, 66, 0F38, 0A, VEX.128.66.0F38.WIG 0A /r, VPSIGND xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsignd_ymm_ymm_ymmm256, VEX, 66, 0F38, 0A, VEX.256.66.0F38.WIG 0A /r, VPSIGND ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
Pmulhrsw_mm_mmm64, legacy, NP, 0F38, 0B, NP 0F 38 0B /r, PMULHRSW mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pmulhrsw_xmm_xmmm128, legacy, 66, 0F38, 0B, 66 0F 38 0B /r, PMULHRSW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmulhrsw_xmm_xmm_xmmm128, VEX, 66, 0F38, 0B, VEX.128.66.0F38.WIG 0B /r, VPMULHRSW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpmulhrsw_ymm_ymm_ymmm256, VEX, 66, 0F38, 0B, VEX.256.66.0F38.WIG 0B /r, VPMULHRSW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpmulhrsw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 0B, EVEX.128.66.0F38.WIG 0B /r, VPMULHRSW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpmulhrsw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 0B, EVEX.256.66.0F38.WIG 0B /r, VPMULHRSW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpmulhrsw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 0B, EVEX.512.66.0F38.WIG 0B /r, VPMULHRSW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
VEX_Vpermilps_xmm_xmm_xmmm128, VEX, 66, 0F38, 0C, VEX.128.66.0F38.W0 0C /r, VPERMILPS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpermilps_ymm_ymm_ymmm256, VEX, 66, 0F38, 0C, VEX.256.66.0F38.W0 0C /r, VPERMILPS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpermilps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 0C, EVEX.128.66.0F38.W0 0C /r, VPERMILPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpermilps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 0C, EVEX.256.66.0F38.W0 0C /r, VPERMILPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpermilps_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 0C, EVEX.512.66.0F38.W0 0C /r, VPERMILPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
VEX_Vpermilpd_xmm_xmm_xmmm128, VEX, 66, 0F38, 0D, VEX.128.66.0F38.W0 0D /r, VPERMILPD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpermilpd_ymm_ymm_ymmm256, VEX, 66, 0F38, 0D, VEX.256.66.0F38.W0 0D /r, VPERMILPD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpermilpd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 0D, EVEX.128.66.0F38.W1 0D /r, VPERMILPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpermilpd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 0D, EVEX.256.66.0F38.W1 0D /r, VPERMILPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpermilpd_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 0D, EVEX.512.66.0F38.W1 0D /r, VPERMILPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
VEX_Vtestps_xmm_xmmm128, VEX, 66, 0F38, 0E, VEX.128.66.0F38.W0 0E /r, VTESTPS xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
VEX_Vtestps_ymm_ymmm256, VEX, 66, 0F38, 0E, VEX.256.66.0F38.W0 0E /r, VTESTPS ymm1| ymm2/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem
VEX_Vtestpd_xmm_xmmm128, VEX, 66, 0F38, 0F, VEX.128.66.0F38.W0 0F /r, VTESTPD xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
VEX_Vtestpd_ymm_ymmm256, VEX, 66, 0F38, 0F, VEX.256.66.0F38.W0 0F /r, VTESTPD ymm1| ymm2/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem
Pblendvb_xmm_xmmm128, legacy, 66, 0F38, 10, 66 0F 38 10 /r, PBLENDVB xmm1| xmm2/m128| <XMM0>, 16b 32b 64b op=xmm_reg;xmm_or_mem
EVEX_Vpsrlvw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 10, EVEX.128.66.0F38.W1 10 /r, VPSRLVW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpsrlvw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 10, EVEX.256.66.0F38.W1 10 /r, VPSRLVW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpsrlvw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 10, EVEX.512.66.0F38.W1 10 /r, VPSRLVW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vpmovuswb_xmmm64_k1z_xmm, EVEX, F3, 0F38, 10, EVEX.128.F3.0F38.W0 10 /r, VPMOVUSWB xmm1/m64 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Half_Mem_128 k z
EVEX_Vpmovuswb_xmmm128_k1z_ymm, EVEX, F3, 0F38, 10, EVEX.256.F3.0F38.W0 10 /r, VPMOVUSWB xmm1/m128 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Half_Mem_256 k z
EVEX_Vpmovuswb_ymmm256_k1z_zmm, EVEX, F3, 0F38, 10, EVEX.512.F3.0F38.W0 10 /r, VPMOVUSWB ymm1/m256 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=ymm_or_mem;zmm_reg tt=Half_Mem_512 k z
EVEX_Vpsravw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 11, EVEX.128.66.0F38.W1 11 /r, VPSRAVW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpsravw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 11, EVEX.256.66.0F38.W1 11 /r, VPSRAVW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpsravw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 11, EVEX.512.66.0F38.W1 11 /r, VPSRAVW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vpmovusdb_xmmm32_k1z_xmm, EVEX, F3, 0F38, 11, EVEX.128.F3.0F38.W0 11 /r, VPMOVUSDB xmm1/m32 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Quarter_Mem_128 k z
EVEX_Vpmovusdb_xmmm64_k1z_ymm, EVEX, F3, 0F38, 11, EVEX.256.F3.0F38.W0 11 /r, VPMOVUSDB xmm1/m64 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Quarter_Mem_256 k z
EVEX_Vpmovusdb_xmmm128_k1z_zmm, EVEX, F3, 0F38, 11, EVEX.512.F3.0F38.W0 11 /r, VPMOVUSDB xmm1/m128 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=xmm_or_mem;zmm_reg tt=Quarter_Mem_512 k z
EVEX_Vpsllvw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 12, EVEX.128.66.0F38.W1 12 /r, VPSLLVW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpsllvw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 12, EVEX.256.66.0F38.W1 12 /r, VPSLLVW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpsllvw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 12, EVEX.512.66.0F38.W1 12 /r, VPSLLVW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vpmovusqb_xmmm16_k1z_xmm, EVEX, F3, 0F38, 12, EVEX.128.F3.0F38.W0 12 /r, VPMOVUSQB xmm1/m16 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Eighth_Mem_128 k z
EVEX_Vpmovusqb_xmmm32_k1z_ymm, EVEX, F3, 0F38, 12, EVEX.256.F3.0F38.W0 12 /r, VPMOVUSQB xmm1/m32 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Eighth_Mem_256 k z
EVEX_Vpmovusqb_xmmm64_k1z_zmm, EVEX, F3, 0F38, 12, EVEX.512.F3.0F38.W0 12 /r, VPMOVUSQB xmm1/m64 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=xmm_or_mem;zmm_reg tt=Eighth_Mem_512 k z
VEX_Vcvtph2ps_xmm_xmmm64, VEX, 66, 0F38, 13, VEX.128.66.0F38.W0 13 /r, VCVTPH2PS xmm1| xmm2/m64, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
VEX_Vcvtph2ps_ymm_xmmm128, VEX, 66, 0F38, 13, VEX.256.66.0F38.W0 13 /r, VCVTPH2PS ymm1| xmm2/m128, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem
EVEX_Vcvtph2ps_xmm_k1z_xmmm64, EVEX, 66, 0F38, 13, EVEX.128.66.0F38.W0 13 /r, VCVTPH2PS xmm1 {k1}{z}| xmm2/m64, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Half_Mem_128 k z
EVEX_Vcvtph2ps_ymm_k1z_xmmm128, EVEX, 66, 0F38, 13, EVEX.256.66.0F38.W0 13 /r, VCVTPH2PS ymm1 {k1}{z}| xmm2/m128, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem tt=Half_Mem_256 k z
EVEX_Vcvtph2ps_zmm_k1z_ymmm256_sae, EVEX, 66, 0F38, 13, EVEX.512.66.0F38.W0 13 /r, VCVTPH2PS zmm1 {k1}{z}| ymm2/m256{sae}, 16b 32b 64b L512 W0 op=zmm_reg;ymm_or_mem tt=Half_Mem_512 sae k z
EVEX_Vpmovusdw_xmmm64_k1z_xmm, EVEX, F3, 0F38, 13, EVEX.128.F3.0F38.W0 13 /r, VPMOVUSDW xmm1/m64 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Half_Mem_128 k z
EVEX_Vpmovusdw_xmmm128_k1z_ymm, EVEX, F3, 0F38, 13, EVEX.256.F3.0F38.W0 13 /r, VPMOVUSDW xmm1/m128 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Half_Mem_256 k z
EVEX_Vpmovusdw_ymmm256_k1z_zmm, EVEX, F3, 0F38, 13, EVEX.512.F3.0F38.W0 13 /r, VPMOVUSDW ymm1/m256 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=ymm_or_mem;zmm_reg tt=Half_Mem_512 k z
Blendvps_xmm_xmmm128, legacy, 66, 0F38, 14, 66 0F 38 14 /r, BLENDVPS xmm1| xmm2/m128| <XMM0>, 16b 32b 64b op=xmm_reg;xmm_or_mem
EVEX_Vprorvd_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 14, EVEX.128.66.0F38.W0 14 /r, VPRORVD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vprorvd_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 14, EVEX.256.66.0F38.W0 14 /r, VPRORVD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vprorvd_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 14, EVEX.512.66.0F38.W0 14 /r, VPRORVD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vprorvq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 14, EVEX.128.66.0F38.W1 14 /r, VPRORVQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vprorvq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 14, EVEX.256.66.0F38.W1 14 /r, VPRORVQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vprorvq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 14, EVEX.512.66.0F38.W1 14 /r, VPRORVQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpmovusqw_xmmm32_k1z_xmm, EVEX, F3, 0F38, 14, EVEX.128.F3.0F38.W0 14 /r, VPMOVUSQW xmm1/m32 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Quarter_Mem_128 k z
EVEX_Vpmovusqw_xmmm64_k1z_ymm, EVEX, F3, 0F38, 14, EVEX.256.F3.0F38.W0 14 /r, VPMOVUSQW xmm1/m64 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Quarter_Mem_256 k z
EVEX_Vpmovusqw_xmmm128_k1z_zmm, EVEX, F3, 0F38, 14, EVEX.512.F3.0F38.W0 14 /r, VPMOVUSQW xmm1/m128 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=xmm_or_mem;zmm_reg tt=Quarter_Mem_512 k z
Blendvpd_xmm_xmmm128, legacy, 66, 0F38, 15, 66 0F 38 15 /r, BLENDVPD xmm1| xmm2/m128| <XMM0>, 16b 32b 64b op=xmm_reg;xmm_or_mem
EVEX_Vprolvd_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 15, EVEX.128.66.0F38.W0 15 /r, VPROLVD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vprolvd_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 15, EVEX.256.66.0F38.W0 15 /r, VPROLVD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vprolvd_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 15, EVEX.512.66.0F38.W0 15 /r, VPROLVD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vprolvq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 15, EVEX.128.66.0F38.W1 15 /r, VPROLVQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vprolvq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 15, EVEX.256.66.0F38.W1 15 /r, VPROLVQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vprolvq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 15, EVEX.512.66.0F38.W1 15 /r, VPROLVQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpmovusqd_xmmm64_k1z_xmm, EVEX, F3, 0F38, 15, EVEX.128.F3.0F38.W0 15 /r, VPMOVUSQD xmm1/m64 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Half_Mem_128 k z
EVEX_Vpmovusqd_xmmm128_k1z_ymm, EVEX, F3, 0F38, 15, EVEX.256.F3.0F38.W0 15 /r, VPMOVUSQD xmm1/m128 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Half_Mem_256 k z
EVEX_Vpmovusqd_ymmm256_k1z_zmm, EVEX, F3, 0F38, 15, EVEX.512.F3.0F38.W0 15 /r, VPMOVUSQD ymm1/m256 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=ymm_or_mem;zmm_reg tt=Half_Mem_512 k z
VEX_Vpermps_ymm_ymm_ymmm256, VEX, 66, 0F38, 16, VEX.256.66.0F38.W0 16 /r, VPERMPS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpermps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 16, EVEX.256.66.0F38.W0 16 /r, VPERMPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpermps_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 16, EVEX.512.66.0F38.W0 16 /r, VPERMPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpermpd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 16, EVEX.256.66.0F38.W1 16 /r, VPERMPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpermpd_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 16, EVEX.512.66.0F38.W1 16 /r, VPERMPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Ptest_xmm_xmmm128, legacy, 66, 0F38, 17, 66 0F 38 17 /r, PTEST xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vptest_xmm_xmmm128, VEX, 66, 0F38, 17, VEX.128.66.0F38.WIG 17 /r, VPTEST xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vptest_ymm_ymmm256, VEX, 66, 0F38, 17, VEX.256.66.0F38.WIG 17 /r, VPTEST ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
VEX_Vbroadcastss_xmm_xmmm32, VEX, 66, 0F38, 18, VEX.128.66.0F38.W0 18 /r, VBROADCASTSS xmm1| xmm2/m32, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
VEX_Vbroadcastss_ymm_xmmm32, VEX, 66, 0F38, 18, VEX.256.66.0F38.W0 18 /r, VBROADCASTSS ymm1| xmm2/m32, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem
EVEX_Vbroadcastss_xmm_k1z_xmmm32, EVEX, 66, 0F38, 18, EVEX.128.66.0F38.W0 18 /r, VBROADCASTSS xmm1 {k1}{z}| xmm2/m32, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vbroadcastss_ymm_k1z_xmmm32, EVEX, 66, 0F38, 18, EVEX.256.66.0F38.W0 18 /r, VBROADCASTSS ymm1 {k1}{z}| xmm2/m32, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vbroadcastss_zmm_k1z_xmmm32, EVEX, 66, 0F38, 18, EVEX.512.66.0F38.W0 18 /r, VBROADCASTSS zmm1 {k1}{z}| xmm2/m32, 16b 32b 64b L512 W0 op=zmm_reg;xmm_or_mem tt=Tuple1_Scalar k z
VEX_Vbroadcastsd_ymm_xmmm64, VEX, 66, 0F38, 19, VEX.256.66.0F38.W0 19 /r, VBROADCASTSD ymm1| xmm2/m64, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem
EVEX_Vbroadcastf32x2_ymm_k1z_xmmm64, EVEX, 66, 0F38, 19, EVEX.256.66.0F38.W0 19 /r, VBROADCASTF32X2 ymm1 {k1}{z}| xmm2/m64, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem tt=Tuple2 k z
EVEX_Vbroadcastf32x2_zmm_k1z_xmmm64, EVEX, 66, 0F38, 19, EVEX.512.66.0F38.W0 19 /r, VBROADCASTF32X2 zmm1 {k1}{z}| xmm2/m64, 16b 32b 64b L512 W0 op=zmm_reg;xmm_or_mem tt=Tuple2 k z
EVEX_Vbroadcastsd_ymm_k1z_xmmm64, EVEX, 66, 0F38, 19, EVEX.256.66.0F38.W1 19 /r, VBROADCASTSD ymm1 {k1}{z}| xmm2/m64, 16b 32b 64b L256 W1 op=ymm_reg;xmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vbroadcastsd_zmm_k1z_xmmm64, EVEX, 66, 0F38, 19, EVEX.512.66.0F38.W1 19 /r, VBROADCASTSD zmm1 {k1}{z}| xmm2/m64, 16b 32b 64b L512 W1 op=zmm_reg;xmm_or_mem tt=Tuple1_Scalar k z
VEX_Vbroadcastf128_ymm_m128, VEX, 66, 0F38, 1A, VEX.256.66.0F38.W0 1A /r, VBROADCASTF128 ymm1| m128, 16b 32b 64b L256 W0 op=ymm_reg;mem
EVEX_Vbroadcastf32x4_ymm_k1z_m128, EVEX, 66, 0F38, 1A, EVEX.256.66.0F38.W0 1A /r, VBROADCASTF32X4 ymm1 {k1}{z}| m128, 16b 32b 64b L256 W0 op=ymm_reg;mem tt=Tuple4 k z
EVEX_Vbroadcastf32x4_zmm_k1z_m128, EVEX, 66, 0F38, 1A, EVEX.512.66.0F38.W0 1A /r, VBROADCASTF32X4 zmm1 {k1}{z}| m128, 16b 32b 64b L512 W0 op=zmm_reg;mem tt=Tuple4 k z
EVEX_Vbroadcastf64x2_ymm_k1z_m128, EVEX, 66, 0F38, 1A, EVEX.256.66.0F38.W1 1A /r, VBROADCASTF64X2 ymm1 {k1}{z}| m128, 16b 32b 64b L256 W1 op=ymm_reg;mem tt=Tuple2 k z
EVEX_Vbroadcastf64x2_zmm_k1z_m128, EVEX, 66, 0F38, 1A, EVEX.512.66.0F38.W1 1A /r, VBROADCASTF64X2 zmm1 {k1}{z}| m128, 16b 32b 64b L512 W1 op=zmm_reg;mem tt=Tuple2 k z
EVEX_Vbroadcastf32x8_zmm_k1z_m256, EVEX, 66, 0F38, 1B, EVEX.512.66.0F38.W0 1B /r, VBROADCASTF32X8 zmm1 {k1}{z}| m256, 16b 32b 64b L512 W0 op=zmm_reg;mem tt=Tuple8 k z
EVEX_Vbroadcastf64x4_zmm_k1z_m256, EVEX, 66, 0F38, 1B, EVEX.512.66.0F38.W1 1B /r, VBROADCASTF64X4 zmm1 {k1}{z}| m256, 16b 32b 64b L512 W1 op=zmm_reg;mem tt=Tuple4 k z
Pabsb_mm_mmm64, legacy, NP, 0F38, 1C, NP 0F 38 1C /r, PABSB mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pabsb_xmm_xmmm128, legacy, 66, 0F38, 1C, 66 0F 38 1C /r, PABSB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpabsb_xmm_xmmm128, VEX, 66, 0F38, 1C, VEX.128.66.0F38.WIG 1C /r, VPABSB xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vpabsb_ymm_ymmm256, VEX, 66, 0F38, 1C, VEX.256.66.0F38.WIG 1C /r, VPABSB ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
EVEX_Vpabsb_xmm_k1z_xmmm128, EVEX, 66, 0F38, 1C, EVEX.128.66.0F38.WIG 1C /r, VPABSB xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpabsb_ymm_k1z_ymmm256, EVEX, 66, 0F38, 1C, EVEX.256.66.0F38.WIG 1C /r, VPABSB ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpabsb_zmm_k1z_zmmm512, EVEX, 66, 0F38, 1C, EVEX.512.66.0F38.WIG 1C /r, VPABSB zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_or_mem tt=Full_Mem_512 k z
Pabsw_mm_mmm64, legacy, NP, 0F38, 1D, NP 0F 38 1D /r, PABSW mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pabsw_xmm_xmmm128, legacy, 66, 0F38, 1D, 66 0F 38 1D /r, PABSW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpabsw_xmm_xmmm128, VEX, 66, 0F38, 1D, VEX.128.66.0F38.WIG 1D /r, VPABSW xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vpabsw_ymm_ymmm256, VEX, 66, 0F38, 1D, VEX.256.66.0F38.WIG 1D /r, VPABSW ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
EVEX_Vpabsw_xmm_k1z_xmmm128, EVEX, 66, 0F38, 1D, EVEX.128.66.0F38.WIG 1D /r, VPABSW xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpabsw_ymm_k1z_ymmm256, EVEX, 66, 0F38, 1D, EVEX.256.66.0F38.WIG 1D /r, VPABSW ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpabsw_zmm_k1z_zmmm512, EVEX, 66, 0F38, 1D, EVEX.512.66.0F38.WIG 1D /r, VPABSW zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_or_mem tt=Full_Mem_512 k z
Pabsd_mm_mmm64, legacy, NP, 0F38, 1E, NP 0F 38 1E /r, PABSD mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Pabsd_xmm_xmmm128, legacy, 66, 0F38, 1E, 66 0F 38 1E /r, PABSD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpabsd_xmm_xmmm128, VEX, 66, 0F38, 1E, VEX.128.66.0F38.WIG 1E /r, VPABSD xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vpabsd_ymm_ymmm256, VEX, 66, 0F38, 1E, VEX.256.66.0F38.WIG 1E /r, VPABSD ymm1| ymm2/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem
EVEX_Vpabsd_xmm_k1z_xmmm128b32, EVEX, 66, 0F38, 1E, EVEX.128.66.0F38.W0 1E /r, VPABSD xmm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vpabsd_ymm_k1z_ymmm256b32, EVEX, 66, 0F38, 1E, EVEX.256.66.0F38.W0 1E /r, VPABSD ymm1 {k1}{z}| ymm2/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vpabsd_zmm_k1z_zmmm512b32, EVEX, 66, 0F38, 1E, EVEX.512.66.0F38.W0 1E /r, VPABSD zmm1 {k1}{z}| zmm2/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_512 b k z
EVEX_Vpabsq_xmm_k1z_xmmm128b64, EVEX, 66, 0F38, 1F, EVEX.128.66.0F38.W1 1F /r, VPABSQ xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vpabsq_ymm_k1z_ymmm256b64, EVEX, 66, 0F38, 1F, EVEX.256.66.0F38.W1 1F /r, VPABSQ ymm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vpabsq_zmm_k1z_zmmm512b64, EVEX, 66, 0F38, 1F, EVEX.512.66.0F38.W1 1F /r, VPABSQ zmm1 {k1}{z}| zmm2/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_512 b k z
Pmovsxbw_xmm_xmmm64, legacy, 66, 0F38, 20, 66 0F 38 20 /r, PMOVSXBW xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmovsxbw_xmm_xmmm64, VEX, 66, 0F38, 20, VEX.128.66.0F38.WIG 20 /r, VPMOVSXBW xmm1| xmm2/m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vpmovsxbw_ymm_xmmm128, VEX, 66, 0F38, 20, VEX.256.66.0F38.WIG 20 /r, VPMOVSXBW ymm1| xmm2/m128, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem
EVEX_Vpmovsxbw_xmm_k1z_xmmm64, EVEX, 66, 0F38, 20, EVEX.128.66.0F38.WIG 20 /r, VPMOVSXBW xmm1 {k1}{z}| xmm2/m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem tt=Half_Mem_128 k z
EVEX_Vpmovsxbw_ymm_k1z_xmmm128, EVEX, 66, 0F38, 20, EVEX.256.66.0F38.WIG 20 /r, VPMOVSXBW ymm1 {k1}{z}| xmm2/m128, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem tt=Half_Mem_256 k z
EVEX_Vpmovsxbw_zmm_k1z_ymmm256, EVEX, 66, 0F38, 20, EVEX.512.66.0F38.WIG 20 /r, VPMOVSXBW zmm1 {k1}{z}| ymm2/m256, 16b 32b 64b L512 WIG op=zmm_reg;ymm_or_mem tt=Half_Mem_512 k z
EVEX_Vpmovswb_xmmm64_k1z_xmm, EVEX, F3, 0F38, 20, EVEX.128.F3.0F38.W0 20 /r, VPMOVSWB xmm1/m64 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Half_Mem_128 k z
EVEX_Vpmovswb_xmmm128_k1z_ymm, EVEX, F3, 0F38, 20, EVEX.256.F3.0F38.W0 20 /r, VPMOVSWB xmm1/m128 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Half_Mem_256 k z
EVEX_Vpmovswb_ymmm256_k1z_zmm, EVEX, F3, 0F38, 20, EVEX.512.F3.0F38.W0 20 /r, VPMOVSWB ymm1/m256 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=ymm_or_mem;zmm_reg tt=Half_Mem_512 k z
Pmovsxbd_xmm_xmmm32, legacy, 66, 0F38, 21, 66 0F 38 21 /r, PMOVSXBD xmm1| xmm2/m32, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmovsxbd_xmm_xmmm32, VEX, 66, 0F38, 21, VEX.128.66.0F38.WIG 21 /r, VPMOVSXBD xmm1| xmm2/m32, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vpmovsxbd_ymm_xmmm64, VEX, 66, 0F38, 21, VEX.256.66.0F38.WIG 21 /r, VPMOVSXBD ymm1| xmm2/m64, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem
EVEX_Vpmovsxbd_xmm_k1z_xmmm32, EVEX, 66, 0F38, 21, EVEX.128.66.0F38.WIG 21 /r, VPMOVSXBD xmm1 {k1}{z}| xmm2/m32, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem tt=Quarter_Mem_128 k z
EVEX_Vpmovsxbd_ymm_k1z_xmmm64, EVEX, 66, 0F38, 21, EVEX.256.66.0F38.WIG 21 /r, VPMOVSXBD ymm1 {k1}{z}| xmm2/m64, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem tt=Quarter_Mem_256 k z
EVEX_Vpmovsxbd_zmm_k1z_xmmm128, EVEX, 66, 0F38, 21, EVEX.512.66.0F38.WIG 21 /r, VPMOVSXBD zmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L512 WIG op=zmm_reg;xmm_or_mem tt=Quarter_Mem_512 k z
EVEX_Vpmovsdb_xmmm32_k1z_xmm, EVEX, F3, 0F38, 21, EVEX.128.F3.0F38.W0 21 /r, VPMOVSDB xmm1/m32 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Quarter_Mem_128 k z
EVEX_Vpmovsdb_xmmm64_k1z_ymm, EVEX, F3, 0F38, 21, EVEX.256.F3.0F38.W0 21 /r, VPMOVSDB xmm1/m64 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Quarter_Mem_256 k z
EVEX_Vpmovsdb_xmmm128_k1z_zmm, EVEX, F3, 0F38, 21, EVEX.512.F3.0F38.W0 21 /r, VPMOVSDB xmm1/m128 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=xmm_or_mem;zmm_reg tt=Quarter_Mem_512 k z
Pmovsxbq_xmm_xmmm16, legacy, 66, 0F38, 22, 66 0F 38 22 /r, PMOVSXBQ xmm1| xmm2/m16, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmovsxbq_xmm_xmmm16, VEX, 66, 0F38, 22, VEX.128.66.0F38.WIG 22 /r, VPMOVSXBQ xmm1| xmm2/m16, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vpmovsxbq_ymm_xmmm32, VEX, 66, 0F38, 22, VEX.256.66.0F38.WIG 22 /r, VPMOVSXBQ ymm1| xmm2/m32, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem
EVEX_Vpmovsxbq_xmm_k1z_xmmm16, EVEX, 66, 0F38, 22, EVEX.128.66.0F38.WIG 22 /r, VPMOVSXBQ xmm1 {k1}{z}| xmm2/m16, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem tt=Eighth_Mem_128 k z
EVEX_Vpmovsxbq_ymm_k1z_xmmm32, EVEX, 66, 0F38, 22, EVEX.256.66.0F38.WIG 22 /r, VPMOVSXBQ ymm1 {k1}{z}| xmm2/m32, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem tt=Eighth_Mem_256 k z
EVEX_Vpmovsxbq_zmm_k1z_xmmm64, EVEX, 66, 0F38, 22, EVEX.512.66.0F38.WIG 22 /r, VPMOVSXBQ zmm1 {k1}{z}| xmm2/m64, 16b 32b 64b L512 WIG op=zmm_reg;xmm_or_mem tt=Eighth_Mem_512 k z
EVEX_Vpmovsqb_xmmm16_k1z_xmm, EVEX, F3, 0F38, 22, EVEX.128.F3.0F38.W0 22 /r, VPMOVSQB xmm1/m16 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Eighth_Mem_128 k z
EVEX_Vpmovsqb_xmmm32_k1z_ymm, EVEX, F3, 0F38, 22, EVEX.256.F3.0F38.W0 22 /r, VPMOVSQB xmm1/m32 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Eighth_Mem_256 k z
EVEX_Vpmovsqb_xmmm64_k1z_zmm, EVEX, F3, 0F38, 22, EVEX.512.F3.0F38.W0 22 /r, VPMOVSQB xmm1/m64 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=xmm_or_mem;zmm_reg tt=Eighth_Mem_512 k z
Pmovsxwd_xmm_xmmm64, legacy, 66, 0F38, 23, 66 0F 38 23 /r, PMOVSXWD xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmovsxwd_xmm_xmmm64, VEX, 66, 0F38, 23, VEX.128.66.0F38.WIG 23 /r, VPMOVSXWD xmm1| xmm2/m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vpmovsxwd_ymm_xmmm128, VEX, 66, 0F38, 23, VEX.256.66.0F38.WIG 23 /r, VPMOVSXWD ymm1| xmm2/m128, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem
EVEX_Vpmovsxwd_xmm_k1z_xmmm64, EVEX, 66, 0F38, 23, EVEX.128.66.0F38.WIG 23 /r, VPMOVSXWD xmm1 {k1}{z}| xmm2/m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem tt=Half_Mem_128 k z
EVEX_Vpmovsxwd_ymm_k1z_xmmm128, EVEX, 66, 0F38, 23, EVEX.256.66.0F38.WIG 23 /r, VPMOVSXWD ymm1 {k1}{z}| xmm2/m128, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem tt=Half_Mem_256 k z
EVEX_Vpmovsxwd_zmm_k1z_ymmm256, EVEX, 66, 0F38, 23, EVEX.512.66.0F38.WIG 23 /r, VPMOVSXWD zmm1 {k1}{z}| ymm2/m256, 16b 32b 64b L512 WIG op=zmm_reg;ymm_or_mem tt=Half_Mem_512 k z
EVEX_Vpmovsdw_xmmm64_k1z_xmm, EVEX, F3, 0F38, 23, EVEX.128.F3.0F38.W0 23 /r, VPMOVSDW xmm1/m64 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Half_Mem_128 k z
EVEX_Vpmovsdw_xmmm128_k1z_ymm, EVEX, F3, 0F38, 23, EVEX.256.F3.0F38.W0 23 /r, VPMOVSDW xmm1/m128 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Half_Mem_256 k z
EVEX_Vpmovsdw_ymmm256_k1z_zmm, EVEX, F3, 0F38, 23, EVEX.512.F3.0F38.W0 23 /r, VPMOVSDW ymm1/m256 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=ymm_or_mem;zmm_reg tt=Half_Mem_512 k z
Pmovsxwq_xmm_xmmm32, legacy, 66, 0F38, 24, 66 0F 38 24 /r, PMOVSXWQ xmm1| xmm2/m32, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmovsxwq_xmm_xmmm32, VEX, 66, 0F38, 24, VEX.128.66.0F38.WIG 24 /r, VPMOVSXWQ xmm1| xmm2/m32, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vpmovsxwq_ymm_xmmm64, VEX, 66, 0F38, 24, VEX.256.66.0F38.WIG 24 /r, VPMOVSXWQ ymm1| xmm2/m64, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem
EVEX_Vpmovsxwq_xmm_k1z_xmmm32, EVEX, 66, 0F38, 24, EVEX.128.66.0F38.WIG 24 /r, VPMOVSXWQ xmm1 {k1}{z}| xmm2/m32, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem tt=Quarter_Mem_128 k z
EVEX_Vpmovsxwq_ymm_k1z_xmmm64, EVEX, 66, 0F38, 24, EVEX.256.66.0F38.WIG 24 /r, VPMOVSXWQ ymm1 {k1}{z}| xmm2/m64, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem tt=Quarter_Mem_256 k z
EVEX_Vpmovsxwq_zmm_k1z_xmmm128, EVEX, 66, 0F38, 24, EVEX.512.66.0F38.WIG 24 /r, VPMOVSXWQ zmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L512 WIG op=zmm_reg;xmm_or_mem tt=Quarter_Mem_512 k z
EVEX_Vpmovsqw_xmmm32_k1z_xmm, EVEX, F3, 0F38, 24, EVEX.128.F3.0F38.W0 24 /r, VPMOVSQW xmm1/m32 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Quarter_Mem_128 k z
EVEX_Vpmovsqw_xmmm64_k1z_ymm, EVEX, F3, 0F38, 24, EVEX.256.F3.0F38.W0 24 /r, VPMOVSQW xmm1/m64 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Quarter_Mem_256 k z
EVEX_Vpmovsqw_xmmm128_k1z_zmm, EVEX, F3, 0F38, 24, EVEX.512.F3.0F38.W0 24 /r, VPMOVSQW xmm1/m128 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=xmm_or_mem;zmm_reg tt=Quarter_Mem_512 k z
Pmovsxdq_xmm_xmmm64, legacy, 66, 0F38, 25, 66 0F 38 25 /r, PMOVSXDQ xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmovsxdq_xmm_xmmm64, VEX, 66, 0F38, 25, VEX.128.66.0F38.WIG 25 /r, VPMOVSXDQ xmm1| xmm2/m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vpmovsxdq_ymm_xmmm128, VEX, 66, 0F38, 25, VEX.256.66.0F38.WIG 25 /r, VPMOVSXDQ ymm1| xmm2/m128, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem
EVEX_Vpmovsxdq_xmm_k1z_xmmm64, EVEX, 66, 0F38, 25, EVEX.128.66.0F38.W0 25 /r, VPMOVSXDQ xmm1 {k1}{z}| xmm2/m64, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Half_Mem_128 k z
EVEX_Vpmovsxdq_ymm_k1z_xmmm128, EVEX, 66, 0F38, 25, EVEX.256.66.0F38.W0 25 /r, VPMOVSXDQ ymm1 {k1}{z}| xmm2/m128, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem tt=Half_Mem_256 k z
EVEX_Vpmovsxdq_zmm_k1z_ymmm256, EVEX, 66, 0F38, 25, EVEX.512.66.0F38.W0 25 /r, VPMOVSXDQ zmm1 {k1}{z}| ymm2/m256, 16b 32b 64b L512 W0 op=zmm_reg;ymm_or_mem tt=Half_Mem_512 k z
EVEX_Vpmovsqd_xmmm64_k1z_xmm, EVEX, F3, 0F38, 25, EVEX.128.F3.0F38.W0 25 /r, VPMOVSQD xmm1/m64 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Half_Mem_128 k z
EVEX_Vpmovsqd_xmmm128_k1z_ymm, EVEX, F3, 0F38, 25, EVEX.256.F3.0F38.W0 25 /r, VPMOVSQD xmm1/m128 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Half_Mem_256 k z
EVEX_Vpmovsqd_ymmm256_k1z_zmm, EVEX, F3, 0F38, 25, EVEX.512.F3.0F38.W0 25 /r, VPMOVSQD ymm1/m256 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=ymm_or_mem;zmm_reg tt=Half_Mem_512 k z
EVEX_Vptestmb_k_k1_xmm_xmmm128, EVEX, 66, 0F38, 26, EVEX.128.66.0F38.W0 26 /r, VPTESTMB k2 {k1}| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=k_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k
EVEX_Vptestmb_k_k1_ymm_ymmm256, EVEX, 66, 0F38, 26, EVEX.256.66.0F38.W0 26 /r, VPTESTMB k2 {k1}| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=k_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k
EVEX_Vptestmb_k_k1_zmm_zmmm512, EVEX, 66, 0F38, 26, EVEX.512.66.0F38.W0 26 /r, VPTESTMB k2 {k1}| zmm2| zmm3/m512, 16b 32b 64b L512 W0 op=k_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k
EVEX_Vptestmw_k_k1_xmm_xmmm128, EVEX, 66, 0F38, 26, EVEX.128.66.0F38.W1 26 /r, VPTESTMW k2 {k1}| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=k_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k
EVEX_Vptestmw_k_k1_ymm_ymmm256, EVEX, 66, 0F38, 26, EVEX.256.66.0F38.W1 26 /r, VPTESTMW k2 {k1}| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=k_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k
EVEX_Vptestmw_k_k1_zmm_zmmm512, EVEX, 66, 0F38, 26, EVEX.512.66.0F38.W1 26 /r, VPTESTMW k2 {k1}| zmm2| zmm3/m512, 16b 32b 64b L512 W1 op=k_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k
EVEX_Vptestnmb_k_k1_xmm_xmmm128, EVEX, F3, 0F38, 26, EVEX.128.F3.0F38.W0 26 /r, VPTESTNMB k2 {k1}| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=k_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k
EVEX_Vptestnmb_k_k1_ymm_ymmm256, EVEX, F3, 0F38, 26, EVEX.256.F3.0F38.W0 26 /r, VPTESTNMB k2 {k1}| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=k_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k
EVEX_Vptestnmb_k_k1_zmm_zmmm512, EVEX, F3, 0F38, 26, EVEX.512.F3.0F38.W0 26 /r, VPTESTNMB k2 {k1}| zmm2| zmm3/m512, 16b 32b 64b L512 W0 op=k_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k
EVEX_Vptestnmw_k_k1_xmm_xmmm128, EVEX, F3, 0F38, 26, EVEX.128.F3.0F38.W1 26 /r, VPTESTNMW k2 {k1}| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=k_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k
EVEX_Vptestnmw_k_k1_ymm_ymmm256, EVEX, F3, 0F38, 26, EVEX.256.F3.0F38.W1 26 /r, VPTESTNMW k2 {k1}| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=k_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k
EVEX_Vptestnmw_k_k1_zmm_zmmm512, EVEX, F3, 0F38, 26, EVEX.512.F3.0F38.W1 26 /r, VPTESTNMW k2 {k1}| zmm2| zmm3/m512, 16b 32b 64b L512 W1 op=k_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k
EVEX_Vptestmd_k_k1_xmm_xmmm128b32, EVEX, 66, 0F38, 27, EVEX.128.66.0F38.W0 27 /r, VPTESTMD k2 {k1}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=k_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k
EVEX_Vptestmd_k_k1_ymm_ymmm256b32, EVEX, 66, 0F38, 27, EVEX.256.66.0F38.W0 27 /r, VPTESTMD k2 {k1}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=k_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k
EVEX_Vptestmd_k_k1_zmm_zmmm512b32, EVEX, 66, 0F38, 27, EVEX.512.66.0F38.W0 27 /r, VPTESTMD k2 {k1}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=k_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k
EVEX_Vptestmq_k_k1_xmm_xmmm128b64, EVEX, 66, 0F38, 27, EVEX.128.66.0F38.W1 27 /r, VPTESTMQ k2 {k1}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=k_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k
EVEX_Vptestmq_k_k1_ymm_ymmm256b64, EVEX, 66, 0F38, 27, EVEX.256.66.0F38.W1 27 /r, VPTESTMQ k2 {k1}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=k_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k
EVEX_Vptestmq_k_k1_zmm_zmmm512b64, EVEX, 66, 0F38, 27, EVEX.512.66.0F38.W1 27 /r, VPTESTMQ k2 {k1}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=k_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k
EVEX_Vptestnmd_k_k1_xmm_xmmm128b32, EVEX, F3, 0F38, 27, EVEX.128.F3.0F38.W0 27 /r, VPTESTNMD k2 {k1}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=k_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k
EVEX_Vptestnmd_k_k1_ymm_ymmm256b32, EVEX, F3, 0F38, 27, EVEX.256.F3.0F38.W0 27 /r, VPTESTNMD k2 {k1}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=k_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k
EVEX_Vptestnmd_k_k1_zmm_zmmm512b32, EVEX, F3, 0F38, 27, EVEX.512.F3.0F38.W0 27 /r, VPTESTNMD k2 {k1}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=k_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k
EVEX_Vptestnmq_k_k1_xmm_xmmm128b64, EVEX, F3, 0F38, 27, EVEX.128.F3.0F38.W1 27 /r, VPTESTNMQ k2 {k1}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=k_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k
EVEX_Vptestnmq_k_k1_ymm_ymmm256b64, EVEX, F3, 0F38, 27, EVEX.256.F3.0F38.W1 27 /r, VPTESTNMQ k2 {k1}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=k_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k
EVEX_Vptestnmq_k_k1_zmm_zmmm512b64, EVEX, F3, 0F38, 27, EVEX.512.F3.0F38.W1 27 /r, VPTESTNMQ k2 {k1}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=k_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k
Pmuldq_xmm_xmmm128, legacy, 66, 0F38, 28, 66 0F 38 28 /r, PMULDQ xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmuldq_xmm_xmm_xmmm128, VEX, 66, 0F38, 28, VEX.128.66.0F38.WIG 28 /r, VPMULDQ xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpmuldq_ymm_ymm_ymmm256, VEX, 66, 0F38, 28, VEX.256.66.0F38.WIG 28 /r, VPMULDQ ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpmuldq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 28, EVEX.128.66.0F38.W1 28 /r, VPMULDQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpmuldq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 28, EVEX.256.66.0F38.W1 28 /r, VPMULDQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpmuldq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 28, EVEX.512.66.0F38.W1 28 /r, VPMULDQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpmovm2b_xmm_k, EVEX, F3, 0F38, 28, EVEX.128.F3.0F38.W0 28 /r, VPMOVM2B xmm1| k1, 16b 32b 64b L128 W0 op=xmm_reg;k_rm
EVEX_Vpmovm2b_ymm_k, EVEX, F3, 0F38, 28, EVEX.256.F3.0F38.W0 28 /r, VPMOVM2B ymm1| k1, 16b 32b 64b L256 W0 op=ymm_reg;k_rm
EVEX_Vpmovm2b_zmm_k, EVEX, F3, 0F38, 28, EVEX.512.F3.0F38.W0 28 /r, VPMOVM2B zmm1| k1, 16b 32b 64b L512 W0 op=zmm_reg;k_rm
EVEX_Vpmovm2w_xmm_k, EVEX, F3, 0F38, 28, EVEX.128.F3.0F38.W1 28 /r, VPMOVM2W xmm1| k1, 16b 32b 64b L128 W1 op=xmm_reg;k_rm
EVEX_Vpmovm2w_ymm_k, EVEX, F3, 0F38, 28, EVEX.256.F3.0F38.W1 28 /r, VPMOVM2W ymm1| k1, 16b 32b 64b L256 W1 op=ymm_reg;k_rm
EVEX_Vpmovm2w_zmm_k, EVEX, F3, 0F38, 28, EVEX.512.F3.0F38.W1 28 /r, VPMOVM2W zmm1| k1, 16b 32b 64b L512 W1 op=zmm_reg;k_rm
Pcmpeqq_xmm_xmmm128, legacy, 66, 0F38, 29, 66 0F 38 29 /r, PCMPEQQ xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpcmpeqq_xmm_xmm_xmmm128, VEX, 66, 0F38, 29, VEX.128.66.0F38.WIG 29 /r, VPCMPEQQ xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpcmpeqq_ymm_ymm_ymmm256, VEX, 66, 0F38, 29, VEX.256.66.0F38.WIG 29 /r, VPCMPEQQ ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpcmpeqq_k_k1_xmm_xmmm128b64, EVEX, 66, 0F38, 29, EVEX.128.66.0F38.W1 29 /r, VPCMPEQQ k1 {k2}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=k_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k
EVEX_Vpcmpeqq_k_k1_ymm_ymmm256b64, EVEX, 66, 0F38, 29, EVEX.256.66.0F38.W1 29 /r, VPCMPEQQ k1 {k2}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=k_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k
EVEX_Vpcmpeqq_k_k1_zmm_zmmm512b64, EVEX, 66, 0F38, 29, EVEX.512.66.0F38.W1 29 /r, VPCMPEQQ k1 {k2}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=k_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k
EVEX_Vpmovb2m_k_xmm, EVEX, F3, 0F38, 29, EVEX.128.F3.0F38.W0 29 /r, VPMOVB2M k1| xmm1, 16b 32b 64b L128 W0 op=k_reg;xmm_rm
EVEX_Vpmovb2m_k_ymm, EVEX, F3, 0F38, 29, EVEX.256.F3.0F38.W0 29 /r, VPMOVB2M k1| ymm1, 16b 32b 64b L256 W0 op=k_reg;ymm_rm
EVEX_Vpmovb2m_k_zmm, EVEX, F3, 0F38, 29, EVEX.512.F3.0F38.W0 29 /r, VPMOVB2M k1| zmm1, 16b 32b 64b L512 W0 op=k_reg;zmm_rm
EVEX_Vpmovw2m_k_xmm, EVEX, F3, 0F38, 29, EVEX.128.F3.0F38.W1 29 /r, VPMOVW2M k1| xmm1, 16b 32b 64b L128 W1 op=k_reg;xmm_rm
EVEX_Vpmovw2m_k_ymm, EVEX, F3, 0F38, 29, EVEX.256.F3.0F38.W1 29 /r, VPMOVW2M k1| ymm1, 16b 32b 64b L256 W1 op=k_reg;ymm_rm
EVEX_Vpmovw2m_k_zmm, EVEX, F3, 0F38, 29, EVEX.512.F3.0F38.W1 29 /r, VPMOVW2M k1| zmm1, 16b 32b 64b L512 W1 op=k_reg;zmm_rm
Movntdqa_xmm_m128, legacy, 66, 0F38, 2A, 66 0F 38 2A /r, MOVNTDQA xmm1| m128, 16b 32b 64b op=xmm_reg;mem
VEX_Vmovntdqa_xmm_m128, VEX, 66, 0F38, 2A, VEX.128.66.0F38.WIG 2A /r, VMOVNTDQA xmm1| m128, 16b 32b 64b L128 WIG op=xmm_reg;mem
VEX_Vmovntdqa_ymm_m256, VEX, 66, 0F38, 2A, VEX.256.66.0F38.WIG 2A /r, VMOVNTDQA ymm1| m256, 16b 32b 64b L256 WIG op=ymm_reg;mem
EVEX_Vmovntdqa_xmm_m128, EVEX, 66, 0F38, 2A, EVEX.128.66.0F38.W0 2A /r, VMOVNTDQA xmm1| m128, 16b 32b 64b L128 W0 op=xmm_reg;mem tt=Full_Mem_128
EVEX_Vmovntdqa_ymm_m256, EVEX, 66, 0F38, 2A, EVEX.256.66.0F38.W0 2A /r, VMOVNTDQA ymm1| m256, 16b 32b 64b L256 W0 op=ymm_reg;mem tt=Full_Mem_256
EVEX_Vmovntdqa_zmm_m512, EVEX, 66, 0F38, 2A, EVEX.512.66.0F38.W0 2A /r, VMOVNTDQA zmm1| m512, 16b 32b 64b L512 W0 op=zmm_reg;mem tt=Full_Mem_512
EVEX_Vpbroadcastmb2q_xmm_k, EVEX, F3, 0F38, 2A, EVEX.128.F3.0F38.W1 2A /r, VPBROADCASTMB2Q xmm1| k1, 16b 32b 64b L128 W1 op=xmm_reg;k_rm
EVEX_Vpbroadcastmb2q_ymm_k, EVEX, F3, 0F38, 2A, EVEX.256.F3.0F38.W1 2A /r, VPBROADCASTMB2Q ymm1| k1, 16b 32b 64b L256 W1 op=ymm_reg;k_rm
EVEX_Vpbroadcastmb2q_zmm_k, EVEX, F3, 0F38, 2A, EVEX.512.F3.0F38.W1 2A /r, VPBROADCASTMB2Q zmm1| k1, 16b 32b 64b L512 W1 op=zmm_reg;k_rm
Packusdw_xmm_xmmm128, legacy, 66, 0F38, 2B, 66 0F 38 2B /r, PACKUSDW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpackusdw_xmm_xmm_xmmm128, VEX, 66, 0F38, 2B, VEX.128.66.0F38.WIG 2B /r, VPACKUSDW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpackusdw_ymm_ymm_ymmm256, VEX, 66, 0F38, 2B, VEX.256.66.0F38.WIG 2B /r, VPACKUSDW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpackusdw_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 2B, EVEX.128.66.0F38.W0 2B /r, VPACKUSDW xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpackusdw_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 2B, EVEX.256.66.0F38.W0 2B /r, VPACKUSDW ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpackusdw_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 2B, EVEX.512.66.0F38.W0 2B /r, VPACKUSDW zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
VEX_Vmaskmovps_xmm_xmm_m128, VEX, 66, 0F38, 2C, VEX.128.66.0F38.W0 2C /r, VMASKMOVPS xmm1| xmm2| m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;mem
VEX_Vmaskmovps_ymm_ymm_m256, VEX, 66, 0F38, 2C, VEX.256.66.0F38.W0 2C /r, VMASKMOVPS ymm1| ymm2| m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;mem
EVEX_Vscalefps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 2C, EVEX.128.66.0F38.W0 2C /r, VSCALEFPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vscalefps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 2C, EVEX.256.66.0F38.W0 2C /r, VSCALEFPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vscalefps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, 2C, EVEX.512.66.0F38.W0 2C /r, VSCALEFPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vscalefpd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 2C, EVEX.128.66.0F38.W1 2C /r, VSCALEFPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vscalefpd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 2C, EVEX.256.66.0F38.W1 2C /r, VSCALEFPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vscalefpd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, 2C, EVEX.512.66.0F38.W1 2C /r, VSCALEFPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
VEX_Vmaskmovpd_xmm_xmm_m128, VEX, 66, 0F38, 2D, VEX.128.66.0F38.W0 2D /r, VMASKMOVPD xmm1| xmm2| m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;mem
VEX_Vmaskmovpd_ymm_ymm_m256, VEX, 66, 0F38, 2D, VEX.256.66.0F38.W0 2D /r, VMASKMOVPD ymm1| ymm2| m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;mem
EVEX_Vscalefss_xmm_k1z_xmm_xmmm32_er, EVEX, 66, 0F38, 2D, EVEX.LIG.66.0F38.W0 2D /r, VSCALEFSS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_Vscalefsd_xmm_k1z_xmm_xmmm64_er, EVEX, 66, 0F38, 2D, EVEX.LIG.66.0F38.W1 2D /r, VSCALEFSD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
VEX_Vmaskmovps_m128_xmm_xmm, VEX, 66, 0F38, 2E, VEX.128.66.0F38.W0 2E /r, VMASKMOVPS m128| xmm1| xmm2, 16b 32b 64b L128 W0 op=mem;xmm_vvvv;xmm_reg
VEX_Vmaskmovps_m256_ymm_ymm, VEX, 66, 0F38, 2E, VEX.256.66.0F38.W0 2E /r, VMASKMOVPS m256| ymm1| ymm2, 16b 32b 64b L256 W0 op=mem;ymm_vvvv;ymm_reg
VEX_Vmaskmovpd_m128_xmm_xmm, VEX, 66, 0F38, 2F, VEX.128.66.0F38.W0 2F /r, VMASKMOVPD m128| xmm1| xmm2, 16b 32b 64b L128 W0 op=mem;xmm_vvvv;xmm_reg
VEX_Vmaskmovpd_m256_ymm_ymm, VEX, 66, 0F38, 2F, VEX.256.66.0F38.W0 2F /r, VMASKMOVPD m256| ymm1| ymm2, 16b 32b 64b L256 W0 op=mem;ymm_vvvv;ymm_reg
Pmovzxbw_xmm_xmmm64, legacy, 66, 0F38, 30, 66 0F 38 30 /r, PMOVZXBW xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmovzxbw_xmm_xmmm64, VEX, 66, 0F38, 30, VEX.128.66.0F38.WIG 30 /r, VPMOVZXBW xmm1| xmm2/m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vpmovzxbw_ymm_xmmm128, VEX, 66, 0F38, 30, VEX.256.66.0F38.WIG 30 /r, VPMOVZXBW ymm1| xmm2/m128, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem
EVEX_Vpmovzxbw_xmm_k1z_xmmm64, EVEX, 66, 0F38, 30, EVEX.128.66.0F38.WIG 30 /r, VPMOVZXBW xmm1 {k1}{z}| xmm2/m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem tt=Half_Mem_128 k z
EVEX_Vpmovzxbw_ymm_k1z_xmmm128, EVEX, 66, 0F38, 30, EVEX.256.66.0F38.WIG 30 /r, VPMOVZXBW ymm1 {k1}{z}| xmm2/m128, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem tt=Half_Mem_256 k z
EVEX_Vpmovzxbw_zmm_k1z_ymmm256, EVEX, 66, 0F38, 30, EVEX.512.66.0F38.WIG 30 /r, VPMOVZXBW zmm1 {k1}{z}| ymm2/m256, 16b 32b 64b L512 WIG op=zmm_reg;ymm_or_mem tt=Half_Mem_512 k z
EVEX_Vpmovwb_xmmm64_k1z_xmm, EVEX, F3, 0F38, 30, EVEX.128.F3.0F38.W0 30 /r, VPMOVWB xmm1/m64 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Half_Mem_128 k z
EVEX_Vpmovwb_xmmm128_k1z_ymm, EVEX, F3, 0F38, 30, EVEX.256.F3.0F38.W0 30 /r, VPMOVWB xmm1/m128 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Half_Mem_256 k z
EVEX_Vpmovwb_ymmm256_k1z_zmm, EVEX, F3, 0F38, 30, EVEX.512.F3.0F38.W0 30 /r, VPMOVWB ymm1/m256 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=ymm_or_mem;zmm_reg tt=Half_Mem_512 k z
Pmovzxbd_xmm_xmmm32, legacy, 66, 0F38, 31, 66 0F 38 31 /r, PMOVZXBD xmm1| xmm2/m32, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmovzxbd_xmm_xmmm32, VEX, 66, 0F38, 31, VEX.128.66.0F38.WIG 31 /r, VPMOVZXBD xmm1| xmm2/m32, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vpmovzxbd_ymm_xmmm64, VEX, 66, 0F38, 31, VEX.256.66.0F38.WIG 31 /r, VPMOVZXBD ymm1| xmm2/m64, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem
EVEX_Vpmovzxbd_xmm_k1z_xmmm32, EVEX, 66, 0F38, 31, EVEX.128.66.0F38.WIG 31 /r, VPMOVZXBD xmm1 {k1}{z}| xmm2/m32, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem tt=Quarter_Mem_128 k z
EVEX_Vpmovzxbd_ymm_k1z_xmmm64, EVEX, 66, 0F38, 31, EVEX.256.66.0F38.WIG 31 /r, VPMOVZXBD ymm1 {k1}{z}| xmm2/m64, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem tt=Quarter_Mem_256 k z
EVEX_Vpmovzxbd_zmm_k1z_xmmm128, EVEX, 66, 0F38, 31, EVEX.512.66.0F38.WIG 31 /r, VPMOVZXBD zmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L512 WIG op=zmm_reg;xmm_or_mem tt=Quarter_Mem_512 k z
EVEX_Vpmovdb_xmmm32_k1z_xmm, EVEX, F3, 0F38, 31, EVEX.128.F3.0F38.W0 31 /r, VPMOVDB xmm1/m32 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Quarter_Mem_128 k z
EVEX_Vpmovdb_xmmm64_k1z_ymm, EVEX, F3, 0F38, 31, EVEX.256.F3.0F38.W0 31 /r, VPMOVDB xmm1/m64 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Quarter_Mem_256 k z
EVEX_Vpmovdb_xmmm128_k1z_zmm, EVEX, F3, 0F38, 31, EVEX.512.F3.0F38.W0 31 /r, VPMOVDB xmm1/m128 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=xmm_or_mem;zmm_reg tt=Quarter_Mem_512 k z
Pmovzxbq_xmm_xmmm16, legacy, 66, 0F38, 32, 66 0F 38 32 /r, PMOVZXBQ xmm1| xmm2/m16, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmovzxbq_xmm_xmmm16, VEX, 66, 0F38, 32, VEX.128.66.0F38.WIG 32 /r, VPMOVZXBQ xmm1| xmm2/m16, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vpmovzxbq_ymm_xmmm32, VEX, 66, 0F38, 32, VEX.256.66.0F38.WIG 32 /r, VPMOVZXBQ ymm1| xmm2/m32, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem
EVEX_Vpmovzxbq_xmm_k1z_xmmm16, EVEX, 66, 0F38, 32, EVEX.128.66.0F38.WIG 32 /r, VPMOVZXBQ xmm1 {k1}{z}| xmm2/m16, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem tt=Eighth_Mem_128 k z
EVEX_Vpmovzxbq_ymm_k1z_xmmm32, EVEX, 66, 0F38, 32, EVEX.256.66.0F38.WIG 32 /r, VPMOVZXBQ ymm1 {k1}{z}| xmm2/m32, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem tt=Eighth_Mem_256 k z
EVEX_Vpmovzxbq_zmm_k1z_xmmm64, EVEX, 66, 0F38, 32, EVEX.512.66.0F38.WIG 32 /r, VPMOVZXBQ zmm1 {k1}{z}| xmm2/m64, 16b 32b 64b L512 WIG op=zmm_reg;xmm_or_mem tt=Eighth_Mem_512 k z
EVEX_Vpmovqb_xmmm16_k1z_xmm, EVEX, F3, 0F38, 32, EVEX.128.F3.0F38.W0 32 /r, VPMOVQB xmm1/m16 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Eighth_Mem_128 k z
EVEX_Vpmovqb_xmmm32_k1z_ymm, EVEX, F3, 0F38, 32, EVEX.256.F3.0F38.W0 32 /r, VPMOVQB xmm1/m32 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Eighth_Mem_256 k z
EVEX_Vpmovqb_xmmm64_k1z_zmm, EVEX, F3, 0F38, 32, EVEX.512.F3.0F38.W0 32 /r, VPMOVQB xmm1/m64 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=xmm_or_mem;zmm_reg tt=Eighth_Mem_512 k z
Pmovzxwd_xmm_xmmm64, legacy, 66, 0F38, 33, 66 0F 38 33 /r, PMOVZXWD xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmovzxwd_xmm_xmmm64, VEX, 66, 0F38, 33, VEX.128.66.0F38.WIG 33 /r, VPMOVZXWD xmm1| xmm2/m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vpmovzxwd_ymm_xmmm128, VEX, 66, 0F38, 33, VEX.256.66.0F38.WIG 33 /r, VPMOVZXWD ymm1| xmm2/m128, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem
EVEX_Vpmovzxwd_xmm_k1z_xmmm64, EVEX, 66, 0F38, 33, EVEX.128.66.0F38.WIG 33 /r, VPMOVZXWD xmm1 {k1}{z}| xmm2/m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem tt=Half_Mem_128 k z
EVEX_Vpmovzxwd_ymm_k1z_xmmm128, EVEX, 66, 0F38, 33, EVEX.256.66.0F38.WIG 33 /r, VPMOVZXWD ymm1 {k1}{z}| xmm2/m128, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem tt=Half_Mem_256 k z
EVEX_Vpmovzxwd_zmm_k1z_ymmm256, EVEX, 66, 0F38, 33, EVEX.512.66.0F38.WIG 33 /r, VPMOVZXWD zmm1 {k1}{z}| ymm2/m256, 16b 32b 64b L512 WIG op=zmm_reg;ymm_or_mem tt=Half_Mem_512 k z
EVEX_Vpmovdw_xmmm64_k1z_xmm, EVEX, F3, 0F38, 33, EVEX.128.F3.0F38.W0 33 /r, VPMOVDW xmm1/m64 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Half_Mem_128 k z
EVEX_Vpmovdw_xmmm128_k1z_ymm, EVEX, F3, 0F38, 33, EVEX.256.F3.0F38.W0 33 /r, VPMOVDW xmm1/m128 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Half_Mem_256 k z
EVEX_Vpmovdw_ymmm256_k1z_zmm, EVEX, F3, 0F38, 33, EVEX.512.F3.0F38.W0 33 /r, VPMOVDW ymm1/m256 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=ymm_or_mem;zmm_reg tt=Half_Mem_512 k z
Pmovzxwq_xmm_xmmm32, legacy, 66, 0F38, 34, 66 0F 38 34 /r, PMOVZXWQ xmm1| xmm2/m32, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmovzxwq_xmm_xmmm32, VEX, 66, 0F38, 34, VEX.128.66.0F38.WIG 34 /r, VPMOVZXWQ xmm1| xmm2/m32, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vpmovzxwq_ymm_xmmm64, VEX, 66, 0F38, 34, VEX.256.66.0F38.WIG 34 /r, VPMOVZXWQ ymm1| xmm2/m64, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem
EVEX_Vpmovzxwq_xmm_k1z_xmmm32, EVEX, 66, 0F38, 34, EVEX.128.66.0F38.WIG 34 /r, VPMOVZXWQ xmm1 {k1}{z}| xmm2/m32, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem tt=Quarter_Mem_128 k z
EVEX_Vpmovzxwq_ymm_k1z_xmmm64, EVEX, 66, 0F38, 34, EVEX.256.66.0F38.WIG 34 /r, VPMOVZXWQ ymm1 {k1}{z}| xmm2/m64, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem tt=Quarter_Mem_256 k z
EVEX_Vpmovzxwq_zmm_k1z_xmmm128, EVEX, 66, 0F38, 34, EVEX.512.66.0F38.WIG 34 /r, VPMOVZXWQ zmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L512 WIG op=zmm_reg;xmm_or_mem tt=Quarter_Mem_512 k z
EVEX_Vpmovqw_xmmm32_k1z_xmm, EVEX, F3, 0F38, 34, EVEX.128.F3.0F38.W0 34 /r, VPMOVQW xmm1/m32 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Quarter_Mem_128 k z
EVEX_Vpmovqw_xmmm64_k1z_ymm, EVEX, F3, 0F38, 34, EVEX.256.F3.0F38.W0 34 /r, VPMOVQW xmm1/m64 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Quarter_Mem_256 k z
EVEX_Vpmovqw_xmmm128_k1z_zmm, EVEX, F3, 0F38, 34, EVEX.512.F3.0F38.W0 34 /r, VPMOVQW xmm1/m128 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=xmm_or_mem;zmm_reg tt=Quarter_Mem_512 k z
Pmovzxdq_xmm_xmmm64, legacy, 66, 0F38, 35, 66 0F 38 35 /r, PMOVZXDQ xmm1| xmm2/m64, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmovzxdq_xmm_xmmm64, VEX, 66, 0F38, 35, VEX.128.66.0F38.WIG 35 /r, VPMOVZXDQ xmm1| xmm2/m64, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
VEX_Vpmovzxdq_ymm_xmmm128, VEX, 66, 0F38, 35, VEX.256.66.0F38.WIG 35 /r, VPMOVZXDQ ymm1| xmm2/m128, 16b 32b 64b L256 WIG op=ymm_reg;xmm_or_mem
EVEX_Vpmovzxdq_xmm_k1z_xmmm64, EVEX, 66, 0F38, 35, EVEX.128.66.0F38.W0 35 /r, VPMOVZXDQ xmm1 {k1}{z}| xmm2/m64, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Half_Mem_128 k z
EVEX_Vpmovzxdq_ymm_k1z_xmmm128, EVEX, 66, 0F38, 35, EVEX.256.66.0F38.W0 35 /r, VPMOVZXDQ ymm1 {k1}{z}| xmm2/m128, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem tt=Half_Mem_256 k z
EVEX_Vpmovzxdq_zmm_k1z_ymmm256, EVEX, 66, 0F38, 35, EVEX.512.66.0F38.W0 35 /r, VPMOVZXDQ zmm1 {k1}{z}| ymm2/m256, 16b 32b 64b L512 W0 op=zmm_reg;ymm_or_mem tt=Half_Mem_512 k z
EVEX_Vpmovqd_xmmm64_k1z_xmm, EVEX, F3, 0F38, 35, EVEX.128.F3.0F38.W0 35 /r, VPMOVQD xmm1/m64 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Half_Mem_128 k z
EVEX_Vpmovqd_xmmm128_k1z_ymm, EVEX, F3, 0F38, 35, EVEX.256.F3.0F38.W0 35 /r, VPMOVQD xmm1/m128 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg tt=Half_Mem_256 k z
EVEX_Vpmovqd_ymmm256_k1z_zmm, EVEX, F3, 0F38, 35, EVEX.512.F3.0F38.W0 35 /r, VPMOVQD ymm1/m256 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=ymm_or_mem;zmm_reg tt=Half_Mem_512 k z
VEX_Vpermd_ymm_ymm_ymmm256, VEX, 66, 0F38, 36, VEX.256.66.0F38.W0 36 /r, VPERMD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpermd_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 36, EVEX.256.66.0F38.W0 36 /r, VPERMD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpermd_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 36, EVEX.512.66.0F38.W0 36 /r, VPERMD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpermq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 36, EVEX.256.66.0F38.W1 36 /r, VPERMQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpermq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 36, EVEX.512.66.0F38.W1 36 /r, VPERMQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Pcmpgtq_xmm_xmmm128, legacy, 66, 0F38, 37, 66 0F 38 37 /r, PCMPGTQ xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpcmpgtq_xmm_xmm_xmmm128, VEX, 66, 0F38, 37, VEX.128.66.0F38.WIG 37 /r, VPCMPGTQ xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpcmpgtq_ymm_ymm_ymmm256, VEX, 66, 0F38, 37, VEX.256.66.0F38.WIG 37 /r, VPCMPGTQ ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpcmpgtq_k_k1_xmm_xmmm128b64, EVEX, 66, 0F38, 37, EVEX.128.66.0F38.W1 37 /r, VPCMPGTQ k1 {k2}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=k_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k
EVEX_Vpcmpgtq_k_k1_ymm_ymmm256b64, EVEX, 66, 0F38, 37, EVEX.256.66.0F38.W1 37 /r, VPCMPGTQ k1 {k2}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=k_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k
EVEX_Vpcmpgtq_k_k1_zmm_zmmm512b64, EVEX, 66, 0F38, 37, EVEX.512.66.0F38.W1 37 /r, VPCMPGTQ k1 {k2}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=k_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k
Pminsb_xmm_xmmm128, legacy, 66, 0F38, 38, 66 0F 38 38 /r, PMINSB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpminsb_xmm_xmm_xmmm128, VEX, 66, 0F38, 38, VEX.128.66.0F38.WIG 38 /r, VPMINSB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpminsb_ymm_ymm_ymmm256, VEX, 66, 0F38, 38, VEX.256.66.0F38.WIG 38 /r, VPMINSB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpminsb_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 38, EVEX.128.66.0F38.WIG 38 /r, VPMINSB xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpminsb_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 38, EVEX.256.66.0F38.WIG 38 /r, VPMINSB ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpminsb_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 38, EVEX.512.66.0F38.WIG 38 /r, VPMINSB zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vpmovm2d_xmm_k, EVEX, F3, 0F38, 38, EVEX.128.F3.0F38.W0 38 /r, VPMOVM2D xmm1| k1, 16b 32b 64b L128 W0 op=xmm_reg;k_rm
EVEX_Vpmovm2d_ymm_k, EVEX, F3, 0F38, 38, EVEX.256.F3.0F38.W0 38 /r, VPMOVM2D ymm1| k1, 16b 32b 64b L256 W0 op=ymm_reg;k_rm
EVEX_Vpmovm2d_zmm_k, EVEX, F3, 0F38, 38, EVEX.512.F3.0F38.W0 38 /r, VPMOVM2D zmm1| k1, 16b 32b 64b L512 W0 op=zmm_reg;k_rm
EVEX_Vpmovm2q_xmm_k, EVEX, F3, 0F38, 38, EVEX.128.F3.0F38.W1 38 /r, VPMOVM2Q xmm1| k1, 16b 32b 64b L128 W1 op=xmm_reg;k_rm
EVEX_Vpmovm2q_ymm_k, EVEX, F3, 0F38, 38, EVEX.256.F3.0F38.W1 38 /r, VPMOVM2Q ymm1| k1, 16b 32b 64b L256 W1 op=ymm_reg;k_rm
EVEX_Vpmovm2q_zmm_k, EVEX, F3, 0F38, 38, EVEX.512.F3.0F38.W1 38 /r, VPMOVM2Q zmm1| k1, 16b 32b 64b L512 W1 op=zmm_reg;k_rm
Pminsd_xmm_xmmm128, legacy, 66, 0F38, 39, 66 0F 38 39 /r, PMINSD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpminsd_xmm_xmm_xmmm128, VEX, 66, 0F38, 39, VEX.128.66.0F38.WIG 39 /r, VPMINSD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpminsd_ymm_ymm_ymmm256, VEX, 66, 0F38, 39, VEX.256.66.0F38.WIG 39 /r, VPMINSD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpminsd_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 39, EVEX.128.66.0F38.W0 39 /r, VPMINSD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpminsd_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 39, EVEX.256.66.0F38.W0 39 /r, VPMINSD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpminsd_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 39, EVEX.512.66.0F38.W0 39 /r, VPMINSD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpminsq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 39, EVEX.128.66.0F38.W1 39 /r, VPMINSQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpminsq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 39, EVEX.256.66.0F38.W1 39 /r, VPMINSQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpminsq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 39, EVEX.512.66.0F38.W1 39 /r, VPMINSQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpmovd2m_k_xmm, EVEX, F3, 0F38, 39, EVEX.128.F3.0F38.W0 39 /r, VPMOVD2M k1| xmm1, 16b 32b 64b L128 W0 op=k_reg;xmm_rm
EVEX_Vpmovd2m_k_ymm, EVEX, F3, 0F38, 39, EVEX.256.F3.0F38.W0 39 /r, VPMOVD2M k1| ymm1, 16b 32b 64b L256 W0 op=k_reg;ymm_rm
EVEX_Vpmovd2m_k_zmm, EVEX, F3, 0F38, 39, EVEX.512.F3.0F38.W0 39 /r, VPMOVD2M k1| zmm1, 16b 32b 64b L512 W0 op=k_reg;zmm_rm
EVEX_Vpmovq2m_k_xmm, EVEX, F3, 0F38, 39, EVEX.128.F3.0F38.W1 39 /r, VPMOVQ2M k1| xmm1, 16b 32b 64b L128 W1 op=k_reg;xmm_rm
EVEX_Vpmovq2m_k_ymm, EVEX, F3, 0F38, 39, EVEX.256.F3.0F38.W1 39 /r, VPMOVQ2M k1| ymm1, 16b 32b 64b L256 W1 op=k_reg;ymm_rm
EVEX_Vpmovq2m_k_zmm, EVEX, F3, 0F38, 39, EVEX.512.F3.0F38.W1 39 /r, VPMOVQ2M k1| zmm1, 16b 32b 64b L512 W1 op=k_reg;zmm_rm
Pminuw_xmm_xmmm128, legacy, 66, 0F38, 3A, 66 0F 38 3A /r, PMINUW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpminuw_xmm_xmm_xmmm128, VEX, 66, 0F38, 3A, VEX.128.66.0F38.WIG 3A /r, VPMINUW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpminuw_ymm_ymm_ymmm256, VEX, 66, 0F38, 3A, VEX.256.66.0F38.WIG 3A /r, VPMINUW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpminuw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 3A, EVEX.128.66.0F38.WIG 3A /r, VPMINUW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpminuw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 3A, EVEX.256.66.0F38.WIG 3A /r, VPMINUW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpminuw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 3A, EVEX.512.66.0F38.WIG 3A /r, VPMINUW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vpbroadcastmw2d_xmm_k, EVEX, F3, 0F38, 3A, EVEX.128.F3.0F38.W0 3A /r, VPBROADCASTMW2D xmm1| k1, 16b 32b 64b L128 W0 op=xmm_reg;k_rm
EVEX_Vpbroadcastmw2d_ymm_k, EVEX, F3, 0F38, 3A, EVEX.256.F3.0F38.W0 3A /r, VPBROADCASTMW2D ymm1| k1, 16b 32b 64b L256 W0 op=ymm_reg;k_rm
EVEX_Vpbroadcastmw2d_zmm_k, EVEX, F3, 0F38, 3A, EVEX.512.F3.0F38.W0 3A /r, VPBROADCASTMW2D zmm1| k1, 16b 32b 64b L512 W0 op=zmm_reg;k_rm
Pminud_xmm_xmmm128, legacy, 66, 0F38, 3B, 66 0F 38 3B /r, PMINUD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpminud_xmm_xmm_xmmm128, VEX, 66, 0F38, 3B, VEX.128.66.0F38.WIG 3B /r, VPMINUD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpminud_ymm_ymm_ymmm256, VEX, 66, 0F38, 3B, VEX.256.66.0F38.WIG 3B /r, VPMINUD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpminud_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 3B, EVEX.128.66.0F38.W0 3B /r, VPMINUD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpminud_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 3B, EVEX.256.66.0F38.W0 3B /r, VPMINUD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpminud_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 3B, EVEX.512.66.0F38.W0 3B /r, VPMINUD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpminuq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 3B, EVEX.128.66.0F38.W1 3B /r, VPMINUQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpminuq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 3B, EVEX.256.66.0F38.W1 3B /r, VPMINUQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpminuq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 3B, EVEX.512.66.0F38.W1 3B /r, VPMINUQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Pmaxsb_xmm_xmmm128, legacy, 66, 0F38, 3C, 66 0F 38 3C /r, PMAXSB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmaxsb_xmm_xmm_xmmm128, VEX, 66, 0F38, 3C, VEX.128.66.0F38.WIG 3C /r, VPMAXSB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpmaxsb_ymm_ymm_ymmm256, VEX, 66, 0F38, 3C, VEX.256.66.0F38.WIG 3C /r, VPMAXSB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpmaxsb_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 3C, EVEX.128.66.0F38.WIG 3C /r, VPMAXSB xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpmaxsb_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 3C, EVEX.256.66.0F38.WIG 3C /r, VPMAXSB ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpmaxsb_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 3C, EVEX.512.66.0F38.WIG 3C /r, VPMAXSB zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Pmaxsd_xmm_xmmm128, legacy, 66, 0F38, 3D, 66 0F 38 3D /r, PMAXSD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmaxsd_xmm_xmm_xmmm128, VEX, 66, 0F38, 3D, VEX.128.66.0F38.WIG 3D /r, VPMAXSD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpmaxsd_ymm_ymm_ymmm256, VEX, 66, 0F38, 3D, VEX.256.66.0F38.WIG 3D /r, VPMAXSD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpmaxsd_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 3D, EVEX.128.66.0F38.W0 3D /r, VPMAXSD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpmaxsd_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 3D, EVEX.256.66.0F38.W0 3D /r, VPMAXSD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpmaxsd_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 3D, EVEX.512.66.0F38.W0 3D /r, VPMAXSD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpmaxsq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 3D, EVEX.128.66.0F38.W1 3D /r, VPMAXSQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpmaxsq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 3D, EVEX.256.66.0F38.W1 3D /r, VPMAXSQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpmaxsq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 3D, EVEX.512.66.0F38.W1 3D /r, VPMAXSQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Pmaxuw_xmm_xmmm128, legacy, 66, 0F38, 3E, 66 0F 38 3E /r, PMAXUW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmaxuw_xmm_xmm_xmmm128, VEX, 66, 0F38, 3E, VEX.128.66.0F38.WIG 3E /r, VPMAXUW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpmaxuw_ymm_ymm_ymmm256, VEX, 66, 0F38, 3E, VEX.256.66.0F38.WIG 3E /r, VPMAXUW ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpmaxuw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 3E, EVEX.128.66.0F38.WIG 3E /r, VPMAXUW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpmaxuw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 3E, EVEX.256.66.0F38.WIG 3E /r, VPMAXUW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpmaxuw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 3E, EVEX.512.66.0F38.WIG 3E /r, VPMAXUW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Pmaxud_xmm_xmmm128, legacy, 66, 0F38, 3F, 66 0F 38 3F /r, PMAXUD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmaxud_xmm_xmm_xmmm128, VEX, 66, 0F38, 3F, VEX.128.66.0F38.WIG 3F /r, VPMAXUD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpmaxud_ymm_ymm_ymmm256, VEX, 66, 0F38, 3F, VEX.256.66.0F38.WIG 3F /r, VPMAXUD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpmaxud_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 3F, EVEX.128.66.0F38.W0 3F /r, VPMAXUD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpmaxud_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 3F, EVEX.256.66.0F38.W0 3F /r, VPMAXUD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpmaxud_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 3F, EVEX.512.66.0F38.W0 3F /r, VPMAXUD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpmaxuq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 3F, EVEX.128.66.0F38.W1 3F /r, VPMAXUQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpmaxuq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 3F, EVEX.256.66.0F38.W1 3F /r, VPMAXUQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpmaxuq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 3F, EVEX.512.66.0F38.W1 3F /r, VPMAXUQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Pmulld_xmm_xmmm128, legacy, 66, 0F38, 40, 66 0F 38 40 /r, PMULLD xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vpmulld_xmm_xmm_xmmm128, VEX, 66, 0F38, 40, VEX.128.66.0F38.WIG 40 /r, VPMULLD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpmulld_ymm_ymm_ymmm256, VEX, 66, 0F38, 40, VEX.256.66.0F38.WIG 40 /r, VPMULLD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpmulld_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 40, EVEX.128.66.0F38.W0 40 /r, VPMULLD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpmulld_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 40, EVEX.256.66.0F38.W0 40 /r, VPMULLD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpmulld_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 40, EVEX.512.66.0F38.W0 40 /r, VPMULLD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpmullq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 40, EVEX.128.66.0F38.W1 40 /r, VPMULLQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpmullq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 40, EVEX.256.66.0F38.W1 40 /r, VPMULLQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpmullq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 40, EVEX.512.66.0F38.W1 40 /r, VPMULLQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Phminposuw_xmm_xmmm128, legacy, 66, 0F38, 41, 66 0F 38 41 /r, PHMINPOSUW xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vphminposuw_xmm_xmmm128, VEX, 66, 0F38, 41, VEX.128.66.0F38.WIG 41 /r, VPHMINPOSUW xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
EVEX_Vgetexpps_xmm_k1z_xmmm128b32, EVEX, 66, 0F38, 42, EVEX.128.66.0F38.W0 42 /r, VGETEXPPS xmm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vgetexpps_ymm_k1z_ymmm256b32, EVEX, 66, 0F38, 42, EVEX.256.66.0F38.W0 42 /r, VGETEXPPS ymm1 {k1}{z}| ymm2/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vgetexpps_zmm_k1z_zmmm512b32_sae, EVEX, 66, 0F38, 42, EVEX.512.66.0F38.W0 42 /r, VGETEXPPS zmm1 {k1}{z}| zmm2/m512/m32bcst{sae}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_512 b sae k z
EVEX_Vgetexppd_xmm_k1z_xmmm128b64, EVEX, 66, 0F38, 42, EVEX.128.66.0F38.W1 42 /r, VGETEXPPD xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vgetexppd_ymm_k1z_ymmm256b64, EVEX, 66, 0F38, 42, EVEX.256.66.0F38.W1 42 /r, VGETEXPPD ymm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vgetexppd_zmm_k1z_zmmm512b64_sae, EVEX, 66, 0F38, 42, EVEX.512.66.0F38.W1 42 /r, VGETEXPPD zmm1 {k1}{z}| zmm2/m512/m64bcst{sae}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_512 b sae k z
EVEX_Vgetexpss_xmm_k1z_xmm_xmmm32_sae, EVEX, 66, 0F38, 43, EVEX.LIG.66.0F38.W0 43 /r, VGETEXPSS xmm1 {k1}{z}| xmm2| xmm3/m32{sae}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar sae k z
EVEX_Vgetexpsd_xmm_k1z_xmm_xmmm64_sae, EVEX, 66, 0F38, 43, EVEX.LIG.66.0F38.W1 43 /r, VGETEXPSD xmm1 {k1}{z}| xmm2| xmm3/m64{sae}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar sae k z
EVEX_Vplzcntd_xmm_k1z_xmmm128b32, EVEX, 66, 0F38, 44, EVEX.128.66.0F38.W0 44 /r, VPLZCNTD xmm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vplzcntd_ymm_k1z_ymmm256b32, EVEX, 66, 0F38, 44, EVEX.256.66.0F38.W0 44 /r, VPLZCNTD ymm1 {k1}{z}| ymm2/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vplzcntd_zmm_k1z_zmmm512b32, EVEX, 66, 0F38, 44, EVEX.512.66.0F38.W0 44 /r, VPLZCNTD zmm1 {k1}{z}| zmm2/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_512 b k z
EVEX_Vplzcntq_xmm_k1z_xmmm128b64, EVEX, 66, 0F38, 44, EVEX.128.66.0F38.W1 44 /r, VPLZCNTQ xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vplzcntq_ymm_k1z_ymmm256b64, EVEX, 66, 0F38, 44, EVEX.256.66.0F38.W1 44 /r, VPLZCNTQ ymm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vplzcntq_zmm_k1z_zmmm512b64, EVEX, 66, 0F38, 44, EVEX.512.66.0F38.W1 44 /r, VPLZCNTQ zmm1 {k1}{z}| zmm2/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_512 b k z
VEX_Vpsrlvd_xmm_xmm_xmmm128, VEX, 66, 0F38, 45, VEX.128.66.0F38.W0 45 /r, VPSRLVD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsrlvd_ymm_ymm_ymmm256, VEX, 66, 0F38, 45, VEX.256.66.0F38.W0 45 /r, VPSRLVD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vpsrlvq_xmm_xmm_xmmm128, VEX, 66, 0F38, 45, VEX.128.66.0F38.W1 45 /r, VPSRLVQ xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsrlvq_ymm_ymm_ymmm256, VEX, 66, 0F38, 45, VEX.256.66.0F38.W1 45 /r, VPSRLVQ ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpsrlvd_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 45, EVEX.128.66.0F38.W0 45 /r, VPSRLVD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpsrlvd_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 45, EVEX.256.66.0F38.W0 45 /r, VPSRLVD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpsrlvd_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 45, EVEX.512.66.0F38.W0 45 /r, VPSRLVD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpsrlvq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 45, EVEX.128.66.0F38.W1 45 /r, VPSRLVQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpsrlvq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 45, EVEX.256.66.0F38.W1 45 /r, VPSRLVQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpsrlvq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 45, EVEX.512.66.0F38.W1 45 /r, VPSRLVQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
VEX_Vpsravd_xmm_xmm_xmmm128, VEX, 66, 0F38, 46, VEX.128.66.0F38.W0 46 /r, VPSRAVD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsravd_ymm_ymm_ymmm256, VEX, 66, 0F38, 46, VEX.256.66.0F38.W0 46 /r, VPSRAVD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpsravd_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 46, EVEX.128.66.0F38.W0 46 /r, VPSRAVD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpsravd_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 46, EVEX.256.66.0F38.W0 46 /r, VPSRAVD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpsravd_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 46, EVEX.512.66.0F38.W0 46 /r, VPSRAVD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpsravq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 46, EVEX.128.66.0F38.W1 46 /r, VPSRAVQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpsravq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 46, EVEX.256.66.0F38.W1 46 /r, VPSRAVQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpsravq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 46, EVEX.512.66.0F38.W1 46 /r, VPSRAVQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
VEX_Vpsllvd_xmm_xmm_xmmm128, VEX, 66, 0F38, 47, VEX.128.66.0F38.W0 47 /r, VPSLLVD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsllvd_ymm_ymm_ymmm256, VEX, 66, 0F38, 47, VEX.256.66.0F38.W0 47 /r, VPSLLVD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vpsllvq_xmm_xmm_xmmm128, VEX, 66, 0F38, 47, VEX.128.66.0F38.W1 47 /r, VPSLLVQ xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vpsllvq_ymm_ymm_ymmm256, VEX, 66, 0F38, 47, VEX.256.66.0F38.W1 47 /r, VPSLLVQ ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vpsllvd_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 47, EVEX.128.66.0F38.W0 47 /r, VPSLLVD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpsllvd_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 47, EVEX.256.66.0F38.W0 47 /r, VPSLLVD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpsllvd_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 47, EVEX.512.66.0F38.W0 47 /r, VPSLLVD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpsllvq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 47, EVEX.128.66.0F38.W1 47 /r, VPSLLVQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpsllvq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 47, EVEX.256.66.0F38.W1 47 /r, VPSLLVQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpsllvq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 47, EVEX.512.66.0F38.W1 47 /r, VPSLLVQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vrcp14ps_xmm_k1z_xmmm128b32, EVEX, 66, 0F38, 4C, EVEX.128.66.0F38.W0 4C /r, VRCP14PS xmm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vrcp14ps_ymm_k1z_ymmm256b32, EVEX, 66, 0F38, 4C, EVEX.256.66.0F38.W0 4C /r, VRCP14PS ymm1 {k1}{z}| ymm2/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vrcp14ps_zmm_k1z_zmmm512b32, EVEX, 66, 0F38, 4C, EVEX.512.66.0F38.W0 4C /r, VRCP14PS zmm1 {k1}{z}| zmm2/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_512 b k z
EVEX_Vrcp14pd_xmm_k1z_xmmm128b64, EVEX, 66, 0F38, 4C, EVEX.128.66.0F38.W1 4C /r, VRCP14PD xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vrcp14pd_ymm_k1z_ymmm256b64, EVEX, 66, 0F38, 4C, EVEX.256.66.0F38.W1 4C /r, VRCP14PD ymm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vrcp14pd_zmm_k1z_zmmm512b64, EVEX, 66, 0F38, 4C, EVEX.512.66.0F38.W1 4C /r, VRCP14PD zmm1 {k1}{z}| zmm2/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_512 b k z
EVEX_Vrcp14ss_xmm_k1z_xmm_xmmm32, EVEX, 66, 0F38, 4D, EVEX.LIG.66.0F38.W0 4D /r, VRCP14SS xmm1 {k1}{z}| xmm2| xmm3/m32, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vrcp14sd_xmm_k1z_xmm_xmmm64, EVEX, 66, 0F38, 4D, EVEX.LIG.66.0F38.W1 4D /r, VRCP14SD xmm1 {k1}{z}| xmm2| xmm3/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vrsqrt14ps_xmm_k1z_xmmm128b32, EVEX, 66, 0F38, 4E, EVEX.128.66.0F38.W0 4E /r, VRSQRT14PS xmm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vrsqrt14ps_ymm_k1z_ymmm256b32, EVEX, 66, 0F38, 4E, EVEX.256.66.0F38.W0 4E /r, VRSQRT14PS ymm1 {k1}{z}| ymm2/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vrsqrt14ps_zmm_k1z_zmmm512b32, EVEX, 66, 0F38, 4E, EVEX.512.66.0F38.W0 4E /r, VRSQRT14PS zmm1 {k1}{z}| zmm2/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_512 b k z
EVEX_Vrsqrt14pd_xmm_k1z_xmmm128b64, EVEX, 66, 0F38, 4E, EVEX.128.66.0F38.W1 4E /r, VRSQRT14PD xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vrsqrt14pd_ymm_k1z_ymmm256b64, EVEX, 66, 0F38, 4E, EVEX.256.66.0F38.W1 4E /r, VRSQRT14PD ymm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vrsqrt14pd_zmm_k1z_zmmm512b64, EVEX, 66, 0F38, 4E, EVEX.512.66.0F38.W1 4E /r, VRSQRT14PD zmm1 {k1}{z}| zmm2/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_512 b k z
EVEX_Vrsqrt14ss_xmm_k1z_xmm_xmmm32, EVEX, 66, 0F38, 4F, EVEX.LIG.66.0F38.W0 4F /r, VRSQRT14SS xmm1 {k1}{z}| xmm2| xmm3/m32, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vrsqrt14sd_xmm_k1z_xmm_xmmm64, EVEX, 66, 0F38, 4F, EVEX.LIG.66.0F38.W1 4F /r, VRSQRT14SD xmm1 {k1}{z}| xmm2| xmm3/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vpdpbusd_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 50, EVEX.128.66.0F38.W0 50 /r, VPDPBUSD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpdpbusd_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 50, EVEX.256.66.0F38.W0 50 /r, VPDPBUSD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpdpbusd_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 50, EVEX.512.66.0F38.W0 50 /r, VPDPBUSD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpdpbusds_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 51, EVEX.128.66.0F38.W0 51 /r, VPDPBUSDS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpdpbusds_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 51, EVEX.256.66.0F38.W0 51 /r, VPDPBUSDS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpdpbusds_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 51, EVEX.512.66.0F38.W0 51 /r, VPDPBUSDS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpdpwssd_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 52, EVEX.128.66.0F38.W0 52 /r, VPDPWSSD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpdpwssd_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 52, EVEX.256.66.0F38.W0 52 /r, VPDPWSSD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpdpwssd_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 52, EVEX.512.66.0F38.W0 52 /r, VPDPWSSD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vdpbf16ps_xmm_k1z_xmm_xmmm128b32, EVEX, F3, 0F38, 52, EVEX.128.F3.0F38.W0 52 /r, VDPBF16PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vdpbf16ps_ymm_k1z_ymm_ymmm256b32, EVEX, F3, 0F38, 52, EVEX.256.F3.0F38.W0 52 /r, VDPBF16PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vdpbf16ps_zmm_k1z_zmm_zmmm512b32, EVEX, F3, 0F38, 52, EVEX.512.F3.0F38.W0 52 /r, VDPBF16PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vp4dpwssd_zmm_k1z_zmmp3_m128, EVEX, F2, 0F38, 52, EVEX.512.F2.0F38.W0 52 /r, VP4DPWSSD zmm1 {k1}{z}| zmm2+3| m128, 16b 32b 64b L512 W0 op=zmm_reg;zmmp3_vvvv;mem tt=Tuple1_4X k z
EVEX_Vpdpwssds_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 53, EVEX.128.66.0F38.W0 53 /r, VPDPWSSDS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpdpwssds_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 53, EVEX.256.66.0F38.W0 53 /r, VPDPWSSDS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpdpwssds_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 53, EVEX.512.66.0F38.W0 53 /r, VPDPWSSDS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vp4dpwssds_zmm_k1z_zmmp3_m128, EVEX, F2, 0F38, 53, EVEX.512.F2.0F38.W0 53 /r, VP4DPWSSDS zmm1 {k1}{z}| zmm2+3| m128, 16b 32b 64b L512 W0 op=zmm_reg;zmmp3_vvvv;mem tt=Tuple1_4X k z
EVEX_Vpopcntb_xmm_k1z_xmmm128, EVEX, 66, 0F38, 54, EVEX.128.66.0F38.W0 54 /r, VPOPCNTB xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpopcntb_ymm_k1z_ymmm256, EVEX, 66, 0F38, 54, EVEX.256.66.0F38.W0 54 /r, VPOPCNTB ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpopcntb_zmm_k1z_zmmm512, EVEX, 66, 0F38, 54, EVEX.512.66.0F38.W0 54 /r, VPOPCNTB zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vpopcntw_xmm_k1z_xmmm128, EVEX, 66, 0F38, 54, EVEX.128.66.0F38.W1 54 /r, VPOPCNTW xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpopcntw_ymm_k1z_ymmm256, EVEX, 66, 0F38, 54, EVEX.256.66.0F38.W1 54 /r, VPOPCNTW ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpopcntw_zmm_k1z_zmmm512, EVEX, 66, 0F38, 54, EVEX.512.66.0F38.W1 54 /r, VPOPCNTW zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vpopcntd_xmm_k1z_xmmm128b32, EVEX, 66, 0F38, 55, EVEX.128.66.0F38.W0 55 /r, VPOPCNTD xmm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vpopcntd_ymm_k1z_ymmm256b32, EVEX, 66, 0F38, 55, EVEX.256.66.0F38.W0 55 /r, VPOPCNTD ymm1 {k1}{z}| ymm2/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vpopcntd_zmm_k1z_zmmm512b32, EVEX, 66, 0F38, 55, EVEX.512.66.0F38.W0 55 /r, VPOPCNTD zmm1 {k1}{z}| zmm2/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_512 b k z
EVEX_Vpopcntq_xmm_k1z_xmmm128b64, EVEX, 66, 0F38, 55, EVEX.128.66.0F38.W1 55 /r, VPOPCNTQ xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vpopcntq_ymm_k1z_ymmm256b64, EVEX, 66, 0F38, 55, EVEX.256.66.0F38.W1 55 /r, VPOPCNTQ ymm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vpopcntq_zmm_k1z_zmmm512b64, EVEX, 66, 0F38, 55, EVEX.512.66.0F38.W1 55 /r, VPOPCNTQ zmm1 {k1}{z}| zmm2/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_512 b k z
VEX_Vpbroadcastd_xmm_xmmm32, VEX, 66, 0F38, 58, VEX.128.66.0F38.W0 58 /r, VPBROADCASTD xmm1| xmm2/m32, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
VEX_Vpbroadcastd_ymm_xmmm32, VEX, 66, 0F38, 58, VEX.256.66.0F38.W0 58 /r, VPBROADCASTD ymm1| xmm2/m32, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem
EVEX_Vpbroadcastd_xmm_k1z_xmmm32, EVEX, 66, 0F38, 58, EVEX.128.66.0F38.W0 58 /r, VPBROADCASTD xmm1 {k1}{z}| xmm2/m32, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vpbroadcastd_ymm_k1z_xmmm32, EVEX, 66, 0F38, 58, EVEX.256.66.0F38.W0 58 /r, VPBROADCASTD ymm1 {k1}{z}| xmm2/m32, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vpbroadcastd_zmm_k1z_xmmm32, EVEX, 66, 0F38, 58, EVEX.512.66.0F38.W0 58 /r, VPBROADCASTD zmm1 {k1}{z}| xmm2/m32, 16b 32b 64b L512 W0 op=zmm_reg;xmm_or_mem tt=Tuple1_Scalar k z
VEX_Vpbroadcastq_xmm_xmmm64, VEX, 66, 0F38, 59, VEX.128.66.0F38.W0 59 /r, VPBROADCASTQ xmm1| xmm2/m64, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
VEX_Vpbroadcastq_ymm_xmmm64, VEX, 66, 0F38, 59, VEX.256.66.0F38.W0 59 /r, VPBROADCASTQ ymm1| xmm2/m64, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem
EVEX_Vbroadcasti32x2_xmm_k1z_xmmm64, EVEX, 66, 0F38, 59, EVEX.128.66.0F38.W0 59 /r, VBROADCASTI32X2 xmm1 {k1}{z}| xmm2/m64, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Tuple2 k z
EVEX_Vbroadcasti32x2_ymm_k1z_xmmm64, EVEX, 66, 0F38, 59, EVEX.256.66.0F38.W0 59 /r, VBROADCASTI32X2 ymm1 {k1}{z}| xmm2/m64, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem tt=Tuple2 k z
EVEX_Vbroadcasti32x2_zmm_k1z_xmmm64, EVEX, 66, 0F38, 59, EVEX.512.66.0F38.W0 59 /r, VBROADCASTI32X2 zmm1 {k1}{z}| xmm2/m64, 16b 32b 64b L512 W0 op=zmm_reg;xmm_or_mem tt=Tuple2 k z
EVEX_Vpbroadcastq_xmm_k1z_xmmm64, EVEX, 66, 0F38, 59, EVEX.128.66.0F38.W1 59 /r, VPBROADCASTQ xmm1 {k1}{z}| xmm2/m64, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vpbroadcastq_ymm_k1z_xmmm64, EVEX, 66, 0F38, 59, EVEX.256.66.0F38.W1 59 /r, VPBROADCASTQ ymm1 {k1}{z}| xmm2/m64, 16b 32b 64b L256 W1 op=ymm_reg;xmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vpbroadcastq_zmm_k1z_xmmm64, EVEX, 66, 0F38, 59, EVEX.512.66.0F38.W1 59 /r, VPBROADCASTQ zmm1 {k1}{z}| xmm2/m64, 16b 32b 64b L512 W1 op=zmm_reg;xmm_or_mem tt=Tuple1_Scalar k z
VEX_Vbroadcasti128_ymm_m128, VEX, 66, 0F38, 5A, VEX.256.66.0F38.W0 5A /r, VBROADCASTI128 ymm1| m128, 16b 32b 64b L256 W0 op=ymm_reg;mem
EVEX_Vbroadcasti32x4_ymm_k1z_m128, EVEX, 66, 0F38, 5A, EVEX.256.66.0F38.W0 5A /r, VBROADCASTI32X4 ymm1 {k1}{z}| m128, 16b 32b 64b L256 W0 op=ymm_reg;mem tt=Tuple4 k z
EVEX_Vbroadcasti32x4_zmm_k1z_m128, EVEX, 66, 0F38, 5A, EVEX.512.66.0F38.W0 5A /r, VBROADCASTI32X4 zmm1 {k1}{z}| m128, 16b 32b 64b L512 W0 op=zmm_reg;mem tt=Tuple4 k z
EVEX_Vbroadcasti64x2_ymm_k1z_m128, EVEX, 66, 0F38, 5A, EVEX.256.66.0F38.W1 5A /r, VBROADCASTI64X2 ymm1 {k1}{z}| m128, 16b 32b 64b L256 W1 op=ymm_reg;mem tt=Tuple2 k z
EVEX_Vbroadcasti64x2_zmm_k1z_m128, EVEX, 66, 0F38, 5A, EVEX.512.66.0F38.W1 5A /r, VBROADCASTI64X2 zmm1 {k1}{z}| m128, 16b 32b 64b L512 W1 op=zmm_reg;mem tt=Tuple2 k z
EVEX_Vbroadcasti32x8_zmm_k1z_m256, EVEX, 66, 0F38, 5B, EVEX.512.66.0F38.W0 5B /r, VBROADCASTI32X8 zmm1 {k1}{z}| m256, 16b 32b 64b L512 W0 op=zmm_reg;mem tt=Tuple8 k z
EVEX_Vbroadcasti64x4_zmm_k1z_m256, EVEX, 66, 0F38, 5B, EVEX.512.66.0F38.W1 5B /r, VBROADCASTI64X4 zmm1 {k1}{z}| m256, 16b 32b 64b L512 W1 op=zmm_reg;mem tt=Tuple4 k z
EVEX_Vpexpandb_xmm_k1z_xmmm128, EVEX, 66, 0F38, 62, EVEX.128.66.0F38.W0 62 /r, VPEXPANDB xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Tuple1_Scalar_1 k z
EVEX_Vpexpandb_ymm_k1z_ymmm256, EVEX, 66, 0F38, 62, EVEX.256.66.0F38.W0 62 /r, VPEXPANDB ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Tuple1_Scalar_1 k z
EVEX_Vpexpandb_zmm_k1z_zmmm512, EVEX, 66, 0F38, 62, EVEX.512.66.0F38.W0 62 /r, VPEXPANDB zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Tuple1_Scalar_1 k z
EVEX_Vpexpandw_xmm_k1z_xmmm128, EVEX, 66, 0F38, 62, EVEX.128.66.0F38.W1 62 /r, VPEXPANDW xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Tuple1_Scalar_2 k z
EVEX_Vpexpandw_ymm_k1z_ymmm256, EVEX, 66, 0F38, 62, EVEX.256.66.0F38.W1 62 /r, VPEXPANDW ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Tuple1_Scalar_2 k z
EVEX_Vpexpandw_zmm_k1z_zmmm512, EVEX, 66, 0F38, 62, EVEX.512.66.0F38.W1 62 /r, VPEXPANDW zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Tuple1_Scalar_2 k z
EVEX_Vpcompressb_xmmm128_k1z_xmm, EVEX, 66, 0F38, 63, EVEX.128.66.0F38.W0 63 /r, VPCOMPRESSB xmm1/m128 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Tuple1_Scalar_1 k z
EVEX_Vpcompressb_ymmm256_k1z_ymm, EVEX, 66, 0F38, 63, EVEX.256.66.0F38.W0 63 /r, VPCOMPRESSB ymm1/m256 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=ymm_or_mem;ymm_reg tt=Tuple1_Scalar_1 k z
EVEX_Vpcompressb_zmmm512_k1z_zmm, EVEX, 66, 0F38, 63, EVEX.512.66.0F38.W0 63 /r, VPCOMPRESSB zmm1/m512 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=zmm_or_mem;zmm_reg tt=Tuple1_Scalar_1 k z
EVEX_Vpcompressw_xmmm128_k1z_xmm, EVEX, 66, 0F38, 63, EVEX.128.66.0F38.W1 63 /r, VPCOMPRESSW xmm1/m128 {k1}{z}| xmm2, 16b 32b 64b L128 W1 op=xmm_or_mem;xmm_reg tt=Tuple1_Scalar_2 k z
EVEX_Vpcompressw_ymmm256_k1z_ymm, EVEX, 66, 0F38, 63, EVEX.256.66.0F38.W1 63 /r, VPCOMPRESSW ymm1/m256 {k1}{z}| ymm2, 16b 32b 64b L256 W1 op=ymm_or_mem;ymm_reg tt=Tuple1_Scalar_2 k z
EVEX_Vpcompressw_zmmm512_k1z_zmm, EVEX, 66, 0F38, 63, EVEX.512.66.0F38.W1 63 /r, VPCOMPRESSW zmm1/m512 {k1}{z}| zmm2, 16b 32b 64b L512 W1 op=zmm_or_mem;zmm_reg tt=Tuple1_Scalar_2 k z
EVEX_Vpblendmd_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 64, EVEX.128.66.0F38.W0 64 /r, VPBLENDMD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpblendmd_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 64, EVEX.256.66.0F38.W0 64 /r, VPBLENDMD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpblendmd_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 64, EVEX.512.66.0F38.W0 64 /r, VPBLENDMD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpblendmq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 64, EVEX.128.66.0F38.W1 64 /r, VPBLENDMQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpblendmq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 64, EVEX.256.66.0F38.W1 64 /r, VPBLENDMQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpblendmq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 64, EVEX.512.66.0F38.W1 64 /r, VPBLENDMQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vblendmps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 65, EVEX.128.66.0F38.W0 65 /r, VBLENDMPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vblendmps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 65, EVEX.256.66.0F38.W0 65 /r, VBLENDMPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vblendmps_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 65, EVEX.512.66.0F38.W0 65 /r, VBLENDMPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vblendmpd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 65, EVEX.128.66.0F38.W1 65 /r, VBLENDMPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vblendmpd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 65, EVEX.256.66.0F38.W1 65 /r, VBLENDMPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vblendmpd_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 65, EVEX.512.66.0F38.W1 65 /r, VBLENDMPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpblendmb_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 66, EVEX.128.66.0F38.W0 66 /r, VPBLENDMB xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpblendmb_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 66, EVEX.256.66.0F38.W0 66 /r, VPBLENDMB ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpblendmb_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 66, EVEX.512.66.0F38.W0 66 /r, VPBLENDMB zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vpblendmw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 66, EVEX.128.66.0F38.W1 66 /r, VPBLENDMW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpblendmw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 66, EVEX.256.66.0F38.W1 66 /r, VPBLENDMW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpblendmw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 66, EVEX.512.66.0F38.W1 66 /r, VPBLENDMW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vp2intersectd_kp1_xmm_xmmm128b32, EVEX, F2, 0F38, 68, EVEX.128.F2.0F38.W0 68 /r, VP2INTERSECTD k1+1| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=kp1_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b
EVEX_Vp2intersectd_kp1_ymm_ymmm256b32, EVEX, F2, 0F38, 68, EVEX.256.F2.0F38.W0 68 /r, VP2INTERSECTD k1+1| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=kp1_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b
EVEX_Vp2intersectd_kp1_zmm_zmmm512b32, EVEX, F2, 0F38, 68, EVEX.512.F2.0F38.W0 68 /r, VP2INTERSECTD k1+1| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=kp1_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b
EVEX_Vp2intersectq_kp1_xmm_xmmm128b64, EVEX, F2, 0F38, 68, EVEX.128.F2.0F38.W1 68 /r, VP2INTERSECTQ k1+1| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=kp1_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b
EVEX_Vp2intersectq_kp1_ymm_ymmm256b64, EVEX, F2, 0F38, 68, EVEX.256.F2.0F38.W1 68 /r, VP2INTERSECTQ k1+1| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=kp1_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b
EVEX_Vp2intersectq_kp1_zmm_zmmm512b64, EVEX, F2, 0F38, 68, EVEX.512.F2.0F38.W1 68 /r, VP2INTERSECTQ k1+1| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=kp1_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b
EVEX_Vpshldvw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 70, EVEX.128.66.0F38.W1 70 /r, VPSHLDVW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpshldvw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 70, EVEX.256.66.0F38.W1 70 /r, VPSHLDVW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpshldvw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 70, EVEX.512.66.0F38.W1 70 /r, VPSHLDVW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vpshldvd_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 71, EVEX.128.66.0F38.W0 71 /r, VPSHLDVD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpshldvd_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 71, EVEX.256.66.0F38.W0 71 /r, VPSHLDVD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpshldvd_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 71, EVEX.512.66.0F38.W0 71 /r, VPSHLDVD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpshldvq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 71, EVEX.128.66.0F38.W1 71 /r, VPSHLDVQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpshldvq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 71, EVEX.256.66.0F38.W1 71 /r, VPSHLDVQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpshldvq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 71, EVEX.512.66.0F38.W1 71 /r, VPSHLDVQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpshrdvw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 72, EVEX.128.66.0F38.W1 72 /r, VPSHRDVW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpshrdvw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 72, EVEX.256.66.0F38.W1 72 /r, VPSHRDVW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpshrdvw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 72, EVEX.512.66.0F38.W1 72 /r, VPSHRDVW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vcvtneps2bf16_xmm_k1z_xmmm128b32, EVEX, F3, 0F38, 72, EVEX.128.F3.0F38.W0 72 /r, VCVTNEPS2BF16 xmm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvtneps2bf16_xmm_k1z_ymmm256b32, EVEX, F3, 0F38, 72, EVEX.256.F3.0F38.W0 72 /r, VCVTNEPS2BF16 xmm1 {k1}{z}| ymm2/m256/m32bcst, 16b 32b 64b L256 W0 op=xmm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvtneps2bf16_ymm_k1z_zmmm512b32, EVEX, F3, 0F38, 72, EVEX.512.F3.0F38.W0 72 /r, VCVTNEPS2BF16 ymm1 {k1}{z}| zmm2/m512/m32bcst, 16b 32b 64b L512 W0 op=ymm_reg;zmm_or_mem tt=Full_512 b k z
EVEX_Vcvtne2ps2bf16_xmm_k1z_xmm_xmmm128b32, EVEX, F2, 0F38, 72, EVEX.128.F2.0F38.W0 72 /r, VCVTNE2PS2BF16 xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vcvtne2ps2bf16_ymm_k1z_ymm_ymmm256b32, EVEX, F2, 0F38, 72, EVEX.256.F2.0F38.W0 72 /r, VCVTNE2PS2BF16 ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vcvtne2ps2bf16_zmm_k1z_zmm_zmmm512b32, EVEX, F2, 0F38, 72, EVEX.512.F2.0F38.W0 72 /r, VCVTNE2PS2BF16 zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpshrdvd_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 73, EVEX.128.66.0F38.W0 73 /r, VPSHRDVD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpshrdvd_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 73, EVEX.256.66.0F38.W0 73 /r, VPSHRDVD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpshrdvd_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 73, EVEX.512.66.0F38.W0 73 /r, VPSHRDVD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpshrdvq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 73, EVEX.128.66.0F38.W1 73 /r, VPSHRDVQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpshrdvq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 73, EVEX.256.66.0F38.W1 73 /r, VPSHRDVQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpshrdvq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 73, EVEX.512.66.0F38.W1 73 /r, VPSHRDVQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpermi2b_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 75, EVEX.128.66.0F38.W0 75 /r, VPERMI2B xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpermi2b_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 75, EVEX.256.66.0F38.W0 75 /r, VPERMI2B ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpermi2b_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 75, EVEX.512.66.0F38.W0 75 /r, VPERMI2B zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vpermi2w_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 75, EVEX.128.66.0F38.W1 75 /r, VPERMI2W xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpermi2w_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 75, EVEX.256.66.0F38.W1 75 /r, VPERMI2W ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpermi2w_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 75, EVEX.512.66.0F38.W1 75 /r, VPERMI2W zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vpermi2d_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 76, EVEX.128.66.0F38.W0 76 /r, VPERMI2D xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpermi2d_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 76, EVEX.256.66.0F38.W0 76 /r, VPERMI2D ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpermi2d_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 76, EVEX.512.66.0F38.W0 76 /r, VPERMI2D zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpermi2q_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 76, EVEX.128.66.0F38.W1 76 /r, VPERMI2Q xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpermi2q_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 76, EVEX.256.66.0F38.W1 76 /r, VPERMI2Q ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpermi2q_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 76, EVEX.512.66.0F38.W1 76 /r, VPERMI2Q zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpermi2ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 77, EVEX.128.66.0F38.W0 77 /r, VPERMI2PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpermi2ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 77, EVEX.256.66.0F38.W0 77 /r, VPERMI2PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpermi2ps_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 77, EVEX.512.66.0F38.W0 77 /r, VPERMI2PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpermi2pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 77, EVEX.128.66.0F38.W1 77 /r, VPERMI2PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpermi2pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 77, EVEX.256.66.0F38.W1 77 /r, VPERMI2PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpermi2pd_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 77, EVEX.512.66.0F38.W1 77 /r, VPERMI2PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
VEX_Vpbroadcastb_xmm_xmmm8, VEX, 66, 0F38, 78, VEX.128.66.0F38.W0 78 /r, VPBROADCASTB xmm1| xmm2/m8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
VEX_Vpbroadcastb_ymm_xmmm8, VEX, 66, 0F38, 78, VEX.256.66.0F38.W0 78 /r, VPBROADCASTB ymm1| xmm2/m8, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem
EVEX_Vpbroadcastb_xmm_k1z_xmmm8, EVEX, 66, 0F38, 78, EVEX.128.66.0F38.W0 78 /r, VPBROADCASTB xmm1 {k1}{z}| xmm2/m8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Tuple1_Scalar_1 k z
EVEX_Vpbroadcastb_ymm_k1z_xmmm8, EVEX, 66, 0F38, 78, EVEX.256.66.0F38.W0 78 /r, VPBROADCASTB ymm1 {k1}{z}| xmm2/m8, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem tt=Tuple1_Scalar_1 k z
EVEX_Vpbroadcastb_zmm_k1z_xmmm8, EVEX, 66, 0F38, 78, EVEX.512.66.0F38.W0 78 /r, VPBROADCASTB zmm1 {k1}{z}| xmm2/m8, 16b 32b 64b L512 W0 op=zmm_reg;xmm_or_mem tt=Tuple1_Scalar_1 k z
VEX_Vpbroadcastw_xmm_xmmm16, VEX, 66, 0F38, 79, VEX.128.66.0F38.W0 79 /r, VPBROADCASTW xmm1| xmm2/m16, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
VEX_Vpbroadcastw_ymm_xmmm16, VEX, 66, 0F38, 79, VEX.256.66.0F38.W0 79 /r, VPBROADCASTW ymm1| xmm2/m16, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem
EVEX_Vpbroadcastw_xmm_k1z_xmmm16, EVEX, 66, 0F38, 79, EVEX.128.66.0F38.W0 79 /r, VPBROADCASTW xmm1 {k1}{z}| xmm2/m16, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Tuple1_Scalar_2 k z
EVEX_Vpbroadcastw_ymm_k1z_xmmm16, EVEX, 66, 0F38, 79, EVEX.256.66.0F38.W0 79 /r, VPBROADCASTW ymm1 {k1}{z}| xmm2/m16, 16b 32b 64b L256 W0 op=ymm_reg;xmm_or_mem tt=Tuple1_Scalar_2 k z
EVEX_Vpbroadcastw_zmm_k1z_xmmm16, EVEX, 66, 0F38, 79, EVEX.512.66.0F38.W0 79 /r, VPBROADCASTW zmm1 {k1}{z}| xmm2/m16, 16b 32b 64b L512 W0 op=zmm_reg;xmm_or_mem tt=Tuple1_Scalar_2 k z
EVEX_Vpbroadcastb_xmm_k1z_r32, EVEX, 66, 0F38, 7A, EVEX.128.66.0F38.W0 7A /r, VPBROADCASTB xmm1 {k1}{z}| r32, 16b 32b 64b L128 W0 op=xmm_reg;r32_rm k z
EVEX_Vpbroadcastb_ymm_k1z_r32, EVEX, 66, 0F38, 7A, EVEX.256.66.0F38.W0 7A /r, VPBROADCASTB ymm1 {k1}{z}| r32, 16b 32b 64b L256 W0 op=ymm_reg;r32_rm k z
EVEX_Vpbroadcastb_zmm_k1z_r32, EVEX, 66, 0F38, 7A, EVEX.512.66.0F38.W0 7A /r, VPBROADCASTB zmm1 {k1}{z}| r32, 16b 32b 64b L512 W0 op=zmm_reg;r32_rm k z
EVEX_Vpbroadcastw_xmm_k1z_r32, EVEX, 66, 0F38, 7B, EVEX.128.66.0F38.W0 7B /r, VPBROADCASTW xmm1 {k1}{z}| r32, 16b 32b 64b L128 W0 op=xmm_reg;r32_rm k z
EVEX_Vpbroadcastw_ymm_k1z_r32, EVEX, 66, 0F38, 7B, EVEX.256.66.0F38.W0 7B /r, VPBROADCASTW ymm1 {k1}{z}| r32, 16b 32b 64b L256 W0 op=ymm_reg;r32_rm k z
EVEX_Vpbroadcastw_zmm_k1z_r32, EVEX, 66, 0F38, 7B, EVEX.512.66.0F38.W0 7B /r, VPBROADCASTW zmm1 {k1}{z}| r32, 16b 32b 64b L512 W0 op=zmm_reg;r32_rm k z
EVEX_Vpbroadcastd_xmm_k1z_r32, EVEX, 66, 0F38, 7C, EVEX.128.66.0F38.W0 7C /r, VPBROADCASTD xmm1 {k1}{z}| r32, 16b 32b 64b L128 WIG32 op=xmm_reg;r32_rm k z
EVEX_Vpbroadcastd_ymm_k1z_r32, EVEX, 66, 0F38, 7C, EVEX.256.66.0F38.W0 7C /r, VPBROADCASTD ymm1 {k1}{z}| r32, 16b 32b 64b L256 WIG32 op=ymm_reg;r32_rm k z
EVEX_Vpbroadcastd_zmm_k1z_r32, EVEX, 66, 0F38, 7C, EVEX.512.66.0F38.W0 7C /r, VPBROADCASTD zmm1 {k1}{z}| r32, 16b 32b 64b L512 WIG32 op=zmm_reg;r32_rm k z
EVEX_Vpbroadcastq_xmm_k1z_r64, EVEX, 66, 0F38, 7C, EVEX.128.66.0F38.W1 7C /r, VPBROADCASTQ xmm1 {k1}{z}| r64, 64b L128 W1 op=xmm_reg;r64_rm k z
EVEX_Vpbroadcastq_ymm_k1z_r64, EVEX, 66, 0F38, 7C, EVEX.256.66.0F38.W1 7C /r, VPBROADCASTQ ymm1 {k1}{z}| r64, 64b L256 W1 op=ymm_reg;r64_rm k z
EVEX_Vpbroadcastq_zmm_k1z_r64, EVEX, 66, 0F38, 7C, EVEX.512.66.0F38.W1 7C /r, VPBROADCASTQ zmm1 {k1}{z}| r64, 64b L512 W1 op=zmm_reg;r64_rm k z
EVEX_Vpermt2b_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 7D, EVEX.128.66.0F38.W0 7D /r, VPERMT2B xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpermt2b_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 7D, EVEX.256.66.0F38.W0 7D /r, VPERMT2B ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpermt2b_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 7D, EVEX.512.66.0F38.W0 7D /r, VPERMT2B zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vpermt2w_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 7D, EVEX.128.66.0F38.W1 7D /r, VPERMT2W xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpermt2w_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 7D, EVEX.256.66.0F38.W1 7D /r, VPERMT2W ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpermt2w_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 7D, EVEX.512.66.0F38.W1 7D /r, VPERMT2W zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vpermt2d_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 7E, EVEX.128.66.0F38.W0 7E /r, VPERMT2D xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpermt2d_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 7E, EVEX.256.66.0F38.W0 7E /r, VPERMT2D ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpermt2d_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 7E, EVEX.512.66.0F38.W0 7E /r, VPERMT2D zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpermt2q_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 7E, EVEX.128.66.0F38.W1 7E /r, VPERMT2Q xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpermt2q_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 7E, EVEX.256.66.0F38.W1 7E /r, VPERMT2Q ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpermt2q_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 7E, EVEX.512.66.0F38.W1 7E /r, VPERMT2Q zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpermt2ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 7F, EVEX.128.66.0F38.W0 7F /r, VPERMT2PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpermt2ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 7F, EVEX.256.66.0F38.W0 7F /r, VPERMT2PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpermt2ps_zmm_k1z_zmm_zmmm512b32, EVEX, 66, 0F38, 7F, EVEX.512.66.0F38.W0 7F /r, VPERMT2PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpermt2pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 7F, EVEX.128.66.0F38.W1 7F /r, VPERMT2PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpermt2pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 7F, EVEX.256.66.0F38.W1 7F /r, VPERMT2PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpermt2pd_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 7F, EVEX.512.66.0F38.W1 7F /r, VPERMT2PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
Invept_r32_m128, legacy, 66, 0F38, 80, 66 0F 38 80 /r, INVEPT r32| m128, 16b 32b op=r32_reg;mem
Invept_r64_m128, legacy, 66, 0F38, 80, 66 0F 38 80 /r, INVEPT r64| m128, 64b op=r64_reg;mem
Invvpid_r32_m128, legacy, 66, 0F38, 81, 66 0F 38 81 /r, INVVPID r32| m128, 16b 32b op=r32_reg;mem
Invvpid_r64_m128, legacy, 66, 0F38, 81, 66 0F 38 81 /r, INVVPID r64| m128, 64b op=r64_reg;mem
Invpcid_r32_m128, legacy, 66, 0F38, 82, 66 0F 38 82 /r, INVPCID r32| m128, 16b 32b op=r32_reg;mem
Invpcid_r64_m128, legacy, 66, 0F38, 82, 66 0F 38 82 /r, INVPCID r64| m128, 64b op=r64_reg;mem
EVEX_Vpmultishiftqb_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 83, EVEX.128.66.0F38.W1 83 /r, VPMULTISHIFTQB xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpmultishiftqb_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 83, EVEX.256.66.0F38.W1 83 /r, VPMULTISHIFTQB ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpmultishiftqb_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, 83, EVEX.512.66.0F38.W1 83 /r, VPMULTISHIFTQB zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vexpandps_xmm_k1z_xmmm128, EVEX, 66, 0F38, 88, EVEX.128.66.0F38.W0 88 /r, VEXPANDPS xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vexpandps_ymm_k1z_ymmm256, EVEX, 66, 0F38, 88, EVEX.256.66.0F38.W0 88 /r, VEXPANDPS ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Tuple1_Scalar k z
EVEX_Vexpandps_zmm_k1z_zmmm512, EVEX, 66, 0F38, 88, EVEX.512.66.0F38.W0 88 /r, VEXPANDPS zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vexpandpd_xmm_k1z_xmmm128, EVEX, 66, 0F38, 88, EVEX.128.66.0F38.W1 88 /r, VEXPANDPD xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vexpandpd_ymm_k1z_ymmm256, EVEX, 66, 0F38, 88, EVEX.256.66.0F38.W1 88 /r, VEXPANDPD ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Tuple1_Scalar k z
EVEX_Vexpandpd_zmm_k1z_zmmm512, EVEX, 66, 0F38, 88, EVEX.512.66.0F38.W1 88 /r, VEXPANDPD zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vpexpandd_xmm_k1z_xmmm128, EVEX, 66, 0F38, 89, EVEX.128.66.0F38.W0 89 /r, VPEXPANDD xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vpexpandd_ymm_k1z_ymmm256, EVEX, 66, 0F38, 89, EVEX.256.66.0F38.W0 89 /r, VPEXPANDD ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Tuple1_Scalar k z
EVEX_Vpexpandd_zmm_k1z_zmmm512, EVEX, 66, 0F38, 89, EVEX.512.66.0F38.W0 89 /r, VPEXPANDD zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vpexpandq_xmm_k1z_xmmm128, EVEX, 66, 0F38, 89, EVEX.128.66.0F38.W1 89 /r, VPEXPANDQ xmm1 {k1}{z}| xmm2/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vpexpandq_ymm_k1z_ymmm256, EVEX, 66, 0F38, 89, EVEX.256.66.0F38.W1 89 /r, VPEXPANDQ ymm1 {k1}{z}| ymm2/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Tuple1_Scalar k z
EVEX_Vpexpandq_zmm_k1z_zmmm512, EVEX, 66, 0F38, 89, EVEX.512.66.0F38.W1 89 /r, VPEXPANDQ zmm1 {k1}{z}| zmm2/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Tuple1_Scalar k z
EVEX_Vcompressps_xmmm128_k1z_xmm, EVEX, 66, 0F38, 8A, EVEX.128.66.0F38.W0 8A /r, VCOMPRESSPS xmm1/m128 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Tuple1_Scalar k z
EVEX_Vcompressps_ymmm256_k1z_ymm, EVEX, 66, 0F38, 8A, EVEX.256.66.0F38.W0 8A /r, VCOMPRESSPS ymm1/m256 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=ymm_or_mem;ymm_reg tt=Tuple1_Scalar k z
EVEX_Vcompressps_zmmm512_k1z_zmm, EVEX, 66, 0F38, 8A, EVEX.512.66.0F38.W0 8A /r, VCOMPRESSPS zmm1/m512 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=zmm_or_mem;zmm_reg tt=Tuple1_Scalar k z
EVEX_Vcompresspd_xmmm128_k1z_xmm, EVEX, 66, 0F38, 8A, EVEX.128.66.0F38.W1 8A /r, VCOMPRESSPD xmm1/m128 {k1}{z}| xmm2, 16b 32b 64b L128 W1 op=xmm_or_mem;xmm_reg tt=Tuple1_Scalar k z
EVEX_Vcompresspd_ymmm256_k1z_ymm, EVEX, 66, 0F38, 8A, EVEX.256.66.0F38.W1 8A /r, VCOMPRESSPD ymm1/m256 {k1}{z}| ymm2, 16b 32b 64b L256 W1 op=ymm_or_mem;ymm_reg tt=Tuple1_Scalar k z
EVEX_Vcompresspd_zmmm512_k1z_zmm, EVEX, 66, 0F38, 8A, EVEX.512.66.0F38.W1 8A /r, VCOMPRESSPD zmm1/m512 {k1}{z}| zmm2, 16b 32b 64b L512 W1 op=zmm_or_mem;zmm_reg tt=Tuple1_Scalar k z
EVEX_Vpcompressd_xmmm128_k1z_xmm, EVEX, 66, 0F38, 8B, EVEX.128.66.0F38.W0 8B /r, VPCOMPRESSD xmm1/m128 {k1}{z}| xmm2, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg tt=Tuple1_Scalar k z
EVEX_Vpcompressd_ymmm256_k1z_ymm, EVEX, 66, 0F38, 8B, EVEX.256.66.0F38.W0 8B /r, VPCOMPRESSD ymm1/m256 {k1}{z}| ymm2, 16b 32b 64b L256 W0 op=ymm_or_mem;ymm_reg tt=Tuple1_Scalar k z
EVEX_Vpcompressd_zmmm512_k1z_zmm, EVEX, 66, 0F38, 8B, EVEX.512.66.0F38.W0 8B /r, VPCOMPRESSD zmm1/m512 {k1}{z}| zmm2, 16b 32b 64b L512 W0 op=zmm_or_mem;zmm_reg tt=Tuple1_Scalar k z
EVEX_Vpcompressq_xmmm128_k1z_xmm, EVEX, 66, 0F38, 8B, EVEX.128.66.0F38.W1 8B /r, VPCOMPRESSQ xmm1/m128 {k1}{z}| xmm2, 16b 32b 64b L128 W1 op=xmm_or_mem;xmm_reg tt=Tuple1_Scalar k z
EVEX_Vpcompressq_ymmm256_k1z_ymm, EVEX, 66, 0F38, 8B, EVEX.256.66.0F38.W1 8B /r, VPCOMPRESSQ ymm1/m256 {k1}{z}| ymm2, 16b 32b 64b L256 W1 op=ymm_or_mem;ymm_reg tt=Tuple1_Scalar k z
EVEX_Vpcompressq_zmmm512_k1z_zmm, EVEX, 66, 0F38, 8B, EVEX.512.66.0F38.W1 8B /r, VPCOMPRESSQ zmm1/m512 {k1}{z}| zmm2, 16b 32b 64b L512 W1 op=zmm_or_mem;zmm_reg tt=Tuple1_Scalar k z
VEX_Vpmaskmovd_xmm_xmm_m128, VEX, 66, 0F38, 8C, VEX.128.66.0F38.W0 8C /r, VPMASKMOVD xmm1| xmm2| m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;mem
VEX_Vpmaskmovd_ymm_ymm_m256, VEX, 66, 0F38, 8C, VEX.256.66.0F38.W0 8C /r, VPMASKMOVD ymm1| ymm2| m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;mem
VEX_Vpmaskmovq_xmm_xmm_m128, VEX, 66, 0F38, 8C, VEX.128.66.0F38.W1 8C /r, VPMASKMOVQ xmm1| xmm2| m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;mem
VEX_Vpmaskmovq_ymm_ymm_m256, VEX, 66, 0F38, 8C, VEX.256.66.0F38.W1 8C /r, VPMASKMOVQ ymm1| ymm2| m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;mem
EVEX_Vpermb_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 8D, EVEX.128.66.0F38.W0 8D /r, VPERMB xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpermb_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 8D, EVEX.256.66.0F38.W0 8D /r, VPERMB ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpermb_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 8D, EVEX.512.66.0F38.W0 8D /r, VPERMB zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
EVEX_Vpermw_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, 8D, EVEX.128.66.0F38.W1 8D /r, VPERMW xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vpermw_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, 8D, EVEX.256.66.0F38.W1 8D /r, VPERMW ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vpermw_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, 8D, EVEX.512.66.0F38.W1 8D /r, VPERMW zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
VEX_Vpmaskmovd_m128_xmm_xmm, VEX, 66, 0F38, 8E, VEX.128.66.0F38.W0 8E /r, VPMASKMOVD m128| xmm1| xmm2, 16b 32b 64b L128 W0 op=mem;xmm_vvvv;xmm_reg
VEX_Vpmaskmovd_m256_ymm_ymm, VEX, 66, 0F38, 8E, VEX.256.66.0F38.W0 8E /r, VPMASKMOVD m256| ymm1| ymm2, 16b 32b 64b L256 W0 op=mem;ymm_vvvv;ymm_reg
VEX_Vpmaskmovq_m128_xmm_xmm, VEX, 66, 0F38, 8E, VEX.128.66.0F38.W1 8E /r, VPMASKMOVQ m128| xmm1| xmm2, 16b 32b 64b L128 W1 op=mem;xmm_vvvv;xmm_reg
VEX_Vpmaskmovq_m256_ymm_ymm, VEX, 66, 0F38, 8E, VEX.256.66.0F38.W1 8E /r, VPMASKMOVQ m256| ymm1| ymm2, 16b 32b 64b L256 W1 op=mem;ymm_vvvv;ymm_reg
EVEX_Vpshufbitqmb_k_k1_xmm_xmmm128, EVEX, 66, 0F38, 8F, EVEX.128.66.0F38.W0 8F /r, VPSHUFBITQMB k1 {k2}| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=k_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k
EVEX_Vpshufbitqmb_k_k1_ymm_ymmm256, EVEX, 66, 0F38, 8F, EVEX.256.66.0F38.W0 8F /r, VPSHUFBITQMB k1 {k2}| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=k_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k
EVEX_Vpshufbitqmb_k_k1_zmm_zmmm512, EVEX, 66, 0F38, 8F, EVEX.512.66.0F38.W0 8F /r, VPSHUFBITQMB k1 {k2}| zmm2| zmm3/m512, 16b 32b 64b L512 W0 op=k_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k
VEX_Vpgatherdd_xmm_vm32x_xmm, VEX, 66, 0F38, 90, VEX.128.66.0F38.W0 90 /r, VPGATHERDD xmm1| vm32x| xmm2, 16b 32b 64b L128 W0 op=xmm_reg;mem_vsib32x;xmm_vvvv
VEX_Vpgatherdd_ymm_vm32y_ymm, VEX, 66, 0F38, 90, VEX.256.66.0F38.W0 90 /r, VPGATHERDD ymm1| vm32y| ymm2, 16b 32b 64b L256 W0 op=ymm_reg;mem_vsib32y;ymm_vvvv
VEX_Vpgatherdq_xmm_vm32x_xmm, VEX, 66, 0F38, 90, VEX.128.66.0F38.W1 90 /r, VPGATHERDQ xmm1| vm32x| xmm2, 16b 32b 64b L128 W1 op=xmm_reg;mem_vsib32x;xmm_vvvv
VEX_Vpgatherdq_ymm_vm32x_ymm, VEX, 66, 0F38, 90, VEX.256.66.0F38.W1 90 /r, VPGATHERDQ ymm1| vm32x| ymm2, 16b 32b 64b L256 W1 op=ymm_reg;mem_vsib32x;ymm_vvvv
EVEX_Vpgatherdd_xmm_k1_vm32x, EVEX, 66, 0F38, 90, EVEX.128.66.0F38.W0 90 /vsib, VPGATHERDD xmm1 {k1}| vm32x, 16b 32b 64b L128 W0 op=xmm_reg;mem_vsib32x tt=Tuple1_Scalar knz
EVEX_Vpgatherdd_ymm_k1_vm32y, EVEX, 66, 0F38, 90, EVEX.256.66.0F38.W0 90 /vsib, VPGATHERDD ymm1 {k1}| vm32y, 16b 32b 64b L256 W0 op=ymm_reg;mem_vsib32y tt=Tuple1_Scalar knz
EVEX_Vpgatherdd_zmm_k1_vm32z, EVEX, 66, 0F38, 90, EVEX.512.66.0F38.W0 90 /vsib, VPGATHERDD zmm1 {k1}| vm32z, 16b 32b 64b L512 W0 op=zmm_reg;mem_vsib32z tt=Tuple1_Scalar knz
EVEX_Vpgatherdq_xmm_k1_vm32x, EVEX, 66, 0F38, 90, EVEX.128.66.0F38.W1 90 /vsib, VPGATHERDQ xmm1 {k1}| vm32x, 16b 32b 64b L128 W1 op=xmm_reg;mem_vsib32x tt=Tuple1_Scalar knz
EVEX_Vpgatherdq_ymm_k1_vm32x, EVEX, 66, 0F38, 90, EVEX.256.66.0F38.W1 90 /vsib, VPGATHERDQ ymm1 {k1}| vm32x, 16b 32b 64b L256 W1 op=ymm_reg;mem_vsib32x tt=Tuple1_Scalar knz
EVEX_Vpgatherdq_zmm_k1_vm32y, EVEX, 66, 0F38, 90, EVEX.512.66.0F38.W1 90 /vsib, VPGATHERDQ zmm1 {k1}| vm32y, 16b 32b 64b L512 W1 op=zmm_reg;mem_vsib32y tt=Tuple1_Scalar knz
VEX_Vpgatherqd_xmm_vm64x_xmm, VEX, 66, 0F38, 91, VEX.128.66.0F38.W0 91 /r, VPGATHERQD xmm1| vm64x| xmm2, 16b 32b 64b L128 W0 op=xmm_reg;mem_vsib64x;xmm_vvvv
VEX_Vpgatherqd_xmm_vm64y_xmm, VEX, 66, 0F38, 91, VEX.256.66.0F38.W0 91 /r, VPGATHERQD xmm1| vm64y| xmm2, 16b 32b 64b L256 W0 op=xmm_reg;mem_vsib64y;xmm_vvvv
VEX_Vpgatherqq_xmm_vm64x_xmm, VEX, 66, 0F38, 91, VEX.128.66.0F38.W1 91 /r, VPGATHERQQ xmm1| vm64x| xmm2, 16b 32b 64b L128 W1 op=xmm_reg;mem_vsib64x;xmm_vvvv
VEX_Vpgatherqq_ymm_vm64y_ymm, VEX, 66, 0F38, 91, VEX.256.66.0F38.W1 91 /r, VPGATHERQQ ymm1| vm64y| ymm2, 16b 32b 64b L256 W1 op=ymm_reg;mem_vsib64y;ymm_vvvv
EVEX_Vpgatherqd_xmm_k1_vm64x, EVEX, 66, 0F38, 91, EVEX.128.66.0F38.W0 91 /vsib, VPGATHERQD xmm1 {k1}| vm64x, 16b 32b 64b L128 W0 op=xmm_reg;mem_vsib64x tt=Tuple1_Scalar knz
EVEX_Vpgatherqd_xmm_k1_vm64y, EVEX, 66, 0F38, 91, EVEX.256.66.0F38.W0 91 /vsib, VPGATHERQD xmm1 {k1}| vm64y, 16b 32b 64b L256 W0 op=xmm_reg;mem_vsib64y tt=Tuple1_Scalar knz
EVEX_Vpgatherqd_ymm_k1_vm64z, EVEX, 66, 0F38, 91, EVEX.512.66.0F38.W0 91 /vsib, VPGATHERQD ymm1 {k1}| vm64z, 16b 32b 64b L512 W0 op=ymm_reg;mem_vsib64z tt=Tuple1_Scalar knz
EVEX_Vpgatherqq_xmm_k1_vm64x, EVEX, 66, 0F38, 91, EVEX.128.66.0F38.W1 91 /vsib, VPGATHERQQ xmm1 {k1}| vm64x, 16b 32b 64b L128 W1 op=xmm_reg;mem_vsib64x tt=Tuple1_Scalar knz
EVEX_Vpgatherqq_ymm_k1_vm64y, EVEX, 66, 0F38, 91, EVEX.256.66.0F38.W1 91 /vsib, VPGATHERQQ ymm1 {k1}| vm64y, 16b 32b 64b L256 W1 op=ymm_reg;mem_vsib64y tt=Tuple1_Scalar knz
EVEX_Vpgatherqq_zmm_k1_vm64z, EVEX, 66, 0F38, 91, EVEX.512.66.0F38.W1 91 /vsib, VPGATHERQQ zmm1 {k1}| vm64z, 16b 32b 64b L512 W1 op=zmm_reg;mem_vsib64z tt=Tuple1_Scalar knz
VEX_Vgatherdps_xmm_vm32x_xmm, VEX, 66, 0F38, 92, VEX.128.66.0F38.W0 92 /r, VGATHERDPS xmm1| vm32x| xmm2, 16b 32b 64b L128 W0 op=xmm_reg;mem_vsib32x;xmm_vvvv
VEX_Vgatherdps_ymm_vm32y_ymm, VEX, 66, 0F38, 92, VEX.256.66.0F38.W0 92 /r, VGATHERDPS ymm1| vm32y| ymm2, 16b 32b 64b L256 W0 op=ymm_reg;mem_vsib32y;ymm_vvvv
VEX_Vgatherdpd_xmm_vm32x_xmm, VEX, 66, 0F38, 92, VEX.128.66.0F38.W1 92 /r, VGATHERDPD xmm1| vm32x| xmm2, 16b 32b 64b L128 W1 op=xmm_reg;mem_vsib32x;xmm_vvvv
VEX_Vgatherdpd_ymm_vm32x_ymm, VEX, 66, 0F38, 92, VEX.256.66.0F38.W1 92 /r, VGATHERDPD ymm1| vm32x| ymm2, 16b 32b 64b L256 W1 op=ymm_reg;mem_vsib32x;ymm_vvvv
EVEX_Vgatherdps_xmm_k1_vm32x, EVEX, 66, 0F38, 92, EVEX.128.66.0F38.W0 92 /vsib, VGATHERDPS xmm1 {k1}| vm32x, 16b 32b 64b L128 W0 op=xmm_reg;mem_vsib32x tt=Tuple1_Scalar knz
EVEX_Vgatherdps_ymm_k1_vm32y, EVEX, 66, 0F38, 92, EVEX.256.66.0F38.W0 92 /vsib, VGATHERDPS ymm1 {k1}| vm32y, 16b 32b 64b L256 W0 op=ymm_reg;mem_vsib32y tt=Tuple1_Scalar knz
EVEX_Vgatherdps_zmm_k1_vm32z, EVEX, 66, 0F38, 92, EVEX.512.66.0F38.W0 92 /vsib, VGATHERDPS zmm1 {k1}| vm32z, 16b 32b 64b L512 W0 op=zmm_reg;mem_vsib32z tt=Tuple1_Scalar knz
EVEX_Vgatherdpd_xmm_k1_vm32x, EVEX, 66, 0F38, 92, EVEX.128.66.0F38.W1 92 /vsib, VGATHERDPD xmm1 {k1}| vm32x, 16b 32b 64b L128 W1 op=xmm_reg;mem_vsib32x tt=Tuple1_Scalar knz
EVEX_Vgatherdpd_ymm_k1_vm32x, EVEX, 66, 0F38, 92, EVEX.256.66.0F38.W1 92 /vsib, VGATHERDPD ymm1 {k1}| vm32x, 16b 32b 64b L256 W1 op=ymm_reg;mem_vsib32x tt=Tuple1_Scalar knz
EVEX_Vgatherdpd_zmm_k1_vm32y, EVEX, 66, 0F38, 92, EVEX.512.66.0F38.W1 92 /vsib, VGATHERDPD zmm1 {k1}| vm32y, 16b 32b 64b L512 W1 op=zmm_reg;mem_vsib32y tt=Tuple1_Scalar knz
VEX_Vgatherqps_xmm_vm64x_xmm, VEX, 66, 0F38, 93, VEX.128.66.0F38.W0 93 /r, VGATHERQPS xmm1| vm64x| xmm2, 16b 32b 64b L128 W0 op=xmm_reg;mem_vsib64x;xmm_vvvv
VEX_Vgatherqps_xmm_vm64y_xmm, VEX, 66, 0F38, 93, VEX.256.66.0F38.W0 93 /r, VGATHERQPS xmm1| vm64y| xmm2, 16b 32b 64b L256 W0 op=xmm_reg;mem_vsib64y;xmm_vvvv
VEX_Vgatherqpd_xmm_vm64x_xmm, VEX, 66, 0F38, 93, VEX.128.66.0F38.W1 93 /r, VGATHERQPD xmm1| vm64x| xmm2, 16b 32b 64b L128 W1 op=xmm_reg;mem_vsib64x;xmm_vvvv
VEX_Vgatherqpd_ymm_vm64y_ymm, VEX, 66, 0F38, 93, VEX.256.66.0F38.W1 93 /r, VGATHERQPD ymm1| vm64y| ymm2, 16b 32b 64b L256 W1 op=ymm_reg;mem_vsib64y;ymm_vvvv
EVEX_Vgatherqps_xmm_k1_vm64x, EVEX, 66, 0F38, 93, EVEX.128.66.0F38.W0 93 /vsib, VGATHERQPS xmm1 {k1}| vm64x, 16b 32b 64b L128 W0 op=xmm_reg;mem_vsib64x tt=Tuple1_Scalar knz
EVEX_Vgatherqps_xmm_k1_vm64y, EVEX, 66, 0F38, 93, EVEX.256.66.0F38.W0 93 /vsib, VGATHERQPS xmm1 {k1}| vm64y, 16b 32b 64b L256 W0 op=xmm_reg;mem_vsib64y tt=Tuple1_Scalar knz
EVEX_Vgatherqps_ymm_k1_vm64z, EVEX, 66, 0F38, 93, EVEX.512.66.0F38.W0 93 /vsib, VGATHERQPS ymm1 {k1}| vm64z, 16b 32b 64b L512 W0 op=ymm_reg;mem_vsib64z tt=Tuple1_Scalar knz
EVEX_Vgatherqpd_xmm_k1_vm64x, EVEX, 66, 0F38, 93, EVEX.128.66.0F38.W1 93 /vsib, VGATHERQPD xmm1 {k1}| vm64x, 16b 32b 64b L128 W1 op=xmm_reg;mem_vsib64x tt=Tuple1_Scalar knz
EVEX_Vgatherqpd_ymm_k1_vm64y, EVEX, 66, 0F38, 93, EVEX.256.66.0F38.W1 93 /vsib, VGATHERQPD ymm1 {k1}| vm64y, 16b 32b 64b L256 W1 op=ymm_reg;mem_vsib64y tt=Tuple1_Scalar knz
EVEX_Vgatherqpd_zmm_k1_vm64z, EVEX, 66, 0F38, 93, EVEX.512.66.0F38.W1 93 /vsib, VGATHERQPD zmm1 {k1}| vm64z, 16b 32b 64b L512 W1 op=zmm_reg;mem_vsib64z tt=Tuple1_Scalar knz
VEX_Vfmaddsub132ps_xmm_xmm_xmmm128, VEX, 66, 0F38, 96, VEX.128.66.0F38.W0 96 /r, VFMADDSUB132PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmaddsub132ps_ymm_ymm_ymmm256, VEX, 66, 0F38, 96, VEX.256.66.0F38.W0 96 /r, VFMADDSUB132PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfmaddsub132pd_xmm_xmm_xmmm128, VEX, 66, 0F38, 96, VEX.128.66.0F38.W1 96 /r, VFMADDSUB132PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmaddsub132pd_ymm_ymm_ymmm256, VEX, 66, 0F38, 96, VEX.256.66.0F38.W1 96 /r, VFMADDSUB132PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfmaddsub132ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 96, EVEX.128.66.0F38.W0 96 /r, VFMADDSUB132PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmaddsub132ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 96, EVEX.256.66.0F38.W0 96 /r, VFMADDSUB132PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmaddsub132ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, 96, EVEX.512.66.0F38.W0 96 /r, VFMADDSUB132PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfmaddsub132pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 96, EVEX.128.66.0F38.W1 96 /r, VFMADDSUB132PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmaddsub132pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 96, EVEX.256.66.0F38.W1 96 /r, VFMADDSUB132PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmaddsub132pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, 96, EVEX.512.66.0F38.W1 96 /r, VFMADDSUB132PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
VEX_Vfmsubadd132ps_xmm_xmm_xmmm128, VEX, 66, 0F38, 97, VEX.128.66.0F38.W0 97 /r, VFMSUBADD132PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmsubadd132ps_ymm_ymm_ymmm256, VEX, 66, 0F38, 97, VEX.256.66.0F38.W0 97 /r, VFMSUBADD132PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfmsubadd132pd_xmm_xmm_xmmm128, VEX, 66, 0F38, 97, VEX.128.66.0F38.W1 97 /r, VFMSUBADD132PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmsubadd132pd_ymm_ymm_ymmm256, VEX, 66, 0F38, 97, VEX.256.66.0F38.W1 97 /r, VFMSUBADD132PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfmsubadd132ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 97, EVEX.128.66.0F38.W0 97 /r, VFMSUBADD132PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmsubadd132ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 97, EVEX.256.66.0F38.W0 97 /r, VFMSUBADD132PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmsubadd132ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, 97, EVEX.512.66.0F38.W0 97 /r, VFMSUBADD132PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfmsubadd132pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 97, EVEX.128.66.0F38.W1 97 /r, VFMSUBADD132PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmsubadd132pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 97, EVEX.256.66.0F38.W1 97 /r, VFMSUBADD132PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmsubadd132pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, 97, EVEX.512.66.0F38.W1 97 /r, VFMSUBADD132PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
VEX_Vfmadd132ps_xmm_xmm_xmmm128, VEX, 66, 0F38, 98, VEX.128.66.0F38.W0 98 /r, VFMADD132PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmadd132ps_ymm_ymm_ymmm256, VEX, 66, 0F38, 98, VEX.256.66.0F38.W0 98 /r, VFMADD132PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfmadd132pd_xmm_xmm_xmmm128, VEX, 66, 0F38, 98, VEX.128.66.0F38.W1 98 /r, VFMADD132PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmadd132pd_ymm_ymm_ymmm256, VEX, 66, 0F38, 98, VEX.256.66.0F38.W1 98 /r, VFMADD132PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfmadd132ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 98, EVEX.128.66.0F38.W0 98 /r, VFMADD132PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmadd132ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 98, EVEX.256.66.0F38.W0 98 /r, VFMADD132PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmadd132ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, 98, EVEX.512.66.0F38.W0 98 /r, VFMADD132PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfmadd132pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 98, EVEX.128.66.0F38.W1 98 /r, VFMADD132PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmadd132pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 98, EVEX.256.66.0F38.W1 98 /r, VFMADD132PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmadd132pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, 98, EVEX.512.66.0F38.W1 98 /r, VFMADD132PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
VEX_Vfmadd132ss_xmm_xmm_xmmm32, VEX, 66, 0F38, 99, VEX.LIG.66.0F38.W0 99 /r, VFMADD132SS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmadd132sd_xmm_xmm_xmmm64, VEX, 66, 0F38, 99, VEX.LIG.66.0F38.W1 99 /r, VFMADD132SD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vfmadd132ss_xmm_k1z_xmm_xmmm32_er, EVEX, 66, 0F38, 99, EVEX.LIG.66.0F38.W0 99 /r, VFMADD132SS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_Vfmadd132sd_xmm_k1z_xmm_xmmm64_er, EVEX, 66, 0F38, 99, EVEX.LIG.66.0F38.W1 99 /r, VFMADD132SD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
VEX_Vfmsub132ps_xmm_xmm_xmmm128, VEX, 66, 0F38, 9A, VEX.128.66.0F38.W0 9A /r, VFMSUB132PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmsub132ps_ymm_ymm_ymmm256, VEX, 66, 0F38, 9A, VEX.256.66.0F38.W0 9A /r, VFMSUB132PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfmsub132pd_xmm_xmm_xmmm128, VEX, 66, 0F38, 9A, VEX.128.66.0F38.W1 9A /r, VFMSUB132PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmsub132pd_ymm_ymm_ymmm256, VEX, 66, 0F38, 9A, VEX.256.66.0F38.W1 9A /r, VFMSUB132PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfmsub132ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 9A, EVEX.128.66.0F38.W0 9A /r, VFMSUB132PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmsub132ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 9A, EVEX.256.66.0F38.W0 9A /r, VFMSUB132PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmsub132ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, 9A, EVEX.512.66.0F38.W0 9A /r, VFMSUB132PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfmsub132pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 9A, EVEX.128.66.0F38.W1 9A /r, VFMSUB132PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmsub132pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 9A, EVEX.256.66.0F38.W1 9A /r, VFMSUB132PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmsub132pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, 9A, EVEX.512.66.0F38.W1 9A /r, VFMSUB132PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_V4fmaddps_zmm_k1z_zmmp3_m128, EVEX, F2, 0F38, 9A, EVEX.512.F2.0F38.W0 9A /r, V4FMADDPS zmm1 {k1}{z}| zmm2+3| m128, 16b 32b 64b L512 W0 op=zmm_reg;zmmp3_vvvv;mem tt=Tuple1_4X k z
VEX_Vfmsub132ss_xmm_xmm_xmmm32, VEX, 66, 0F38, 9B, VEX.LIG.66.0F38.W0 9B /r, VFMSUB132SS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmsub132sd_xmm_xmm_xmmm64, VEX, 66, 0F38, 9B, VEX.LIG.66.0F38.W1 9B /r, VFMSUB132SD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vfmsub132ss_xmm_k1z_xmm_xmmm32_er, EVEX, 66, 0F38, 9B, EVEX.LIG.66.0F38.W0 9B /r, VFMSUB132SS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_Vfmsub132sd_xmm_k1z_xmm_xmmm64_er, EVEX, 66, 0F38, 9B, EVEX.LIG.66.0F38.W1 9B /r, VFMSUB132SD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_V4fmaddss_xmm_k1z_xmmp3_m128, EVEX, F2, 0F38, 9B, EVEX.LIG.F2.0F38.W0 9B /r, V4FMADDSS xmm1 {k1}{z}| xmm2+3| m128, 16b 32b 64b LIG W0 op=xmm_reg;xmmp3_vvvv;mem tt=Tuple1_4X k z
VEX_Vfnmadd132ps_xmm_xmm_xmmm128, VEX, 66, 0F38, 9C, VEX.128.66.0F38.W0 9C /r, VFNMADD132PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmadd132ps_ymm_ymm_ymmm256, VEX, 66, 0F38, 9C, VEX.256.66.0F38.W0 9C /r, VFNMADD132PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfnmadd132pd_xmm_xmm_xmmm128, VEX, 66, 0F38, 9C, VEX.128.66.0F38.W1 9C /r, VFNMADD132PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmadd132pd_ymm_ymm_ymmm256, VEX, 66, 0F38, 9C, VEX.256.66.0F38.W1 9C /r, VFNMADD132PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfnmadd132ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 9C, EVEX.128.66.0F38.W0 9C /r, VFNMADD132PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfnmadd132ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 9C, EVEX.256.66.0F38.W0 9C /r, VFNMADD132PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfnmadd132ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, 9C, EVEX.512.66.0F38.W0 9C /r, VFNMADD132PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfnmadd132pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 9C, EVEX.128.66.0F38.W1 9C /r, VFNMADD132PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfnmadd132pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 9C, EVEX.256.66.0F38.W1 9C /r, VFNMADD132PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfnmadd132pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, 9C, EVEX.512.66.0F38.W1 9C /r, VFNMADD132PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
VEX_Vfnmadd132ss_xmm_xmm_xmmm32, VEX, 66, 0F38, 9D, VEX.LIG.66.0F38.W0 9D /r, VFNMADD132SS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmadd132sd_xmm_xmm_xmmm64, VEX, 66, 0F38, 9D, VEX.LIG.66.0F38.W1 9D /r, VFNMADD132SD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vfnmadd132ss_xmm_k1z_xmm_xmmm32_er, EVEX, 66, 0F38, 9D, EVEX.LIG.66.0F38.W0 9D /r, VFNMADD132SS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_Vfnmadd132sd_xmm_k1z_xmm_xmmm64_er, EVEX, 66, 0F38, 9D, EVEX.LIG.66.0F38.W1 9D /r, VFNMADD132SD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
VEX_Vfnmsub132ps_xmm_xmm_xmmm128, VEX, 66, 0F38, 9E, VEX.128.66.0F38.W0 9E /r, VFNMSUB132PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmsub132ps_ymm_ymm_ymmm256, VEX, 66, 0F38, 9E, VEX.256.66.0F38.W0 9E /r, VFNMSUB132PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfnmsub132pd_xmm_xmm_xmmm128, VEX, 66, 0F38, 9E, VEX.128.66.0F38.W1 9E /r, VFNMSUB132PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmsub132pd_ymm_ymm_ymmm256, VEX, 66, 0F38, 9E, VEX.256.66.0F38.W1 9E /r, VFNMSUB132PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfnmsub132ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, 9E, EVEX.128.66.0F38.W0 9E /r, VFNMSUB132PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfnmsub132ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, 9E, EVEX.256.66.0F38.W0 9E /r, VFNMSUB132PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfnmsub132ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, 9E, EVEX.512.66.0F38.W0 9E /r, VFNMSUB132PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfnmsub132pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, 9E, EVEX.128.66.0F38.W1 9E /r, VFNMSUB132PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfnmsub132pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, 9E, EVEX.256.66.0F38.W1 9E /r, VFNMSUB132PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfnmsub132pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, 9E, EVEX.512.66.0F38.W1 9E /r, VFNMSUB132PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
VEX_Vfnmsub132ss_xmm_xmm_xmmm32, VEX, 66, 0F38, 9F, VEX.LIG.66.0F38.W0 9F /r, VFNMSUB132SS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmsub132sd_xmm_xmm_xmmm64, VEX, 66, 0F38, 9F, VEX.LIG.66.0F38.W1 9F /r, VFNMSUB132SD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vfnmsub132ss_xmm_k1z_xmm_xmmm32_er, EVEX, 66, 0F38, 9F, EVEX.LIG.66.0F38.W0 9F /r, VFNMSUB132SS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_Vfnmsub132sd_xmm_k1z_xmm_xmmm64_er, EVEX, 66, 0F38, 9F, EVEX.LIG.66.0F38.W1 9F /r, VFNMSUB132SD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_Vpscatterdd_vm32x_k1_xmm, EVEX, 66, 0F38, A0, EVEX.128.66.0F38.W0 A0 /vsib, VPSCATTERDD vm32x {k1}| xmm1, 16b 32b 64b L128 W0 op=mem_vsib32x;xmm_reg tt=Tuple1_Scalar knz
EVEX_Vpscatterdd_vm32y_k1_ymm, EVEX, 66, 0F38, A0, EVEX.256.66.0F38.W0 A0 /vsib, VPSCATTERDD vm32y {k1}| ymm1, 16b 32b 64b L256 W0 op=mem_vsib32y;ymm_reg tt=Tuple1_Scalar knz
EVEX_Vpscatterdd_vm32z_k1_zmm, EVEX, 66, 0F38, A0, EVEX.512.66.0F38.W0 A0 /vsib, VPSCATTERDD vm32z {k1}| zmm1, 16b 32b 64b L512 W0 op=mem_vsib32z;zmm_reg tt=Tuple1_Scalar knz
EVEX_Vpscatterdq_vm32x_k1_xmm, EVEX, 66, 0F38, A0, EVEX.128.66.0F38.W1 A0 /vsib, VPSCATTERDQ vm32x {k1}| xmm1, 16b 32b 64b L128 W1 op=mem_vsib32x;xmm_reg tt=Tuple1_Scalar knz
EVEX_Vpscatterdq_vm32x_k1_ymm, EVEX, 66, 0F38, A0, EVEX.256.66.0F38.W1 A0 /vsib, VPSCATTERDQ vm32x {k1}| ymm1, 16b 32b 64b L256 W1 op=mem_vsib32x;ymm_reg tt=Tuple1_Scalar knz
EVEX_Vpscatterdq_vm32y_k1_zmm, EVEX, 66, 0F38, A0, EVEX.512.66.0F38.W1 A0 /vsib, VPSCATTERDQ vm32y {k1}| zmm1, 16b 32b 64b L512 W1 op=mem_vsib32y;zmm_reg tt=Tuple1_Scalar knz
EVEX_Vpscatterqd_vm64x_k1_xmm, EVEX, 66, 0F38, A1, EVEX.128.66.0F38.W0 A1 /vsib, VPSCATTERQD vm64x {k1}| xmm1, 16b 32b 64b L128 W0 op=mem_vsib64x;xmm_reg tt=Tuple1_Scalar knz
EVEX_Vpscatterqd_vm64y_k1_xmm, EVEX, 66, 0F38, A1, EVEX.256.66.0F38.W0 A1 /vsib, VPSCATTERQD vm64y {k1}| xmm1, 16b 32b 64b L256 W0 op=mem_vsib64y;xmm_reg tt=Tuple1_Scalar knz
EVEX_Vpscatterqd_vm64z_k1_ymm, EVEX, 66, 0F38, A1, EVEX.512.66.0F38.W0 A1 /vsib, VPSCATTERQD vm64z {k1}| ymm1, 16b 32b 64b L512 W0 op=mem_vsib64z;ymm_reg tt=Tuple1_Scalar knz
EVEX_Vpscatterqq_vm64x_k1_xmm, EVEX, 66, 0F38, A1, EVEX.128.66.0F38.W1 A1 /vsib, VPSCATTERQQ vm64x {k1}| xmm1, 16b 32b 64b L128 W1 op=mem_vsib64x;xmm_reg tt=Tuple1_Scalar knz
EVEX_Vpscatterqq_vm64y_k1_ymm, EVEX, 66, 0F38, A1, EVEX.256.66.0F38.W1 A1 /vsib, VPSCATTERQQ vm64y {k1}| ymm1, 16b 32b 64b L256 W1 op=mem_vsib64y;ymm_reg tt=Tuple1_Scalar knz
EVEX_Vpscatterqq_vm64z_k1_zmm, EVEX, 66, 0F38, A1, EVEX.512.66.0F38.W1 A1 /vsib, VPSCATTERQQ vm64z {k1}| zmm1, 16b 32b 64b L512 W1 op=mem_vsib64z;zmm_reg tt=Tuple1_Scalar knz
EVEX_Vscatterdps_vm32x_k1_xmm, EVEX, 66, 0F38, A2, EVEX.128.66.0F38.W0 A2 /vsib, VSCATTERDPS vm32x {k1}| xmm1, 16b 32b 64b L128 W0 op=mem_vsib32x;xmm_reg tt=Tuple1_Scalar knz
EVEX_Vscatterdps_vm32y_k1_ymm, EVEX, 66, 0F38, A2, EVEX.256.66.0F38.W0 A2 /vsib, VSCATTERDPS vm32y {k1}| ymm1, 16b 32b 64b L256 W0 op=mem_vsib32y;ymm_reg tt=Tuple1_Scalar knz
EVEX_Vscatterdps_vm32z_k1_zmm, EVEX, 66, 0F38, A2, EVEX.512.66.0F38.W0 A2 /vsib, VSCATTERDPS vm32z {k1}| zmm1, 16b 32b 64b L512 W0 op=mem_vsib32z;zmm_reg tt=Tuple1_Scalar knz
EVEX_Vscatterdpd_vm32x_k1_xmm, EVEX, 66, 0F38, A2, EVEX.128.66.0F38.W1 A2 /vsib, VSCATTERDPD vm32x {k1}| xmm1, 16b 32b 64b L128 W1 op=mem_vsib32x;xmm_reg tt=Tuple1_Scalar knz
EVEX_Vscatterdpd_vm32x_k1_ymm, EVEX, 66, 0F38, A2, EVEX.256.66.0F38.W1 A2 /vsib, VSCATTERDPD vm32x {k1}| ymm1, 16b 32b 64b L256 W1 op=mem_vsib32x;ymm_reg tt=Tuple1_Scalar knz
EVEX_Vscatterdpd_vm32y_k1_zmm, EVEX, 66, 0F38, A2, EVEX.512.66.0F38.W1 A2 /vsib, VSCATTERDPD vm32y {k1}| zmm1, 16b 32b 64b L512 W1 op=mem_vsib32y;zmm_reg tt=Tuple1_Scalar knz
EVEX_Vscatterqps_vm64x_k1_xmm, EVEX, 66, 0F38, A3, EVEX.128.66.0F38.W0 A3 /vsib, VSCATTERQPS vm64x {k1}| xmm1, 16b 32b 64b L128 W0 op=mem_vsib64x;xmm_reg tt=Tuple1_Scalar knz
EVEX_Vscatterqps_vm64y_k1_xmm, EVEX, 66, 0F38, A3, EVEX.256.66.0F38.W0 A3 /vsib, VSCATTERQPS vm64y {k1}| xmm1, 16b 32b 64b L256 W0 op=mem_vsib64y;xmm_reg tt=Tuple1_Scalar knz
EVEX_Vscatterqps_vm64z_k1_ymm, EVEX, 66, 0F38, A3, EVEX.512.66.0F38.W0 A3 /vsib, VSCATTERQPS vm64z {k1}| ymm1, 16b 32b 64b L512 W0 op=mem_vsib64z;ymm_reg tt=Tuple1_Scalar knz
EVEX_Vscatterqpd_vm64x_k1_xmm, EVEX, 66, 0F38, A3, EVEX.128.66.0F38.W1 A3 /vsib, VSCATTERQPD vm64x {k1}| xmm1, 16b 32b 64b L128 W1 op=mem_vsib64x;xmm_reg tt=Tuple1_Scalar knz
EVEX_Vscatterqpd_vm64y_k1_ymm, EVEX, 66, 0F38, A3, EVEX.256.66.0F38.W1 A3 /vsib, VSCATTERQPD vm64y {k1}| ymm1, 16b 32b 64b L256 W1 op=mem_vsib64y;ymm_reg tt=Tuple1_Scalar knz
EVEX_Vscatterqpd_vm64z_k1_zmm, EVEX, 66, 0F38, A3, EVEX.512.66.0F38.W1 A3 /vsib, VSCATTERQPD vm64z {k1}| zmm1, 16b 32b 64b L512 W1 op=mem_vsib64z;zmm_reg tt=Tuple1_Scalar knz
VEX_Vfmaddsub213ps_xmm_xmm_xmmm128, VEX, 66, 0F38, A6, VEX.128.66.0F38.W0 A6 /r, VFMADDSUB213PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmaddsub213ps_ymm_ymm_ymmm256, VEX, 66, 0F38, A6, VEX.256.66.0F38.W0 A6 /r, VFMADDSUB213PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfmaddsub213pd_xmm_xmm_xmmm128, VEX, 66, 0F38, A6, VEX.128.66.0F38.W1 A6 /r, VFMADDSUB213PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmaddsub213pd_ymm_ymm_ymmm256, VEX, 66, 0F38, A6, VEX.256.66.0F38.W1 A6 /r, VFMADDSUB213PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfmaddsub213ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, A6, EVEX.128.66.0F38.W0 A6 /r, VFMADDSUB213PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmaddsub213ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, A6, EVEX.256.66.0F38.W0 A6 /r, VFMADDSUB213PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmaddsub213ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, A6, EVEX.512.66.0F38.W0 A6 /r, VFMADDSUB213PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfmaddsub213pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, A6, EVEX.128.66.0F38.W1 A6 /r, VFMADDSUB213PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmaddsub213pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, A6, EVEX.256.66.0F38.W1 A6 /r, VFMADDSUB213PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmaddsub213pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, A6, EVEX.512.66.0F38.W1 A6 /r, VFMADDSUB213PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
VEX_Vfmsubadd213ps_xmm_xmm_xmmm128, VEX, 66, 0F38, A7, VEX.128.66.0F38.W0 A7 /r, VFMSUBADD213PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmsubadd213ps_ymm_ymm_ymmm256, VEX, 66, 0F38, A7, VEX.256.66.0F38.W0 A7 /r, VFMSUBADD213PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfmsubadd213pd_xmm_xmm_xmmm128, VEX, 66, 0F38, A7, VEX.128.66.0F38.W1 A7 /r, VFMSUBADD213PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmsubadd213pd_ymm_ymm_ymmm256, VEX, 66, 0F38, A7, VEX.256.66.0F38.W1 A7 /r, VFMSUBADD213PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfmsubadd213ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, A7, EVEX.128.66.0F38.W0 A7 /r, VFMSUBADD213PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmsubadd213ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, A7, EVEX.256.66.0F38.W0 A7 /r, VFMSUBADD213PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmsubadd213ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, A7, EVEX.512.66.0F38.W0 A7 /r, VFMSUBADD213PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfmsubadd213pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, A7, EVEX.128.66.0F38.W1 A7 /r, VFMSUBADD213PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmsubadd213pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, A7, EVEX.256.66.0F38.W1 A7 /r, VFMSUBADD213PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmsubadd213pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, A7, EVEX.512.66.0F38.W1 A7 /r, VFMSUBADD213PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
VEX_Vfmadd213ps_xmm_xmm_xmmm128, VEX, 66, 0F38, A8, VEX.128.66.0F38.W0 A8 /r, VFMADD213PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmadd213ps_ymm_ymm_ymmm256, VEX, 66, 0F38, A8, VEX.256.66.0F38.W0 A8 /r, VFMADD213PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfmadd213pd_xmm_xmm_xmmm128, VEX, 66, 0F38, A8, VEX.128.66.0F38.W1 A8 /r, VFMADD213PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmadd213pd_ymm_ymm_ymmm256, VEX, 66, 0F38, A8, VEX.256.66.0F38.W1 A8 /r, VFMADD213PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfmadd213ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, A8, EVEX.128.66.0F38.W0 A8 /r, VFMADD213PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmadd213ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, A8, EVEX.256.66.0F38.W0 A8 /r, VFMADD213PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmadd213ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, A8, EVEX.512.66.0F38.W0 A8 /r, VFMADD213PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfmadd213pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, A8, EVEX.128.66.0F38.W1 A8 /r, VFMADD213PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmadd213pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, A8, EVEX.256.66.0F38.W1 A8 /r, VFMADD213PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmadd213pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, A8, EVEX.512.66.0F38.W1 A8 /r, VFMADD213PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
VEX_Vfmadd213ss_xmm_xmm_xmmm32, VEX, 66, 0F38, A9, VEX.LIG.66.0F38.W0 A9 /r, VFMADD213SS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmadd213sd_xmm_xmm_xmmm64, VEX, 66, 0F38, A9, VEX.LIG.66.0F38.W1 A9 /r, VFMADD213SD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vfmadd213ss_xmm_k1z_xmm_xmmm32_er, EVEX, 66, 0F38, A9, EVEX.LIG.66.0F38.W0 A9 /r, VFMADD213SS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_Vfmadd213sd_xmm_k1z_xmm_xmmm64_er, EVEX, 66, 0F38, A9, EVEX.LIG.66.0F38.W1 A9 /r, VFMADD213SD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
VEX_Vfmsub213ps_xmm_xmm_xmmm128, VEX, 66, 0F38, AA, VEX.128.66.0F38.W0 AA /r, VFMSUB213PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmsub213ps_ymm_ymm_ymmm256, VEX, 66, 0F38, AA, VEX.256.66.0F38.W0 AA /r, VFMSUB213PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfmsub213pd_xmm_xmm_xmmm128, VEX, 66, 0F38, AA, VEX.128.66.0F38.W1 AA /r, VFMSUB213PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmsub213pd_ymm_ymm_ymmm256, VEX, 66, 0F38, AA, VEX.256.66.0F38.W1 AA /r, VFMSUB213PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfmsub213ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, AA, EVEX.128.66.0F38.W0 AA /r, VFMSUB213PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmsub213ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, AA, EVEX.256.66.0F38.W0 AA /r, VFMSUB213PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmsub213ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, AA, EVEX.512.66.0F38.W0 AA /r, VFMSUB213PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfmsub213pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, AA, EVEX.128.66.0F38.W1 AA /r, VFMSUB213PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmsub213pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, AA, EVEX.256.66.0F38.W1 AA /r, VFMSUB213PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmsub213pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, AA, EVEX.512.66.0F38.W1 AA /r, VFMSUB213PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_V4fnmaddps_zmm_k1z_zmmp3_m128, EVEX, F2, 0F38, AA, EVEX.512.F2.0F38.W0 AA /r, V4FNMADDPS zmm1 {k1}{z}| zmm2+3| m128, 16b 32b 64b L512 W0 op=zmm_reg;zmmp3_vvvv;mem tt=Tuple1_4X k z
VEX_Vfmsub213ss_xmm_xmm_xmmm32, VEX, 66, 0F38, AB, VEX.LIG.66.0F38.W0 AB /r, VFMSUB213SS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmsub213sd_xmm_xmm_xmmm64, VEX, 66, 0F38, AB, VEX.LIG.66.0F38.W1 AB /r, VFMSUB213SD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vfmsub213ss_xmm_k1z_xmm_xmmm32_er, EVEX, 66, 0F38, AB, EVEX.LIG.66.0F38.W0 AB /r, VFMSUB213SS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_Vfmsub213sd_xmm_k1z_xmm_xmmm64_er, EVEX, 66, 0F38, AB, EVEX.LIG.66.0F38.W1 AB /r, VFMSUB213SD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_V4fnmaddss_xmm_k1z_xmmp3_m128, EVEX, F2, 0F38, AB, EVEX.LIG.F2.0F38.W0 AB /r, V4FNMADDSS xmm1 {k1}{z}| xmm2+3| m128, 16b 32b 64b LIG W0 op=xmm_reg;xmmp3_vvvv;mem tt=Tuple1_4X k z
VEX_Vfnmadd213ps_xmm_xmm_xmmm128, VEX, 66, 0F38, AC, VEX.128.66.0F38.W0 AC /r, VFNMADD213PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmadd213ps_ymm_ymm_ymmm256, VEX, 66, 0F38, AC, VEX.256.66.0F38.W0 AC /r, VFNMADD213PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfnmadd213pd_xmm_xmm_xmmm128, VEX, 66, 0F38, AC, VEX.128.66.0F38.W1 AC /r, VFNMADD213PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmadd213pd_ymm_ymm_ymmm256, VEX, 66, 0F38, AC, VEX.256.66.0F38.W1 AC /r, VFNMADD213PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfnmadd213ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, AC, EVEX.128.66.0F38.W0 AC /r, VFNMADD213PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfnmadd213ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, AC, EVEX.256.66.0F38.W0 AC /r, VFNMADD213PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfnmadd213ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, AC, EVEX.512.66.0F38.W0 AC /r, VFNMADD213PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfnmadd213pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, AC, EVEX.128.66.0F38.W1 AC /r, VFNMADD213PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfnmadd213pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, AC, EVEX.256.66.0F38.W1 AC /r, VFNMADD213PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfnmadd213pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, AC, EVEX.512.66.0F38.W1 AC /r, VFNMADD213PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
VEX_Vfnmadd213ss_xmm_xmm_xmmm32, VEX, 66, 0F38, AD, VEX.LIG.66.0F38.W0 AD /r, VFNMADD213SS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmadd213sd_xmm_xmm_xmmm64, VEX, 66, 0F38, AD, VEX.LIG.66.0F38.W1 AD /r, VFNMADD213SD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vfnmadd213ss_xmm_k1z_xmm_xmmm32_er, EVEX, 66, 0F38, AD, EVEX.LIG.66.0F38.W0 AD /r, VFNMADD213SS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_Vfnmadd213sd_xmm_k1z_xmm_xmmm64_er, EVEX, 66, 0F38, AD, EVEX.LIG.66.0F38.W1 AD /r, VFNMADD213SD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
VEX_Vfnmsub213ps_xmm_xmm_xmmm128, VEX, 66, 0F38, AE, VEX.128.66.0F38.W0 AE /r, VFNMSUB213PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmsub213ps_ymm_ymm_ymmm256, VEX, 66, 0F38, AE, VEX.256.66.0F38.W0 AE /r, VFNMSUB213PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfnmsub213pd_xmm_xmm_xmmm128, VEX, 66, 0F38, AE, VEX.128.66.0F38.W1 AE /r, VFNMSUB213PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmsub213pd_ymm_ymm_ymmm256, VEX, 66, 0F38, AE, VEX.256.66.0F38.W1 AE /r, VFNMSUB213PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfnmsub213ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, AE, EVEX.128.66.0F38.W0 AE /r, VFNMSUB213PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfnmsub213ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, AE, EVEX.256.66.0F38.W0 AE /r, VFNMSUB213PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfnmsub213ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, AE, EVEX.512.66.0F38.W0 AE /r, VFNMSUB213PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfnmsub213pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, AE, EVEX.128.66.0F38.W1 AE /r, VFNMSUB213PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfnmsub213pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, AE, EVEX.256.66.0F38.W1 AE /r, VFNMSUB213PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfnmsub213pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, AE, EVEX.512.66.0F38.W1 AE /r, VFNMSUB213PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
VEX_Vfnmsub213ss_xmm_xmm_xmmm32, VEX, 66, 0F38, AF, VEX.LIG.66.0F38.W0 AF /r, VFNMSUB213SS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmsub213sd_xmm_xmm_xmmm64, VEX, 66, 0F38, AF, VEX.LIG.66.0F38.W1 AF /r, VFNMSUB213SD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vfnmsub213ss_xmm_k1z_xmm_xmmm32_er, EVEX, 66, 0F38, AF, EVEX.LIG.66.0F38.W0 AF /r, VFNMSUB213SS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_Vfnmsub213sd_xmm_k1z_xmm_xmmm64_er, EVEX, 66, 0F38, AF, EVEX.LIG.66.0F38.W1 AF /r, VFNMSUB213SD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_Vpmadd52luq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, B4, EVEX.128.66.0F38.W1 B4 /r, VPMADD52LUQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpmadd52luq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, B4, EVEX.256.66.0F38.W1 B4 /r, VPMADD52LUQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpmadd52luq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, B4, EVEX.512.66.0F38.W1 B4 /r, VPMADD52LUQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
EVEX_Vpmadd52huq_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, B5, EVEX.128.66.0F38.W1 B5 /r, VPMADD52HUQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vpmadd52huq_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, B5, EVEX.256.66.0F38.W1 B5 /r, VPMADD52HUQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vpmadd52huq_zmm_k1z_zmm_zmmm512b64, EVEX, 66, 0F38, B5, EVEX.512.66.0F38.W1 B5 /r, VPMADD52HUQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b k z
VEX_Vfmaddsub231ps_xmm_xmm_xmmm128, VEX, 66, 0F38, B6, VEX.128.66.0F38.W0 B6 /r, VFMADDSUB231PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmaddsub231ps_ymm_ymm_ymmm256, VEX, 66, 0F38, B6, VEX.256.66.0F38.W0 B6 /r, VFMADDSUB231PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfmaddsub231pd_xmm_xmm_xmmm128, VEX, 66, 0F38, B6, VEX.128.66.0F38.W1 B6 /r, VFMADDSUB231PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmaddsub231pd_ymm_ymm_ymmm256, VEX, 66, 0F38, B6, VEX.256.66.0F38.W1 B6 /r, VFMADDSUB231PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfmaddsub231ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, B6, EVEX.128.66.0F38.W0 B6 /r, VFMADDSUB231PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmaddsub231ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, B6, EVEX.256.66.0F38.W0 B6 /r, VFMADDSUB231PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmaddsub231ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, B6, EVEX.512.66.0F38.W0 B6 /r, VFMADDSUB231PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfmaddsub231pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, B6, EVEX.128.66.0F38.W1 B6 /r, VFMADDSUB231PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmaddsub231pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, B6, EVEX.256.66.0F38.W1 B6 /r, VFMADDSUB231PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmaddsub231pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, B6, EVEX.512.66.0F38.W1 B6 /r, VFMADDSUB231PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
VEX_Vfmsubadd231ps_xmm_xmm_xmmm128, VEX, 66, 0F38, B7, VEX.128.66.0F38.W0 B7 /r, VFMSUBADD231PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmsubadd231ps_ymm_ymm_ymmm256, VEX, 66, 0F38, B7, VEX.256.66.0F38.W0 B7 /r, VFMSUBADD231PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfmsubadd231pd_xmm_xmm_xmmm128, VEX, 66, 0F38, B7, VEX.128.66.0F38.W1 B7 /r, VFMSUBADD231PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmsubadd231pd_ymm_ymm_ymmm256, VEX, 66, 0F38, B7, VEX.256.66.0F38.W1 B7 /r, VFMSUBADD231PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfmsubadd231ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, B7, EVEX.128.66.0F38.W0 B7 /r, VFMSUBADD231PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmsubadd231ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, B7, EVEX.256.66.0F38.W0 B7 /r, VFMSUBADD231PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmsubadd231ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, B7, EVEX.512.66.0F38.W0 B7 /r, VFMSUBADD231PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfmsubadd231pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, B7, EVEX.128.66.0F38.W1 B7 /r, VFMSUBADD231PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmsubadd231pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, B7, EVEX.256.66.0F38.W1 B7 /r, VFMSUBADD231PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmsubadd231pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, B7, EVEX.512.66.0F38.W1 B7 /r, VFMSUBADD231PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
VEX_Vfmadd231ps_xmm_xmm_xmmm128, VEX, 66, 0F38, B8, VEX.128.66.0F38.W0 B8 /r, VFMADD231PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmadd231ps_ymm_ymm_ymmm256, VEX, 66, 0F38, B8, VEX.256.66.0F38.W0 B8 /r, VFMADD231PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfmadd231pd_xmm_xmm_xmmm128, VEX, 66, 0F38, B8, VEX.128.66.0F38.W1 B8 /r, VFMADD231PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmadd231pd_ymm_ymm_ymmm256, VEX, 66, 0F38, B8, VEX.256.66.0F38.W1 B8 /r, VFMADD231PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfmadd231ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, B8, EVEX.128.66.0F38.W0 B8 /r, VFMADD231PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmadd231ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, B8, EVEX.256.66.0F38.W0 B8 /r, VFMADD231PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmadd231ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, B8, EVEX.512.66.0F38.W0 B8 /r, VFMADD231PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfmadd231pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, B8, EVEX.128.66.0F38.W1 B8 /r, VFMADD231PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmadd231pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, B8, EVEX.256.66.0F38.W1 B8 /r, VFMADD231PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmadd231pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, B8, EVEX.512.66.0F38.W1 B8 /r, VFMADD231PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
VEX_Vfmadd231ss_xmm_xmm_xmmm32, VEX, 66, 0F38, B9, VEX.LIG.66.0F38.W0 B9 /r, VFMADD231SS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmadd231sd_xmm_xmm_xmmm64, VEX, 66, 0F38, B9, VEX.LIG.66.0F38.W1 B9 /r, VFMADD231SD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vfmadd231ss_xmm_k1z_xmm_xmmm32_er, EVEX, 66, 0F38, B9, EVEX.LIG.66.0F38.W0 B9 /r, VFMADD231SS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_Vfmadd231sd_xmm_k1z_xmm_xmmm64_er, EVEX, 66, 0F38, B9, EVEX.LIG.66.0F38.W1 B9 /r, VFMADD231SD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
VEX_Vfmsub231ps_xmm_xmm_xmmm128, VEX, 66, 0F38, BA, VEX.128.66.0F38.W0 BA /r, VFMSUB231PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmsub231ps_ymm_ymm_ymmm256, VEX, 66, 0F38, BA, VEX.256.66.0F38.W0 BA /r, VFMSUB231PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfmsub231pd_xmm_xmm_xmmm128, VEX, 66, 0F38, BA, VEX.128.66.0F38.W1 BA /r, VFMSUB231PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmsub231pd_ymm_ymm_ymmm256, VEX, 66, 0F38, BA, VEX.256.66.0F38.W1 BA /r, VFMSUB231PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfmsub231ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, BA, EVEX.128.66.0F38.W0 BA /r, VFMSUB231PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmsub231ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, BA, EVEX.256.66.0F38.W0 BA /r, VFMSUB231PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmsub231ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, BA, EVEX.512.66.0F38.W0 BA /r, VFMSUB231PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfmsub231pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, BA, EVEX.128.66.0F38.W1 BA /r, VFMSUB231PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfmsub231pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, BA, EVEX.256.66.0F38.W1 BA /r, VFMSUB231PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfmsub231pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, BA, EVEX.512.66.0F38.W1 BA /r, VFMSUB231PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
VEX_Vfmsub231ss_xmm_xmm_xmmm32, VEX, 66, 0F38, BB, VEX.LIG.66.0F38.W0 BB /r, VFMSUB231SS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfmsub231sd_xmm_xmm_xmmm64, VEX, 66, 0F38, BB, VEX.LIG.66.0F38.W1 BB /r, VFMSUB231SD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vfmsub231ss_xmm_k1z_xmm_xmmm32_er, EVEX, 66, 0F38, BB, EVEX.LIG.66.0F38.W0 BB /r, VFMSUB231SS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_Vfmsub231sd_xmm_k1z_xmm_xmmm64_er, EVEX, 66, 0F38, BB, EVEX.LIG.66.0F38.W1 BB /r, VFMSUB231SD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
VEX_Vfnmadd231ps_xmm_xmm_xmmm128, VEX, 66, 0F38, BC, VEX.128.66.0F38.W0 BC /r, VFNMADD231PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmadd231ps_ymm_ymm_ymmm256, VEX, 66, 0F38, BC, VEX.256.66.0F38.W0 BC /r, VFNMADD231PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfnmadd231pd_xmm_xmm_xmmm128, VEX, 66, 0F38, BC, VEX.128.66.0F38.W1 BC /r, VFNMADD231PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmadd231pd_ymm_ymm_ymmm256, VEX, 66, 0F38, BC, VEX.256.66.0F38.W1 BC /r, VFNMADD231PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfnmadd231ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, BC, EVEX.128.66.0F38.W0 BC /r, VFNMADD231PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfnmadd231ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, BC, EVEX.256.66.0F38.W0 BC /r, VFNMADD231PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfnmadd231ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, BC, EVEX.512.66.0F38.W0 BC /r, VFNMADD231PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfnmadd231pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, BC, EVEX.128.66.0F38.W1 BC /r, VFNMADD231PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfnmadd231pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, BC, EVEX.256.66.0F38.W1 BC /r, VFNMADD231PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfnmadd231pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, BC, EVEX.512.66.0F38.W1 BC /r, VFNMADD231PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
VEX_Vfnmadd231ss_xmm_xmm_xmmm32, VEX, 66, 0F38, BD, VEX.LIG.66.0F38.W0 BD /r, VFNMADD231SS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmadd231sd_xmm_xmm_xmmm64, VEX, 66, 0F38, BD, VEX.LIG.66.0F38.W1 BD /r, VFNMADD231SD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vfnmadd231ss_xmm_k1z_xmm_xmmm32_er, EVEX, 66, 0F38, BD, EVEX.LIG.66.0F38.W0 BD /r, VFNMADD231SS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_Vfnmadd231sd_xmm_k1z_xmm_xmmm64_er, EVEX, 66, 0F38, BD, EVEX.LIG.66.0F38.W1 BD /r, VFNMADD231SD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
VEX_Vfnmsub231ps_xmm_xmm_xmmm128, VEX, 66, 0F38, BE, VEX.128.66.0F38.W0 BE /r, VFNMSUB231PS xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmsub231ps_ymm_ymm_ymmm256, VEX, 66, 0F38, BE, VEX.256.66.0F38.W0 BE /r, VFNMSUB231PS ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
VEX_Vfnmsub231pd_xmm_xmm_xmmm128, VEX, 66, 0F38, BE, VEX.128.66.0F38.W1 BE /r, VFNMSUB231PD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmsub231pd_ymm_ymm_ymmm256, VEX, 66, 0F38, BE, VEX.256.66.0F38.W1 BE /r, VFNMSUB231PD ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vfnmsub231ps_xmm_k1z_xmm_xmmm128b32, EVEX, 66, 0F38, BE, EVEX.128.66.0F38.W0 BE /r, VFNMSUB231PS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfnmsub231ps_ymm_k1z_ymm_ymmm256b32, EVEX, 66, 0F38, BE, EVEX.256.66.0F38.W0 BE /r, VFNMSUB231PS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfnmsub231ps_zmm_k1z_zmm_zmmm512b32_er, EVEX, 66, 0F38, BE, EVEX.512.66.0F38.W0 BE /r, VFNMSUB231PS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{er}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
EVEX_Vfnmsub231pd_xmm_k1z_xmm_xmmm128b64, EVEX, 66, 0F38, BE, EVEX.128.66.0F38.W1 BE /r, VFNMSUB231PD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_128 b k z
EVEX_Vfnmsub231pd_ymm_k1z_ymm_ymmm256b64, EVEX, 66, 0F38, BE, EVEX.256.66.0F38.W1 BE /r, VFNMSUB231PD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_256 b k z
EVEX_Vfnmsub231pd_zmm_k1z_zmm_zmmm512b64_er, EVEX, 66, 0F38, BE, EVEX.512.66.0F38.W1 BE /r, VFNMSUB231PD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{er}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_512 b er k z
VEX_Vfnmsub231ss_xmm_xmm_xmmm32, VEX, 66, 0F38, BF, VEX.LIG.66.0F38.W0 BF /r, VFNMSUB231SS xmm1| xmm2| xmm3/m32, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vfnmsub231sd_xmm_xmm_xmmm64, VEX, 66, 0F38, BF, VEX.LIG.66.0F38.W1 BF /r, VFNMSUB231SD xmm1| xmm2| xmm3/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
EVEX_Vfnmsub231ss_xmm_k1z_xmm_xmmm32_er, EVEX, 66, 0F38, BF, EVEX.LIG.66.0F38.W0 BF /r, VFNMSUB231SS xmm1 {k1}{z}| xmm2| xmm3/m32{er}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_Vfnmsub231sd_xmm_k1z_xmm_xmmm64_er, EVEX, 66, 0F38, BF, EVEX.LIG.66.0F38.W1 BF /r, VFNMSUB231SD xmm1 {k1}{z}| xmm2| xmm3/m64{er}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar er k z
EVEX_Vpconflictd_xmm_k1z_xmmm128b32, EVEX, 66, 0F38, C4, EVEX.128.66.0F38.W0 C4 /r, VPCONFLICTD xmm1 {k1}{z}| xmm2/m128/m32bcst, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vpconflictd_ymm_k1z_ymmm256b32, EVEX, 66, 0F38, C4, EVEX.256.66.0F38.W0 C4 /r, VPCONFLICTD ymm1 {k1}{z}| ymm2/m256/m32bcst, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vpconflictd_zmm_k1z_zmmm512b32, EVEX, 66, 0F38, C4, EVEX.512.66.0F38.W0 C4 /r, VPCONFLICTD zmm1 {k1}{z}| zmm2/m512/m32bcst, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_512 b k z
EVEX_Vpconflictq_xmm_k1z_xmmm128b64, EVEX, 66, 0F38, C4, EVEX.128.66.0F38.W1 C4 /r, VPCONFLICTQ xmm1 {k1}{z}| xmm2/m128/m64bcst, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem tt=Full_128 b k z
EVEX_Vpconflictq_ymm_k1z_ymmm256b64, EVEX, 66, 0F38, C4, EVEX.256.66.0F38.W1 C4 /r, VPCONFLICTQ ymm1 {k1}{z}| ymm2/m256/m64bcst, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem tt=Full_256 b k z
EVEX_Vpconflictq_zmm_k1z_zmmm512b64, EVEX, 66, 0F38, C4, EVEX.512.66.0F38.W1 C4 /r, VPCONFLICTQ zmm1 {k1}{z}| zmm2/m512/m64bcst, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_512 b k z
EVEX_Vgatherpf0dps_vm32z_k1, EVEX, 66, 0F38, C6, EVEX.512.66.0F38.W0 C6 /1 /vsib, VGATHERPF0DPS vm32z {k1}, g=1 16b 32b 64b L512 W0 op=mem_vsib32z tt=Tuple1_Scalar knz
EVEX_Vgatherpf0dpd_vm32y_k1, EVEX, 66, 0F38, C6, EVEX.512.66.0F38.W1 C6 /1 /vsib, VGATHERPF0DPD vm32y {k1}, g=1 16b 32b 64b L512 W1 op=mem_vsib32y tt=Tuple1_Scalar knz
EVEX_Vgatherpf1dps_vm32z_k1, EVEX, 66, 0F38, C6, EVEX.512.66.0F38.W0 C6 /2 /vsib, VGATHERPF1DPS vm32z {k1}, g=2 16b 32b 64b L512 W0 op=mem_vsib32z tt=Tuple1_Scalar knz
EVEX_Vgatherpf1dpd_vm32y_k1, EVEX, 66, 0F38, C6, EVEX.512.66.0F38.W1 C6 /2 /vsib, VGATHERPF1DPD vm32y {k1}, g=2 16b 32b 64b L512 W1 op=mem_vsib32y tt=Tuple1_Scalar knz
EVEX_Vscatterpf0dps_vm32z_k1, EVEX, 66, 0F38, C6, EVEX.512.66.0F38.W0 C6 /5 /vsib, VSCATTERPF0DPS vm32z {k1}, g=5 16b 32b 64b L512 W0 op=mem_vsib32z tt=Tuple1_Scalar knz
EVEX_Vscatterpf0dpd_vm32y_k1, EVEX, 66, 0F38, C6, EVEX.512.66.0F38.W1 C6 /5 /vsib, VSCATTERPF0DPD vm32y {k1}, g=5 16b 32b 64b L512 W1 op=mem_vsib32y tt=Tuple1_Scalar knz
EVEX_Vscatterpf1dps_vm32z_k1, EVEX, 66, 0F38, C6, EVEX.512.66.0F38.W0 C6 /6 /vsib, VSCATTERPF1DPS vm32z {k1}, g=6 16b 32b 64b L512 W0 op=mem_vsib32z tt=Tuple1_Scalar knz
EVEX_Vscatterpf1dpd_vm32y_k1, EVEX, 66, 0F38, C6, EVEX.512.66.0F38.W1 C6 /6 /vsib, VSCATTERPF1DPD vm32y {k1}, g=6 16b 32b 64b L512 W1 op=mem_vsib32y tt=Tuple1_Scalar knz
EVEX_Vgatherpf0qps_vm64z_k1, EVEX, 66, 0F38, C7, EVEX.512.66.0F38.W0 C7 /1 /vsib, VGATHERPF0QPS vm64z {k1}, g=1 16b 32b 64b L512 W0 op=mem_vsib64z tt=Tuple1_Scalar knz
EVEX_Vgatherpf0qpd_vm64z_k1, EVEX, 66, 0F38, C7, EVEX.512.66.0F38.W1 C7 /1 /vsib, VGATHERPF0QPD vm64z {k1}, g=1 16b 32b 64b L512 W1 op=mem_vsib64z tt=Tuple1_Scalar knz
EVEX_Vgatherpf1qps_vm64z_k1, EVEX, 66, 0F38, C7, EVEX.512.66.0F38.W0 C7 /2 /vsib, VGATHERPF1QPS vm64z {k1}, g=2 16b 32b 64b L512 W0 op=mem_vsib64z tt=Tuple1_Scalar knz
EVEX_Vgatherpf1qpd_vm64z_k1, EVEX, 66, 0F38, C7, EVEX.512.66.0F38.W1 C7 /2 /vsib, VGATHERPF1QPD vm64z {k1}, g=2 16b 32b 64b L512 W1 op=mem_vsib64z tt=Tuple1_Scalar knz
EVEX_Vscatterpf0qps_vm64z_k1, EVEX, 66, 0F38, C7, EVEX.512.66.0F38.W0 C7 /5 /vsib, VSCATTERPF0QPS vm64z {k1}, g=5 16b 32b 64b L512 W0 op=mem_vsib64z tt=Tuple1_Scalar knz
EVEX_Vscatterpf0qpd_vm64z_k1, EVEX, 66, 0F38, C7, EVEX.512.66.0F38.W1 C7 /5 /vsib, VSCATTERPF0QPD vm64z {k1}, g=5 16b 32b 64b L512 W1 op=mem_vsib64z tt=Tuple1_Scalar knz
EVEX_Vscatterpf1qps_vm64z_k1, EVEX, 66, 0F38, C7, EVEX.512.66.0F38.W0 C7 /6 /vsib, VSCATTERPF1QPS vm64z {k1}, g=6 16b 32b 64b L512 W0 op=mem_vsib64z tt=Tuple1_Scalar knz
EVEX_Vscatterpf1qpd_vm64z_k1, EVEX, 66, 0F38, C7, EVEX.512.66.0F38.W1 C7 /6 /vsib, VSCATTERPF1QPD vm64z {k1}, g=6 16b 32b 64b L512 W1 op=mem_vsib64z tt=Tuple1_Scalar knz
Sha1nexte_xmm_xmmm128, legacy, NP, 0F38, C8, NP 0F 38 C8 /r, SHA1NEXTE xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
EVEX_Vexp2ps_zmm_k1z_zmmm512b32_sae, EVEX, 66, 0F38, C8, EVEX.512.66.0F38.W0 C8 /r, VEXP2PS zmm1 {k1}{z}| zmm2/m512/m32bcst{sae}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_512 b sae k z
EVEX_Vexp2pd_zmm_k1z_zmmm512b64_sae, EVEX, 66, 0F38, C8, EVEX.512.66.0F38.W1 C8 /r, VEXP2PD zmm1 {k1}{z}| zmm2/m512/m64bcst{sae}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_512 b sae k z
Sha1msg1_xmm_xmmm128, legacy, NP, 0F38, C9, NP 0F 38 C9 /r, SHA1MSG1 xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
Sha1msg2_xmm_xmmm128, legacy, NP, 0F38, CA, NP 0F 38 CA /r, SHA1MSG2 xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
EVEX_Vrcp28ps_zmm_k1z_zmmm512b32_sae, EVEX, 66, 0F38, CA, EVEX.512.66.0F38.W0 CA /r, VRCP28PS zmm1 {k1}{z}| zmm2/m512/m32bcst{sae}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_512 b sae k z
EVEX_Vrcp28pd_zmm_k1z_zmmm512b64_sae, EVEX, 66, 0F38, CA, EVEX.512.66.0F38.W1 CA /r, VRCP28PD zmm1 {k1}{z}| zmm2/m512/m64bcst{sae}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_512 b sae k z
Sha256rnds2_xmm_xmmm128, legacy, NP, 0F38, CB, NP 0F 38 CB /r, SHA256RNDS2 xmm1| xmm2/m128| <XMM0>, 16b 32b 64b op=xmm_reg;xmm_or_mem
EVEX_Vrcp28ss_xmm_k1z_xmm_xmmm32_sae, EVEX, 66, 0F38, CB, EVEX.LIG.66.0F38.W0 CB /r, VRCP28SS xmm1 {k1}{z}| xmm2| xmm3/m32{sae}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar sae k z
EVEX_Vrcp28sd_xmm_k1z_xmm_xmmm64_sae, EVEX, 66, 0F38, CB, EVEX.LIG.66.0F38.W1 CB /r, VRCP28SD xmm1 {k1}{z}| xmm2| xmm3/m64{sae}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar sae k z
Sha256msg1_xmm_xmmm128, legacy, NP, 0F38, CC, NP 0F 38 CC /r, SHA256MSG1 xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
EVEX_Vrsqrt28ps_zmm_k1z_zmmm512b32_sae, EVEX, 66, 0F38, CC, EVEX.512.66.0F38.W0 CC /r, VRSQRT28PS zmm1 {k1}{z}| zmm2/m512/m32bcst{sae}, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem tt=Full_512 b sae k z
EVEX_Vrsqrt28pd_zmm_k1z_zmmm512b64_sae, EVEX, 66, 0F38, CC, EVEX.512.66.0F38.W1 CC /r, VRSQRT28PD zmm1 {k1}{z}| zmm2/m512/m64bcst{sae}, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem tt=Full_512 b sae k z
Sha256msg2_xmm_xmmm128, legacy, NP, 0F38, CD, NP 0F 38 CD /r, SHA256MSG2 xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
EVEX_Vrsqrt28ss_xmm_k1z_xmm_xmmm32_sae, EVEX, 66, 0F38, CD, EVEX.LIG.66.0F38.W0 CD /r, VRSQRT28SS xmm1 {k1}{z}| xmm2| xmm3/m32{sae}, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar sae k z
EVEX_Vrsqrt28sd_xmm_k1z_xmm_xmmm64_sae, EVEX, 66, 0F38, CD, EVEX.LIG.66.0F38.W1 CD /r, VRSQRT28SD xmm1 {k1}{z}| xmm2| xmm3/m64{sae}, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Tuple1_Scalar sae k z
Gf2p8mulb_xmm_xmmm128, legacy, 66, 0F38, CF, 66 0F 38 CF /r, GF2P8MULB xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vgf2p8mulb_xmm_xmm_xmmm128, VEX, 66, 0F38, CF, VEX.128.66.0F38.W0 CF /r, VGF2P8MULB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vgf2p8mulb_ymm_ymm_ymmm256, VEX, 66, 0F38, CF, VEX.256.66.0F38.W0 CF /r, VGF2P8MULB ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vgf2p8mulb_xmm_k1z_xmm_xmmm128, EVEX, 66, 0F38, CF, EVEX.128.66.0F38.W0 CF /r, VGF2P8MULB xmm1 {k1}{z}| xmm2| xmm3/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128 k z
EVEX_Vgf2p8mulb_ymm_k1z_ymm_ymmm256, EVEX, 66, 0F38, CF, EVEX.256.66.0F38.W0 CF /r, VGF2P8MULB ymm1 {k1}{z}| ymm2| ymm3/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256 k z
EVEX_Vgf2p8mulb_zmm_k1z_zmm_zmmm512, EVEX, 66, 0F38, CF, EVEX.512.66.0F38.W0 CF /r, VGF2P8MULB zmm1 {k1}{z}| zmm2| zmm3/m512, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512 k z
Aesimc_xmm_xmmm128, legacy, 66, 0F38, DB, 66 0F 38 DB /r, AESIMC xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vaesimc_xmm_xmmm128, VEX, 66, 0F38, DB, VEX.128.66.0F38.WIG DB /r, VAESIMC xmm1| xmm2/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem
Aesenc_xmm_xmmm128, legacy, 66, 0F38, DC, 66 0F 38 DC /r, AESENC xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vaesenc_xmm_xmm_xmmm128, VEX, 66, 0F38, DC, VEX.128.66.0F38.WIG DC /r, VAESENC xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vaesenc_ymm_ymm_ymmm256, VEX, 66, 0F38, DC, VEX.256.66.0F38.WIG DC /r, VAESENC ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vaesenc_xmm_xmm_xmmm128, EVEX, 66, 0F38, DC, EVEX.128.66.0F38.WIG DC /r, VAESENC xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128
EVEX_Vaesenc_ymm_ymm_ymmm256, EVEX, 66, 0F38, DC, EVEX.256.66.0F38.WIG DC /r, VAESENC ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256
EVEX_Vaesenc_zmm_zmm_zmmm512, EVEX, 66, 0F38, DC, EVEX.512.66.0F38.WIG DC /r, VAESENC zmm1| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512
Aesenclast_xmm_xmmm128, legacy, 66, 0F38, DD, 66 0F 38 DD /r, AESENCLAST xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vaesenclast_xmm_xmm_xmmm128, VEX, 66, 0F38, DD, VEX.128.66.0F38.WIG DD /r, VAESENCLAST xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vaesenclast_ymm_ymm_ymmm256, VEX, 66, 0F38, DD, VEX.256.66.0F38.WIG DD /r, VAESENCLAST ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vaesenclast_xmm_xmm_xmmm128, EVEX, 66, 0F38, DD, EVEX.128.66.0F38.WIG DD /r, VAESENCLAST xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128
EVEX_Vaesenclast_ymm_ymm_ymmm256, EVEX, 66, 0F38, DD, EVEX.256.66.0F38.WIG DD /r, VAESENCLAST ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256
EVEX_Vaesenclast_zmm_zmm_zmmm512, EVEX, 66, 0F38, DD, EVEX.512.66.0F38.WIG DD /r, VAESENCLAST zmm1| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512
Aesdec_xmm_xmmm128, legacy, 66, 0F38, DE, 66 0F 38 DE /r, AESDEC xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vaesdec_xmm_xmm_xmmm128, VEX, 66, 0F38, DE, VEX.128.66.0F38.WIG DE /r, VAESDEC xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vaesdec_ymm_ymm_ymmm256, VEX, 66, 0F38, DE, VEX.256.66.0F38.WIG DE /r, VAESDEC ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vaesdec_xmm_xmm_xmmm128, EVEX, 66, 0F38, DE, EVEX.128.66.0F38.WIG DE /r, VAESDEC xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128
EVEX_Vaesdec_ymm_ymm_ymmm256, EVEX, 66, 0F38, DE, EVEX.256.66.0F38.WIG DE /r, VAESDEC ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256
EVEX_Vaesdec_zmm_zmm_zmmm512, EVEX, 66, 0F38, DE, EVEX.512.66.0F38.WIG DE /r, VAESDEC zmm1| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512
Aesdeclast_xmm_xmmm128, legacy, 66, 0F38, DF, 66 0F 38 DF /r, AESDECLAST xmm1| xmm2/m128, 16b 32b 64b op=xmm_reg;xmm_or_mem
VEX_Vaesdeclast_xmm_xmm_xmmm128, VEX, 66, 0F38, DF, VEX.128.66.0F38.WIG DF /r, VAESDECLAST xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem
VEX_Vaesdeclast_ymm_ymm_ymmm256, VEX, 66, 0F38, DF, VEX.256.66.0F38.WIG DF /r, VAESDECLAST ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem
EVEX_Vaesdeclast_xmm_xmm_xmmm128, EVEX, 66, 0F38, DF, EVEX.128.66.0F38.WIG DF /r, VAESDECLAST xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem tt=Full_Mem_128
EVEX_Vaesdeclast_ymm_ymm_ymmm256, EVEX, 66, 0F38, DF, EVEX.256.66.0F38.WIG DF /r, VAESDECLAST ymm1| ymm2| ymm3/m256, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem tt=Full_Mem_256
EVEX_Vaesdeclast_zmm_zmm_zmmm512, EVEX, 66, 0F38, DF, EVEX.512.66.0F38.WIG DF /r, VAESDECLAST zmm1| zmm2| zmm3/m512, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem tt=Full_Mem_512
Movbe_r16_m16, legacy, , 0F38, F0, o16 0F 38 F0 /r, MOVBE r16| m16, 16b 32b 64b o16 op=r16_reg;mem
Movbe_r32_m32, legacy, , 0F38, F0, o32 0F 38 F0 /r, MOVBE r32| m32, 16b 32b 64b o32 op=r32_reg;mem
Movbe_r64_m64, legacy, , 0F38, F0, REX.W 0F 38 F0 /r, MOVBE r64| m64, 64b o64 op=r64_reg;mem
Movbe_m16_r16, legacy, , 0F38, F1, o16 0F 38 F1 /r, MOVBE m16| r16, 16b 32b 64b o16 op=mem;r16_reg
Movbe_m32_r32, legacy, , 0F38, F1, o32 0F 38 F1 /r, MOVBE m32| r32, 16b 32b 64b o32 op=mem;r32_reg
Movbe_m64_r64, legacy, , 0F38, F1, REX.W 0F 38 F1 /r, MOVBE m64| r64, 64b o64 op=mem;r64_reg
Crc32_r32_rm8, legacy, F2, 0F38, F0, F2 0F 38 F0 /r, CRC32 r32| r/m8, 16b 32b 64b op=r32_reg;r8_or_mem
Crc32_r64_rm8, legacy, F2, 0F38, F0, F2 REX.W 0F 38 F0 /r, CRC32 r64| r/m8, 64b o64 op=r64_reg;r8_or_mem
Crc32_r32_rm16, legacy, F2, 0F38, F1, o16 F2 0F 38 F1 /r, CRC32 r32| r/m16, 16b 32b 64b o16 op=r32_reg;r16_or_mem
Crc32_r32_rm32, legacy, F2, 0F38, F1, o32 F2 0F 38 F1 /r, CRC32 r32| r/m32, 16b 32b 64b o32 op=r32_reg;r32_or_mem
Crc32_r64_rm64, legacy, F2, 0F38, F1, F2 REX.W 0F 38 F1 /r, CRC32 r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
VEX_Andn_r32_r32_rm32, VEX, NP, 0F38, F2, VEX.LZ.0F38.W0 F2 /r, ANDN r32a| r32b| r/m32, 16b 32b 64b L0 WIG32 op=r32_reg;r32_vvvv;r32_or_mem
VEX_Andn_r64_r64_rm64, VEX, NP, 0F38, F2, VEX.LZ.0F38.W1 F2 /r, ANDN r64a| r64b| r/m64, 64b L0 W1 op=r64_reg;r64_vvvv;r64_or_mem
VEX_Blsr_r32_rm32, VEX, NP, 0F38, F3, VEX.LZ.0F38.W0 F3 /1, BLSR r32| r/m32, g=1 16b 32b 64b L0 WIG32 op=r32_vvvv;r32_or_mem
VEX_Blsr_r64_rm64, VEX, NP, 0F38, F3, VEX.LZ.0F38.W1 F3 /1, BLSR r64| r/m64, g=1 64b L0 W1 op=r64_vvvv;r64_or_mem
VEX_Blsmsk_r32_rm32, VEX, NP, 0F38, F3, VEX.LZ.0F38.W0 F3 /2, BLSMSK r32| r/m32, g=2 16b 32b 64b L0 WIG32 op=r32_vvvv;r32_or_mem
VEX_Blsmsk_r64_rm64, VEX, NP, 0F38, F3, VEX.LZ.0F38.W1 F3 /2, BLSMSK r64| r/m64, g=2 64b L0 W1 op=r64_vvvv;r64_or_mem
VEX_Blsi_r32_rm32, VEX, NP, 0F38, F3, VEX.LZ.0F38.W0 F3 /3, BLSI r32| r/m32, g=3 16b 32b 64b L0 WIG32 op=r32_vvvv;r32_or_mem
VEX_Blsi_r64_rm64, VEX, NP, 0F38, F3, VEX.LZ.0F38.W1 F3 /3, BLSI r64| r/m64, g=3 64b L0 W1 op=r64_vvvv;r64_or_mem
VEX_Bzhi_r32_rm32_r32, VEX, NP, 0F38, F5, VEX.LZ.0F38.W0 F5 /r, BZHI r32a| r/m32| r32b, 16b 32b 64b L0 WIG32 op=r32_reg;r32_or_mem;r32_vvvv
VEX_Bzhi_r64_rm64_r64, VEX, NP, 0F38, F5, VEX.LZ.0F38.W1 F5 /r, BZHI r64a| r/m64| r64b, 64b L0 W1 op=r64_reg;r64_or_mem;r64_vvvv
Wrussd_m32_r32, legacy, 66, 0F38, F5, 66 0F 38 F5 /r, WRUSSD m32| r32, 16b 32b 64b op=mem;r32_reg
Wrussq_m64_r64, legacy, 66, 0F38, F5, 66 REX.W 0F 38 F5 /r, WRUSSQ m64| r64, 64b o64 op=mem;r64_reg
VEX_Pext_r32_r32_rm32, VEX, F3, 0F38, F5, VEX.LZ.F3.0F38.W0 F5 /r, PEXT r32a| r32b| r/m32, 16b 32b 64b L0 WIG32 op=r32_reg;r32_vvvv;r32_or_mem
VEX_Pext_r64_r64_rm64, VEX, F3, 0F38, F5, VEX.LZ.F3.0F38.W1 F5 /r, PEXT r64a| r64b| r/m64, 64b L0 W1 op=r64_reg;r64_vvvv;r64_or_mem
VEX_Pdep_r32_r32_rm32, VEX, F2, 0F38, F5, VEX.LZ.F2.0F38.W0 F5 /r, PDEP r32a| r32b| r/m32, 16b 32b 64b L0 WIG32 op=r32_reg;r32_vvvv;r32_or_mem
VEX_Pdep_r64_r64_rm64, VEX, F2, 0F38, F5, VEX.LZ.F2.0F38.W1 F5 /r, PDEP r64a| r64b| r/m64, 64b L0 W1 op=r64_reg;r64_vvvv;r64_or_mem
Wrssd_m32_r32, legacy, NP, 0F38, F6, NP 0F 38 F6 /r, WRSSD m32| r32, 16b 32b 64b op=mem;r32_reg
Wrssq_m64_r64, legacy, NP, 0F38, F6, NP REX.W 0F 38 F6 /r, WRSSQ m64| r64, 64b o64 op=mem;r64_reg
Adcx_r32_rm32, legacy, 66, 0F38, F6, 66 0F 38 F6 /r, ADCX r32| r/m32, 16b 32b 64b op=r32_reg;r32_or_mem
Adcx_r64_rm64, legacy, 66, 0F38, F6, 66 REX.W 0F 38 F6 /r, ADCX r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
Adox_r32_rm32, legacy, F3, 0F38, F6, F3 0F 38 F6 /r, ADOX r32| r/m32, 16b 32b 64b op=r32_reg;r32_or_mem
Adox_r64_rm64, legacy, F3, 0F38, F6, F3 REX.W 0F 38 F6 /r, ADOX r64| r/m64, 64b o64 op=r64_reg;r64_or_mem
VEX_Mulx_r32_r32_rm32, VEX, F2, 0F38, F6, VEX.LZ.F2.0F38.W0 F6 /r, MULX r32a| r32b| r/m32, 16b 32b 64b L0 WIG32 op=r32_reg;r32_vvvv;r32_or_mem
VEX_Mulx_r64_r64_rm64, VEX, F2, 0F38, F6, VEX.LZ.F2.0F38.W1 F6 /r, MULX r64a| r64b| r/m64, 64b L0 W1 op=r64_reg;r64_vvvv;r64_or_mem
VEX_Bextr_r32_rm32_r32, VEX, NP, 0F38, F7, VEX.LZ.0F38.W0 F7 /r, BEXTR r32a| r/m32| r32b, 16b 32b 64b L0 WIG32 op=r32_reg;r32_or_mem;r32_vvvv
VEX_Bextr_r64_rm64_r64, VEX, NP, 0F38, F7, VEX.LZ.0F38.W1 F7 /r, BEXTR r64a| r/m64| r64b, 64b L0 W1 op=r64_reg;r64_or_mem;r64_vvvv
VEX_Shlx_r32_rm32_r32, VEX, 66, 0F38, F7, VEX.LZ.66.0F38.W0 F7 /r, SHLX r32a| r/m32| r32b, 16b 32b 64b L0 WIG32 op=r32_reg;r32_or_mem;r32_vvvv
VEX_Shlx_r64_rm64_r64, VEX, 66, 0F38, F7, VEX.LZ.66.0F38.W1 F7 /r, SHLX r64a| r/m64| r64b, 64b L0 W1 op=r64_reg;r64_or_mem;r64_vvvv
VEX_Sarx_r32_rm32_r32, VEX, F3, 0F38, F7, VEX.LZ.F3.0F38.W0 F7 /r, SARX r32a| r/m32| r32b, 16b 32b 64b L0 WIG32 op=r32_reg;r32_or_mem;r32_vvvv
VEX_Sarx_r64_rm64_r64, VEX, F3, 0F38, F7, VEX.LZ.F3.0F38.W1 F7 /r, SARX r64a| r/m64| r64b, 64b L0 W1 op=r64_reg;r64_or_mem;r64_vvvv
VEX_Shrx_r32_rm32_r32, VEX, F2, 0F38, F7, VEX.LZ.F2.0F38.W0 F7 /r, SHRX r32a| r/m32| r32b, 16b 32b 64b L0 WIG32 op=r32_reg;r32_or_mem;r32_vvvv
VEX_Shrx_r64_rm64_r64, VEX, F2, 0F38, F7, VEX.LZ.F2.0F38.W1 F7 /r, SHRX r64a| r/m64| r64b, 64b L0 W1 op=r64_reg;r64_or_mem;r64_vvvv
Movdir64b_r16_m512, legacy, 66, 0F38, F8, a16 66 0F 38 F8 /r, MOVDIR64B r16| m512, 16b 32b a16 op=r16_reg_mem;mem
Movdir64b_r32_m512, legacy, 66, 0F38, F8, a32 66 0F 38 F8 /r, MOVDIR64B r32| m512, 16b 32b 64b a32 op=r32_reg_mem;mem
Movdir64b_r64_m512, legacy, 66, 0F38, F8, 66 0F 38 F8 /r, MOVDIR64B r64| m512, 64b op=r64_reg_mem;mem
Enqcmds_r16_m512, legacy, F3, 0F38, F8, a16 F3 0F 38 F8 /r, ENQCMDS r16| m512, 16b 32b a16 op=r16_reg_mem;mem
Enqcmds_r32_m512, legacy, F3, 0F38, F8, a32 F3 0F 38 F8 /r, ENQCMDS r32| m512, 16b 32b 64b a32 op=r32_reg_mem;mem
Enqcmds_r64_m512, legacy, F3, 0F38, F8, F3 0F 38 F8 /r, ENQCMDS r64| m512, 64b op=r64_reg_mem;mem
Enqcmd_r16_m512, legacy, F2, 0F38, F8, a16 F2 0F 38 F8 /r, ENQCMD r16| m512, 16b 32b a16 op=r16_reg_mem;mem
Enqcmd_r32_m512, legacy, F2, 0F38, F8, a32 F2 0F 38 F8 /r, ENQCMD r32| m512, 16b 32b 64b a32 op=r32_reg_mem;mem
Enqcmd_r64_m512, legacy, F2, 0F38, F8, F2 0F 38 F8 /r, ENQCMD r64| m512, 64b op=r64_reg_mem;mem
Movdiri_m32_r32, legacy, NP, 0F38, F9, NP 0F 38 F9 /r, MOVDIRI m32| r32, 16b 32b 64b op=mem;r32_reg
Movdiri_m64_r64, legacy, NP, 0F38, F9, NP REX.W 0F 38 F9 /r, MOVDIRI m64| r64, 64b o64 op=mem;r64_reg
VEX_Vpermq_ymm_ymmm256_imm8, VEX, 66, 0F3A, 00, VEX.256.66.0F3A.W1 00 /r ib, VPERMQ ymm1| ymm2/m256| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem;imm8
EVEX_Vpermq_ymm_k1z_ymmm256b64_imm8, EVEX, 66, 0F3A, 00, EVEX.256.66.0F3A.W1 00 /r ib, VPERMQ ymm1 {k1}{z}| ymm2/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vpermq_zmm_k1z_zmmm512b64_imm8, EVEX, 66, 0F3A, 00, EVEX.512.66.0F3A.W1 00 /r ib, VPERMQ zmm1 {k1}{z}| zmm2/m512/m64bcst| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem;imm8 tt=Full_512 b k z
VEX_Vpermpd_ymm_ymmm256_imm8, VEX, 66, 0F3A, 01, VEX.256.66.0F3A.W1 01 /r ib, VPERMPD ymm1| ymm2/m256| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem;imm8
EVEX_Vpermpd_ymm_k1z_ymmm256b64_imm8, EVEX, 66, 0F3A, 01, EVEX.256.66.0F3A.W1 01 /r ib, VPERMPD ymm1 {k1}{z}| ymm2/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vpermpd_zmm_k1z_zmmm512b64_imm8, EVEX, 66, 0F3A, 01, EVEX.512.66.0F3A.W1 01 /r ib, VPERMPD zmm1 {k1}{z}| zmm2/m512/m64bcst| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem;imm8 tt=Full_512 b k z
VEX_Vpblendd_xmm_xmm_xmmm128_imm8, VEX, 66, 0F3A, 02, VEX.128.66.0F3A.W0 02 /r ib, VPBLENDD xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
VEX_Vpblendd_ymm_ymm_ymmm256_imm8, VEX, 66, 0F3A, 02, VEX.256.66.0F3A.W0 02 /r ib, VPBLENDD ymm1| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8
EVEX_Valignd_xmm_k1z_xmm_xmmm128b32_imm8, EVEX, 66, 0F3A, 03, EVEX.128.66.0F3A.W0 03 /r ib, VALIGND xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Valignd_ymm_k1z_ymm_ymmm256b32_imm8, EVEX, 66, 0F3A, 03, EVEX.256.66.0F3A.W0 03 /r ib, VALIGND ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Valignd_zmm_k1z_zmm_zmmm512b32_imm8, EVEX, 66, 0F3A, 03, EVEX.512.66.0F3A.W0 03 /r ib, VALIGND zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
EVEX_Valignq_xmm_k1z_xmm_xmmm128b64_imm8, EVEX, 66, 0F3A, 03, EVEX.128.66.0F3A.W1 03 /r ib, VALIGNQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst| imm8, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Valignq_ymm_k1z_ymm_ymmm256b64_imm8, EVEX, 66, 0F3A, 03, EVEX.256.66.0F3A.W1 03 /r ib, VALIGNQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Valignq_zmm_k1z_zmm_zmmm512b64_imm8, EVEX, 66, 0F3A, 03, EVEX.512.66.0F3A.W1 03 /r ib, VALIGNQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
VEX_Vpermilps_xmm_xmmm128_imm8, VEX, 66, 0F3A, 04, VEX.128.66.0F3A.W0 04 /r ib, VPERMILPS xmm1| xmm2/m128| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;imm8
VEX_Vpermilps_ymm_ymmm256_imm8, VEX, 66, 0F3A, 04, VEX.256.66.0F3A.W0 04 /r ib, VPERMILPS ymm1| ymm2/m256| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem;imm8
EVEX_Vpermilps_xmm_k1z_xmmm128b32_imm8, EVEX, 66, 0F3A, 04, EVEX.128.66.0F3A.W0 04 /r ib, VPERMILPS xmm1 {k1}{z}| xmm2/m128/m32bcst| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vpermilps_ymm_k1z_ymmm256b32_imm8, EVEX, 66, 0F3A, 04, EVEX.256.66.0F3A.W0 04 /r ib, VPERMILPS ymm1 {k1}{z}| ymm2/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vpermilps_zmm_k1z_zmmm512b32_imm8, EVEX, 66, 0F3A, 04, EVEX.512.66.0F3A.W0 04 /r ib, VPERMILPS zmm1 {k1}{z}| zmm2/m512/m32bcst| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem;imm8 tt=Full_512 b k z
VEX_Vpermilpd_xmm_xmmm128_imm8, VEX, 66, 0F3A, 05, VEX.128.66.0F3A.W0 05 /r ib, VPERMILPD xmm1| xmm2/m128| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;imm8
VEX_Vpermilpd_ymm_ymmm256_imm8, VEX, 66, 0F3A, 05, VEX.256.66.0F3A.W0 05 /r ib, VPERMILPD ymm1| ymm2/m256| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem;imm8
EVEX_Vpermilpd_xmm_k1z_xmmm128b64_imm8, EVEX, 66, 0F3A, 05, EVEX.128.66.0F3A.W1 05 /r ib, VPERMILPD xmm1 {k1}{z}| xmm2/m128/m64bcst| imm8, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vpermilpd_ymm_k1z_ymmm256b64_imm8, EVEX, 66, 0F3A, 05, EVEX.256.66.0F3A.W1 05 /r ib, VPERMILPD ymm1 {k1}{z}| ymm2/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vpermilpd_zmm_k1z_zmmm512b64_imm8, EVEX, 66, 0F3A, 05, EVEX.512.66.0F3A.W1 05 /r ib, VPERMILPD zmm1 {k1}{z}| zmm2/m512/m64bcst| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem;imm8 tt=Full_512 b k z
VEX_Vperm2f128_ymm_ymm_ymmm256_imm8, VEX, 66, 0F3A, 06, VEX.256.66.0F3A.W0 06 /r ib, VPERM2F128 ymm1| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8
Roundps_xmm_xmmm128_imm8, legacy, 66, 0F3A, 08, 66 0F 3A 08 /r ib, ROUNDPS xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vroundps_xmm_xmmm128_imm8, VEX, 66, 0F3A, 08, VEX.128.66.0F3A.WIG 08 /r ib, VROUNDPS xmm1| xmm2/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem;imm8
VEX_Vroundps_ymm_ymmm256_imm8, VEX, 66, 0F3A, 08, VEX.256.66.0F3A.WIG 08 /r ib, VROUNDPS ymm1| ymm2/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem;imm8
EVEX_Vrndscaleps_xmm_k1z_xmmm128b32_imm8, EVEX, 66, 0F3A, 08, EVEX.128.66.0F3A.W0 08 /r ib, VRNDSCALEPS xmm1 {k1}{z}| xmm2/m128/m32bcst| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vrndscaleps_ymm_k1z_ymmm256b32_imm8, EVEX, 66, 0F3A, 08, EVEX.256.66.0F3A.W0 08 /r ib, VRNDSCALEPS ymm1 {k1}{z}| ymm2/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vrndscaleps_zmm_k1z_zmmm512b32_imm8_sae, EVEX, 66, 0F3A, 08, EVEX.512.66.0F3A.W0 08 /r ib, VRNDSCALEPS zmm1 {k1}{z}| zmm2/m512/m32bcst{sae}| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem;imm8 tt=Full_512 b sae k z
Roundpd_xmm_xmmm128_imm8, legacy, 66, 0F3A, 09, 66 0F 3A 09 /r ib, ROUNDPD xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vroundpd_xmm_xmmm128_imm8, VEX, 66, 0F3A, 09, VEX.128.66.0F3A.WIG 09 /r ib, VROUNDPD xmm1| xmm2/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem;imm8
VEX_Vroundpd_ymm_ymmm256_imm8, VEX, 66, 0F3A, 09, VEX.256.66.0F3A.WIG 09 /r ib, VROUNDPD ymm1| ymm2/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_or_mem;imm8
EVEX_Vrndscalepd_xmm_k1z_xmmm128b64_imm8, EVEX, 66, 0F3A, 09, EVEX.128.66.0F3A.W1 09 /r ib, VRNDSCALEPD xmm1 {k1}{z}| xmm2/m128/m64bcst| imm8, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vrndscalepd_ymm_k1z_ymmm256b64_imm8, EVEX, 66, 0F3A, 09, EVEX.256.66.0F3A.W1 09 /r ib, VRNDSCALEPD ymm1 {k1}{z}| ymm2/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vrndscalepd_zmm_k1z_zmmm512b64_imm8_sae, EVEX, 66, 0F3A, 09, EVEX.512.66.0F3A.W1 09 /r ib, VRNDSCALEPD zmm1 {k1}{z}| zmm2/m512/m64bcst{sae}| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem;imm8 tt=Full_512 b sae k z
Roundss_xmm_xmmm32_imm8, legacy, 66, 0F3A, 0A, 66 0F 3A 0A /r ib, ROUNDSS xmm1| xmm2/m32| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vroundss_xmm_xmm_xmmm32_imm8, VEX, 66, 0F3A, 0A, VEX.LIG.66.0F3A.WIG 0A /r ib, VROUNDSS xmm1| xmm2| xmm3/m32| imm8, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
EVEX_Vrndscaless_xmm_k1z_xmm_xmmm32_imm8_sae, EVEX, 66, 0F3A, 0A, EVEX.LIG.66.0F3A.W0 0A /r ib, VRNDSCALESS xmm1 {k1}{z}| xmm2| xmm3/m32{sae}| imm8, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Tuple1_Scalar sae k z
Roundsd_xmm_xmmm64_imm8, legacy, 66, 0F3A, 0B, 66 0F 3A 0B /r ib, ROUNDSD xmm1| xmm2/m64| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vroundsd_xmm_xmm_xmmm64_imm8, VEX, 66, 0F3A, 0B, VEX.LIG.66.0F3A.WIG 0B /r ib, VROUNDSD xmm1| xmm2| xmm3/m64| imm8, 16b 32b 64b LIG WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
EVEX_Vrndscalesd_xmm_k1z_xmm_xmmm64_imm8_sae, EVEX, 66, 0F3A, 0B, EVEX.LIG.66.0F3A.W1 0B /r ib, VRNDSCALESD xmm1 {k1}{z}| xmm2| xmm3/m64{sae}| imm8, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Tuple1_Scalar sae k z
Blendps_xmm_xmmm128_imm8, legacy, 66, 0F3A, 0C, 66 0F 3A 0C /r ib, BLENDPS xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vblendps_xmm_xmm_xmmm128_imm8, VEX, 66, 0F3A, 0C, VEX.128.66.0F3A.WIG 0C /r ib, VBLENDPS xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
VEX_Vblendps_ymm_ymm_ymmm256_imm8, VEX, 66, 0F3A, 0C, VEX.256.66.0F3A.WIG 0C /r ib, VBLENDPS ymm1| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8
Blendpd_xmm_xmmm128_imm8, legacy, 66, 0F3A, 0D, 66 0F 3A 0D /r ib, BLENDPD xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vblendpd_xmm_xmm_xmmm128_imm8, VEX, 66, 0F3A, 0D, VEX.128.66.0F3A.WIG 0D /r ib, VBLENDPD xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
VEX_Vblendpd_ymm_ymm_ymmm256_imm8, VEX, 66, 0F3A, 0D, VEX.256.66.0F3A.WIG 0D /r ib, VBLENDPD ymm1| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8
Pblendw_xmm_xmmm128_imm8, legacy, 66, 0F3A, 0E, 66 0F 3A 0E /r ib, PBLENDW xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vpblendw_xmm_xmm_xmmm128_imm8, VEX, 66, 0F3A, 0E, VEX.128.66.0F3A.WIG 0E /r ib, VPBLENDW xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
VEX_Vpblendw_ymm_ymm_ymmm256_imm8, VEX, 66, 0F3A, 0E, VEX.256.66.0F3A.WIG 0E /r ib, VPBLENDW ymm1| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8
Palignr_mm_mmm64_imm8, legacy, NP, 0F3A, 0F, NP 0F 3A 0F /r ib, PALIGNR mm1| mm2/m64| imm8, 16b 32b 64b op=mm_reg;mm_or_mem;imm8
Palignr_xmm_xmmm128_imm8, legacy, 66, 0F3A, 0F, 66 0F 3A 0F /r ib, PALIGNR xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vpalignr_xmm_xmm_xmmm128_imm8, VEX, 66, 0F3A, 0F, VEX.128.66.0F3A.WIG 0F /r ib, VPALIGNR xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
VEX_Vpalignr_ymm_ymm_ymmm256_imm8, VEX, 66, 0F3A, 0F, VEX.256.66.0F3A.WIG 0F /r ib, VPALIGNR ymm1| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8
EVEX_Vpalignr_xmm_k1z_xmm_xmmm128_imm8, EVEX, 66, 0F3A, 0F, EVEX.128.66.0F3A.WIG 0F /r ib, VPALIGNR xmm1 {k1}{z}| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_Mem_128 k z
EVEX_Vpalignr_ymm_k1z_ymm_ymmm256_imm8, EVEX, 66, 0F3A, 0F, EVEX.256.66.0F3A.WIG 0F /r ib, VPALIGNR ymm1 {k1}{z}| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_Mem_256 k z
EVEX_Vpalignr_zmm_k1z_zmm_zmmm512_imm8, EVEX, 66, 0F3A, 0F, EVEX.512.66.0F3A.WIG 0F /r ib, VPALIGNR zmm1 {k1}{z}| zmm2| zmm3/m512| imm8, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_Mem_512 k z
Pextrb_r32m8_xmm_imm8, legacy, 66, 0F3A, 14, 66 0F 3A 14 /r ib, PEXTRB r32/m8| xmm2| imm8, 16b 32b 64b op=r32_or_mem;xmm_reg;imm8
Pextrb_r64m8_xmm_imm8, legacy, 66, 0F3A, 14, 66 REX.W 0F 3A 14 /r ib, PEXTRB r64/m8| xmm2| imm8, 64b o64 op=r64_or_mem;xmm_reg;imm8
VEX_Vpextrb_r32m8_xmm_imm8, VEX, 66, 0F3A, 14, VEX.128.66.0F3A.W0 14 /r ib, VPEXTRB r32/m8| xmm2| imm8, 16b 32b 64b L128 WIG32 op=r32_or_mem;xmm_reg;imm8
VEX_Vpextrb_r64m8_xmm_imm8, VEX, 66, 0F3A, 14, VEX.128.66.0F3A.W1 14 /r ib, VPEXTRB r64/m8| xmm2| imm8, 64b L128 W1 op=r64_or_mem;xmm_reg;imm8
EVEX_Vpextrb_r32m8_xmm_imm8, EVEX, 66, 0F3A, 14, EVEX.128.66.0F3A.W0 14 /r ib, VPEXTRB r32/m8| xmm2| imm8, 16b 32b 64b L128 WIG32 op=r32_or_mem;xmm_reg;imm8 tt=Tuple1_Scalar_1
EVEX_Vpextrb_r64m8_xmm_imm8, EVEX, 66, 0F3A, 14, EVEX.128.66.0F3A.W1 14 /r ib, VPEXTRB r64/m8| xmm2| imm8, 64b L128 W1 op=r64_or_mem;xmm_reg;imm8 tt=Tuple1_Scalar_1
Pextrw_r32m16_xmm_imm8, legacy, 66, 0F3A, 15, 66 0F 3A 15 /r ib, PEXTRW r32/m16| xmm| imm8, 16b 32b 64b op=r32_or_mem;xmm_reg;imm8
Pextrw_r64m16_xmm_imm8, legacy, 66, 0F3A, 15, 66 REX.W 0F 3A 15 /r ib, PEXTRW r64/m16| xmm| imm8, 64b o64 op=r64_or_mem;xmm_reg;imm8
VEX_Vpextrw_r32m16_xmm_imm8, VEX, 66, 0F3A, 15, VEX.128.66.0F3A.W0 15 /r ib, VPEXTRW r32/m16| xmm2| imm8, 16b 32b 64b L128 WIG32 op=r32_or_mem;xmm_reg;imm8
VEX_Vpextrw_r64m16_xmm_imm8, VEX, 66, 0F3A, 15, VEX.128.66.0F3A.W1 15 /r ib, VPEXTRW r64/m16| xmm2| imm8, 64b L128 W1 op=r64_or_mem;xmm_reg;imm8
EVEX_Vpextrw_r32m16_xmm_imm8, EVEX, 66, 0F3A, 15, EVEX.128.66.0F3A.W0 15 /r ib, VPEXTRW r32/m16| xmm2| imm8, 16b 32b 64b L128 WIG32 op=r32_or_mem;xmm_reg;imm8 tt=Tuple1_Scalar_2
EVEX_Vpextrw_r64m16_xmm_imm8, EVEX, 66, 0F3A, 15, EVEX.128.66.0F3A.W1 15 /r ib, VPEXTRW r64/m16| xmm2| imm8, 64b L128 W1 op=r64_or_mem;xmm_reg;imm8 tt=Tuple1_Scalar_2
Pextrd_rm32_xmm_imm8, legacy, 66, 0F3A, 16, 66 0F 3A 16 /r ib, PEXTRD r/m32| xmm2| imm8, 16b 32b 64b op=r32_or_mem;xmm_reg;imm8
Pextrq_rm64_xmm_imm8, legacy, 66, 0F3A, 16, 66 REX.W 0F 3A 16 /r ib, PEXTRQ r/m64| xmm2| imm8, 64b o64 op=r64_or_mem;xmm_reg;imm8
VEX_Vpextrd_rm32_xmm_imm8, VEX, 66, 0F3A, 16, VEX.128.66.0F3A.W0 16 /r ib, VPEXTRD r/m32| xmm2| imm8, 16b 32b 64b L128 WIG32 op=r32_or_mem;xmm_reg;imm8
VEX_Vpextrq_rm64_xmm_imm8, VEX, 66, 0F3A, 16, VEX.128.66.0F3A.W1 16 /r ib, VPEXTRQ r/m64| xmm2| imm8, 64b L128 W1 op=r64_or_mem;xmm_reg;imm8
EVEX_Vpextrd_rm32_xmm_imm8, EVEX, 66, 0F3A, 16, EVEX.128.66.0F3A.W0 16 /r ib, VPEXTRD r/m32| xmm2| imm8, 16b 32b 64b L128 WIG32 op=r32_or_mem;xmm_reg;imm8 tt=Tuple1_Scalar_4
EVEX_Vpextrq_rm64_xmm_imm8, EVEX, 66, 0F3A, 16, EVEX.128.66.0F3A.W1 16 /r ib, VPEXTRQ r/m64| xmm2| imm8, 64b L128 W1 op=r64_or_mem;xmm_reg;imm8 tt=Tuple1_Scalar_8
Extractps_rm32_xmm_imm8, legacy, 66, 0F3A, 17, 66 0F 3A 17 /r ib, EXTRACTPS r/m32| xmm1| imm8, 16b 32b 64b op=r32_or_mem;xmm_reg;imm8
Extractps_r64m32_xmm_imm8, legacy, 66, 0F3A, 17, 66 REX.W 0F 3A 17 /r ib, EXTRACTPS r64/m32| xmm1| imm8, 64b o64 op=r64_or_mem;xmm_reg;imm8
VEX_Vextractps_rm32_xmm_imm8, VEX, 66, 0F3A, 17, VEX.128.66.0F3A.W0 17 /r ib, VEXTRACTPS r/m32| xmm1| imm8, 16b 32b 64b L128 WIG32 op=r32_or_mem;xmm_reg;imm8
VEX_Vextractps_r64m32_xmm_imm8, VEX, 66, 0F3A, 17, VEX.128.66.0F3A.W1 17 /r ib, VEXTRACTPS r64/m32| xmm1| imm8, 64b L128 W1 op=r64_or_mem;xmm_reg;imm8
EVEX_Vextractps_rm32_xmm_imm8, EVEX, 66, 0F3A, 17, EVEX.128.66.0F3A.W0 17 /r ib, VEXTRACTPS r/m32| xmm1| imm8, 16b 32b 64b L128 WIG32 op=r32_or_mem;xmm_reg;imm8 tt=Tuple1_Scalar_4
EVEX_Vextractps_r64m32_xmm_imm8, EVEX, 66, 0F3A, 17, EVEX.128.66.0F3A.W1 17 /r ib, VEXTRACTPS r64/m32| xmm1| imm8, 64b L128 W1 op=r64_or_mem;xmm_reg;imm8 tt=Tuple1_Scalar_4
VEX_Vinsertf128_ymm_ymm_xmmm128_imm8, VEX, 66, 0F3A, 18, VEX.256.66.0F3A.W0 18 /r ib, VINSERTF128 ymm1| ymm2| xmm3/m128| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;xmm_or_mem;imm8
EVEX_Vinsertf32x4_ymm_k1z_ymm_xmmm128_imm8, EVEX, 66, 0F3A, 18, EVEX.256.66.0F3A.W0 18 /r ib, VINSERTF32X4 ymm1 {k1}{z}| ymm2| xmm3/m128| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;xmm_or_mem;imm8 tt=Tuple4 k z
EVEX_Vinsertf32x4_zmm_k1z_zmm_xmmm128_imm8, EVEX, 66, 0F3A, 18, EVEX.512.66.0F3A.W0 18 /r ib, VINSERTF32X4 zmm1 {k1}{z}| zmm2| xmm3/m128| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;xmm_or_mem;imm8 tt=Tuple4 k z
EVEX_Vinsertf64x2_ymm_k1z_ymm_xmmm128_imm8, EVEX, 66, 0F3A, 18, EVEX.256.66.0F3A.W1 18 /r ib, VINSERTF64X2 ymm1 {k1}{z}| ymm2| xmm3/m128| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;xmm_or_mem;imm8 tt=Tuple2 k z
EVEX_Vinsertf64x2_zmm_k1z_zmm_xmmm128_imm8, EVEX, 66, 0F3A, 18, EVEX.512.66.0F3A.W1 18 /r ib, VINSERTF64X2 zmm1 {k1}{z}| zmm2| xmm3/m128| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;xmm_or_mem;imm8 tt=Tuple2 k z
VEX_Vextractf128_xmmm128_ymm_imm8, VEX, 66, 0F3A, 19, VEX.256.66.0F3A.W0 19 /r ib, VEXTRACTF128 xmm1/m128| ymm2| imm8, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg;imm8
EVEX_Vextractf32x4_xmmm128_k1z_ymm_imm8, EVEX, 66, 0F3A, 19, EVEX.256.66.0F3A.W0 19 /r ib, VEXTRACTF32X4 xmm1/m128 {k1}{z}| ymm2| imm8, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg;imm8 tt=Tuple4 k z
EVEX_Vextractf32x4_xmmm128_k1z_zmm_imm8, EVEX, 66, 0F3A, 19, EVEX.512.66.0F3A.W0 19 /r ib, VEXTRACTF32X4 xmm1/m128 {k1}{z}| zmm2| imm8, 16b 32b 64b L512 W0 op=xmm_or_mem;zmm_reg;imm8 tt=Tuple4 k z
EVEX_Vextractf64x2_xmmm128_k1z_ymm_imm8, EVEX, 66, 0F3A, 19, EVEX.256.66.0F3A.W1 19 /r ib, VEXTRACTF64X2 xmm1/m128 {k1}{z}| ymm2| imm8, 16b 32b 64b L256 W1 op=xmm_or_mem;ymm_reg;imm8 tt=Tuple2 k z
EVEX_Vextractf64x2_xmmm128_k1z_zmm_imm8, EVEX, 66, 0F3A, 19, EVEX.512.66.0F3A.W1 19 /r ib, VEXTRACTF64X2 xmm1/m128 {k1}{z}| zmm2| imm8, 16b 32b 64b L512 W1 op=xmm_or_mem;zmm_reg;imm8 tt=Tuple2 k z
EVEX_Vinsertf32x8_zmm_k1z_zmm_ymmm256_imm8, EVEX, 66, 0F3A, 1A, EVEX.512.66.0F3A.W0 1A /r ib, VINSERTF32X8 zmm1 {k1}{z}| zmm2| ymm3/m256| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;ymm_or_mem;imm8 tt=Tuple8 k z
EVEX_Vinsertf64x4_zmm_k1z_zmm_ymmm256_imm8, EVEX, 66, 0F3A, 1A, EVEX.512.66.0F3A.W1 1A /r ib, VINSERTF64X4 zmm1 {k1}{z}| zmm2| ymm3/m256| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;ymm_or_mem;imm8 tt=Tuple4 k z
EVEX_Vextractf32x8_ymmm256_k1z_zmm_imm8, EVEX, 66, 0F3A, 1B, EVEX.512.66.0F3A.W0 1B /r ib, VEXTRACTF32X8 ymm1/m256 {k1}{z}| zmm2| imm8, 16b 32b 64b L512 W0 op=ymm_or_mem;zmm_reg;imm8 tt=Tuple8 k z
EVEX_Vextractf64x4_ymmm256_k1z_zmm_imm8, EVEX, 66, 0F3A, 1B, EVEX.512.66.0F3A.W1 1B /r ib, VEXTRACTF64X4 ymm1/m256 {k1}{z}| zmm2| imm8, 16b 32b 64b L512 W1 op=ymm_or_mem;zmm_reg;imm8 tt=Tuple4 k z
VEX_Vcvtps2ph_xmmm64_xmm_imm8, VEX, 66, 0F3A, 1D, VEX.128.66.0F3A.W0 1D /r ib, VCVTPS2PH xmm1/m64| xmm2| imm8, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg;imm8
VEX_Vcvtps2ph_xmmm128_ymm_imm8, VEX, 66, 0F3A, 1D, VEX.256.66.0F3A.W0 1D /r ib, VCVTPS2PH xmm1/m128| ymm2| imm8, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg;imm8
EVEX_Vcvtps2ph_xmmm64_k1z_xmm_imm8, EVEX, 66, 0F3A, 1D, EVEX.128.66.0F3A.W0 1D /r ib, VCVTPS2PH xmm1/m64 {k1}{z}| xmm2| imm8, 16b 32b 64b L128 W0 op=xmm_or_mem;xmm_reg;imm8 tt=Half_Mem_128 k z
EVEX_Vcvtps2ph_xmmm128_k1z_ymm_imm8, EVEX, 66, 0F3A, 1D, EVEX.256.66.0F3A.W0 1D /r ib, VCVTPS2PH xmm1/m128 {k1}{z}| ymm2| imm8, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg;imm8 tt=Half_Mem_256 k z
EVEX_Vcvtps2ph_ymmm256_k1z_zmm_imm8_sae, EVEX, 66, 0F3A, 1D, EVEX.512.66.0F3A.W0 1D /r ib, VCVTPS2PH ymm1/m256 {k1}{z}| zmm2{sae}| imm8, 16b 32b 64b L512 W0 op=ymm_or_mem;zmm_reg;imm8 tt=Half_Mem_512 sae k z
EVEX_Vpcmpud_k_k1_xmm_xmmm128b32_imm8, EVEX, 66, 0F3A, 1E, EVEX.128.66.0F3A.W0 1E /r ib, VPCMPUD k1 {k2}| xmm2| xmm3/m128/m32bcst| imm8, 16b 32b 64b L128 W0 op=k_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k
EVEX_Vpcmpud_k_k1_ymm_ymmm256b32_imm8, EVEX, 66, 0F3A, 1E, EVEX.256.66.0F3A.W0 1E /r ib, VPCMPUD k1 {k2}| ymm2| ymm3/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=k_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k
EVEX_Vpcmpud_k_k1_zmm_zmmm512b32_imm8, EVEX, 66, 0F3A, 1E, EVEX.512.66.0F3A.W0 1E /r ib, VPCMPUD k1 {k2}| zmm2| zmm3/m512/m32bcst| imm8, 16b 32b 64b L512 W0 op=k_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k
EVEX_Vpcmpuq_k_k1_xmm_xmmm128b64_imm8, EVEX, 66, 0F3A, 1E, EVEX.128.66.0F3A.W1 1E /r ib, VPCMPUQ k1 {k2}| xmm2| xmm3/m128/m64bcst| imm8, 16b 32b 64b L128 W1 op=k_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k
EVEX_Vpcmpuq_k_k1_ymm_ymmm256b64_imm8, EVEX, 66, 0F3A, 1E, EVEX.256.66.0F3A.W1 1E /r ib, VPCMPUQ k1 {k2}| ymm2| ymm3/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=k_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k
EVEX_Vpcmpuq_k_k1_zmm_zmmm512b64_imm8, EVEX, 66, 0F3A, 1E, EVEX.512.66.0F3A.W1 1E /r ib, VPCMPUQ k1 {k2}| zmm2| zmm3/m512/m64bcst| imm8, 16b 32b 64b L512 W1 op=k_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k
EVEX_Vpcmpd_k_k1_xmm_xmmm128b32_imm8, EVEX, 66, 0F3A, 1F, EVEX.128.66.0F3A.W0 1F /r ib, VPCMPD k1 {k2}| xmm2| xmm3/m128/m32bcst| imm8, 16b 32b 64b L128 W0 op=k_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k
EVEX_Vpcmpd_k_k1_ymm_ymmm256b32_imm8, EVEX, 66, 0F3A, 1F, EVEX.256.66.0F3A.W0 1F /r ib, VPCMPD k1 {k2}| ymm2| ymm3/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=k_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k
EVEX_Vpcmpd_k_k1_zmm_zmmm512b32_imm8, EVEX, 66, 0F3A, 1F, EVEX.512.66.0F3A.W0 1F /r ib, VPCMPD k1 {k2}| zmm2| zmm3/m512/m32bcst| imm8, 16b 32b 64b L512 W0 op=k_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k
EVEX_Vpcmpq_k_k1_xmm_xmmm128b64_imm8, EVEX, 66, 0F3A, 1F, EVEX.128.66.0F3A.W1 1F /r ib, VPCMPQ k1 {k2}| xmm2| xmm3/m128/m64bcst| imm8, 16b 32b 64b L128 W1 op=k_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k
EVEX_Vpcmpq_k_k1_ymm_ymmm256b64_imm8, EVEX, 66, 0F3A, 1F, EVEX.256.66.0F3A.W1 1F /r ib, VPCMPQ k1 {k2}| ymm2| ymm3/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=k_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k
EVEX_Vpcmpq_k_k1_zmm_zmmm512b64_imm8, EVEX, 66, 0F3A, 1F, EVEX.512.66.0F3A.W1 1F /r ib, VPCMPQ k1 {k2}| zmm2| zmm3/m512/m64bcst| imm8, 16b 32b 64b L512 W1 op=k_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k
Pinsrb_xmm_r32m8_imm8, legacy, 66, 0F3A, 20, 66 0F 3A 20 /r ib, PINSRB xmm1| r32/m8| imm8, 16b 32b 64b op=xmm_reg;r32_or_mem;imm8
Pinsrb_xmm_r64m8_imm8, legacy, 66, 0F3A, 20, 66 REX.W 0F 3A 20 /r ib, PINSRB xmm1| r64/m8| imm8, 64b o64 op=xmm_reg;r64_or_mem;imm8
VEX_Vpinsrb_xmm_xmm_r32m8_imm8, VEX, 66, 0F3A, 20, VEX.128.66.0F3A.W0 20 /r ib, VPINSRB xmm1| xmm2| r32/m8| imm8, 16b 32b 64b L128 WIG32 op=xmm_reg;xmm_vvvv;r32_or_mem;imm8
VEX_Vpinsrb_xmm_xmm_r64m8_imm8, VEX, 66, 0F3A, 20, VEX.128.66.0F3A.W1 20 /r ib, VPINSRB xmm1| xmm2| r64/m8| imm8, 64b L128 W1 op=xmm_reg;xmm_vvvv;r64_or_mem;imm8
EVEX_Vpinsrb_xmm_xmm_r32m8_imm8, EVEX, 66, 0F3A, 20, EVEX.128.66.0F3A.W0 20 /r ib, VPINSRB xmm1| xmm2| r32/m8| imm8, 16b 32b 64b L128 WIG32 op=xmm_reg;xmm_vvvv;r32_or_mem;imm8 tt=Tuple1_Scalar_1
EVEX_Vpinsrb_xmm_xmm_r64m8_imm8, EVEX, 66, 0F3A, 20, EVEX.128.66.0F3A.W1 20 /r ib, VPINSRB xmm1| xmm2| r64/m8| imm8, 64b L128 W1 op=xmm_reg;xmm_vvvv;r64_or_mem;imm8 tt=Tuple1_Scalar_1
Insertps_xmm_xmmm32_imm8, legacy, 66, 0F3A, 21, 66 0F 3A 21 /r ib, INSERTPS xmm1| xmm2/m32| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vinsertps_xmm_xmm_xmmm32_imm8, VEX, 66, 0F3A, 21, VEX.128.66.0F3A.WIG 21 /r ib, VINSERTPS xmm1| xmm2| xmm3/m32| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
EVEX_Vinsertps_xmm_xmm_xmmm32_imm8, EVEX, 66, 0F3A, 21, EVEX.128.66.0F3A.W0 21 /r ib, VINSERTPS xmm1| xmm2| xmm3/m32| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Tuple1_Scalar
Pinsrd_xmm_rm32_imm8, legacy, 66, 0F3A, 22, 66 0F 3A 22 /r ib, PINSRD xmm1| r/m32| imm8, 16b 32b 64b op=xmm_reg;r32_or_mem;imm8
Pinsrq_xmm_rm64_imm8, legacy, 66, 0F3A, 22, 66 REX.W 0F 3A 22 /r ib, PINSRQ xmm1| r/m64| imm8, 64b o64 op=xmm_reg;r64_or_mem;imm8
VEX_Vpinsrd_xmm_xmm_rm32_imm8, VEX, 66, 0F3A, 22, VEX.128.66.0F3A.W0 22 /r ib, VPINSRD xmm1| xmm2| r/m32| imm8, 16b 32b 64b L128 WIG32 op=xmm_reg;xmm_vvvv;r32_or_mem;imm8
VEX_Vpinsrq_xmm_xmm_rm64_imm8, VEX, 66, 0F3A, 22, VEX.128.66.0F3A.W1 22 /r ib, VPINSRQ xmm1| xmm2| r/m64| imm8, 64b L128 W1 op=xmm_reg;xmm_vvvv;r64_or_mem;imm8
EVEX_Vpinsrd_xmm_xmm_rm32_imm8, EVEX, 66, 0F3A, 22, EVEX.128.66.0F3A.W0 22 /r ib, VPINSRD xmm1| xmm2| r/m32| imm8, 16b 32b 64b L128 WIG32 op=xmm_reg;xmm_vvvv;r32_or_mem;imm8 tt=Tuple1_Scalar_4
EVEX_Vpinsrq_xmm_xmm_rm64_imm8, EVEX, 66, 0F3A, 22, EVEX.128.66.0F3A.W1 22 /r ib, VPINSRQ xmm1| xmm2| r/m64| imm8, 64b L128 W1 op=xmm_reg;xmm_vvvv;r64_or_mem;imm8 tt=Tuple1_Scalar_8
EVEX_Vshuff32x4_ymm_k1z_ymm_ymmm256b32_imm8, EVEX, 66, 0F3A, 23, EVEX.256.66.0F3A.W0 23 /r ib, VSHUFF32X4 ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vshuff32x4_zmm_k1z_zmm_zmmm512b32_imm8, EVEX, 66, 0F3A, 23, EVEX.512.66.0F3A.W0 23 /r ib, VSHUFF32X4 zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
EVEX_Vshuff64x2_ymm_k1z_ymm_ymmm256b64_imm8, EVEX, 66, 0F3A, 23, EVEX.256.66.0F3A.W1 23 /r ib, VSHUFF64X2 ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vshuff64x2_zmm_k1z_zmm_zmmm512b64_imm8, EVEX, 66, 0F3A, 23, EVEX.512.66.0F3A.W1 23 /r ib, VSHUFF64X2 zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
EVEX_Vpternlogd_xmm_k1z_xmm_xmmm128b32_imm8, EVEX, 66, 0F3A, 25, EVEX.128.66.0F3A.W0 25 /r ib, VPTERNLOGD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vpternlogd_ymm_k1z_ymm_ymmm256b32_imm8, EVEX, 66, 0F3A, 25, EVEX.256.66.0F3A.W0 25 /r ib, VPTERNLOGD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vpternlogd_zmm_k1z_zmm_zmmm512b32_imm8, EVEX, 66, 0F3A, 25, EVEX.512.66.0F3A.W0 25 /r ib, VPTERNLOGD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
EVEX_Vpternlogq_xmm_k1z_xmm_xmmm128b64_imm8, EVEX, 66, 0F3A, 25, EVEX.128.66.0F3A.W1 25 /r ib, VPTERNLOGQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst| imm8, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vpternlogq_ymm_k1z_ymm_ymmm256b64_imm8, EVEX, 66, 0F3A, 25, EVEX.256.66.0F3A.W1 25 /r ib, VPTERNLOGQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vpternlogq_zmm_k1z_zmm_zmmm512b64_imm8, EVEX, 66, 0F3A, 25, EVEX.512.66.0F3A.W1 25 /r ib, VPTERNLOGQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
EVEX_Vgetmantps_xmm_k1z_xmmm128b32_imm8, EVEX, 66, 0F3A, 26, EVEX.128.66.0F3A.W0 26 /r ib, VGETMANTPS xmm1 {k1}{z}| xmm2/m128/m32bcst| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vgetmantps_ymm_k1z_ymmm256b32_imm8, EVEX, 66, 0F3A, 26, EVEX.256.66.0F3A.W0 26 /r ib, VGETMANTPS ymm1 {k1}{z}| ymm2/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vgetmantps_zmm_k1z_zmmm512b32_imm8_sae, EVEX, 66, 0F3A, 26, EVEX.512.66.0F3A.W0 26 /r ib, VGETMANTPS zmm1 {k1}{z}| zmm2/m512/m32bcst{sae}| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem;imm8 tt=Full_512 b sae k z
EVEX_Vgetmantpd_xmm_k1z_xmmm128b64_imm8, EVEX, 66, 0F3A, 26, EVEX.128.66.0F3A.W1 26 /r ib, VGETMANTPD xmm1 {k1}{z}| xmm2/m128/m64bcst| imm8, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vgetmantpd_ymm_k1z_ymmm256b64_imm8, EVEX, 66, 0F3A, 26, EVEX.256.66.0F3A.W1 26 /r ib, VGETMANTPD ymm1 {k1}{z}| ymm2/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vgetmantpd_zmm_k1z_zmmm512b64_imm8_sae, EVEX, 66, 0F3A, 26, EVEX.512.66.0F3A.W1 26 /r ib, VGETMANTPD zmm1 {k1}{z}| zmm2/m512/m64bcst{sae}| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem;imm8 tt=Full_512 b sae k z
EVEX_Vgetmantss_xmm_k1z_xmm_xmmm32_imm8_sae, EVEX, 66, 0F3A, 27, EVEX.LIG.66.0F3A.W0 27 /r ib, VGETMANTSS xmm1 {k1}{z}| xmm2| xmm3/m32{sae}| imm8, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Tuple1_Scalar sae k z
EVEX_Vgetmantsd_xmm_k1z_xmm_xmmm64_imm8_sae, EVEX, 66, 0F3A, 27, EVEX.LIG.66.0F3A.W1 27 /r ib, VGETMANTSD xmm1 {k1}{z}| xmm2| xmm3/m64{sae}| imm8, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Tuple1_Scalar sae k z
VEX_Kshiftrb_k_k_imm8, VEX, 66, 0F3A, 30, VEX.L0.66.0F3A.W0 30 /r ib, KSHIFTRB k1| k2| imm8, 16b 32b 64b L0 W0 op=k_reg;k_rm;imm8
VEX_Kshiftrw_k_k_imm8, VEX, 66, 0F3A, 30, VEX.L0.66.0F3A.W1 30 /r ib, KSHIFTRW k1| k2| imm8, 16b 32b 64b L0 W1 op=k_reg;k_rm;imm8
VEX_Kshiftrd_k_k_imm8, VEX, 66, 0F3A, 31, VEX.L0.66.0F3A.W0 31 /r ib, KSHIFTRD k1| k2| imm8, 16b 32b 64b L0 W0 op=k_reg;k_rm;imm8
VEX_Kshiftrq_k_k_imm8, VEX, 66, 0F3A, 31, VEX.L0.66.0F3A.W1 31 /r ib, KSHIFTRQ k1| k2| imm8, 16b 32b 64b L0 W1 op=k_reg;k_rm;imm8
VEX_Kshiftlb_k_k_imm8, VEX, 66, 0F3A, 32, VEX.L0.66.0F3A.W0 32 /r ib, KSHIFTLB k1| k2| imm8, 16b 32b 64b L0 W0 op=k_reg;k_rm;imm8
VEX_Kshiftlw_k_k_imm8, VEX, 66, 0F3A, 32, VEX.L0.66.0F3A.W1 32 /r ib, KSHIFTLW k1| k2| imm8, 16b 32b 64b L0 W1 op=k_reg;k_rm;imm8
VEX_Kshiftld_k_k_imm8, VEX, 66, 0F3A, 33, VEX.L0.66.0F3A.W0 33 /r ib, KSHIFTLD k1| k2| imm8, 16b 32b 64b L0 W0 op=k_reg;k_rm;imm8
VEX_Kshiftlq_k_k_imm8, VEX, 66, 0F3A, 33, VEX.L0.66.0F3A.W1 33 /r ib, KSHIFTLQ k1| k2| imm8, 16b 32b 64b L0 W1 op=k_reg;k_rm;imm8
VEX_Vinserti128_ymm_ymm_xmmm128_imm8, VEX, 66, 0F3A, 38, VEX.256.66.0F3A.W0 38 /r ib, VINSERTI128 ymm1| ymm2| xmm3/m128| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;xmm_or_mem;imm8
EVEX_Vinserti32x4_ymm_k1z_ymm_xmmm128_imm8, EVEX, 66, 0F3A, 38, EVEX.256.66.0F3A.W0 38 /r ib, VINSERTI32X4 ymm1 {k1}{z}| ymm2| xmm3/m128| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;xmm_or_mem;imm8 tt=Tuple4 k z
EVEX_Vinserti32x4_zmm_k1z_zmm_xmmm128_imm8, EVEX, 66, 0F3A, 38, EVEX.512.66.0F3A.W0 38 /r ib, VINSERTI32X4 zmm1 {k1}{z}| zmm2| xmm3/m128| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;xmm_or_mem;imm8 tt=Tuple4 k z
EVEX_Vinserti64x2_ymm_k1z_ymm_xmmm128_imm8, EVEX, 66, 0F3A, 38, EVEX.256.66.0F3A.W1 38 /r ib, VINSERTI64X2 ymm1 {k1}{z}| ymm2| xmm3/m128| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;xmm_or_mem;imm8 tt=Tuple2 k z
EVEX_Vinserti64x2_zmm_k1z_zmm_xmmm128_imm8, EVEX, 66, 0F3A, 38, EVEX.512.66.0F3A.W1 38 /r ib, VINSERTI64X2 zmm1 {k1}{z}| zmm2| xmm3/m128| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;xmm_or_mem;imm8 tt=Tuple2 k z
VEX_Vextracti128_xmmm128_ymm_imm8, VEX, 66, 0F3A, 39, VEX.256.66.0F3A.W0 39 /r ib, VEXTRACTI128 xmm1/m128| ymm2| imm8, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg;imm8
EVEX_Vextracti32x4_xmmm128_k1z_ymm_imm8, EVEX, 66, 0F3A, 39, EVEX.256.66.0F3A.W0 39 /r ib, VEXTRACTI32X4 xmm1/m128 {k1}{z}| ymm2| imm8, 16b 32b 64b L256 W0 op=xmm_or_mem;ymm_reg;imm8 tt=Tuple4 k z
EVEX_Vextracti32x4_xmmm128_k1z_zmm_imm8, EVEX, 66, 0F3A, 39, EVEX.512.66.0F3A.W0 39 /r ib, VEXTRACTI32X4 xmm1/m128 {k1}{z}| zmm2| imm8, 16b 32b 64b L512 W0 op=xmm_or_mem;zmm_reg;imm8 tt=Tuple4 k z
EVEX_Vextracti64x2_xmmm128_k1z_ymm_imm8, EVEX, 66, 0F3A, 39, EVEX.256.66.0F3A.W1 39 /r ib, VEXTRACTI64X2 xmm1/m128 {k1}{z}| ymm2| imm8, 16b 32b 64b L256 W1 op=xmm_or_mem;ymm_reg;imm8 tt=Tuple2 k z
EVEX_Vextracti64x2_xmmm128_k1z_zmm_imm8, EVEX, 66, 0F3A, 39, EVEX.512.66.0F3A.W1 39 /r ib, VEXTRACTI64X2 xmm1/m128 {k1}{z}| zmm2| imm8, 16b 32b 64b L512 W1 op=xmm_or_mem;zmm_reg;imm8 tt=Tuple2 k z
EVEX_Vinserti32x8_zmm_k1z_zmm_ymmm256_imm8, EVEX, 66, 0F3A, 3A, EVEX.512.66.0F3A.W0 3A /r ib, VINSERTI32X8 zmm1 {k1}{z}| zmm2| ymm3/m256| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;ymm_or_mem;imm8 tt=Tuple8 k z
EVEX_Vinserti64x4_zmm_k1z_zmm_ymmm256_imm8, EVEX, 66, 0F3A, 3A, EVEX.512.66.0F3A.W1 3A /r ib, VINSERTI64X4 zmm1 {k1}{z}| zmm2| ymm3/m256| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;ymm_or_mem;imm8 tt=Tuple4 k z
EVEX_Vextracti32x8_ymmm256_k1z_zmm_imm8, EVEX, 66, 0F3A, 3B, EVEX.512.66.0F3A.W0 3B /r ib, VEXTRACTI32X8 ymm1/m256 {k1}{z}| zmm2| imm8, 16b 32b 64b L512 W0 op=ymm_or_mem;zmm_reg;imm8 tt=Tuple8 k z
EVEX_Vextracti64x4_ymmm256_k1z_zmm_imm8, EVEX, 66, 0F3A, 3B, EVEX.512.66.0F3A.W1 3B /r ib, VEXTRACTI64X4 ymm1/m256 {k1}{z}| zmm2| imm8, 16b 32b 64b L512 W1 op=ymm_or_mem;zmm_reg;imm8 tt=Tuple4 k z
EVEX_Vpcmpub_k_k1_xmm_xmmm128_imm8, EVEX, 66, 0F3A, 3E, EVEX.128.66.0F3A.W0 3E /r ib, VPCMPUB k1 {k2}| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W0 op=k_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_Mem_128 k
EVEX_Vpcmpub_k_k1_ymm_ymmm256_imm8, EVEX, 66, 0F3A, 3E, EVEX.256.66.0F3A.W0 3E /r ib, VPCMPUB k1 {k2}| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 W0 op=k_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_Mem_256 k
EVEX_Vpcmpub_k_k1_zmm_zmmm512_imm8, EVEX, 66, 0F3A, 3E, EVEX.512.66.0F3A.W0 3E /r ib, VPCMPUB k1 {k2}| zmm2| zmm3/m512| imm8, 16b 32b 64b L512 W0 op=k_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_Mem_512 k
EVEX_Vpcmpuw_k_k1_xmm_xmmm128_imm8, EVEX, 66, 0F3A, 3E, EVEX.128.66.0F3A.W1 3E /r ib, VPCMPUW k1 {k2}| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W1 op=k_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_Mem_128 k
EVEX_Vpcmpuw_k_k1_ymm_ymmm256_imm8, EVEX, 66, 0F3A, 3E, EVEX.256.66.0F3A.W1 3E /r ib, VPCMPUW k1 {k2}| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 W1 op=k_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_Mem_256 k
EVEX_Vpcmpuw_k_k1_zmm_zmmm512_imm8, EVEX, 66, 0F3A, 3E, EVEX.512.66.0F3A.W1 3E /r ib, VPCMPUW k1 {k2}| zmm2| zmm3/m512| imm8, 16b 32b 64b L512 W1 op=k_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_Mem_512 k
EVEX_Vpcmpb_k_k1_xmm_xmmm128_imm8, EVEX, 66, 0F3A, 3F, EVEX.128.66.0F3A.W0 3F /r ib, VPCMPB k1 {k2}| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W0 op=k_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_Mem_128 k
EVEX_Vpcmpb_k_k1_ymm_ymmm256_imm8, EVEX, 66, 0F3A, 3F, EVEX.256.66.0F3A.W0 3F /r ib, VPCMPB k1 {k2}| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 W0 op=k_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_Mem_256 k
EVEX_Vpcmpb_k_k1_zmm_zmmm512_imm8, EVEX, 66, 0F3A, 3F, EVEX.512.66.0F3A.W0 3F /r ib, VPCMPB k1 {k2}| zmm2| zmm3/m512| imm8, 16b 32b 64b L512 W0 op=k_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_Mem_512 k
EVEX_Vpcmpw_k_k1_xmm_xmmm128_imm8, EVEX, 66, 0F3A, 3F, EVEX.128.66.0F3A.W1 3F /r ib, VPCMPW k1 {k2}| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W1 op=k_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_Mem_128 k
EVEX_Vpcmpw_k_k1_ymm_ymmm256_imm8, EVEX, 66, 0F3A, 3F, EVEX.256.66.0F3A.W1 3F /r ib, VPCMPW k1 {k2}| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 W1 op=k_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_Mem_256 k
EVEX_Vpcmpw_k_k1_zmm_zmmm512_imm8, EVEX, 66, 0F3A, 3F, EVEX.512.66.0F3A.W1 3F /r ib, VPCMPW k1 {k2}| zmm2| zmm3/m512| imm8, 16b 32b 64b L512 W1 op=k_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_Mem_512 k
Dpps_xmm_xmmm128_imm8, legacy, 66, 0F3A, 40, 66 0F 3A 40 /r ib, DPPS xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vdpps_xmm_xmm_xmmm128_imm8, VEX, 66, 0F3A, 40, VEX.128.66.0F3A.WIG 40 /r ib, VDPPS xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
VEX_Vdpps_ymm_ymm_ymmm256_imm8, VEX, 66, 0F3A, 40, VEX.256.66.0F3A.WIG 40 /r ib, VDPPS ymm1| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8
Dppd_xmm_xmmm128_imm8, legacy, 66, 0F3A, 41, 66 0F 3A 41 /r ib, DPPD xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vdppd_xmm_xmm_xmmm128_imm8, VEX, 66, 0F3A, 41, VEX.128.66.0F3A.WIG 41 /r ib, VDPPD xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
Mpsadbw_xmm_xmmm128_imm8, legacy, 66, 0F3A, 42, 66 0F 3A 42 /r ib, MPSADBW xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vmpsadbw_xmm_xmm_xmmm128_imm8, VEX, 66, 0F3A, 42, VEX.128.66.0F3A.WIG 42 /r ib, VMPSADBW xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
VEX_Vmpsadbw_ymm_ymm_ymmm256_imm8, VEX, 66, 0F3A, 42, VEX.256.66.0F3A.WIG 42 /r ib, VMPSADBW ymm1| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8
EVEX_Vdbpsadbw_xmm_k1z_xmm_xmmm128_imm8, EVEX, 66, 0F3A, 42, EVEX.128.66.0F3A.W0 42 /r ib, VDBPSADBW xmm1 {k1}{z}| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_Mem_128 k z
EVEX_Vdbpsadbw_ymm_k1z_ymm_ymmm256_imm8, EVEX, 66, 0F3A, 42, EVEX.256.66.0F3A.W0 42 /r ib, VDBPSADBW ymm1 {k1}{z}| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_Mem_256 k z
EVEX_Vdbpsadbw_zmm_k1z_zmm_zmmm512_imm8, EVEX, 66, 0F3A, 42, EVEX.512.66.0F3A.W0 42 /r ib, VDBPSADBW zmm1 {k1}{z}| zmm2| zmm3/m512| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_Mem_512 k z
EVEX_Vshufi32x4_ymm_k1z_ymm_ymmm256b32_imm8, EVEX, 66, 0F3A, 43, EVEX.256.66.0F3A.W0 43 /r ib, VSHUFI32X4 ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vshufi32x4_zmm_k1z_zmm_zmmm512b32_imm8, EVEX, 66, 0F3A, 43, EVEX.512.66.0F3A.W0 43 /r ib, VSHUFI32X4 zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
EVEX_Vshufi64x2_ymm_k1z_ymm_ymmm256b64_imm8, EVEX, 66, 0F3A, 43, EVEX.256.66.0F3A.W1 43 /r ib, VSHUFI64X2 ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vshufi64x2_zmm_k1z_zmm_zmmm512b64_imm8, EVEX, 66, 0F3A, 43, EVEX.512.66.0F3A.W1 43 /r ib, VSHUFI64X2 zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
Pclmulqdq_xmm_xmmm128_imm8, legacy, 66, 0F3A, 44, 66 0F 3A 44 /r ib, PCLMULQDQ xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vpclmulqdq_xmm_xmm_xmmm128_imm8, VEX, 66, 0F3A, 44, VEX.128.66.0F3A.WIG 44 /r ib, VPCLMULQDQ xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
VEX_Vpclmulqdq_ymm_ymm_ymmm256_imm8, VEX, 66, 0F3A, 44, VEX.256.66.0F3A.WIG 44 /r ib, VPCLMULQDQ ymm1| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8
EVEX_Vpclmulqdq_xmm_xmm_xmmm128_imm8, EVEX, 66, 0F3A, 44, EVEX.128.66.0F3A.WIG 44 /r ib, VPCLMULQDQ xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_Mem_128
EVEX_Vpclmulqdq_ymm_ymm_ymmm256_imm8, EVEX, 66, 0F3A, 44, EVEX.256.66.0F3A.WIG 44 /r ib, VPCLMULQDQ ymm1| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 WIG op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_Mem_256
EVEX_Vpclmulqdq_zmm_zmm_zmmm512_imm8, EVEX, 66, 0F3A, 44, EVEX.512.66.0F3A.WIG 44 /r ib, VPCLMULQDQ zmm1| zmm2| zmm3/m512| imm8, 16b 32b 64b L512 WIG op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_Mem_512
VEX_Vperm2i128_ymm_ymm_ymmm256_imm8, VEX, 66, 0F3A, 46, VEX.256.66.0F3A.W0 46 /r ib, VPERM2I128 ymm1| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8
VEX_Vpermil2ps_xmm_xmm_xmmm128_xmm_imm2, VEX, 66, 0F3A, 48, VEX.128.66.0F3A.W0 48 /r /is5, VPERMIL2PS xmm1| xmm2| xmm3/m128| xmm4| imm2, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is5;imm2_m2z
VEX_Vpermil2ps_ymm_ymm_ymmm256_ymm_imm2, VEX, 66, 0F3A, 48, VEX.256.66.0F3A.W0 48 /r /is5, VPERMIL2PS ymm1| ymm2| ymm3/m256| ymm4| imm2, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is5;imm2_m2z
VEX_Vpermil2ps_xmm_xmm_xmm_xmmm128_imm2, VEX, 66, 0F3A, 48, VEX.128.66.0F3A.W1 48 /r /is5, VPERMIL2PS xmm1| xmm2| xmm3| xmm4/m128| imm2, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_is5;xmm_or_mem;imm2_m2z
VEX_Vpermil2ps_ymm_ymm_ymm_ymmm256_imm2, VEX, 66, 0F3A, 48, VEX.256.66.0F3A.W1 48 /r /is5, VPERMIL2PS ymm1| ymm2| ymm3| ymm4/m256| imm2, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_is5;ymm_or_mem;imm2_m2z
VEX_Vpermil2pd_xmm_xmm_xmmm128_xmm_imm2, VEX, 66, 0F3A, 49, VEX.128.66.0F3A.W0 49 /r /is5, VPERMIL2PD xmm1| xmm2| xmm3/m128| xmm4| imm2, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is5;imm2_m2z
VEX_Vpermil2pd_ymm_ymm_ymmm256_ymm_imm2, VEX, 66, 0F3A, 49, VEX.256.66.0F3A.W0 49 /r /is5, VPERMIL2PD ymm1| ymm2| ymm3/m256| ymm4| imm2, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is5;imm2_m2z
VEX_Vpermil2pd_xmm_xmm_xmm_xmmm128_imm2, VEX, 66, 0F3A, 49, VEX.128.66.0F3A.W1 49 /r /is5, VPERMIL2PD xmm1| xmm2| xmm3| xmm4/m128| imm2, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_is5;xmm_or_mem;imm2_m2z
VEX_Vpermil2pd_ymm_ymm_ymm_ymmm256_imm2, VEX, 66, 0F3A, 49, VEX.256.66.0F3A.W1 49 /r /is5, VPERMIL2PD ymm1| ymm2| ymm3| ymm4/m256| imm2, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_is5;ymm_or_mem;imm2_m2z
VEX_Vblendvps_xmm_xmm_xmmm128_xmm, VEX, 66, 0F3A, 4A, VEX.128.66.0F3A.W0 4A /r /is4, VBLENDVPS xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vblendvps_ymm_ymm_ymmm256_ymm, VEX, 66, 0F3A, 4A, VEX.256.66.0F3A.W0 4A /r /is4, VBLENDVPS ymm1| ymm2| ymm3/m256| ymm4, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is4
VEX_Vblendvpd_xmm_xmm_xmmm128_xmm, VEX, 66, 0F3A, 4B, VEX.128.66.0F3A.W0 4B /r /is4, VBLENDVPD xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vblendvpd_ymm_ymm_ymmm256_ymm, VEX, 66, 0F3A, 4B, VEX.256.66.0F3A.W0 4B /r /is4, VBLENDVPD ymm1| ymm2| ymm3/m256| ymm4, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is4
VEX_Vpblendvb_xmm_xmm_xmmm128_xmm, VEX, 66, 0F3A, 4C, VEX.128.66.0F3A.W0 4C /r /is4, VPBLENDVB xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vpblendvb_ymm_ymm_ymmm256_ymm, VEX, 66, 0F3A, 4C, VEX.256.66.0F3A.W0 4C /r /is4, VPBLENDVB ymm1| ymm2| ymm3/m256| ymm4, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is4
EVEX_Vrangeps_xmm_k1z_xmm_xmmm128b32_imm8, EVEX, 66, 0F3A, 50, EVEX.128.66.0F3A.W0 50 /r ib, VRANGEPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vrangeps_ymm_k1z_ymm_ymmm256b32_imm8, EVEX, 66, 0F3A, 50, EVEX.256.66.0F3A.W0 50 /r ib, VRANGEPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vrangeps_zmm_k1z_zmm_zmmm512b32_imm8_sae, EVEX, 66, 0F3A, 50, EVEX.512.66.0F3A.W0 50 /r ib, VRANGEPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{sae}| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b sae k z
EVEX_Vrangepd_xmm_k1z_xmm_xmmm128b64_imm8, EVEX, 66, 0F3A, 50, EVEX.128.66.0F3A.W1 50 /r ib, VRANGEPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst| imm8, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vrangepd_ymm_k1z_ymm_ymmm256b64_imm8, EVEX, 66, 0F3A, 50, EVEX.256.66.0F3A.W1 50 /r ib, VRANGEPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vrangepd_zmm_k1z_zmm_zmmm512b64_imm8_sae, EVEX, 66, 0F3A, 50, EVEX.512.66.0F3A.W1 50 /r ib, VRANGEPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{sae}| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b sae k z
EVEX_Vrangess_xmm_k1z_xmm_xmmm32_imm8_sae, EVEX, 66, 0F3A, 51, EVEX.LIG.66.0F3A.W0 51 /r ib, VRANGESS xmm1 {k1}{z}| xmm2| xmm3/m32{sae}| imm8, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Tuple1_Scalar sae k z
EVEX_Vrangesd_xmm_k1z_xmm_xmmm64_imm8_sae, EVEX, 66, 0F3A, 51, EVEX.LIG.66.0F3A.W1 51 /r ib, VRANGESD xmm1 {k1}{z}| xmm2| xmm3/m64{sae}| imm8, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Tuple1_Scalar sae k z
EVEX_Vfixupimmps_xmm_k1z_xmm_xmmm128b32_imm8, EVEX, 66, 0F3A, 54, EVEX.128.66.0F3A.W0 54 /r ib, VFIXUPIMMPS xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vfixupimmps_ymm_k1z_ymm_ymmm256b32_imm8, EVEX, 66, 0F3A, 54, EVEX.256.66.0F3A.W0 54 /r ib, VFIXUPIMMPS ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vfixupimmps_zmm_k1z_zmm_zmmm512b32_imm8_sae, EVEX, 66, 0F3A, 54, EVEX.512.66.0F3A.W0 54 /r ib, VFIXUPIMMPS zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst{sae}| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b sae k z
EVEX_Vfixupimmpd_xmm_k1z_xmm_xmmm128b64_imm8, EVEX, 66, 0F3A, 54, EVEX.128.66.0F3A.W1 54 /r ib, VFIXUPIMMPD xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst| imm8, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vfixupimmpd_ymm_k1z_ymm_ymmm256b64_imm8, EVEX, 66, 0F3A, 54, EVEX.256.66.0F3A.W1 54 /r ib, VFIXUPIMMPD ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vfixupimmpd_zmm_k1z_zmm_zmmm512b64_imm8_sae, EVEX, 66, 0F3A, 54, EVEX.512.66.0F3A.W1 54 /r ib, VFIXUPIMMPD zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst{sae}| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b sae k z
EVEX_Vfixupimmss_xmm_k1z_xmm_xmmm32_imm8_sae, EVEX, 66, 0F3A, 55, EVEX.LIG.66.0F3A.W0 55 /r ib, VFIXUPIMMSS xmm1 {k1}{z}| xmm2| xmm3/m32{sae}| imm8, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Tuple1_Scalar sae k z
EVEX_Vfixupimmsd_xmm_k1z_xmm_xmmm64_imm8_sae, EVEX, 66, 0F3A, 55, EVEX.LIG.66.0F3A.W1 55 /r ib, VFIXUPIMMSD xmm1 {k1}{z}| xmm2| xmm3/m64{sae}| imm8, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Tuple1_Scalar sae k z
EVEX_Vreduceps_xmm_k1z_xmmm128b32_imm8, EVEX, 66, 0F3A, 56, EVEX.128.66.0F3A.W0 56 /r ib, VREDUCEPS xmm1 {k1}{z}| xmm2/m128/m32bcst| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vreduceps_ymm_k1z_ymmm256b32_imm8, EVEX, 66, 0F3A, 56, EVEX.256.66.0F3A.W0 56 /r ib, VREDUCEPS ymm1 {k1}{z}| ymm2/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vreduceps_zmm_k1z_zmmm512b32_imm8_sae, EVEX, 66, 0F3A, 56, EVEX.512.66.0F3A.W0 56 /r ib, VREDUCEPS zmm1 {k1}{z}| zmm2/m512/m32bcst{sae}| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_or_mem;imm8 tt=Full_512 b sae k z
EVEX_Vreducepd_xmm_k1z_xmmm128b64_imm8, EVEX, 66, 0F3A, 56, EVEX.128.66.0F3A.W1 56 /r ib, VREDUCEPD xmm1 {k1}{z}| xmm2/m128/m64bcst| imm8, 16b 32b 64b L128 W1 op=xmm_reg;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vreducepd_ymm_k1z_ymmm256b64_imm8, EVEX, 66, 0F3A, 56, EVEX.256.66.0F3A.W1 56 /r ib, VREDUCEPD ymm1 {k1}{z}| ymm2/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vreducepd_zmm_k1z_zmmm512b64_imm8_sae, EVEX, 66, 0F3A, 56, EVEX.512.66.0F3A.W1 56 /r ib, VREDUCEPD zmm1 {k1}{z}| zmm2/m512/m64bcst{sae}| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_or_mem;imm8 tt=Full_512 b sae k z
EVEX_Vreducess_xmm_k1z_xmm_xmmm32_imm8_sae, EVEX, 66, 0F3A, 57, EVEX.LIG.66.0F3A.W0 57 /r ib, VREDUCESS xmm1 {k1}{z}| xmm2| xmm3/m32{sae}| imm8, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Tuple1_Scalar sae k z
EVEX_Vreducesd_xmm_k1z_xmm_xmmm64_imm8_sae, EVEX, 66, 0F3A, 57, EVEX.LIG.66.0F3A.W1 57 /r ib, VREDUCESD xmm1 {k1}{z}| xmm2| xmm3/m64{sae}| imm8, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Tuple1_Scalar sae k z
VEX_Vfmaddsubps_xmm_xmm_xmmm128_xmm, VEX, 66, 0F3A, 5C, VEX.128.66.0F3A.W0 5C /r /is4, VFMADDSUBPS xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfmaddsubps_ymm_ymm_ymmm256_ymm, VEX, 66, 0F3A, 5C, VEX.256.66.0F3A.W0 5C /r /is4, VFMADDSUBPS ymm1| ymm2| ymm3/m256| ymm4, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is4
VEX_Vfmaddsubps_xmm_xmm_xmm_xmmm128, VEX, 66, 0F3A, 5C, VEX.128.66.0F3A.W1 5C /r /is4, VFMADDSUBPS xmm1| xmm2| xmm3| xmm4/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfmaddsubps_ymm_ymm_ymm_ymmm256, VEX, 66, 0F3A, 5C, VEX.256.66.0F3A.W1 5C /r /is4, VFMADDSUBPS ymm1| ymm2| ymm3| ymm4/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_is4;ymm_or_mem
VEX_Vfmaddsubpd_xmm_xmm_xmmm128_xmm, VEX, 66, 0F3A, 5D, VEX.128.66.0F3A.W0 5D /r /is4, VFMADDSUBPD xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfmaddsubpd_ymm_ymm_ymmm256_ymm, VEX, 66, 0F3A, 5D, VEX.256.66.0F3A.W0 5D /r /is4, VFMADDSUBPD ymm1| ymm2| ymm3/m256| ymm4, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is4
VEX_Vfmaddsubpd_xmm_xmm_xmm_xmmm128, VEX, 66, 0F3A, 5D, VEX.128.66.0F3A.W1 5D /r /is4, VFMADDSUBPD xmm1| xmm2| xmm3| xmm4/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfmaddsubpd_ymm_ymm_ymm_ymmm256, VEX, 66, 0F3A, 5D, VEX.256.66.0F3A.W1 5D /r /is4, VFMADDSUBPD ymm1| ymm2| ymm3| ymm4/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_is4;ymm_or_mem
VEX_Vfmsubaddps_xmm_xmm_xmmm128_xmm, VEX, 66, 0F3A, 5E, VEX.128.66.0F3A.W0 5E /r /is4, VFMSUBADDPS xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfmsubaddps_ymm_ymm_ymmm256_ymm, VEX, 66, 0F3A, 5E, VEX.256.66.0F3A.W0 5E /r /is4, VFMSUBADDPS ymm1| ymm2| ymm3/m256| ymm4, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is4
VEX_Vfmsubaddps_xmm_xmm_xmm_xmmm128, VEX, 66, 0F3A, 5E, VEX.128.66.0F3A.W1 5E /r /is4, VFMSUBADDPS xmm1| xmm2| xmm3| xmm4/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfmsubaddps_ymm_ymm_ymm_ymmm256, VEX, 66, 0F3A, 5E, VEX.256.66.0F3A.W1 5E /r /is4, VFMSUBADDPS ymm1| ymm2| ymm3| ymm4/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_is4;ymm_or_mem
VEX_Vfmsubaddpd_xmm_xmm_xmmm128_xmm, VEX, 66, 0F3A, 5F, VEX.128.66.0F3A.W0 5F /r /is4, VFMSUBADDPD xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfmsubaddpd_ymm_ymm_ymmm256_ymm, VEX, 66, 0F3A, 5F, VEX.256.66.0F3A.W0 5F /r /is4, VFMSUBADDPD ymm1| ymm2| ymm3/m256| ymm4, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is4
VEX_Vfmsubaddpd_xmm_xmm_xmm_xmmm128, VEX, 66, 0F3A, 5F, VEX.128.66.0F3A.W1 5F /r /is4, VFMSUBADDPD xmm1| xmm2| xmm3| xmm4/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfmsubaddpd_ymm_ymm_ymm_ymmm256, VEX, 66, 0F3A, 5F, VEX.256.66.0F3A.W1 5F /r /is4, VFMSUBADDPD ymm1| ymm2| ymm3| ymm4/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_is4;ymm_or_mem
Pcmpestrm_xmm_xmmm128_imm8, legacy, 66, 0F3A, 60, 66 0F 3A 60 /r ib, PCMPESTRM xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
Pcmpestrm64_xmm_xmmm128_imm8, legacy, 66, 0F3A, 60, 66 REX.W 0F 3A 60 /r ib, PCMPESTRM64 xmm1| xmm2/m128| imm8, 64b o64 op=xmm_reg;xmm_or_mem;imm8
VEX_Vpcmpestrm_xmm_xmmm128_imm8, VEX, 66, 0F3A, 60, VEX.128.66.0F3A.W0 60 /r ib, VPCMPESTRM xmm1| xmm2/m128| imm8, 16b 32b 64b L128 WIG32 op=xmm_reg;xmm_or_mem;imm8
VEX_Vpcmpestrm64_xmm_xmmm128_imm8, VEX, 66, 0F3A, 60, VEX.128.66.0F3A.W1 60 /r ib, VPCMPESTRM64 xmm1| xmm2/m128| imm8, 64b L128 W1 op=xmm_reg;xmm_or_mem;imm8
Pcmpestri_xmm_xmmm128_imm8, legacy, 66, 0F3A, 61, 66 0F 3A 61 /r ib, PCMPESTRI xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
Pcmpestri64_xmm_xmmm128_imm8, legacy, 66, 0F3A, 61, 66 REX.W 0F 3A 61 /r ib, PCMPESTRI64 xmm1| xmm2/m128| imm8, 64b o64 op=xmm_reg;xmm_or_mem;imm8
VEX_Vpcmpestri_xmm_xmmm128_imm8, VEX, 66, 0F3A, 61, VEX.128.66.0F3A.W0 61 /r ib, VPCMPESTRI xmm1| xmm2/m128| imm8, 16b 32b 64b L128 WIG32 op=xmm_reg;xmm_or_mem;imm8
VEX_Vpcmpestri64_xmm_xmmm128_imm8, VEX, 66, 0F3A, 61, VEX.128.66.0F3A.W1 61 /r ib, VPCMPESTRI64 xmm1| xmm2/m128| imm8, 64b L128 W1 op=xmm_reg;xmm_or_mem;imm8
Pcmpistrm_xmm_xmmm128_imm8, legacy, 66, 0F3A, 62, 66 0F 3A 62 /r ib, PCMPISTRM xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vpcmpistrm_xmm_xmmm128_imm8, VEX, 66, 0F3A, 62, VEX.128.66.0F3A.WIG 62 /r ib, VPCMPISTRM xmm1| xmm2/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem;imm8
Pcmpistri_xmm_xmmm128_imm8, legacy, 66, 0F3A, 63, 66 0F 3A 63 /r ib, PCMPISTRI xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vpcmpistri_xmm_xmmm128_imm8, VEX, 66, 0F3A, 63, VEX.128.66.0F3A.WIG 63 /r ib, VPCMPISTRI xmm1| xmm2/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem;imm8
EVEX_Vfpclassps_k_k1_xmmm128b32_imm8, EVEX, 66, 0F3A, 66, EVEX.128.66.0F3A.W0 66 /r ib, VFPCLASSPS k2 {k1}| xmm2/m128/m32bcst| imm8, 16b 32b 64b L128 W0 op=k_reg;xmm_or_mem;imm8 tt=Full_128 b k
EVEX_Vfpclassps_k_k1_ymmm256b32_imm8, EVEX, 66, 0F3A, 66, EVEX.256.66.0F3A.W0 66 /r ib, VFPCLASSPS k2 {k1}| ymm2/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=k_reg;ymm_or_mem;imm8 tt=Full_256 b k
EVEX_Vfpclassps_k_k1_zmmm512b32_imm8, EVEX, 66, 0F3A, 66, EVEX.512.66.0F3A.W0 66 /r ib, VFPCLASSPS k2 {k1}| zmm2/m512/m32bcst| imm8, 16b 32b 64b L512 W0 op=k_reg;zmm_or_mem;imm8 tt=Full_512 b k
EVEX_Vfpclasspd_k_k1_xmmm128b64_imm8, EVEX, 66, 0F3A, 66, EVEX.128.66.0F3A.W1 66 /r ib, VFPCLASSPD k2 {k1}| xmm2/m128/m64bcst| imm8, 16b 32b 64b L128 W1 op=k_reg;xmm_or_mem;imm8 tt=Full_128 b k
EVEX_Vfpclasspd_k_k1_ymmm256b64_imm8, EVEX, 66, 0F3A, 66, EVEX.256.66.0F3A.W1 66 /r ib, VFPCLASSPD k2 {k1}| ymm2/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=k_reg;ymm_or_mem;imm8 tt=Full_256 b k
EVEX_Vfpclasspd_k_k1_zmmm512b64_imm8, EVEX, 66, 0F3A, 66, EVEX.512.66.0F3A.W1 66 /r ib, VFPCLASSPD k2 {k1}| zmm2/m512/m64bcst| imm8, 16b 32b 64b L512 W1 op=k_reg;zmm_or_mem;imm8 tt=Full_512 b k
EVEX_Vfpclassss_k_k1_xmmm32_imm8, EVEX, 66, 0F3A, 67, EVEX.LIG.66.0F3A.W0 67 /r ib, VFPCLASSSS k2 {k1}| xmm2/m32| imm8, 16b 32b 64b LIG W0 op=k_reg;xmm_or_mem;imm8 tt=Tuple1_Scalar k
EVEX_Vfpclasssd_k_k1_xmmm64_imm8, EVEX, 66, 0F3A, 67, EVEX.LIG.66.0F3A.W1 67 /r ib, VFPCLASSSD k2 {k1}| xmm2/m64| imm8, 16b 32b 64b LIG W1 op=k_reg;xmm_or_mem;imm8 tt=Tuple1_Scalar k
VEX_Vfmaddps_xmm_xmm_xmmm128_xmm, VEX, 66, 0F3A, 68, VEX.128.66.0F3A.W0 68 /r /is4, VFMADDPS xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfmaddps_ymm_ymm_ymmm256_ymm, VEX, 66, 0F3A, 68, VEX.256.66.0F3A.W0 68 /r /is4, VFMADDPS ymm1| ymm2| ymm3/m256| ymm4, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is4
VEX_Vfmaddps_xmm_xmm_xmm_xmmm128, VEX, 66, 0F3A, 68, VEX.128.66.0F3A.W1 68 /r /is4, VFMADDPS xmm1| xmm2| xmm3| xmm4/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfmaddps_ymm_ymm_ymm_ymmm256, VEX, 66, 0F3A, 68, VEX.256.66.0F3A.W1 68 /r /is4, VFMADDPS ymm1| ymm2| ymm3| ymm4/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_is4;ymm_or_mem
VEX_Vfmaddpd_xmm_xmm_xmmm128_xmm, VEX, 66, 0F3A, 69, VEX.128.66.0F3A.W0 69 /r /is4, VFMADDPD xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfmaddpd_ymm_ymm_ymmm256_ymm, VEX, 66, 0F3A, 69, VEX.256.66.0F3A.W0 69 /r /is4, VFMADDPD ymm1| ymm2| ymm3/m256| ymm4, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is4
VEX_Vfmaddpd_xmm_xmm_xmm_xmmm128, VEX, 66, 0F3A, 69, VEX.128.66.0F3A.W1 69 /r /is4, VFMADDPD xmm1| xmm2| xmm3| xmm4/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfmaddpd_ymm_ymm_ymm_ymmm256, VEX, 66, 0F3A, 69, VEX.256.66.0F3A.W1 69 /r /is4, VFMADDPD ymm1| ymm2| ymm3| ymm4/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_is4;ymm_or_mem
VEX_Vfmaddss_xmm_xmm_xmmm32_xmm, VEX, 66, 0F3A, 6A, VEX.LIG.66.0F3A.W0 6A /r /is4, VFMADDSS xmm1| xmm2| xmm3/m32| xmm4, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfmaddss_xmm_xmm_xmm_xmmm32, VEX, 66, 0F3A, 6A, VEX.LIG.66.0F3A.W1 6A /r /is4, VFMADDSS xmm1| xmm2| xmm3| xmm4/m32, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfmaddsd_xmm_xmm_xmmm64_xmm, VEX, 66, 0F3A, 6B, VEX.LIG.66.0F3A.W0 6B /r /is4, VFMADDSD xmm1| xmm2| xmm3/m64| xmm4, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfmaddsd_xmm_xmm_xmm_xmmm64, VEX, 66, 0F3A, 6B, VEX.LIG.66.0F3A.W1 6B /r /is4, VFMADDSD xmm1| xmm2| xmm3| xmm4/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfmsubps_xmm_xmm_xmmm128_xmm, VEX, 66, 0F3A, 6C, VEX.128.66.0F3A.W0 6C /r /is4, VFMSUBPS xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfmsubps_ymm_ymm_ymmm256_ymm, VEX, 66, 0F3A, 6C, VEX.256.66.0F3A.W0 6C /r /is4, VFMSUBPS ymm1| ymm2| ymm3/m256| ymm4, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is4
VEX_Vfmsubps_xmm_xmm_xmm_xmmm128, VEX, 66, 0F3A, 6C, VEX.128.66.0F3A.W1 6C /r /is4, VFMSUBPS xmm1| xmm2| xmm3| xmm4/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfmsubps_ymm_ymm_ymm_ymmm256, VEX, 66, 0F3A, 6C, VEX.256.66.0F3A.W1 6C /r /is4, VFMSUBPS ymm1| ymm2| ymm3| ymm4/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_is4;ymm_or_mem
VEX_Vfmsubpd_xmm_xmm_xmmm128_xmm, VEX, 66, 0F3A, 6D, VEX.128.66.0F3A.W0 6D /r /is4, VFMSUBPD xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfmsubpd_ymm_ymm_ymmm256_ymm, VEX, 66, 0F3A, 6D, VEX.256.66.0F3A.W0 6D /r /is4, VFMSUBPD ymm1| ymm2| ymm3/m256| ymm4, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is4
VEX_Vfmsubpd_xmm_xmm_xmm_xmmm128, VEX, 66, 0F3A, 6D, VEX.128.66.0F3A.W1 6D /r /is4, VFMSUBPD xmm1| xmm2| xmm3| xmm4/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfmsubpd_ymm_ymm_ymm_ymmm256, VEX, 66, 0F3A, 6D, VEX.256.66.0F3A.W1 6D /r /is4, VFMSUBPD ymm1| ymm2| ymm3| ymm4/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_is4;ymm_or_mem
VEX_Vfmsubss_xmm_xmm_xmmm32_xmm, VEX, 66, 0F3A, 6E, VEX.LIG.66.0F3A.W0 6E /r /is4, VFMSUBSS xmm1| xmm2| xmm3/m32| xmm4, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfmsubss_xmm_xmm_xmm_xmmm32, VEX, 66, 0F3A, 6E, VEX.LIG.66.0F3A.W1 6E /r /is4, VFMSUBSS xmm1| xmm2| xmm3| xmm4/m32, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfmsubsd_xmm_xmm_xmmm64_xmm, VEX, 66, 0F3A, 6F, VEX.LIG.66.0F3A.W0 6F /r /is4, VFMSUBSD xmm1| xmm2| xmm3/m64| xmm4, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfmsubsd_xmm_xmm_xmm_xmmm64, VEX, 66, 0F3A, 6F, VEX.LIG.66.0F3A.W1 6F /r /is4, VFMSUBSD xmm1| xmm2| xmm3| xmm4/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
EVEX_Vpshldw_xmm_k1z_xmm_xmmm128_imm8, EVEX, 66, 0F3A, 70, EVEX.128.66.0F3A.W1 70 /r ib, VPSHLDW xmm1 {k1}{z}| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_Mem_128 k z
EVEX_Vpshldw_ymm_k1z_ymm_ymmm256_imm8, EVEX, 66, 0F3A, 70, EVEX.256.66.0F3A.W1 70 /r ib, VPSHLDW ymm1 {k1}{z}| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_Mem_256 k z
EVEX_Vpshldw_zmm_k1z_zmm_zmmm512_imm8, EVEX, 66, 0F3A, 70, EVEX.512.66.0F3A.W1 70 /r ib, VPSHLDW zmm1 {k1}{z}| zmm2| zmm3/m512| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_Mem_512 k z
EVEX_Vpshldd_xmm_k1z_xmm_xmmm128b32_imm8, EVEX, 66, 0F3A, 71, EVEX.128.66.0F3A.W0 71 /r ib, VPSHLDD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vpshldd_ymm_k1z_ymm_ymmm256b32_imm8, EVEX, 66, 0F3A, 71, EVEX.256.66.0F3A.W0 71 /r ib, VPSHLDD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vpshldd_zmm_k1z_zmm_zmmm512b32_imm8, EVEX, 66, 0F3A, 71, EVEX.512.66.0F3A.W0 71 /r ib, VPSHLDD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
EVEX_Vpshldq_xmm_k1z_xmm_xmmm128b64_imm8, EVEX, 66, 0F3A, 71, EVEX.128.66.0F3A.W1 71 /r ib, VPSHLDQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst| imm8, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vpshldq_ymm_k1z_ymm_ymmm256b64_imm8, EVEX, 66, 0F3A, 71, EVEX.256.66.0F3A.W1 71 /r ib, VPSHLDQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vpshldq_zmm_k1z_zmm_zmmm512b64_imm8, EVEX, 66, 0F3A, 71, EVEX.512.66.0F3A.W1 71 /r ib, VPSHLDQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
EVEX_Vpshrdw_xmm_k1z_xmm_xmmm128_imm8, EVEX, 66, 0F3A, 72, EVEX.128.66.0F3A.W1 72 /r ib, VPSHRDW xmm1 {k1}{z}| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_Mem_128 k z
EVEX_Vpshrdw_ymm_k1z_ymm_ymmm256_imm8, EVEX, 66, 0F3A, 72, EVEX.256.66.0F3A.W1 72 /r ib, VPSHRDW ymm1 {k1}{z}| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_Mem_256 k z
EVEX_Vpshrdw_zmm_k1z_zmm_zmmm512_imm8, EVEX, 66, 0F3A, 72, EVEX.512.66.0F3A.W1 72 /r ib, VPSHRDW zmm1 {k1}{z}| zmm2| zmm3/m512| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_Mem_512 k z
EVEX_Vpshrdd_xmm_k1z_xmm_xmmm128b32_imm8, EVEX, 66, 0F3A, 73, EVEX.128.66.0F3A.W0 73 /r ib, VPSHRDD xmm1 {k1}{z}| xmm2| xmm3/m128/m32bcst| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vpshrdd_ymm_k1z_ymm_ymmm256b32_imm8, EVEX, 66, 0F3A, 73, EVEX.256.66.0F3A.W0 73 /r ib, VPSHRDD ymm1 {k1}{z}| ymm2| ymm3/m256/m32bcst| imm8, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vpshrdd_zmm_k1z_zmm_zmmm512b32_imm8, EVEX, 66, 0F3A, 73, EVEX.512.66.0F3A.W0 73 /r ib, VPSHRDD zmm1 {k1}{z}| zmm2| zmm3/m512/m32bcst| imm8, 16b 32b 64b L512 W0 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
EVEX_Vpshrdq_xmm_k1z_xmm_xmmm128b64_imm8, EVEX, 66, 0F3A, 73, EVEX.128.66.0F3A.W1 73 /r ib, VPSHRDQ xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst| imm8, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vpshrdq_ymm_k1z_ymm_ymmm256b64_imm8, EVEX, 66, 0F3A, 73, EVEX.256.66.0F3A.W1 73 /r ib, VPSHRDQ ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vpshrdq_zmm_k1z_zmm_zmmm512b64_imm8, EVEX, 66, 0F3A, 73, EVEX.512.66.0F3A.W1 73 /r ib, VPSHRDQ zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
VEX_Vfnmaddps_xmm_xmm_xmmm128_xmm, VEX, 66, 0F3A, 78, VEX.128.66.0F3A.W0 78 /r /is4, VFNMADDPS xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfnmaddps_ymm_ymm_ymmm256_ymm, VEX, 66, 0F3A, 78, VEX.256.66.0F3A.W0 78 /r /is4, VFNMADDPS ymm1| ymm2| ymm3/m256| ymm4, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is4
VEX_Vfnmaddps_xmm_xmm_xmm_xmmm128, VEX, 66, 0F3A, 78, VEX.128.66.0F3A.W1 78 /r /is4, VFNMADDPS xmm1| xmm2| xmm3| xmm4/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfnmaddps_ymm_ymm_ymm_ymmm256, VEX, 66, 0F3A, 78, VEX.256.66.0F3A.W1 78 /r /is4, VFNMADDPS ymm1| ymm2| ymm3| ymm4/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_is4;ymm_or_mem
VEX_Vfnmaddpd_xmm_xmm_xmmm128_xmm, VEX, 66, 0F3A, 79, VEX.128.66.0F3A.W0 79 /r /is4, VFNMADDPD xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfnmaddpd_ymm_ymm_ymmm256_ymm, VEX, 66, 0F3A, 79, VEX.256.66.0F3A.W0 79 /r /is4, VFNMADDPD ymm1| ymm2| ymm3/m256| ymm4, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is4
VEX_Vfnmaddpd_xmm_xmm_xmm_xmmm128, VEX, 66, 0F3A, 79, VEX.128.66.0F3A.W1 79 /r /is4, VFNMADDPD xmm1| xmm2| xmm3| xmm4/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfnmaddpd_ymm_ymm_ymm_ymmm256, VEX, 66, 0F3A, 79, VEX.256.66.0F3A.W1 79 /r /is4, VFNMADDPD ymm1| ymm2| ymm3| ymm4/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_is4;ymm_or_mem
VEX_Vfnmaddss_xmm_xmm_xmmm32_xmm, VEX, 66, 0F3A, 7A, VEX.LIG.66.0F3A.W0 7A /r /is4, VFNMADDSS xmm1| xmm2| xmm3/m32| xmm4, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfnmaddss_xmm_xmm_xmm_xmmm32, VEX, 66, 0F3A, 7A, VEX.LIG.66.0F3A.W1 7A /r /is4, VFNMADDSS xmm1| xmm2| xmm3| xmm4/m32, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfnmaddsd_xmm_xmm_xmmm64_xmm, VEX, 66, 0F3A, 7B, VEX.LIG.66.0F3A.W0 7B /r /is4, VFNMADDSD xmm1| xmm2| xmm3/m64| xmm4, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfnmaddsd_xmm_xmm_xmm_xmmm64, VEX, 66, 0F3A, 7B, VEX.LIG.66.0F3A.W1 7B /r /is4, VFNMADDSD xmm1| xmm2| xmm3| xmm4/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfnmsubps_xmm_xmm_xmmm128_xmm, VEX, 66, 0F3A, 7C, VEX.128.66.0F3A.W0 7C /r /is4, VFNMSUBPS xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfnmsubps_ymm_ymm_ymmm256_ymm, VEX, 66, 0F3A, 7C, VEX.256.66.0F3A.W0 7C /r /is4, VFNMSUBPS ymm1| ymm2| ymm3/m256| ymm4, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is4
VEX_Vfnmsubps_xmm_xmm_xmm_xmmm128, VEX, 66, 0F3A, 7C, VEX.128.66.0F3A.W1 7C /r /is4, VFNMSUBPS xmm1| xmm2| xmm3| xmm4/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfnmsubps_ymm_ymm_ymm_ymmm256, VEX, 66, 0F3A, 7C, VEX.256.66.0F3A.W1 7C /r /is4, VFNMSUBPS ymm1| ymm2| ymm3| ymm4/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_is4;ymm_or_mem
VEX_Vfnmsubpd_xmm_xmm_xmmm128_xmm, VEX, 66, 0F3A, 7D, VEX.128.66.0F3A.W0 7D /r /is4, VFNMSUBPD xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfnmsubpd_ymm_ymm_ymmm256_ymm, VEX, 66, 0F3A, 7D, VEX.256.66.0F3A.W0 7D /r /is4, VFNMSUBPD ymm1| ymm2| ymm3/m256| ymm4, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is4
VEX_Vfnmsubpd_xmm_xmm_xmm_xmmm128, VEX, 66, 0F3A, 7D, VEX.128.66.0F3A.W1 7D /r /is4, VFNMSUBPD xmm1| xmm2| xmm3| xmm4/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfnmsubpd_ymm_ymm_ymm_ymmm256, VEX, 66, 0F3A, 7D, VEX.256.66.0F3A.W1 7D /r /is4, VFNMSUBPD ymm1| ymm2| ymm3| ymm4/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_is4;ymm_or_mem
VEX_Vfnmsubss_xmm_xmm_xmmm32_xmm, VEX, 66, 0F3A, 7E, VEX.LIG.66.0F3A.W0 7E /r /is4, VFNMSUBSS xmm1| xmm2| xmm3/m32| xmm4, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfnmsubss_xmm_xmm_xmm_xmmm32, VEX, 66, 0F3A, 7E, VEX.LIG.66.0F3A.W1 7E /r /is4, VFNMSUBSS xmm1| xmm2| xmm3| xmm4/m32, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
VEX_Vfnmsubsd_xmm_xmm_xmmm64_xmm, VEX, 66, 0F3A, 7F, VEX.LIG.66.0F3A.W0 7F /r /is4, VFNMSUBSD xmm1| xmm2| xmm3/m64| xmm4, 16b 32b 64b LIG W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
VEX_Vfnmsubsd_xmm_xmm_xmm_xmmm64, VEX, 66, 0F3A, 7F, VEX.LIG.66.0F3A.W1 7F /r /is4, VFNMSUBSD xmm1| xmm2| xmm3| xmm4/m64, 16b 32b 64b LIG W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
Sha1rnds4_xmm_xmmm128_imm8, legacy, NP, 0F3A, CC, NP 0F 3A CC /r ib, SHA1RNDS4 xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
Gf2p8affineqb_xmm_xmmm128_imm8, legacy, 66, 0F3A, CE, 66 0F 3A CE /r ib, GF2P8AFFINEQB xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vgf2p8affineqb_xmm_xmm_xmmm128_imm8, VEX, 66, 0F3A, CE, VEX.128.66.0F3A.W1 CE /r ib, VGF2P8AFFINEQB xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
VEX_Vgf2p8affineqb_ymm_ymm_ymmm256_imm8, VEX, 66, 0F3A, CE, VEX.256.66.0F3A.W1 CE /r ib, VGF2P8AFFINEQB ymm1| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8
EVEX_Vgf2p8affineqb_xmm_k1z_xmm_xmmm128b64_imm8, EVEX, 66, 0F3A, CE, EVEX.128.66.0F3A.W1 CE /r ib, VGF2P8AFFINEQB xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst| imm8, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vgf2p8affineqb_ymm_k1z_ymm_ymmm256b64_imm8, EVEX, 66, 0F3A, CE, EVEX.256.66.0F3A.W1 CE /r ib, VGF2P8AFFINEQB ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vgf2p8affineqb_zmm_k1z_zmm_zmmm512b64_imm8, EVEX, 66, 0F3A, CE, EVEX.512.66.0F3A.W1 CE /r ib, VGF2P8AFFINEQB zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
Gf2p8affineinvqb_xmm_xmmm128_imm8, legacy, 66, 0F3A, CF, 66 0F 3A CF /r ib, GF2P8AFFINEINVQB xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vgf2p8affineinvqb_xmm_xmm_xmmm128_imm8, VEX, 66, 0F3A, CF, VEX.128.66.0F3A.W1 CF /r ib, VGF2P8AFFINEINVQB xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
VEX_Vgf2p8affineinvqb_ymm_ymm_ymmm256_imm8, VEX, 66, 0F3A, CF, VEX.256.66.0F3A.W1 CF /r ib, VGF2P8AFFINEINVQB ymm1| ymm2| ymm3/m256| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8
EVEX_Vgf2p8affineinvqb_xmm_k1z_xmm_xmmm128b64_imm8, EVEX, 66, 0F3A, CF, EVEX.128.66.0F3A.W1 CF /r ib, VGF2P8AFFINEINVQB xmm1 {k1}{z}| xmm2| xmm3/m128/m64bcst| imm8, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8 tt=Full_128 b k z
EVEX_Vgf2p8affineinvqb_ymm_k1z_ymm_ymmm256b64_imm8, EVEX, 66, 0F3A, CF, EVEX.256.66.0F3A.W1 CF /r ib, VGF2P8AFFINEINVQB ymm1 {k1}{z}| ymm2| ymm3/m256/m64bcst| imm8, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_or_mem;imm8 tt=Full_256 b k z
EVEX_Vgf2p8affineinvqb_zmm_k1z_zmm_zmmm512b64_imm8, EVEX, 66, 0F3A, CF, EVEX.512.66.0F3A.W1 CF /r ib, VGF2P8AFFINEINVQB zmm1 {k1}{z}| zmm2| zmm3/m512/m64bcst| imm8, 16b 32b 64b L512 W1 op=zmm_reg;zmm_vvvv;zmm_or_mem;imm8 tt=Full_512 b k z
Aeskeygenassist_xmm_xmmm128_imm8, legacy, 66, 0F3A, DF, 66 0F 3A DF /r ib, AESKEYGENASSIST xmm1| xmm2/m128| imm8, 16b 32b 64b op=xmm_reg;xmm_or_mem;imm8
VEX_Vaeskeygenassist_xmm_xmmm128_imm8, VEX, 66, 0F3A, DF, VEX.128.66.0F3A.WIG DF /r ib, VAESKEYGENASSIST xmm1| xmm2/m128| imm8, 16b 32b 64b L128 WIG op=xmm_reg;xmm_or_mem;imm8
VEX_Rorx_r32_rm32_imm8, VEX, F2, 0F3A, F0, VEX.LZ.F2.0F3A.W0 F0 /r ib, RORX r32| r/m32| imm8, 16b 32b 64b L0 WIG32 op=r32_reg;r32_or_mem;imm8
VEX_Rorx_r64_rm64_imm8, VEX, F2, 0F3A, F0, VEX.LZ.F2.0F3A.W1 F0 /r ib, RORX r64| r/m64| imm8, 64b L0 W1 op=r64_reg;r64_or_mem;imm8
XOP_Vpmacssww_xmm_xmm_xmmm128_xmm, XOP, NP, X8, 85, XOP.128.X8.W0 85 /r /is4, VPMACSSWW xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
XOP_Vpmacsswd_xmm_xmm_xmmm128_xmm, XOP, NP, X8, 86, XOP.128.X8.W0 86 /r /is4, VPMACSSWD xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
XOP_Vpmacssdql_xmm_xmm_xmmm128_xmm, XOP, NP, X8, 87, XOP.128.X8.W0 87 /r /is4, VPMACSSDQL xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
XOP_Vpmacssdd_xmm_xmm_xmmm128_xmm, XOP, NP, X8, 8E, XOP.128.X8.W0 8E /r /is4, VPMACSSDD xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
XOP_Vpmacssdqh_xmm_xmm_xmmm128_xmm, XOP, NP, X8, 8F, XOP.128.X8.W0 8F /r /is4, VPMACSSDQH xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
XOP_Vpmacsww_xmm_xmm_xmmm128_xmm, XOP, NP, X8, 95, XOP.128.X8.W0 95 /r /is4, VPMACSWW xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
XOP_Vpmacswd_xmm_xmm_xmmm128_xmm, XOP, NP, X8, 96, XOP.128.X8.W0 96 /r /is4, VPMACSWD xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
XOP_Vpmacsdql_xmm_xmm_xmmm128_xmm, XOP, NP, X8, 97, XOP.128.X8.W0 97 /r /is4, VPMACSDQL xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
XOP_Vpmacsdd_xmm_xmm_xmmm128_xmm, XOP, NP, X8, 9E, XOP.128.X8.W0 9E /r /is4, VPMACSDD xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
XOP_Vpmacsdqh_xmm_xmm_xmmm128_xmm, XOP, NP, X8, 9F, XOP.128.X8.W0 9F /r /is4, VPMACSDQH xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
XOP_Vpcmov_xmm_xmm_xmmm128_xmm, XOP, NP, X8, A2, XOP.128.X8.W0 A2 /r /is4, VPCMOV xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
XOP_Vpcmov_ymm_ymm_ymmm256_ymm, XOP, NP, X8, A2, XOP.256.X8.W0 A2 /r /is4, VPCMOV ymm1| ymm2| ymm3/m256| ymm4, 16b 32b 64b L256 W0 op=ymm_reg;ymm_vvvv;ymm_or_mem;ymm_is4
XOP_Vpcmov_xmm_xmm_xmm_xmmm128, XOP, NP, X8, A2, XOP.128.X8.W1 A2 /r /is4, VPCMOV xmm1| xmm2| xmm3| xmm4/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
XOP_Vpcmov_ymm_ymm_ymm_ymmm256, XOP, NP, X8, A2, XOP.256.X8.W1 A2 /r /is4, VPCMOV ymm1| ymm2| ymm3| ymm4/m256, 16b 32b 64b L256 W1 op=ymm_reg;ymm_vvvv;ymm_is4;ymm_or_mem
XOP_Vpperm_xmm_xmm_xmmm128_xmm, XOP, NP, X8, A3, XOP.128.X8.W0 A3 /r /is4, VPPERM xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
XOP_Vpperm_xmm_xmm_xmm_xmmm128, XOP, NP, X8, A3, XOP.128.X8.W1 A3 /r /is4, VPPERM xmm1| xmm2| xmm3| xmm4/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_is4;xmm_or_mem
XOP_Vpmadcsswd_xmm_xmm_xmmm128_xmm, XOP, NP, X8, A6, XOP.128.X8.W0 A6 /r /is4, VPMADCSSWD xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
XOP_Vpmadcswd_xmm_xmm_xmmm128_xmm, XOP, NP, X8, B6, XOP.128.X8.W0 B6 /r /is4, VPMADCSWD xmm1| xmm2| xmm3/m128| xmm4, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;xmm_is4
XOP_Vprotb_xmm_xmmm128_imm8, XOP, NP, X8, C0, XOP.128.X8.W0 C0 /r ib, VPROTB xmm1| xmm2/m128| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;imm8
XOP_Vprotw_xmm_xmmm128_imm8, XOP, NP, X8, C1, XOP.128.X8.W0 C1 /r ib, VPROTW xmm1| xmm2/m128| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;imm8
XOP_Vprotd_xmm_xmmm128_imm8, XOP, NP, X8, C2, XOP.128.X8.W0 C2 /r ib, VPROTD xmm1| xmm2/m128| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;imm8
XOP_Vprotq_xmm_xmmm128_imm8, XOP, NP, X8, C3, XOP.128.X8.W0 C3 /r ib, VPROTQ xmm1| xmm2/m128| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;imm8
XOP_Vpcomb_xmm_xmm_xmmm128_imm8, XOP, NP, X8, CC, XOP.128.X8.W0 CC /r ib, VPCOMB xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
XOP_Vpcomw_xmm_xmm_xmmm128_imm8, XOP, NP, X8, CD, XOP.128.X8.W0 CD /r ib, VPCOMW xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
XOP_Vpcomd_xmm_xmm_xmmm128_imm8, XOP, NP, X8, CE, XOP.128.X8.W0 CE /r ib, VPCOMD xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
XOP_Vpcomq_xmm_xmm_xmmm128_imm8, XOP, NP, X8, CF, XOP.128.X8.W0 CF /r ib, VPCOMQ xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
XOP_Vpcomub_xmm_xmm_xmmm128_imm8, XOP, NP, X8, EC, XOP.128.X8.W0 EC /r ib, VPCOMUB xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
XOP_Vpcomuw_xmm_xmm_xmmm128_imm8, XOP, NP, X8, ED, XOP.128.X8.W0 ED /r ib, VPCOMUW xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
XOP_Vpcomud_xmm_xmm_xmmm128_imm8, XOP, NP, X8, EE, XOP.128.X8.W0 EE /r ib, VPCOMUD xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
XOP_Vpcomuq_xmm_xmm_xmmm128_imm8, XOP, NP, X8, EF, XOP.128.X8.W0 EF /r ib, VPCOMUQ xmm1| xmm2| xmm3/m128| imm8, 16b 32b 64b L128 W0 op=xmm_reg;xmm_vvvv;xmm_or_mem;imm8
XOP_Blcfill_r32_rm32, XOP, NP, X9, 01, XOP.L0.X9.W0 01 /1, BLCFILL r32| r/m32, g=1 16b 32b 64b L0 WIG32 op=r32_vvvv;r32_or_mem
XOP_Blcfill_r64_rm64, XOP, NP, X9, 01, XOP.L0.X9.W1 01 /1, BLCFILL r64| r/m64, g=1 64b L0 W1 op=r64_vvvv;r64_or_mem
XOP_Blsfill_r32_rm32, XOP, NP, X9, 01, XOP.L0.X9.W0 01 /2, BLSFILL r32| r/m32, g=2 16b 32b 64b L0 WIG32 op=r32_vvvv;r32_or_mem
XOP_Blsfill_r64_rm64, XOP, NP, X9, 01, XOP.L0.X9.W1 01 /2, BLSFILL r64| r/m64, g=2 64b L0 W1 op=r64_vvvv;r64_or_mem
XOP_Blcs_r32_rm32, XOP, NP, X9, 01, XOP.L0.X9.W0 01 /3, BLCS r32| r/m32, g=3 16b 32b 64b L0 WIG32 op=r32_vvvv;r32_or_mem
XOP_Blcs_r64_rm64, XOP, NP, X9, 01, XOP.L0.X9.W1 01 /3, BLCS r64| r/m64, g=3 64b L0 W1 op=r64_vvvv;r64_or_mem
XOP_Tzmsk_r32_rm32, XOP, NP, X9, 01, XOP.L0.X9.W0 01 /4, TZMSK r32| r/m32, g=4 16b 32b 64b L0 WIG32 op=r32_vvvv;r32_or_mem
XOP_Tzmsk_r64_rm64, XOP, NP, X9, 01, XOP.L0.X9.W1 01 /4, TZMSK r64| r/m64, g=4 64b L0 W1 op=r64_vvvv;r64_or_mem
XOP_Blcic_r32_rm32, XOP, NP, X9, 01, XOP.L0.X9.W0 01 /5, BLCIC r32| r/m32, g=5 16b 32b 64b L0 WIG32 op=r32_vvvv;r32_or_mem
XOP_Blcic_r64_rm64, XOP, NP, X9, 01, XOP.L0.X9.W1 01 /5, BLCIC r64| r/m64, g=5 64b L0 W1 op=r64_vvvv;r64_or_mem
XOP_Blsic_r32_rm32, XOP, NP, X9, 01, XOP.L0.X9.W0 01 /6, BLSIC r32| r/m32, g=6 16b 32b 64b L0 WIG32 op=r32_vvvv;r32_or_mem
XOP_Blsic_r64_rm64, XOP, NP, X9, 01, XOP.L0.X9.W1 01 /6, BLSIC r64| r/m64, g=6 64b L0 W1 op=r64_vvvv;r64_or_mem
XOP_T1mskc_r32_rm32, XOP, NP, X9, 01, XOP.L0.X9.W0 01 /7, T1MSKC r32| r/m32, g=7 16b 32b 64b L0 WIG32 op=r32_vvvv;r32_or_mem
XOP_T1mskc_r64_rm64, XOP, NP, X9, 01, XOP.L0.X9.W1 01 /7, T1MSKC r64| r/m64, g=7 64b L0 W1 op=r64_vvvv;r64_or_mem
XOP_Blcmsk_r32_rm32, XOP, NP, X9, 02, XOP.L0.X9.W0 02 /1, BLCMSK r32| r/m32, g=1 16b 32b 64b L0 WIG32 op=r32_vvvv;r32_or_mem
XOP_Blcmsk_r64_rm64, XOP, NP, X9, 02, XOP.L0.X9.W1 02 /1, BLCMSK r64| r/m64, g=1 64b L0 W1 op=r64_vvvv;r64_or_mem
XOP_Blci_r32_rm32, XOP, NP, X9, 02, XOP.L0.X9.W0 02 /6, BLCI r32| r/m32, g=6 16b 32b 64b L0 WIG32 op=r32_vvvv;r32_or_mem
XOP_Blci_r64_rm64, XOP, NP, X9, 02, XOP.L0.X9.W1 02 /6, BLCI r64| r/m64, g=6 64b L0 W1 op=r64_vvvv;r64_or_mem
XOP_Llwpcb_r32, XOP, NP, X9, 12, XOP.L0.X9.W0 12 /0, LLWPCB r32, g=0 16b 32b 64b L0 WIG32 op=r32_rm
XOP_Llwpcb_r64, XOP, NP, X9, 12, XOP.L0.X9.W1 12 /0, LLWPCB r64, g=0 64b L0 W1 op=r64_rm
XOP_Slwpcb_r32, XOP, NP, X9, 12, XOP.L0.X9.W0 12 /1, SLWPCB r32, g=1 16b 32b 64b L0 WIG32 op=r32_rm
XOP_Slwpcb_r64, XOP, NP, X9, 12, XOP.L0.X9.W1 12 /1, SLWPCB r64, g=1 64b L0 W1 op=r64_rm
XOP_Vfrczps_xmm_xmmm128, XOP, NP, X9, 80, XOP.128.X9.W0 80 /r, VFRCZPS xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vfrczps_ymm_ymmm256, XOP, NP, X9, 80, XOP.256.X9.W0 80 /r, VFRCZPS ymm1| ymm2/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem
XOP_Vfrczpd_xmm_xmmm128, XOP, NP, X9, 81, XOP.128.X9.W0 81 /r, VFRCZPD xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vfrczpd_ymm_ymmm256, XOP, NP, X9, 81, XOP.256.X9.W0 81 /r, VFRCZPD ymm1| ymm2/m256, 16b 32b 64b L256 W0 op=ymm_reg;ymm_or_mem
XOP_Vfrczss_xmm_xmmm32, XOP, NP, X9, 82, XOP.128.X9.W0 82 /r, VFRCZSS xmm1| xmm2/m32, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vfrczsd_xmm_xmmm64, XOP, NP, X9, 83, XOP.128.X9.W0 83 /r, VFRCZSD xmm1| xmm2/m64, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vprotb_xmm_xmmm128_xmm, XOP, NP, X9, 90, XOP.128.X9.W0 90 /r, VPROTB xmm1| xmm2/m128| xmm3, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;xmm_vvvv
XOP_Vprotb_xmm_xmm_xmmm128, XOP, NP, X9, 90, XOP.128.X9.W1 90 /r, VPROTB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
XOP_Vprotw_xmm_xmmm128_xmm, XOP, NP, X9, 91, XOP.128.X9.W0 91 /r, VPROTW xmm1| xmm2/m128| xmm3, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;xmm_vvvv
XOP_Vprotw_xmm_xmm_xmmm128, XOP, NP, X9, 91, XOP.128.X9.W1 91 /r, VPROTW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
XOP_Vprotd_xmm_xmmm128_xmm, XOP, NP, X9, 92, XOP.128.X9.W0 92 /r, VPROTD xmm1| xmm2/m128| xmm3, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;xmm_vvvv
XOP_Vprotd_xmm_xmm_xmmm128, XOP, NP, X9, 92, XOP.128.X9.W1 92 /r, VPROTD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
XOP_Vprotq_xmm_xmmm128_xmm, XOP, NP, X9, 93, XOP.128.X9.W0 93 /r, VPROTQ xmm1| xmm2/m128| xmm3, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;xmm_vvvv
XOP_Vprotq_xmm_xmm_xmmm128, XOP, NP, X9, 93, XOP.128.X9.W1 93 /r, VPROTQ xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
XOP_Vpshlb_xmm_xmmm128_xmm, XOP, NP, X9, 94, XOP.128.X9.W0 94 /r, VPSHLB xmm1| xmm2/m128| xmm3, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;xmm_vvvv
XOP_Vpshlb_xmm_xmm_xmmm128, XOP, NP, X9, 94, XOP.128.X9.W1 94 /r, VPSHLB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
XOP_Vpshlw_xmm_xmmm128_xmm, XOP, NP, X9, 95, XOP.128.X9.W0 95 /r, VPSHLW xmm1| xmm2/m128| xmm3, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;xmm_vvvv
XOP_Vpshlw_xmm_xmm_xmmm128, XOP, NP, X9, 95, XOP.128.X9.W1 95 /r, VPSHLW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
XOP_Vpshld_xmm_xmmm128_xmm, XOP, NP, X9, 96, XOP.128.X9.W0 96 /r, VPSHLD xmm1| xmm2/m128| xmm3, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;xmm_vvvv
XOP_Vpshld_xmm_xmm_xmmm128, XOP, NP, X9, 96, XOP.128.X9.W1 96 /r, VPSHLD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
XOP_Vpshlq_xmm_xmmm128_xmm, XOP, NP, X9, 97, XOP.128.X9.W0 97 /r, VPSHLQ xmm1| xmm2/m128| xmm3, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;xmm_vvvv
XOP_Vpshlq_xmm_xmm_xmmm128, XOP, NP, X9, 97, XOP.128.X9.W1 97 /r, VPSHLQ xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
XOP_Vpshab_xmm_xmmm128_xmm, XOP, NP, X9, 98, XOP.128.X9.W0 98 /r, VPSHAB xmm1| xmm2/m128| xmm3, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;xmm_vvvv
XOP_Vpshab_xmm_xmm_xmmm128, XOP, NP, X9, 98, XOP.128.X9.W1 98 /r, VPSHAB xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
XOP_Vpshaw_xmm_xmmm128_xmm, XOP, NP, X9, 99, XOP.128.X9.W0 99 /r, VPSHAW xmm1| xmm2/m128| xmm3, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;xmm_vvvv
XOP_Vpshaw_xmm_xmm_xmmm128, XOP, NP, X9, 99, XOP.128.X9.W1 99 /r, VPSHAW xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
XOP_Vpshad_xmm_xmmm128_xmm, XOP, NP, X9, 9A, XOP.128.X9.W0 9A /r, VPSHAD xmm1| xmm2/m128| xmm3, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;xmm_vvvv
XOP_Vpshad_xmm_xmm_xmmm128, XOP, NP, X9, 9A, XOP.128.X9.W1 9A /r, VPSHAD xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
XOP_Vpshaq_xmm_xmmm128_xmm, XOP, NP, X9, 9B, XOP.128.X9.W0 9B /r, VPSHAQ xmm1| xmm2/m128| xmm3, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem;xmm_vvvv
XOP_Vpshaq_xmm_xmm_xmmm128, XOP, NP, X9, 9B, XOP.128.X9.W1 9B /r, VPSHAQ xmm1| xmm2| xmm3/m128, 16b 32b 64b L128 W1 op=xmm_reg;xmm_vvvv;xmm_or_mem
XOP_Vphaddbw_xmm_xmmm128, XOP, NP, X9, C1, XOP.128.X9.W0 C1 /r, VPHADDBW xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vphaddbd_xmm_xmmm128, XOP, NP, X9, C2, XOP.128.X9.W0 C2 /r, VPHADDBD xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vphaddbq_xmm_xmmm128, XOP, NP, X9, C3, XOP.128.X9.W0 C3 /r, VPHADDBQ xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vphaddwd_xmm_xmmm128, XOP, NP, X9, C6, XOP.128.X9.W0 C6 /r, VPHADDWD xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vphaddwq_xmm_xmmm128, XOP, NP, X9, C7, XOP.128.X9.W0 C7 /r, VPHADDWQ xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vphadddq_xmm_xmmm128, XOP, NP, X9, CB, XOP.128.X9.W0 CB /r, VPHADDDQ xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vphaddubw_xmm_xmmm128, XOP, NP, X9, D1, XOP.128.X9.W0 D1 /r, VPHADDUBW xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vphaddubd_xmm_xmmm128, XOP, NP, X9, D2, XOP.128.X9.W0 D2 /r, VPHADDUBD xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vphaddubq_xmm_xmmm128, XOP, NP, X9, D3, XOP.128.X9.W0 D3 /r, VPHADDUBQ xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vphadduwd_xmm_xmmm128, XOP, NP, X9, D6, XOP.128.X9.W0 D6 /r, VPHADDUWD xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vphadduwq_xmm_xmmm128, XOP, NP, X9, D7, XOP.128.X9.W0 D7 /r, VPHADDUWQ xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vphaddudq_xmm_xmmm128, XOP, NP, X9, DB, XOP.128.X9.W0 DB /r, VPHADDUDQ xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vphsubbw_xmm_xmmm128, XOP, NP, X9, E1, XOP.128.X9.W0 E1 /r, VPHSUBBW xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vphsubwd_xmm_xmmm128, XOP, NP, X9, E2, XOP.128.X9.W0 E2 /r, VPHSUBWD xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Vphsubdq_xmm_xmmm128, XOP, NP, X9, E3, XOP.128.X9.W0 E3 /r, VPHSUBDQ xmm1| xmm2/m128, 16b 32b 64b L128 W0 op=xmm_reg;xmm_or_mem
XOP_Bextr_r32_rm32_imm32, XOP, NP, XA, 10, XOP.L0.XA.W0 10 /r id, BEXTR r32| r/m32| imm32, 16b 32b 64b L0 WIG32 op=r32_reg;r32_or_mem;imm32
XOP_Bextr_r64_rm64_imm32, XOP, NP, XA, 10, XOP.L0.XA.W1 10 /r id, BEXTR r64| r/m64| imm32, 64b L0 W1 op=r64_reg;r64_or_mem;imm32
XOP_Lwpins_r32_rm32_imm32, XOP, NP, XA, 12, XOP.L0.XA.W0 12 /0 id, LWPINS r32| r/m32| imm32, g=0 16b 32b 64b L0 WIG32 op=r32_vvvv;r32_or_mem;imm32
XOP_Lwpins_r64_rm32_imm32, XOP, NP, XA, 12, XOP.L0.XA.W1 12 /0 id, LWPINS r64| r/m32| imm32, g=0 64b L0 W1 op=r64_vvvv;r32_or_mem;imm32
XOP_Lwpval_r32_rm32_imm32, XOP, NP, XA, 12, XOP.L0.XA.W0 12 /1 id, LWPVAL r32| r/m32| imm32, g=1 16b 32b 64b L0 WIG32 op=r32_vvvv;r32_or_mem;imm32
XOP_Lwpval_r64_rm32_imm32, XOP, NP, XA, 12, XOP.L0.XA.W1 12 /1 id, LWPVAL r64| r/m32| imm32, g=1 64b L0 W1 op=r64_vvvv;r32_or_mem;imm32
D3NOW_Pi2fw_mm_mmm64, 3DNow!, , 0F, 0C, 0F 0F /r 0C, PI2FW mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pi2fd_mm_mmm64, 3DNow!, , 0F, 0D, 0F 0F /r 0D, PI2FD mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pf2iw_mm_mmm64, 3DNow!, , 0F, 1C, 0F 0F /r 1C, PF2IW mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pf2id_mm_mmm64, 3DNow!, , 0F, 1D, 0F 0F /r 1D, PF2ID mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfrcpv_mm_mmm64, 3DNow!, , 0F, 86, 0F 0F /r 86, PFRCPV mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfrsqrtv_mm_mmm64, 3DNow!, , 0F, 87, 0F 0F /r 87, PFRSQRTV mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfnacc_mm_mmm64, 3DNow!, , 0F, 8A, 0F 0F /r 8A, PFNACC mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfpnacc_mm_mmm64, 3DNow!, , 0F, 8E, 0F 0F /r 8E, PFPNACC mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfcmpge_mm_mmm64, 3DNow!, , 0F, 90, 0F 0F /r 90, PFCMPGE mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfmin_mm_mmm64, 3DNow!, , 0F, 94, 0F 0F /r 94, PFMIN mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfrcp_mm_mmm64, 3DNow!, , 0F, 96, 0F 0F /r 96, PFRCP mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfrsqrt_mm_mmm64, 3DNow!, , 0F, 97, 0F 0F /r 97, PFRSQRT mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfsub_mm_mmm64, 3DNow!, , 0F, 9A, 0F 0F /r 9A, PFSUB mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfadd_mm_mmm64, 3DNow!, , 0F, 9E, 0F 0F /r 9E, PFADD mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfcmpgt_mm_mmm64, 3DNow!, , 0F, A0, 0F 0F /r A0, PFCMPGT mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfmax_mm_mmm64, 3DNow!, , 0F, A4, 0F 0F /r A4, PFMAX mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfrcpit1_mm_mmm64, 3DNow!, , 0F, A6, 0F 0F /r A6, PFRCPIT1 mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfrsqit1_mm_mmm64, 3DNow!, , 0F, A7, 0F 0F /r A7, PFRSQIT1 mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfsubr_mm_mmm64, 3DNow!, , 0F, AA, 0F 0F /r AA, PFSUBR mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfacc_mm_mmm64, 3DNow!, , 0F, AE, 0F 0F /r AE, PFACC mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfcmpeq_mm_mmm64, 3DNow!, , 0F, B0, 0F 0F /r B0, PFCMPEQ mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfmul_mm_mmm64, 3DNow!, , 0F, B4, 0F 0F /r B4, PFMUL mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pfrcpit2_mm_mmm64, 3DNow!, , 0F, B6, 0F 0F /r B6, PFRCPIT2 mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pmulhrw_mm_mmm64, 3DNow!, , 0F, B7, 0F 0F /r B7, PMULHRW mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pswapd_mm_mmm64, 3DNow!, , 0F, BB, 0F 0F /r BB, PSWAPD mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
D3NOW_Pavgusb_mm_mmm64, 3DNow!, , 0F, BF, 0F 0F /r BF, PAVGUSB mm1| mm2/m64, 16b 32b 64b op=mm_reg;mm_or_mem
Rmpadjust, legacy, F3, 0F, 01FE, F3 0F 01 FE, RMPADJUST, 64b
Rmpupdate, legacy, F2, 0F, 01FE, F2 0F 01 FE, RMPUPDATE, 64b
Psmash, legacy, F3, 0F, 01FF, F3 0F 01 FF, PSMASH, 64b
Pvalidatew, legacy, F2, 0F, 01FF, a16 F2 0F 01 FF, PVALIDATE, 16b 32b a16
Pvalidated, legacy, F2, 0F, 01FF, a32 F2 0F 01 FF, PVALIDATE, 16b 32b 64b a32
Pvalidateq, legacy, F2, 0F, 01FF, F2 0F 01 FF, PVALIDATE, 64b
Serialize, legacy, NP, 0F, 01E8, NP 0F 01 E8, SERIALIZE, 16b 32b 64b
Xsusldtrk, legacy, F2, 0F, 01E8, F2 0F 01 E8, XSUSLDTRK, 16b 32b 64b
Xresldtrk, legacy, F2, 0F, 01E9, F2 0F 01 E9, XRESLDTRK, 16b 32b 64b
Invlpgbw, legacy, NP, 0F, 01FE, a16 NP 0F 01 FE, INVLPGB, 16b 32b a16
Invlpgbd, legacy, NP, 0F, 01FE, a32 NP 0F 01 FE, INVLPGB, 16b 32b 64b a32
Invlpgbq, legacy, NP, 0F, 01FE, NP 0F 01 FE, INVLPGB, 64b
Tlbsync, legacy, NP, 0F, 01FF, NP 0F 01 FF, TLBSYNC, 16b 32b 64b
